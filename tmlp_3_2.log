nohup: ignoring input
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_2
----------------------



epoch 1, loss 0.6934, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693212).  Saving model ...
Validation loss decreased (0.693212 --> 0.693113).  Saving model ...
Validation loss decreased (0.693113 --> 0.693051).  Saving model ...
Validation loss decreased (0.693051 --> 0.692990).  Saving model ...
Validation loss decreased (0.692990 --> 0.692914).  Saving model ...
Validation loss decreased (0.692914 --> 0.692819).  Saving model ...
Validation loss decreased (0.692819 --> 0.692713).  Saving model ...
Validation loss decreased (0.692713 --> 0.692597).  Saving model ...
Validation loss decreased (0.692597 --> 0.692476).  Saving model ...
Validation loss decreased (0.692476 --> 0.692351).  Saving model ...
Validation loss decreased (0.692351 --> 0.692219).  Saving model ...
Validation loss decreased (0.692219 --> 0.692072).  Saving model ...
Validation loss decreased (0.692072 --> 0.691912).  Saving model ...
Validation loss decreased (0.691912 --> 0.691739).  Saving model ...
Validation loss decreased (0.691739 --> 0.691549).  Saving model ...
Validation loss decreased (0.691549 --> 0.691344).  Saving model ...
Validation loss decreased (0.691344 --> 0.691122).  Saving model ...
Validation loss decreased (0.691122 --> 0.690871).  Saving model ...
Validation loss decreased (0.690871 --> 0.690602).  Saving model ...
Validation loss decreased (0.690602 --> 0.690316).  Saving model ...
Validation loss decreased (0.690316 --> 0.690004).  Saving model ...
Validation loss decreased (0.690004 --> 0.689673).  Saving model ...
Validation loss decreased (0.689673 --> 0.689319).  Saving model ...
Validation loss decreased (0.689319 --> 0.688944).  Saving model ...
Validation loss decreased (0.688944 --> 0.688541).  Saving model ...
Validation loss decreased (0.688541 --> 0.688100).  Saving model ...
Validation loss decreased (0.688100 --> 0.687644).  Saving model ...
Validation loss decreased (0.687644 --> 0.687155).  Saving model ...
Validation loss decreased (0.687155 --> 0.686651).  Saving model ...
Validation loss decreased (0.686651 --> 0.686125).  Saving model ...
Validation loss decreased (0.686125 --> 0.685571).  Saving model ...
Validation loss decreased (0.685571 --> 0.684993).  Saving model ...
Validation loss decreased (0.684993 --> 0.684380).  Saving model ...
Validation loss decreased (0.684380 --> 0.683733).  Saving model ...
Validation loss decreased (0.683733 --> 0.683045).  Saving model ...
Validation loss decreased (0.683045 --> 0.682321).  Saving model ...
Validation loss decreased (0.682321 --> 0.681577).  Saving model ...
Validation loss decreased (0.681577 --> 0.680828).  Saving model ...
Validation loss decreased (0.680828 --> 0.680061).  Saving model ...
Validation loss decreased (0.680061 --> 0.679282).  Saving model ...
Validation loss decreased (0.679282 --> 0.678473).  Saving model ...
Validation loss decreased (0.678473 --> 0.677640).  Saving model ...
Validation loss decreased (0.677640 --> 0.676814).  Saving model ...
Validation loss decreased (0.676814 --> 0.675923).  Saving model ...
Validation loss decreased (0.675923 --> 0.675009).  Saving model ...
Validation loss decreased (0.675009 --> 0.674053).  Saving model ...
Validation loss decreased (0.674053 --> 0.673077).  Saving model ...
Validation loss decreased (0.673077 --> 0.672077).  Saving model ...
Validation loss decreased (0.672077 --> 0.671055).  Saving model ...
Validation loss decreased (0.671055 --> 0.670017).  Saving model ...
Validation loss decreased (0.670017 --> 0.668941).  Saving model ...
Validation loss decreased (0.668941 --> 0.667847).  Saving model ...
Validation loss decreased (0.667847 --> 0.666725).  Saving model ...
Validation loss decreased (0.666725 --> 0.665570).  Saving model ...
Validation loss decreased (0.665570 --> 0.664377).  Saving model ...
Validation loss decreased (0.664377 --> 0.663167).  Saving model ...
Validation loss decreased (0.663167 --> 0.661922).  Saving model ...
Validation loss decreased (0.661922 --> 0.660651).  Saving model ...
Validation loss decreased (0.660651 --> 0.659383).  Saving model ...
Validation loss decreased (0.659383 --> 0.658128).  Saving model ...
Validation loss decreased (0.658128 --> 0.656894).  Saving model ...
Validation loss decreased (0.656894 --> 0.655623).  Saving model ...
Validation loss decreased (0.655623 --> 0.654412).  Saving model ...
Validation loss decreased (0.654412 --> 0.653178).  Saving model ...
Validation loss decreased (0.653178 --> 0.651894).  Saving model ...
Validation loss decreased (0.651894 --> 0.650596).  Saving model ...
Validation loss decreased (0.650596 --> 0.649365).  Saving model ...
Validation loss decreased (0.649365 --> 0.648099).  Saving model ...
Validation loss decreased (0.648099 --> 0.646821).  Saving model ...
Validation loss decreased (0.646821 --> 0.645534).  Saving model ...
Validation loss decreased (0.645534 --> 0.644158).  Saving model ...
Validation loss decreased (0.644158 --> 0.642765).  Saving model ...
Validation loss decreased (0.642765 --> 0.641376).  Saving model ...
Validation loss decreased (0.641376 --> 0.639953).  Saving model ...
Validation loss decreased (0.639953 --> 0.638564).  Saving model ...
Validation loss decreased (0.638564 --> 0.637114).  Saving model ...
Validation loss decreased (0.637114 --> 0.635658).  Saving model ...
Validation loss decreased (0.635658 --> 0.634214).  Saving model ...
Validation loss decreased (0.634214 --> 0.632778).  Saving model ...
Validation loss decreased (0.632778 --> 0.631330).  Saving model ...
Validation loss decreased (0.631330 --> 0.629819).  Saving model ...
Validation loss decreased (0.629819 --> 0.628250).  Saving model ...
Validation loss decreased (0.628250 --> 0.626629).  Saving model ...
Validation loss decreased (0.626629 --> 0.625013).  Saving model ...
Validation loss decreased (0.625013 --> 0.623378).  Saving model ...
Validation loss decreased (0.623378 --> 0.621772).  Saving model ...
Validation loss decreased (0.621772 --> 0.620098).  Saving model ...
Validation loss decreased (0.620098 --> 0.618479).  Saving model ...
Validation loss decreased (0.618479 --> 0.616897).  Saving model ...
Validation loss decreased (0.616897 --> 0.615362).  Saving model ...
Validation loss decreased (0.615362 --> 0.613847).  Saving model ...
Validation loss decreased (0.613847 --> 0.612290).  Saving model ...
Validation loss decreased (0.612290 --> 0.610748).  Saving model ...
Validation loss decreased (0.610748 --> 0.609284).  Saving model ...
Validation loss decreased (0.609284 --> 0.607793).  Saving model ...
Validation loss decreased (0.607793 --> 0.606252).  Saving model ...
Validation loss decreased (0.606252 --> 0.604638).  Saving model ...
Validation loss decreased (0.604638 --> 0.603121).  Saving model ...
Validation loss decreased (0.603121 --> 0.601727).  Saving model ...
Validation loss decreased (0.601727 --> 0.600337).  Saving model ...
epoch 101, loss 0.5467, train acc 69.50%, f1 0.6950, precision 0.6950, recall 0.6950, auc 0.6950
Validation loss decreased (0.600337 --> 0.598969).  Saving model ...
Validation loss decreased (0.598969 --> 0.597545).  Saving model ...
Validation loss decreased (0.597545 --> 0.596084).  Saving model ...
Validation loss decreased (0.596084 --> 0.594692).  Saving model ...
Validation loss decreased (0.594692 --> 0.593263).  Saving model ...
Validation loss decreased (0.593263 --> 0.591935).  Saving model ...
Validation loss decreased (0.591935 --> 0.590594).  Saving model ...
Validation loss decreased (0.590594 --> 0.589175).  Saving model ...
Validation loss decreased (0.589175 --> 0.587843).  Saving model ...
Validation loss decreased (0.587843 --> 0.586466).  Saving model ...
Validation loss decreased (0.586466 --> 0.585096).  Saving model ...
Validation loss decreased (0.585096 --> 0.583759).  Saving model ...
Validation loss decreased (0.583759 --> 0.582517).  Saving model ...
Validation loss decreased (0.582517 --> 0.581165).  Saving model ...
Validation loss decreased (0.581165 --> 0.579866).  Saving model ...
Validation loss decreased (0.579866 --> 0.578612).  Saving model ...
Validation loss decreased (0.578612 --> 0.577322).  Saving model ...
Validation loss decreased (0.577322 --> 0.576003).  Saving model ...
Validation loss decreased (0.576003 --> 0.574633).  Saving model ...
Validation loss decreased (0.574633 --> 0.573257).  Saving model ...
Validation loss decreased (0.573257 --> 0.571902).  Saving model ...
Validation loss decreased (0.571902 --> 0.570454).  Saving model ...
Validation loss decreased (0.570454 --> 0.568989).  Saving model ...
Validation loss decreased (0.568989 --> 0.567533).  Saving model ...
Validation loss decreased (0.567533 --> 0.566126).  Saving model ...
Validation loss decreased (0.566126 --> 0.564797).  Saving model ...
Validation loss decreased (0.564797 --> 0.563403).  Saving model ...
Validation loss decreased (0.563403 --> 0.562052).  Saving model ...
Validation loss decreased (0.562052 --> 0.560650).  Saving model ...
Validation loss decreased (0.560650 --> 0.559291).  Saving model ...
Validation loss decreased (0.559291 --> 0.557983).  Saving model ...
Validation loss decreased (0.557983 --> 0.556702).  Saving model ...
Validation loss decreased (0.556702 --> 0.555503).  Saving model ...
Validation loss decreased (0.555503 --> 0.554181).  Saving model ...
Validation loss decreased (0.554181 --> 0.552904).  Saving model ...
Validation loss decreased (0.552904 --> 0.551810).  Saving model ...
Validation loss decreased (0.551810 --> 0.550703).  Saving model ...
Validation loss decreased (0.550703 --> 0.549737).  Saving model ...
Validation loss decreased (0.549737 --> 0.548648).  Saving model ...
Validation loss decreased (0.548648 --> 0.547529).  Saving model ...
Validation loss decreased (0.547529 --> 0.546399).  Saving model ...
Validation loss decreased (0.546399 --> 0.545306).  Saving model ...
Validation loss decreased (0.545306 --> 0.544278).  Saving model ...
Validation loss decreased (0.544278 --> 0.543243).  Saving model ...
Validation loss decreased (0.543243 --> 0.542117).  Saving model ...
Validation loss decreased (0.542117 --> 0.540996).  Saving model ...
Validation loss decreased (0.540996 --> 0.539878).  Saving model ...
Validation loss decreased (0.539878 --> 0.538790).  Saving model ...
Validation loss decreased (0.538790 --> 0.537685).  Saving model ...
Validation loss decreased (0.537685 --> 0.536685).  Saving model ...
Validation loss decreased (0.536685 --> 0.535643).  Saving model ...
Validation loss decreased (0.535643 --> 0.534487).  Saving model ...
Validation loss decreased (0.534487 --> 0.533270).  Saving model ...
Validation loss decreased (0.533270 --> 0.532014).  Saving model ...
Validation loss decreased (0.532014 --> 0.530689).  Saving model ...
Validation loss decreased (0.530689 --> 0.529451).  Saving model ...
Validation loss decreased (0.529451 --> 0.528191).  Saving model ...
Validation loss decreased (0.528191 --> 0.526965).  Saving model ...
Validation loss decreased (0.526965 --> 0.525749).  Saving model ...
Validation loss decreased (0.525749 --> 0.524559).  Saving model ...
Validation loss decreased (0.524559 --> 0.523354).  Saving model ...
Validation loss decreased (0.523354 --> 0.522259).  Saving model ...
Validation loss decreased (0.522259 --> 0.521190).  Saving model ...
Validation loss decreased (0.521190 --> 0.520097).  Saving model ...
Validation loss decreased (0.520097 --> 0.519189).  Saving model ...
Validation loss decreased (0.519189 --> 0.518320).  Saving model ...
Validation loss decreased (0.518320 --> 0.517510).  Saving model ...
Validation loss decreased (0.517510 --> 0.516812).  Saving model ...
Validation loss decreased (0.516812 --> 0.516076).  Saving model ...
Validation loss decreased (0.516076 --> 0.515293).  Saving model ...
Validation loss decreased (0.515293 --> 0.514557).  Saving model ...
Validation loss decreased (0.514557 --> 0.513887).  Saving model ...
Validation loss decreased (0.513887 --> 0.513312).  Saving model ...
Validation loss decreased (0.513312 --> 0.512690).  Saving model ...
Validation loss decreased (0.512690 --> 0.512065).  Saving model ...
Validation loss decreased (0.512065 --> 0.511477).  Saving model ...
Validation loss decreased (0.511477 --> 0.510927).  Saving model ...
Validation loss decreased (0.510927 --> 0.510318).  Saving model ...
Validation loss decreased (0.510318 --> 0.509683).  Saving model ...
Validation loss decreased (0.509683 --> 0.509070).  Saving model ...
Validation loss decreased (0.509070 --> 0.508274).  Saving model ...
Validation loss decreased (0.508274 --> 0.507497).  Saving model ...
Validation loss decreased (0.507497 --> 0.506710).  Saving model ...
Validation loss decreased (0.506710 --> 0.505925).  Saving model ...
Validation loss decreased (0.505925 --> 0.505255).  Saving model ...
Validation loss decreased (0.505255 --> 0.504554).  Saving model ...
Validation loss decreased (0.504554 --> 0.503670).  Saving model ...
Validation loss decreased (0.503670 --> 0.502742).  Saving model ...
Validation loss decreased (0.502742 --> 0.501766).  Saving model ...
Validation loss decreased (0.501766 --> 0.500920).  Saving model ...
Validation loss decreased (0.500920 --> 0.500060).  Saving model ...
Validation loss decreased (0.500060 --> 0.499109).  Saving model ...
Validation loss decreased (0.499109 --> 0.498400).  Saving model ...
Validation loss decreased (0.498400 --> 0.497553).  Saving model ...
Validation loss decreased (0.497553 --> 0.496590).  Saving model ...
Validation loss decreased (0.496590 --> 0.495769).  Saving model ...
Validation loss decreased (0.495769 --> 0.495090).  Saving model ...
Validation loss decreased (0.495090 --> 0.494637).  Saving model ...
Validation loss decreased (0.494637 --> 0.494132).  Saving model ...
Validation loss decreased (0.494132 --> 0.493516).  Saving model ...
epoch 201, loss 0.4706, train acc 73.00%, f1 0.7300, precision 0.7300, recall 0.7300, auc 0.7300
Validation loss decreased (0.493516 --> 0.492792).  Saving model ...
Validation loss decreased (0.492792 --> 0.491989).  Saving model ...
Validation loss decreased (0.491989 --> 0.491156).  Saving model ...
Validation loss decreased (0.491156 --> 0.490340).  Saving model ...
Validation loss decreased (0.490340 --> 0.489475).  Saving model ...
Validation loss decreased (0.489475 --> 0.488643).  Saving model ...
Validation loss decreased (0.488643 --> 0.487782).  Saving model ...
Validation loss decreased (0.487782 --> 0.486896).  Saving model ...
Validation loss decreased (0.486896 --> 0.485908).  Saving model ...
Validation loss decreased (0.485908 --> 0.484945).  Saving model ...
Validation loss decreased (0.484945 --> 0.483997).  Saving model ...
Validation loss decreased (0.483997 --> 0.483094).  Saving model ...
Validation loss decreased (0.483094 --> 0.482290).  Saving model ...
Validation loss decreased (0.482290 --> 0.481526).  Saving model ...
Validation loss decreased (0.481526 --> 0.480863).  Saving model ...
Validation loss decreased (0.480863 --> 0.480274).  Saving model ...
Validation loss decreased (0.480274 --> 0.479722).  Saving model ...
Validation loss decreased (0.479722 --> 0.479182).  Saving model ...
Validation loss decreased (0.479182 --> 0.478663).  Saving model ...
Validation loss decreased (0.478663 --> 0.478370).  Saving model ...
Validation loss decreased (0.478370 --> 0.478146).  Saving model ...
Validation loss decreased (0.478146 --> 0.477857).  Saving model ...
Validation loss decreased (0.477857 --> 0.477696).  Saving model ...
Validation loss decreased (0.477696 --> 0.477496).  Saving model ...
Validation loss decreased (0.477496 --> 0.477214).  Saving model ...
Validation loss decreased (0.477214 --> 0.476909).  Saving model ...
Validation loss decreased (0.476909 --> 0.476470).  Saving model ...
Validation loss decreased (0.476470 --> 0.476169).  Saving model ...
Validation loss decreased (0.476169 --> 0.475755).  Saving model ...
Validation loss decreased (0.475755 --> 0.475306).  Saving model ...
Validation loss decreased (0.475306 --> 0.474883).  Saving model ...
Validation loss decreased (0.474883 --> 0.474536).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.474536 --> 0.474253).  Saving model ...
Validation loss decreased (0.474253 --> 0.473991).  Saving model ...
Validation loss decreased (0.473991 --> 0.473760).  Saving model ...
Validation loss decreased (0.473760 --> 0.473451).  Saving model ...
Validation loss decreased (0.473451 --> 0.473143).  Saving model ...
Validation loss decreased (0.473143 --> 0.472833).  Saving model ...
Validation loss decreased (0.472833 --> 0.472362).  Saving model ...
Validation loss decreased (0.472362 --> 0.471843).  Saving model ...
Validation loss decreased (0.471843 --> 0.471326).  Saving model ...
Validation loss decreased (0.471326 --> 0.470883).  Saving model ...
Validation loss decreased (0.470883 --> 0.470463).  Saving model ...
Validation loss decreased (0.470463 --> 0.470153).  Saving model ...
Validation loss decreased (0.470153 --> 0.469803).  Saving model ...
Validation loss decreased (0.469803 --> 0.469343).  Saving model ...
Validation loss decreased (0.469343 --> 0.468846).  Saving model ...
Validation loss decreased (0.468846 --> 0.468196).  Saving model ...
Validation loss decreased (0.468196 --> 0.467595).  Saving model ...
Validation loss decreased (0.467595 --> 0.466987).  Saving model ...
Validation loss decreased (0.466987 --> 0.466412).  Saving model ...
Validation loss decreased (0.466412 --> 0.465870).  Saving model ...
Validation loss decreased (0.465870 --> 0.465386).  Saving model ...
Validation loss decreased (0.465386 --> 0.464935).  Saving model ...
Validation loss decreased (0.464935 --> 0.464368).  Saving model ...
Validation loss decreased (0.464368 --> 0.463835).  Saving model ...
Validation loss decreased (0.463835 --> 0.463342).  Saving model ...
Validation loss decreased (0.463342 --> 0.462825).  Saving model ...
Validation loss decreased (0.462825 --> 0.462332).  Saving model ...
Validation loss decreased (0.462332 --> 0.461808).  Saving model ...
Validation loss decreased (0.461808 --> 0.461235).  Saving model ...
Validation loss decreased (0.461235 --> 0.460727).  Saving model ...
Validation loss decreased (0.460727 --> 0.460278).  Saving model ...
Validation loss decreased (0.460278 --> 0.459911).  Saving model ...
Validation loss decreased (0.459911 --> 0.459546).  Saving model ...
Validation loss decreased (0.459546 --> 0.459015).  Saving model ...
Validation loss decreased (0.459015 --> 0.458518).  Saving model ...
Validation loss decreased (0.458518 --> 0.458104).  Saving model ...
Validation loss decreased (0.458104 --> 0.457684).  Saving model ...
Validation loss decreased (0.457684 --> 0.457226).  Saving model ...
Validation loss decreased (0.457226 --> 0.456597).  Saving model ...
Validation loss decreased (0.456597 --> 0.455956).  Saving model ...
Validation loss decreased (0.455956 --> 0.455384).  Saving model ...
Validation loss decreased (0.455384 --> 0.454937).  Saving model ...
Validation loss decreased (0.454937 --> 0.454550).  Saving model ...
Validation loss decreased (0.454550 --> 0.454181).  Saving model ...
Validation loss decreased (0.454181 --> 0.453864).  Saving model ...
Validation loss decreased (0.453864 --> 0.453667).  Saving model ...
Validation loss decreased (0.453667 --> 0.453415).  Saving model ...
Validation loss decreased (0.453415 --> 0.453141).  Saving model ...
Validation loss decreased (0.453141 --> 0.452919).  Saving model ...
Validation loss decreased (0.452919 --> 0.452831).  Saving model ...
Validation loss decreased (0.452831 --> 0.452652).  Saving model ...
Validation loss decreased (0.452652 --> 0.452470).  Saving model ...
Validation loss decreased (0.452470 --> 0.452235).  Saving model ...
Validation loss decreased (0.452235 --> 0.451963).  Saving model ...
Validation loss decreased (0.451963 --> 0.451695).  Saving model ...
Validation loss decreased (0.451695 --> 0.451549).  Saving model ...
Validation loss decreased (0.451549 --> 0.451387).  Saving model ...
Validation loss decreased (0.451387 --> 0.451087).  Saving model ...
Validation loss decreased (0.451087 --> 0.450861).  Saving model ...
Validation loss decreased (0.450861 --> 0.450681).  Saving model ...
Validation loss decreased (0.450681 --> 0.450674).  Saving model ...
Validation loss decreased (0.450674 --> 0.450671).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
epoch 301, loss 0.4607, train acc 78.00%, f1 0.7800, precision 0.7800, recall 0.7800, auc 0.7800
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 314, loss 0.3293, train acc 77.75%, f1 0.7781, precision 0.7761, recall 0.7800, auc 0.7775



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_2
./test_pima/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.5907407407407407

the Fscore is 0.5668449197860963

the precision is 0.39849624060150374

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_2
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5419, train acc 78.83%, f1 0.7886, precision 0.7874, recall 0.7899, auc 0.7883
epoch 201, loss 0.3778, train acc 81.76%, f1 0.8176, precision 0.8176, recall 0.8176, auc 0.8176
epoch 301, loss 0.3309, train acc 82.94%, f1 0.8293, precision 0.8297, recall 0.8290, auc 0.8294
epoch 401, loss 0.4927, train acc 83.53%, f1 0.8352, precision 0.8356, recall 0.8348, auc 0.8353
epoch 501, loss 0.4347, train acc 83.92%, f1 0.8391, precision 0.8395, recall 0.8387, auc 0.8392
epoch 601, loss 0.4094, train acc 84.08%, f1 0.8407, precision 0.8410, recall 0.8404, auc 0.8408
epoch 701, loss 0.4125, train acc 84.03%, f1 0.8402, precision 0.8406, recall 0.8398, auc 0.8403
epoch 801, loss 0.3266, train acc 83.98%, f1 0.8398, precision 0.8400, recall 0.8396, auc 0.8398
epoch 901, loss 0.4427, train acc 84.04%, f1 0.8403, precision 0.8405, recall 0.8402, auc 0.8404
epoch 1001, loss 0.3955, train acc 84.08%, f1 0.8408, precision 0.8409, recall 0.8407, auc 0.8408
epoch 1101, loss 0.3161, train acc 84.13%, f1 0.8413, precision 0.8414, recall 0.8412, auc 0.8413
epoch 1201, loss 0.3969, train acc 84.09%, f1 0.8409, precision 0.8412, recall 0.8406, auc 0.8409
epoch 1301, loss 0.3428, train acc 84.11%, f1 0.8410, precision 0.8412, recall 0.8408, auc 0.8411
epoch 1401, loss 0.3152, train acc 84.04%, f1 0.8403, precision 0.8407, recall 0.8399, auc 0.8404
epoch 1501, loss 0.3351, train acc 84.00%, f1 0.8399, precision 0.8402, recall 0.8397, auc 0.8400
epoch 1601, loss 0.3056, train acc 84.08%, f1 0.8407, precision 0.8411, recall 0.8403, auc 0.8408
epoch 1701, loss 0.5103, train acc 84.12%, f1 0.8411, precision 0.8415, recall 0.8408, auc 0.8412
epoch 1801, loss 0.3916, train acc 84.17%, f1 0.8416, precision 0.8419, recall 0.8413, auc 0.8417
epoch 1901, loss 0.3571, train acc 84.19%, f1 0.8418, precision 0.8420, recall 0.8416, auc 0.8419
epoch 2001, loss 0.3039, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8414, auc 0.8415
epoch 2101, loss 0.3290, train acc 84.14%, f1 0.8414, precision 0.8417, recall 0.8411, auc 0.8414
epoch 2201, loss 0.3598, train acc 84.23%, f1 0.8422, precision 0.8426, recall 0.8417, auc 0.8423
epoch 2301, loss 0.2650, train acc 84.30%, f1 0.8430, precision 0.8432, recall 0.8428, auc 0.8430
epoch 2401, loss 0.2682, train acc 84.34%, f1 0.8434, precision 0.8435, recall 0.8433, auc 0.8434
epoch 2501, loss 0.3703, train acc 84.38%, f1 0.8438, precision 0.8439, recall 0.8437, auc 0.8438
epoch 2601, loss 0.2517, train acc 84.47%, f1 0.8447, precision 0.8448, recall 0.8445, auc 0.8447
epoch 2701, loss 0.3561, train acc 84.50%, f1 0.8451, precision 0.8450, recall 0.8452, auc 0.8450
epoch 2801, loss 0.4365, train acc 84.60%, f1 0.8460, precision 0.8464, recall 0.8455, auc 0.8460
epoch 2901, loss 0.3849, train acc 84.78%, f1 0.8478, precision 0.8479, recall 0.8476, auc 0.8478
epoch 3001, loss 0.4848, train acc 84.88%, f1 0.8488, precision 0.8489, recall 0.8487, auc 0.8488
epoch 3101, loss 0.3739, train acc 84.99%, f1 0.8498, precision 0.8501, recall 0.8496, auc 0.8499
epoch 3201, loss 0.3258, train acc 85.13%, f1 0.8512, precision 0.8519, recall 0.8506, auc 0.8513
epoch 3301, loss 0.4063, train acc 85.23%, f1 0.8524, precision 0.8519, recall 0.8529, auc 0.8523
epoch 3401, loss 0.2271, train acc 85.36%, f1 0.8535, precision 0.8538, recall 0.8532, auc 0.8536
epoch 3501, loss 0.4000, train acc 85.49%, f1 0.8550, precision 0.8543, recall 0.8556, auc 0.8549
epoch 3601, loss 0.3911, train acc 85.68%, f1 0.8569, precision 0.8563, recall 0.8575, auc 0.8568
epoch 3701, loss 0.3741, train acc 85.71%, f1 0.8572, precision 0.8567, recall 0.8577, auc 0.8571
epoch 3801, loss 0.3186, train acc 85.85%, f1 0.8586, precision 0.8580, recall 0.8592, auc 0.8585
epoch 3901, loss 0.2332, train acc 86.02%, f1 0.8603, precision 0.8597, recall 0.8608, auc 0.8602
epoch 4001, loss 0.2567, train acc 86.13%, f1 0.8614, precision 0.8611, recall 0.8617, auc 0.8613
epoch 4101, loss 0.3364, train acc 86.26%, f1 0.8626, precision 0.8625, recall 0.8626, auc 0.8626
epoch 4201, loss 0.1970, train acc 86.31%, f1 0.8632, precision 0.8627, recall 0.8637, auc 0.8631
epoch 4301, loss 0.4133, train acc 86.47%, f1 0.8648, precision 0.8642, recall 0.8653, auc 0.8647
epoch 4401, loss 0.2348, train acc 86.54%, f1 0.8655, precision 0.8649, recall 0.8660, auc 0.8654
epoch 4501, loss 0.2922, train acc 86.58%, f1 0.8659, precision 0.8656, recall 0.8662, auc 0.8658
epoch 4601, loss 0.3676, train acc 86.69%, f1 0.8670, precision 0.8664, recall 0.8676, auc 0.8669
epoch 4701, loss 0.1809, train acc 86.74%, f1 0.8675, precision 0.8668, recall 0.8683, auc 0.8674
epoch 4801, loss 0.2036, train acc 86.77%, f1 0.8677, precision 0.8678, recall 0.8676, auc 0.8677
epoch 4901, loss 0.2577, train acc 86.80%, f1 0.8681, precision 0.8677, recall 0.8684, auc 0.8680
epoch 5001, loss 0.4077, train acc 86.85%, f1 0.8685, precision 0.8682, recall 0.8688, auc 0.8685
epoch 5101, loss 0.2932, train acc 86.96%, f1 0.8696, precision 0.8694, recall 0.8699, auc 0.8696
epoch 5201, loss 0.3435, train acc 87.05%, f1 0.8705, precision 0.8704, recall 0.8705, auc 0.8705
epoch 5301, loss 0.2639, train acc 87.07%, f1 0.8707, precision 0.8704, recall 0.8711, auc 0.8707
epoch 5401, loss 0.3270, train acc 87.10%, f1 0.8709, precision 0.8712, recall 0.8706, auc 0.8710
epoch 5501, loss 0.2905, train acc 87.14%, f1 0.8715, precision 0.8707, recall 0.8723, auc 0.8714
epoch 5601, loss 0.2373, train acc 87.11%, f1 0.8712, precision 0.8710, recall 0.8713, auc 0.8711
epoch 5701, loss 0.3165, train acc 87.17%, f1 0.8717, precision 0.8716, recall 0.8718, auc 0.8717
epoch 5801, loss 0.3507, train acc 87.20%, f1 0.8720, precision 0.8715, recall 0.8725, auc 0.8720
epoch 5901, loss 0.2594, train acc 87.22%, f1 0.8723, precision 0.8713, recall 0.8734, auc 0.8722
epoch 6001, loss 0.3692, train acc 87.29%, f1 0.8729, precision 0.8729, recall 0.8728, auc 0.8729
epoch 6101, loss 0.2846, train acc 87.32%, f1 0.8732, precision 0.8733, recall 0.8731, auc 0.8732
epoch 6201, loss 0.3428, train acc 87.33%, f1 0.8733, precision 0.8734, recall 0.8732, auc 0.8733
epoch 6301, loss 0.3610, train acc 87.36%, f1 0.8737, precision 0.8730, recall 0.8744, auc 0.8736
epoch 6401, loss 0.2844, train acc 87.36%, f1 0.8736, precision 0.8735, recall 0.8738, auc 0.8736
epoch 6501, loss 0.2748, train acc 87.43%, f1 0.8741, precision 0.8751, recall 0.8732, auc 0.8743
epoch 6601, loss 0.2495, train acc 87.43%, f1 0.8744, precision 0.8734, recall 0.8755, auc 0.8743
epoch 6701, loss 0.1982, train acc 87.47%, f1 0.8746, precision 0.8749, recall 0.8744, auc 0.8747
epoch 6801, loss 0.2270, train acc 87.46%, f1 0.8746, precision 0.8744, recall 0.8749, auc 0.8746
epoch 6901, loss 0.2980, train acc 87.51%, f1 0.8752, precision 0.8745, recall 0.8760, auc 0.8751
epoch 7001, loss 0.3592, train acc 87.52%, f1 0.8752, precision 0.8752, recall 0.8752, auc 0.8752
epoch 7101, loss 0.2148, train acc 87.53%, f1 0.8752, precision 0.8756, recall 0.8749, auc 0.8753
epoch 7201, loss 0.2628, train acc 87.63%, f1 0.8764, precision 0.8756, recall 0.8771, auc 0.8763
epoch 7301, loss 0.3464, train acc 87.57%, f1 0.8758, precision 0.8749, recall 0.8767, auc 0.8757
epoch 7401, loss 0.2852, train acc 87.58%, f1 0.8759, precision 0.8754, recall 0.8764, auc 0.8758
epoch 7501, loss 0.2442, train acc 87.71%, f1 0.8771, precision 0.8770, recall 0.8773, auc 0.8771
epoch 7601, loss 0.3412, train acc 87.68%, f1 0.8768, precision 0.8767, recall 0.8769, auc 0.8768
epoch 7701, loss 0.2574, train acc 87.69%, f1 0.8770, precision 0.8762, recall 0.8778, auc 0.8769
epoch 7801, loss 0.2068, train acc 87.77%, f1 0.8777, precision 0.8773, recall 0.8782, auc 0.8777
epoch 7901, loss 0.2282, train acc 87.76%, f1 0.8776, precision 0.8775, recall 0.8778, auc 0.8776
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_2
./test_pima/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6407407407407408

the Fscore is 0.5988700564971751

the precision is 0.43089430894308944

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_2
----------------------



epoch 1, loss 0.6931, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.5244, train acc 78.88%, f1 0.7891, precision 0.7880, recall 0.7902, auc 0.7888
epoch 201, loss 0.5258, train acc 81.72%, f1 0.8170, precision 0.8176, recall 0.8165, auc 0.8172
epoch 301, loss 0.3900, train acc 83.06%, f1 0.8305, precision 0.8308, recall 0.8302, auc 0.8306
epoch 401, loss 0.3786, train acc 83.68%, f1 0.8367, precision 0.8371, recall 0.8362, auc 0.8368
epoch 501, loss 0.4223, train acc 83.88%, f1 0.8387, precision 0.8391, recall 0.8383, auc 0.8388
epoch 601, loss 0.4410, train acc 83.97%, f1 0.8396, precision 0.8401, recall 0.8392, auc 0.8397
epoch 701, loss 0.4365, train acc 84.12%, f1 0.8411, precision 0.8412, recall 0.8410, auc 0.8412
epoch 801, loss 0.3513, train acc 84.07%, f1 0.8406, precision 0.8410, recall 0.8403, auc 0.8407
epoch 901, loss 0.3779, train acc 84.13%, f1 0.8412, precision 0.8415, recall 0.8410, auc 0.8413
epoch 1001, loss 0.4271, train acc 84.09%, f1 0.8409, precision 0.8409, recall 0.8408, auc 0.8409
epoch 1101, loss 0.3451, train acc 84.12%, f1 0.8411, precision 0.8415, recall 0.8407, auc 0.8412
epoch 1201, loss 0.3149, train acc 84.08%, f1 0.8407, precision 0.8411, recall 0.8403, auc 0.8408
epoch 1301, loss 0.3553, train acc 84.08%, f1 0.8407, precision 0.8411, recall 0.8404, auc 0.8408
epoch 1401, loss 0.3133, train acc 84.08%, f1 0.8407, precision 0.8413, recall 0.8401, auc 0.8408
epoch 1501, loss 0.3312, train acc 84.04%, f1 0.8403, precision 0.8409, recall 0.8396, auc 0.8404
epoch 1601, loss 0.3864, train acc 84.08%, f1 0.8407, precision 0.8411, recall 0.8402, auc 0.8408
epoch 1701, loss 0.3104, train acc 84.14%, f1 0.8413, precision 0.8419, recall 0.8407, auc 0.8414
epoch 1801, loss 0.4344, train acc 84.16%, f1 0.8415, precision 0.8423, recall 0.8406, auc 0.8416
epoch 1901, loss 0.3594, train acc 84.19%, f1 0.8417, precision 0.8425, recall 0.8409, auc 0.8419
epoch 2001, loss 0.4677, train acc 84.16%, f1 0.8415, precision 0.8419, recall 0.8412, auc 0.8416
epoch 2101, loss 0.2935, train acc 84.20%, f1 0.8419, precision 0.8424, recall 0.8414, auc 0.8420
epoch 2201, loss 0.3005, train acc 84.25%, f1 0.8424, precision 0.8432, recall 0.8415, auc 0.8425
epoch 2301, loss 0.3124, train acc 84.29%, f1 0.8427, precision 0.8436, recall 0.8418, auc 0.8429
epoch 2401, loss 0.4229, train acc 84.31%, f1 0.8430, precision 0.8435, recall 0.8425, auc 0.8431
epoch 2501, loss 0.4062, train acc 84.28%, f1 0.8427, precision 0.8432, recall 0.8421, auc 0.8428
epoch 2601, loss 0.3661, train acc 84.43%, f1 0.8441, precision 0.8448, recall 0.8434, auc 0.8443
epoch 2701, loss 0.3378, train acc 84.44%, f1 0.8444, precision 0.8447, recall 0.8440, auc 0.8444
epoch 2801, loss 0.2525, train acc 84.60%, f1 0.8460, precision 0.8463, recall 0.8457, auc 0.8460
epoch 2901, loss 0.4532, train acc 84.64%, f1 0.8463, precision 0.8468, recall 0.8458, auc 0.8464
epoch 3001, loss 0.2118, train acc 84.80%, f1 0.8479, precision 0.8482, recall 0.8476, auc 0.8480
epoch 3101, loss 0.3687, train acc 84.93%, f1 0.8491, precision 0.8499, recall 0.8484, auc 0.8493
epoch 3201, loss 0.2158, train acc 85.00%, f1 0.8499, precision 0.8506, recall 0.8492, auc 0.8500
epoch 3301, loss 0.3406, train acc 85.16%, f1 0.8515, precision 0.8519, recall 0.8511, auc 0.8516
epoch 3401, loss 0.2882, train acc 85.24%, f1 0.8524, precision 0.8525, recall 0.8522, auc 0.8524
epoch 3501, loss 0.4166, train acc 85.45%, f1 0.8544, precision 0.8548, recall 0.8540, auc 0.8545
epoch 3601, loss 0.3353, train acc 85.56%, f1 0.8556, precision 0.8559, recall 0.8552, auc 0.8556
epoch 3701, loss 0.3058, train acc 85.68%, f1 0.8568, precision 0.8571, recall 0.8564, auc 0.8568
epoch 3801, loss 0.4175, train acc 85.80%, f1 0.8580, precision 0.8579, recall 0.8580, auc 0.8580
epoch 3901, loss 0.3073, train acc 85.83%, f1 0.8583, precision 0.8584, recall 0.8582, auc 0.8583
epoch 4001, loss 0.2846, train acc 86.02%, f1 0.8601, precision 0.8612, recall 0.8589, auc 0.8602
epoch 4101, loss 0.4924, train acc 86.13%, f1 0.8613, precision 0.8612, recall 0.8613, auc 0.8613
epoch 4201, loss 0.2903, train acc 86.28%, f1 0.8628, precision 0.8624, recall 0.8632, auc 0.8628
epoch 4301, loss 0.1999, train acc 86.37%, f1 0.8637, precision 0.8640, recall 0.8634, auc 0.8637
epoch 4401, loss 0.2728, train acc 86.48%, f1 0.8649, precision 0.8646, recall 0.8651, auc 0.8648
epoch 4501, loss 0.3606, train acc 86.55%, f1 0.8656, precision 0.8651, recall 0.8661, auc 0.8655
epoch 4601, loss 0.2374, train acc 86.62%, f1 0.8662, precision 0.8663, recall 0.8660, auc 0.8662
epoch 4701, loss 0.3352, train acc 86.64%, f1 0.8665, precision 0.8659, recall 0.8670, auc 0.8664
epoch 4801, loss 0.3605, train acc 86.72%, f1 0.8672, precision 0.8669, recall 0.8675, auc 0.8672
epoch 4901, loss 0.4267, train acc 86.77%, f1 0.8678, precision 0.8675, recall 0.8680, auc 0.8677
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_Mirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_2
./test_pima/result_MLP_concat_Mirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6699999999999999

the Fscore is 0.6206896551724138

the precision is 0.45

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_2
----------------------



epoch 1, loss 0.6931, train acc 65.22%, f1 0.5673, precision 0.7506, recall 0.4560, auc 0.6522
epoch 101, loss 0.5128, train acc 79.36%, f1 0.7939, precision 0.7929, recall 0.7950, auc 0.7936
epoch 201, loss 0.5065, train acc 81.76%, f1 0.8175, precision 0.8179, recall 0.8171, auc 0.8176
epoch 301, loss 0.3343, train acc 83.08%, f1 0.8307, precision 0.8310, recall 0.8305, auc 0.8308
epoch 401, loss 0.3372, train acc 83.59%, f1 0.8359, precision 0.8360, recall 0.8357, auc 0.8359
epoch 501, loss 0.4138, train acc 83.81%, f1 0.8380, precision 0.8382, recall 0.8379, auc 0.8381
epoch 601, loss 0.3250, train acc 84.01%, f1 0.8401, precision 0.8402, recall 0.8400, auc 0.8401
epoch 701, loss 0.4629, train acc 84.01%, f1 0.8401, precision 0.8402, recall 0.8399, auc 0.8401
epoch 801, loss 0.5269, train acc 84.06%, f1 0.8406, precision 0.8406, recall 0.8406, auc 0.8406
epoch 901, loss 0.4514, train acc 84.09%, f1 0.8409, precision 0.8409, recall 0.8408, auc 0.8409
epoch 1001, loss 0.2539, train acc 84.10%, f1 0.8410, precision 0.8409, recall 0.8411, auc 0.8410
epoch 1101, loss 0.4368, train acc 84.13%, f1 0.8413, precision 0.8413, recall 0.8413, auc 0.8413
epoch 1201, loss 0.3455, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 1301, loss 0.4232, train acc 84.11%, f1 0.8411, precision 0.8411, recall 0.8411, auc 0.8411
epoch 1401, loss 0.2339, train acc 84.17%, f1 0.8417, precision 0.8416, recall 0.8417, auc 0.8417
epoch 1501, loss 0.3462, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 1601, loss 0.4178, train acc 84.11%, f1 0.8411, precision 0.8412, recall 0.8411, auc 0.8411
epoch 1701, loss 0.5016, train acc 84.13%, f1 0.8413, precision 0.8414, recall 0.8411, auc 0.8413
epoch 1801, loss 0.3246, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8416, auc 0.8415
epoch 1901, loss 0.2852, train acc 84.16%, f1 0.8415, precision 0.8417, recall 0.8414, auc 0.8416
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_Mirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_2
./test_pima/result_MLP_concat_Mirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6007407407407408

the Fscore is 0.572972972972973

the precision is 0.40458015267175573

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_2
----------------------



epoch 1, loss 0.6924, train acc 56.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.688605).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 21, loss 0.6900, train acc 79.00%, f1 0.7123, precision 0.8814, recall 0.5977, auc 0.7679



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_notMirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_2
./test_pima/result_MLP_concat_notMirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6344444444444444

the Fscore is 0.5853658536585366

the precision is 0.43636363636363634

the recall is 0.8888888888888888

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_2
----------------------



epoch 1, loss 0.6931, train acc 50.18%, f1 0.6683, precision 0.5018, recall 1.0000, auc 0.5000
epoch 101, loss 0.5933, train acc 78.38%, f1 0.7721, precision 0.8194, recall 0.7299, auc 0.7840
epoch 201, loss 0.4258, train acc 81.55%, f1 0.8149, precision 0.8206, recall 0.8094, auc 0.8155
epoch 301, loss 0.3257, train acc 82.98%, f1 0.8307, precision 0.8295, recall 0.8319, auc 0.8298
epoch 401, loss 0.4379, train acc 83.47%, f1 0.8361, precision 0.8320, recall 0.8402, auc 0.8347
epoch 501, loss 0.3425, train acc 83.77%, f1 0.8390, precision 0.8354, recall 0.8426, auc 0.8377
epoch 601, loss 0.3273, train acc 84.00%, f1 0.8409, precision 0.8394, recall 0.8424, auc 0.8400
epoch 701, loss 0.4165, train acc 84.04%, f1 0.8416, precision 0.8386, recall 0.8445, auc 0.8404
epoch 801, loss 0.3245, train acc 84.08%, f1 0.8426, precision 0.8360, recall 0.8494, auc 0.8408
epoch 901, loss 0.3112, train acc 84.14%, f1 0.8425, precision 0.8399, recall 0.8452, auc 0.8414
epoch 1001, loss 0.3568, train acc 84.10%, f1 0.8423, precision 0.8385, recall 0.8461, auc 0.8410
epoch 1101, loss 0.4156, train acc 84.11%, f1 0.8425, precision 0.8385, recall 0.8465, auc 0.8411
epoch 1201, loss 0.4122, train acc 84.11%, f1 0.8423, precision 0.8394, recall 0.8451, auc 0.8411
epoch 1301, loss 0.4566, train acc 84.09%, f1 0.8422, precision 0.8385, recall 0.8460, auc 0.8409
epoch 1401, loss 0.3330, train acc 84.12%, f1 0.8416, precision 0.8427, recall 0.8405, auc 0.8412
epoch 1501, loss 0.3229, train acc 84.04%, f1 0.8412, precision 0.8402, recall 0.8422, auc 0.8404
epoch 1601, loss 0.4134, train acc 84.01%, f1 0.8407, precision 0.8408, recall 0.8406, auc 0.8401
epoch 1701, loss 0.4041, train acc 84.07%, f1 0.8418, precision 0.8394, recall 0.8442, auc 0.8407
epoch 1801, loss 0.4596, train acc 84.08%, f1 0.8418, precision 0.8397, recall 0.8440, auc 0.8408
epoch 1901, loss 0.2990, train acc 84.06%, f1 0.8416, precision 0.8393, recall 0.8440, auc 0.8406
epoch 2001, loss 0.5491, train acc 84.11%, f1 0.8421, precision 0.8399, recall 0.8443, auc 0.8411
epoch 2101, loss 0.2780, train acc 84.15%, f1 0.8422, precision 0.8416, recall 0.8427, auc 0.8415
epoch 2201, loss 0.3197, train acc 84.14%, f1 0.8425, precision 0.8398, recall 0.8453, auc 0.8414
epoch 2301, loss 0.4037, train acc 84.14%, f1 0.8422, precision 0.8410, recall 0.8434, auc 0.8414
epoch 2401, loss 0.4357, train acc 84.16%, f1 0.8428, precision 0.8394, recall 0.8462, auc 0.8415
epoch 2501, loss 0.4229, train acc 84.15%, f1 0.8427, precision 0.8391, recall 0.8464, auc 0.8414
epoch 2601, loss 0.3527, train acc 84.15%, f1 0.8424, precision 0.8407, recall 0.8440, auc 0.8415
epoch 2701, loss 0.4327, train acc 84.20%, f1 0.8430, precision 0.8409, recall 0.8451, auc 0.8420
epoch 2801, loss 0.2847, train acc 84.16%, f1 0.8428, precision 0.8391, recall 0.8466, auc 0.8415
epoch 2901, loss 0.4109, train acc 84.22%, f1 0.8429, precision 0.8422, recall 0.8436, auc 0.8422
epoch 3001, loss 0.3685, train acc 84.27%, f1 0.8434, precision 0.8425, recall 0.8444, auc 0.8427
epoch 3101, loss 0.2642, train acc 84.32%, f1 0.8443, precision 0.8415, recall 0.8471, auc 0.8432
epoch 3201, loss 0.3842, train acc 84.39%, f1 0.8445, precision 0.8445, recall 0.8445, auc 0.8439
epoch 3301, loss 0.3036, train acc 84.48%, f1 0.8450, precision 0.8467, recall 0.8433, auc 0.8448
epoch 3401, loss 0.2620, train acc 84.56%, f1 0.8466, precision 0.8443, recall 0.8488, auc 0.8456
epoch 3501, loss 0.3844, train acc 84.67%, f1 0.8474, precision 0.8467, recall 0.8480, auc 0.8467
epoch 3601, loss 0.2868, train acc 84.77%, f1 0.8484, precision 0.8476, recall 0.8492, auc 0.8477
epoch 3701, loss 0.4004, train acc 84.92%, f1 0.8497, precision 0.8499, recall 0.8496, auc 0.8492
epoch 3801, loss 0.2694, train acc 84.99%, f1 0.8505, precision 0.8498, recall 0.8513, auc 0.8499
epoch 3901, loss 0.2670, train acc 85.09%, f1 0.8516, precision 0.8506, recall 0.8525, auc 0.8509
epoch 4001, loss 0.2484, train acc 85.12%, f1 0.8519, precision 0.8513, recall 0.8525, auc 0.8512
epoch 4101, loss 0.2694, train acc 85.28%, f1 0.8527, precision 0.8562, recall 0.8494, auc 0.8528
epoch 4201, loss 0.3627, train acc 85.41%, f1 0.8548, precision 0.8538, recall 0.8557, auc 0.8541
epoch 4301, loss 0.4010, train acc 85.54%, f1 0.8557, precision 0.8571, recall 0.8543, auc 0.8554
epoch 4401, loss 0.4241, train acc 85.66%, f1 0.8566, precision 0.8595, recall 0.8538, auc 0.8566
epoch 4501, loss 0.3226, train acc 85.83%, f1 0.8585, precision 0.8609, recall 0.8561, auc 0.8583
epoch 4601, loss 0.4036, train acc 85.89%, f1 0.8592, precision 0.8606, recall 0.8579, auc 0.8589
epoch 4701, loss 0.2625, train acc 86.09%, f1 0.8614, precision 0.8613, recall 0.8616, auc 0.8609
epoch 4801, loss 0.3462, train acc 86.16%, f1 0.8626, precision 0.8597, recall 0.8655, auc 0.8616
epoch 4901, loss 0.3242, train acc 86.29%, f1 0.8635, precision 0.8628, recall 0.8642, auc 0.8629
epoch 5001, loss 0.2683, train acc 86.34%, f1 0.8635, precision 0.8662, recall 0.8608, auc 0.8634
epoch 5101, loss 0.2720, train acc 86.48%, f1 0.8655, precision 0.8640, recall 0.8671, auc 0.8648
epoch 5201, loss 0.3842, train acc 86.61%, f1 0.8663, precision 0.8680, recall 0.8647, auc 0.8661
epoch 5301, loss 0.3458, train acc 86.64%, f1 0.8664, precision 0.8699, recall 0.8630, auc 0.8665
epoch 5401, loss 0.2657, train acc 86.72%, f1 0.8673, precision 0.8703, recall 0.8643, auc 0.8673
epoch 5501, loss 0.3523, train acc 86.79%, f1 0.8682, precision 0.8690, recall 0.8675, auc 0.8679
epoch 5601, loss 0.2956, train acc 86.86%, f1 0.8692, precision 0.8687, recall 0.8696, auc 0.8686
epoch 5701, loss 0.2904, train acc 86.91%, f1 0.8696, precision 0.8693, recall 0.8700, auc 0.8691
epoch 5801, loss 0.3764, train acc 86.96%, f1 0.8698, precision 0.8713, recall 0.8684, auc 0.8696
epoch 5901, loss 0.3825, train acc 87.05%, f1 0.8707, precision 0.8725, recall 0.8689, auc 0.8705
epoch 6001, loss 0.2098, train acc 87.10%, f1 0.8712, precision 0.8733, recall 0.8691, auc 0.8710
epoch 6101, loss 0.2772, train acc 87.09%, f1 0.8712, precision 0.8722, recall 0.8702, auc 0.8709
epoch 6201, loss 0.3946, train acc 87.14%, f1 0.8716, precision 0.8732, recall 0.8700, auc 0.8714
epoch 6301, loss 0.3278, train acc 87.13%, f1 0.8717, precision 0.8725, recall 0.8708, auc 0.8713
epoch 6401, loss 0.3450, train acc 87.27%, f1 0.8733, precision 0.8727, recall 0.8739, auc 0.8727
epoch 6501, loss 0.2149, train acc 87.28%, f1 0.8728, precision 0.8760, recall 0.8696, auc 0.8728
epoch 6601, loss 0.2754, train acc 87.35%, f1 0.8738, precision 0.8746, recall 0.8731, auc 0.8735
epoch 6701, loss 0.3200, train acc 87.34%, f1 0.8740, precision 0.8728, recall 0.8753, auc 0.8734
epoch 6801, loss 0.3334, train acc 87.41%, f1 0.8747, precision 0.8736, recall 0.8759, auc 0.8741
epoch 6901, loss 0.3330, train acc 87.44%, f1 0.8749, precision 0.8746, recall 0.8752, auc 0.8744
epoch 7001, loss 0.3224, train acc 87.41%, f1 0.8740, precision 0.8778, recall 0.8703, auc 0.8741
epoch 7101, loss 0.2284, train acc 87.50%, f1 0.8753, precision 0.8758, recall 0.8749, auc 0.8750
epoch 7201, loss 0.3534, train acc 87.56%, f1 0.8760, precision 0.8767, recall 0.8752, auc 0.8756
epoch 7301, loss 0.3031, train acc 87.55%, f1 0.8758, precision 0.8771, recall 0.8745, auc 0.8755
epoch 7401, loss 0.2684, train acc 87.63%, f1 0.8767, precision 0.8773, recall 0.8761, auc 0.8763
epoch 7501, loss 0.2385, train acc 87.62%, f1 0.8767, precision 0.8765, recall 0.8769, auc 0.8762
epoch 7601, loss 0.3196, train acc 87.67%, f1 0.8773, precision 0.8762, recall 0.8784, auc 0.8767
epoch 7701, loss 0.3297, train acc 87.72%, f1 0.8778, precision 0.8767, recall 0.8789, auc 0.8772
epoch 7801, loss 0.2985, train acc 87.71%, f1 0.8772, precision 0.8796, recall 0.8749, auc 0.8771
epoch 7901, loss 0.2396, train acc 87.77%, f1 0.8786, precision 0.8755, recall 0.8817, auc 0.8777
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_notMirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_2
./test_pima/result_MLP_concat_notMirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6414814814814814

the Fscore is 0.5977011494252873

the precision is 0.43333333333333335

the recall is 0.9629629629629629

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_2
----------------------



epoch 1, loss 0.6931, train acc 49.72%, f1 0.6642, precision 0.4972, recall 1.0000, auc 0.5000
epoch 101, loss 0.5499, train acc 78.43%, f1 0.7847, precision 0.7789, recall 0.7906, auc 0.7844
epoch 201, loss 0.3595, train acc 81.68%, f1 0.8162, precision 0.8142, recall 0.8183, auc 0.8168
epoch 301, loss 0.4221, train acc 82.87%, f1 0.8278, precision 0.8275, recall 0.8282, auc 0.8287
epoch 401, loss 0.3852, train acc 83.57%, f1 0.8348, precision 0.8345, recall 0.8351, auc 0.8357
epoch 501, loss 0.3142, train acc 83.75%, f1 0.8369, precision 0.8353, recall 0.8385, auc 0.8375
epoch 601, loss 0.3993, train acc 84.02%, f1 0.8399, precision 0.8369, recall 0.8429, auc 0.8402
epoch 701, loss 0.2697, train acc 84.08%, f1 0.8401, precision 0.8393, recall 0.8409, auc 0.8408
epoch 801, loss 0.3796, train acc 84.05%, f1 0.8400, precision 0.8382, recall 0.8418, auc 0.8405
epoch 901, loss 0.3336, train acc 84.04%, f1 0.8397, precision 0.8386, recall 0.8408, auc 0.8404
epoch 1001, loss 0.3642, train acc 84.15%, f1 0.8410, precision 0.8393, recall 0.8426, auc 0.8415
epoch 1101, loss 0.3876, train acc 84.12%, f1 0.8407, precision 0.8388, recall 0.8426, auc 0.8412
epoch 1201, loss 0.2875, train acc 84.10%, f1 0.8402, precision 0.8397, recall 0.8408, auc 0.8410
epoch 1301, loss 0.3606, train acc 84.14%, f1 0.8406, precision 0.8404, recall 0.8408, auc 0.8414
epoch 1401, loss 0.3154, train acc 84.15%, f1 0.8405, precision 0.8412, recall 0.8398, auc 0.8415
epoch 1501, loss 0.3353, train acc 84.03%, f1 0.8392, precision 0.8403, recall 0.8380, auc 0.8403
epoch 1601, loss 0.3628, train acc 84.20%, f1 0.8409, precision 0.8417, recall 0.8402, auc 0.8420
epoch 1701, loss 0.4288, train acc 84.15%, f1 0.8410, precision 0.8393, recall 0.8427, auc 0.8415
epoch 1801, loss 0.4205, train acc 84.10%, f1 0.8404, precision 0.8390, recall 0.8418, auc 0.8410
epoch 1901, loss 0.3587, train acc 84.14%, f1 0.8403, precision 0.8414, recall 0.8392, auc 0.8414
epoch 2001, loss 0.4465, train acc 84.13%, f1 0.8410, precision 0.8381, recall 0.8439, auc 0.8413
epoch 2101, loss 0.3244, train acc 84.17%, f1 0.8411, precision 0.8394, recall 0.8429, auc 0.8417
epoch 2201, loss 0.4063, train acc 84.15%, f1 0.8412, precision 0.8383, recall 0.8441, auc 0.8415
epoch 2301, loss 0.3388, train acc 84.11%, f1 0.8406, precision 0.8383, recall 0.8430, auc 0.8411
epoch 2401, loss 0.2988, train acc 84.11%, f1 0.8405, precision 0.8391, recall 0.8419, auc 0.8411
epoch 2501, loss 0.4089, train acc 84.18%, f1 0.8409, precision 0.8409, recall 0.8409, auc 0.8418
epoch 2601, loss 0.4433, train acc 84.15%, f1 0.8407, precision 0.8400, recall 0.8415, auc 0.8415
epoch 2701, loss 0.3042, train acc 84.14%, f1 0.8408, precision 0.8396, recall 0.8419, auc 0.8415
epoch 2801, loss 0.3622, train acc 84.24%, f1 0.8412, precision 0.8428, recall 0.8396, auc 0.8424
epoch 2901, loss 0.3908, train acc 84.23%, f1 0.8415, precision 0.8411, recall 0.8420, auc 0.8423
epoch 3001, loss 0.2771, train acc 84.24%, f1 0.8418, precision 0.8403, recall 0.8432, auc 0.8424
epoch 3101, loss 0.3110, train acc 84.25%, f1 0.8424, precision 0.8386, recall 0.8462, auc 0.8426
epoch 3201, loss 0.4150, train acc 84.34%, f1 0.8423, precision 0.8435, recall 0.8411, auc 0.8434
epoch 3301, loss 0.3439, train acc 84.44%, f1 0.8432, precision 0.8448, recall 0.8417, auc 0.8444
epoch 3401, loss 0.2890, train acc 84.52%, f1 0.8442, precision 0.8452, recall 0.8431, auc 0.8452
epoch 3501, loss 0.2862, train acc 84.66%, f1 0.8453, precision 0.8478, recall 0.8428, auc 0.8466
epoch 3601, loss 0.3261, train acc 84.72%, f1 0.8465, precision 0.8457, recall 0.8474, auc 0.8472
epoch 3701, loss 0.3557, train acc 84.88%, f1 0.8482, precision 0.8469, recall 0.8495, auc 0.8488
epoch 3801, loss 0.4847, train acc 85.00%, f1 0.8492, precision 0.8494, recall 0.8490, auc 0.8500
epoch 3901, loss 0.2512, train acc 85.07%, f1 0.8500, precision 0.8492, recall 0.8509, auc 0.8507
epoch 4001, loss 0.3789, train acc 85.20%, f1 0.8515, precision 0.8498, recall 0.8531, auc 0.8520
epoch 4101, loss 0.3042, train acc 85.39%, f1 0.8532, precision 0.8521, recall 0.8544, auc 0.8539
epoch 4201, loss 0.3095, train acc 85.51%, f1 0.8546, precision 0.8525, recall 0.8568, auc 0.8551
epoch 4301, loss 0.3334, train acc 85.67%, f1 0.8558, precision 0.8560, recall 0.8557, auc 0.8567
epoch 4401, loss 0.3954, train acc 85.82%, f1 0.8572, precision 0.8582, recall 0.8562, auc 0.8582
epoch 4501, loss 0.3397, train acc 85.84%, f1 0.8574, precision 0.8584, recall 0.8565, auc 0.8584
epoch 4601, loss 0.3374, train acc 86.02%, f1 0.8591, precision 0.8610, recall 0.8571, auc 0.8601
epoch 4701, loss 0.2338, train acc 86.07%, f1 0.8593, precision 0.8634, recall 0.8552, auc 0.8607
epoch 4801, loss 0.3550, train acc 86.14%, f1 0.8604, precision 0.8621, recall 0.8586, auc 0.8614
epoch 4901, loss 0.2915, train acc 86.26%, f1 0.8612, precision 0.8651, recall 0.8573, auc 0.8625
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_notMirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_2
./test_pima/result_MLP_concat_notMirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6357407407407407

the Fscore is 0.5955056179775281

the precision is 0.4274193548387097

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_2
----------------------



epoch 1, loss 0.6931, train acc 50.04%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5743, train acc 78.29%, f1 0.7810, precision 0.7874, recall 0.7747, auc 0.7829
epoch 201, loss 0.4104, train acc 81.84%, f1 0.8181, precision 0.8187, recall 0.8175, auc 0.8184
epoch 301, loss 0.2847, train acc 83.03%, f1 0.8298, precision 0.8314, recall 0.8282, auc 0.8303
epoch 401, loss 0.3095, train acc 83.67%, f1 0.8366, precision 0.8363, recall 0.8370, auc 0.8367
epoch 501, loss 0.2816, train acc 83.91%, f1 0.8395, precision 0.8367, recall 0.8423, auc 0.8391
epoch 601, loss 0.2572, train acc 84.01%, f1 0.8404, precision 0.8378, recall 0.8432, auc 0.8401
epoch 701, loss 0.2728, train acc 84.04%, f1 0.8405, precision 0.8396, recall 0.8413, auc 0.8404
epoch 801, loss 0.3585, train acc 84.10%, f1 0.8409, precision 0.8412, recall 0.8406, auc 0.8410
epoch 901, loss 0.4026, train acc 84.03%, f1 0.8406, precision 0.8385, recall 0.8426, auc 0.8403
epoch 1001, loss 0.3347, train acc 84.06%, f1 0.8406, precision 0.8399, recall 0.8414, auc 0.8406
epoch 1101, loss 0.3982, train acc 84.12%, f1 0.8410, precision 0.8414, recall 0.8405, auc 0.8412
epoch 1201, loss 0.5965, train acc 84.11%, f1 0.8413, precision 0.8400, recall 0.8425, auc 0.8411
epoch 1301, loss 0.4213, train acc 84.04%, f1 0.8403, precision 0.8405, recall 0.8401, auc 0.8404
epoch 1401, loss 0.4410, train acc 84.12%, f1 0.8413, precision 0.8404, recall 0.8421, auc 0.8412
epoch 1501, loss 0.3782, train acc 84.12%, f1 0.8413, precision 0.8405, recall 0.8421, auc 0.8413
epoch 1601, loss 0.3475, train acc 84.17%, f1 0.8415, precision 0.8420, recall 0.8410, auc 0.8417
epoch 1701, loss 0.3635, train acc 84.10%, f1 0.8409, precision 0.8408, recall 0.8409, auc 0.8410
epoch 1801, loss 0.3769, train acc 84.14%, f1 0.8410, precision 0.8424, recall 0.8395, auc 0.8414
epoch 1901, loss 0.4779, train acc 84.10%, f1 0.8413, precision 0.8387, recall 0.8439, auc 0.8410
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_concat_notMirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_2
./test_pima/result_MLP_concat_notMirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.585

the Fscore is 0.5654450261780105

the precision is 0.39416058394160586

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_2
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693136).  Saving model ...
Validation loss decreased (0.693136 --> 0.693094).  Saving model ...
Validation loss decreased (0.693094 --> 0.693050).  Saving model ...
Validation loss decreased (0.693050 --> 0.693002).  Saving model ...
Validation loss decreased (0.693002 --> 0.692954).  Saving model ...
Validation loss decreased (0.692954 --> 0.692904).  Saving model ...
Validation loss decreased (0.692904 --> 0.692844).  Saving model ...
Validation loss decreased (0.692844 --> 0.692777).  Saving model ...
Validation loss decreased (0.692777 --> 0.692705).  Saving model ...
Validation loss decreased (0.692705 --> 0.692621).  Saving model ...
Validation loss decreased (0.692621 --> 0.692533).  Saving model ...
Validation loss decreased (0.692533 --> 0.692439).  Saving model ...
Validation loss decreased (0.692439 --> 0.692335).  Saving model ...
Validation loss decreased (0.692335 --> 0.692219).  Saving model ...
Validation loss decreased (0.692219 --> 0.692093).  Saving model ...
Validation loss decreased (0.692093 --> 0.691959).  Saving model ...
Validation loss decreased (0.691959 --> 0.691810).  Saving model ...
Validation loss decreased (0.691810 --> 0.691647).  Saving model ...
Validation loss decreased (0.691647 --> 0.691475).  Saving model ...
Validation loss decreased (0.691475 --> 0.691294).  Saving model ...
Validation loss decreased (0.691294 --> 0.691098).  Saving model ...
Validation loss decreased (0.691098 --> 0.690879).  Saving model ...
Validation loss decreased (0.690879 --> 0.690651).  Saving model ...
Validation loss decreased (0.690651 --> 0.690401).  Saving model ...
Validation loss decreased (0.690401 --> 0.690149).  Saving model ...
Validation loss decreased (0.690149 --> 0.689883).  Saving model ...
Validation loss decreased (0.689883 --> 0.689609).  Saving model ...
Validation loss decreased (0.689609 --> 0.689313).  Saving model ...
Validation loss decreased (0.689313 --> 0.688987).  Saving model ...
Validation loss decreased (0.688987 --> 0.688643).  Saving model ...
Validation loss decreased (0.688643 --> 0.688309).  Saving model ...
Validation loss decreased (0.688309 --> 0.687980).  Saving model ...
Validation loss decreased (0.687980 --> 0.687628).  Saving model ...
Validation loss decreased (0.687628 --> 0.687250).  Saving model ...
Validation loss decreased (0.687250 --> 0.686851).  Saving model ...
Validation loss decreased (0.686851 --> 0.686461).  Saving model ...
Validation loss decreased (0.686461 --> 0.686038).  Saving model ...
Validation loss decreased (0.686038 --> 0.685593).  Saving model ...
Validation loss decreased (0.685593 --> 0.685135).  Saving model ...
Validation loss decreased (0.685135 --> 0.684640).  Saving model ...
Validation loss decreased (0.684640 --> 0.684114).  Saving model ...
Validation loss decreased (0.684114 --> 0.683577).  Saving model ...
Validation loss decreased (0.683577 --> 0.683023).  Saving model ...
Validation loss decreased (0.683023 --> 0.682442).  Saving model ...
Validation loss decreased (0.682442 --> 0.681833).  Saving model ...
Validation loss decreased (0.681833 --> 0.681190).  Saving model ...
Validation loss decreased (0.681190 --> 0.680512).  Saving model ...
Validation loss decreased (0.680512 --> 0.679811).  Saving model ...
Validation loss decreased (0.679811 --> 0.679129).  Saving model ...
Validation loss decreased (0.679129 --> 0.678426).  Saving model ...
Validation loss decreased (0.678426 --> 0.677678).  Saving model ...
Validation loss decreased (0.677678 --> 0.676931).  Saving model ...
Validation loss decreased (0.676931 --> 0.676150).  Saving model ...
Validation loss decreased (0.676150 --> 0.675353).  Saving model ...
Validation loss decreased (0.675353 --> 0.674588).  Saving model ...
Validation loss decreased (0.674588 --> 0.673804).  Saving model ...
Validation loss decreased (0.673804 --> 0.672986).  Saving model ...
Validation loss decreased (0.672986 --> 0.672124).  Saving model ...
Validation loss decreased (0.672124 --> 0.671249).  Saving model ...
Validation loss decreased (0.671249 --> 0.670351).  Saving model ...
Validation loss decreased (0.670351 --> 0.669409).  Saving model ...
Validation loss decreased (0.669409 --> 0.668485).  Saving model ...
Validation loss decreased (0.668485 --> 0.667574).  Saving model ...
Validation loss decreased (0.667574 --> 0.666626).  Saving model ...
Validation loss decreased (0.666626 --> 0.665683).  Saving model ...
Validation loss decreased (0.665683 --> 0.664697).  Saving model ...
Validation loss decreased (0.664697 --> 0.663727).  Saving model ...
Validation loss decreased (0.663727 --> 0.662757).  Saving model ...
Validation loss decreased (0.662757 --> 0.661826).  Saving model ...
Validation loss decreased (0.661826 --> 0.660944).  Saving model ...
Validation loss decreased (0.660944 --> 0.660075).  Saving model ...
Validation loss decreased (0.660075 --> 0.659200).  Saving model ...
Validation loss decreased (0.659200 --> 0.658292).  Saving model ...
Validation loss decreased (0.658292 --> 0.657393).  Saving model ...
Validation loss decreased (0.657393 --> 0.656477).  Saving model ...
Validation loss decreased (0.656477 --> 0.655571).  Saving model ...
Validation loss decreased (0.655571 --> 0.654630).  Saving model ...
Validation loss decreased (0.654630 --> 0.653661).  Saving model ...
Validation loss decreased (0.653661 --> 0.652687).  Saving model ...
Validation loss decreased (0.652687 --> 0.651676).  Saving model ...
Validation loss decreased (0.651676 --> 0.650678).  Saving model ...
Validation loss decreased (0.650678 --> 0.649684).  Saving model ...
Validation loss decreased (0.649684 --> 0.648732).  Saving model ...
Validation loss decreased (0.648732 --> 0.647826).  Saving model ...
Validation loss decreased (0.647826 --> 0.646889).  Saving model ...
Validation loss decreased (0.646889 --> 0.645995).  Saving model ...
Validation loss decreased (0.645995 --> 0.645064).  Saving model ...
Validation loss decreased (0.645064 --> 0.644136).  Saving model ...
Validation loss decreased (0.644136 --> 0.643239).  Saving model ...
Validation loss decreased (0.643239 --> 0.642280).  Saving model ...
Validation loss decreased (0.642280 --> 0.641327).  Saving model ...
Validation loss decreased (0.641327 --> 0.640299).  Saving model ...
Validation loss decreased (0.640299 --> 0.639262).  Saving model ...
Validation loss decreased (0.639262 --> 0.638194).  Saving model ...
Validation loss decreased (0.638194 --> 0.637120).  Saving model ...
Validation loss decreased (0.637120 --> 0.636008).  Saving model ...
Validation loss decreased (0.636008 --> 0.634927).  Saving model ...
Validation loss decreased (0.634927 --> 0.633860).  Saving model ...
Validation loss decreased (0.633860 --> 0.632743).  Saving model ...
Validation loss decreased (0.632743 --> 0.631625).  Saving model ...
epoch 101, loss 0.6171, train acc 74.00%, f1 0.7400, precision 0.7400, recall 0.7400, auc 0.7400
Validation loss decreased (0.631625 --> 0.630565).  Saving model ...
Validation loss decreased (0.630565 --> 0.629507).  Saving model ...
Validation loss decreased (0.629507 --> 0.628511).  Saving model ...
Validation loss decreased (0.628511 --> 0.627531).  Saving model ...
Validation loss decreased (0.627531 --> 0.626641).  Saving model ...
Validation loss decreased (0.626641 --> 0.625769).  Saving model ...
Validation loss decreased (0.625769 --> 0.624909).  Saving model ...
Validation loss decreased (0.624909 --> 0.624067).  Saving model ...
Validation loss decreased (0.624067 --> 0.623213).  Saving model ...
Validation loss decreased (0.623213 --> 0.622352).  Saving model ...
Validation loss decreased (0.622352 --> 0.621400).  Saving model ...
Validation loss decreased (0.621400 --> 0.620510).  Saving model ...
Validation loss decreased (0.620510 --> 0.619693).  Saving model ...
Validation loss decreased (0.619693 --> 0.618846).  Saving model ...
Validation loss decreased (0.618846 --> 0.618013).  Saving model ...
Validation loss decreased (0.618013 --> 0.617185).  Saving model ...
Validation loss decreased (0.617185 --> 0.616344).  Saving model ...
Validation loss decreased (0.616344 --> 0.615536).  Saving model ...
Validation loss decreased (0.615536 --> 0.614639).  Saving model ...
Validation loss decreased (0.614639 --> 0.613719).  Saving model ...
Validation loss decreased (0.613719 --> 0.612738).  Saving model ...
Validation loss decreased (0.612738 --> 0.611819).  Saving model ...
Validation loss decreased (0.611819 --> 0.610909).  Saving model ...
Validation loss decreased (0.610909 --> 0.610019).  Saving model ...
Validation loss decreased (0.610019 --> 0.609111).  Saving model ...
Validation loss decreased (0.609111 --> 0.608223).  Saving model ...
Validation loss decreased (0.608223 --> 0.607385).  Saving model ...
Validation loss decreased (0.607385 --> 0.606556).  Saving model ...
Validation loss decreased (0.606556 --> 0.605730).  Saving model ...
Validation loss decreased (0.605730 --> 0.604884).  Saving model ...
Validation loss decreased (0.604884 --> 0.604070).  Saving model ...
Validation loss decreased (0.604070 --> 0.603196).  Saving model ...
Validation loss decreased (0.603196 --> 0.602311).  Saving model ...
Validation loss decreased (0.602311 --> 0.601390).  Saving model ...
Validation loss decreased (0.601390 --> 0.600497).  Saving model ...
Validation loss decreased (0.600497 --> 0.599668).  Saving model ...
Validation loss decreased (0.599668 --> 0.598873).  Saving model ...
Validation loss decreased (0.598873 --> 0.597985).  Saving model ...
Validation loss decreased (0.597985 --> 0.597138).  Saving model ...
Validation loss decreased (0.597138 --> 0.596352).  Saving model ...
Validation loss decreased (0.596352 --> 0.595606).  Saving model ...
Validation loss decreased (0.595606 --> 0.594831).  Saving model ...
Validation loss decreased (0.594831 --> 0.593991).  Saving model ...
Validation loss decreased (0.593991 --> 0.593174).  Saving model ...
Validation loss decreased (0.593174 --> 0.592353).  Saving model ...
Validation loss decreased (0.592353 --> 0.591576).  Saving model ...
Validation loss decreased (0.591576 --> 0.590787).  Saving model ...
Validation loss decreased (0.590787 --> 0.589977).  Saving model ...
Validation loss decreased (0.589977 --> 0.589198).  Saving model ...
Validation loss decreased (0.589198 --> 0.588437).  Saving model ...
Validation loss decreased (0.588437 --> 0.587708).  Saving model ...
Validation loss decreased (0.587708 --> 0.586991).  Saving model ...
Validation loss decreased (0.586991 --> 0.586304).  Saving model ...
Validation loss decreased (0.586304 --> 0.585681).  Saving model ...
Validation loss decreased (0.585681 --> 0.585104).  Saving model ...
Validation loss decreased (0.585104 --> 0.584523).  Saving model ...
Validation loss decreased (0.584523 --> 0.583970).  Saving model ...
Validation loss decreased (0.583970 --> 0.583352).  Saving model ...
Validation loss decreased (0.583352 --> 0.582787).  Saving model ...
Validation loss decreased (0.582787 --> 0.582253).  Saving model ...
Validation loss decreased (0.582253 --> 0.581793).  Saving model ...
Validation loss decreased (0.581793 --> 0.581382).  Saving model ...
Validation loss decreased (0.581382 --> 0.581000).  Saving model ...
Validation loss decreased (0.581000 --> 0.580615).  Saving model ...
Validation loss decreased (0.580615 --> 0.580271).  Saving model ...
Validation loss decreased (0.580271 --> 0.579971).  Saving model ...
Validation loss decreased (0.579971 --> 0.579581).  Saving model ...
Validation loss decreased (0.579581 --> 0.579237).  Saving model ...
Validation loss decreased (0.579237 --> 0.578828).  Saving model ...
Validation loss decreased (0.578828 --> 0.578396).  Saving model ...
Validation loss decreased (0.578396 --> 0.577941).  Saving model ...
Validation loss decreased (0.577941 --> 0.577502).  Saving model ...
Validation loss decreased (0.577502 --> 0.577024).  Saving model ...
Validation loss decreased (0.577024 --> 0.576513).  Saving model ...
Validation loss decreased (0.576513 --> 0.576038).  Saving model ...
Validation loss decreased (0.576038 --> 0.575564).  Saving model ...
Validation loss decreased (0.575564 --> 0.575121).  Saving model ...
Validation loss decreased (0.575121 --> 0.574676).  Saving model ...
Validation loss decreased (0.574676 --> 0.574228).  Saving model ...
Validation loss decreased (0.574228 --> 0.573829).  Saving model ...
Validation loss decreased (0.573829 --> 0.573480).  Saving model ...
Validation loss decreased (0.573480 --> 0.573103).  Saving model ...
Validation loss decreased (0.573103 --> 0.572678).  Saving model ...
Validation loss decreased (0.572678 --> 0.572310).  Saving model ...
Validation loss decreased (0.572310 --> 0.572051).  Saving model ...
Validation loss decreased (0.572051 --> 0.571760).  Saving model ...
Validation loss decreased (0.571760 --> 0.571492).  Saving model ...
Validation loss decreased (0.571492 --> 0.571104).  Saving model ...
Validation loss decreased (0.571104 --> 0.570659).  Saving model ...
Validation loss decreased (0.570659 --> 0.570213).  Saving model ...
Validation loss decreased (0.570213 --> 0.569823).  Saving model ...
Validation loss decreased (0.569823 --> 0.569366).  Saving model ...
Validation loss decreased (0.569366 --> 0.568912).  Saving model ...
Validation loss decreased (0.568912 --> 0.568465).  Saving model ...
Validation loss decreased (0.568465 --> 0.567987).  Saving model ...
Validation loss decreased (0.567987 --> 0.567483).  Saving model ...
Validation loss decreased (0.567483 --> 0.566971).  Saving model ...
Validation loss decreased (0.566971 --> 0.566483).  Saving model ...
Validation loss decreased (0.566483 --> 0.565931).  Saving model ...
Validation loss decreased (0.565931 --> 0.565471).  Saving model ...
epoch 201, loss 0.4811, train acc 75.00%, f1 0.7500, precision 0.7500, recall 0.7500, auc 0.7500
Validation loss decreased (0.565471 --> 0.565013).  Saving model ...
Validation loss decreased (0.565013 --> 0.564566).  Saving model ...
Validation loss decreased (0.564566 --> 0.564197).  Saving model ...
Validation loss decreased (0.564197 --> 0.563811).  Saving model ...
Validation loss decreased (0.563811 --> 0.563397).  Saving model ...
Validation loss decreased (0.563397 --> 0.563051).  Saving model ...
Validation loss decreased (0.563051 --> 0.562728).  Saving model ...
Validation loss decreased (0.562728 --> 0.562436).  Saving model ...
Validation loss decreased (0.562436 --> 0.562050).  Saving model ...
Validation loss decreased (0.562050 --> 0.561675).  Saving model ...
Validation loss decreased (0.561675 --> 0.561428).  Saving model ...
Validation loss decreased (0.561428 --> 0.561161).  Saving model ...
Validation loss decreased (0.561161 --> 0.560996).  Saving model ...
Validation loss decreased (0.560996 --> 0.560813).  Saving model ...
Validation loss decreased (0.560813 --> 0.560737).  Saving model ...
Validation loss decreased (0.560737 --> 0.560599).  Saving model ...
Validation loss decreased (0.560599 --> 0.560477).  Saving model ...
Validation loss decreased (0.560477 --> 0.560361).  Saving model ...
Validation loss decreased (0.560361 --> 0.560243).  Saving model ...
Validation loss decreased (0.560243 --> 0.560087).  Saving model ...
Validation loss decreased (0.560087 --> 0.559910).  Saving model ...
Validation loss decreased (0.559910 --> 0.559777).  Saving model ...
Validation loss decreased (0.559777 --> 0.559631).  Saving model ...
Validation loss decreased (0.559631 --> 0.559606).  Saving model ...
Validation loss decreased (0.559606 --> 0.559506).  Saving model ...
Validation loss decreased (0.559506 --> 0.559337).  Saving model ...
Validation loss decreased (0.559337 --> 0.559196).  Saving model ...
Validation loss decreased (0.559196 --> 0.558965).  Saving model ...
Validation loss decreased (0.558965 --> 0.558730).  Saving model ...
Validation loss decreased (0.558730 --> 0.558512).  Saving model ...
Validation loss decreased (0.558512 --> 0.558260).  Saving model ...
Validation loss decreased (0.558260 --> 0.558048).  Saving model ...
Validation loss decreased (0.558048 --> 0.557849).  Saving model ...
Validation loss decreased (0.557849 --> 0.557691).  Saving model ...
Validation loss decreased (0.557691 --> 0.557524).  Saving model ...
Validation loss decreased (0.557524 --> 0.557371).  Saving model ...
Validation loss decreased (0.557371 --> 0.557226).  Saving model ...
Validation loss decreased (0.557226 --> 0.557128).  Saving model ...
Validation loss decreased (0.557128 --> 0.557012).  Saving model ...
Validation loss decreased (0.557012 --> 0.556935).  Saving model ...
Validation loss decreased (0.556935 --> 0.556779).  Saving model ...
Validation loss decreased (0.556779 --> 0.556679).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.556679 --> 0.556519).  Saving model ...
Validation loss decreased (0.556519 --> 0.556374).  Saving model ...
Validation loss decreased (0.556374 --> 0.556237).  Saving model ...
Validation loss decreased (0.556237 --> 0.556049).  Saving model ...
Validation loss decreased (0.556049 --> 0.555914).  Saving model ...
Validation loss decreased (0.555914 --> 0.555833).  Saving model ...
Validation loss decreased (0.555833 --> 0.555768).  Saving model ...
Validation loss decreased (0.555768 --> 0.555683).  Saving model ...
Validation loss decreased (0.555683 --> 0.555580).  Saving model ...
Validation loss decreased (0.555580 --> 0.555443).  Saving model ...
Validation loss decreased (0.555443 --> 0.555279).  Saving model ...
Validation loss decreased (0.555279 --> 0.555135).  Saving model ...
Validation loss decreased (0.555135 --> 0.555071).  Saving model ...
Validation loss decreased (0.555071 --> 0.555016).  Saving model ...
Validation loss decreased (0.555016 --> 0.554927).  Saving model ...
Validation loss decreased (0.554927 --> 0.554792).  Saving model ...
Validation loss decreased (0.554792 --> 0.554572).  Saving model ...
Validation loss decreased (0.554572 --> 0.554377).  Saving model ...
Validation loss decreased (0.554377 --> 0.554172).  Saving model ...
Validation loss decreased (0.554172 --> 0.553979).  Saving model ...
Validation loss decreased (0.553979 --> 0.553823).  Saving model ...
Validation loss decreased (0.553823 --> 0.553715).  Saving model ...
Validation loss decreased (0.553715 --> 0.553592).  Saving model ...
Validation loss decreased (0.553592 --> 0.553502).  Saving model ...
Validation loss decreased (0.553502 --> 0.553404).  Saving model ...
Validation loss decreased (0.553404 --> 0.553393).  Saving model ...
Validation loss decreased (0.553393 --> 0.553286).  Saving model ...
Validation loss decreased (0.553286 --> 0.553217).  Saving model ...
Validation loss decreased (0.553217 --> 0.553164).  Saving model ...
Validation loss decreased (0.553164 --> 0.553140).  Saving model ...
Validation loss decreased (0.553140 --> 0.553119).  Saving model ...
Validation loss decreased (0.553119 --> 0.552945).  Saving model ...
Validation loss decreased (0.552945 --> 0.552685).  Saving model ...
Validation loss decreased (0.552685 --> 0.552417).  Saving model ...
Validation loss decreased (0.552417 --> 0.552190).  Saving model ...
Validation loss decreased (0.552190 --> 0.552050).  Saving model ...
Validation loss decreased (0.552050 --> 0.551882).  Saving model ...
Validation loss decreased (0.551882 --> 0.551761).  Saving model ...
Validation loss decreased (0.551761 --> 0.551613).  Saving model ...
Validation loss decreased (0.551613 --> 0.551435).  Saving model ...
Validation loss decreased (0.551435 --> 0.551207).  Saving model ...
Validation loss decreased (0.551207 --> 0.550978).  Saving model ...
Validation loss decreased (0.550978 --> 0.550730).  Saving model ...
Validation loss decreased (0.550730 --> 0.550539).  Saving model ...
Validation loss decreased (0.550539 --> 0.550378).  Saving model ...
Validation loss decreased (0.550378 --> 0.550190).  Saving model ...
Validation loss decreased (0.550190 --> 0.550039).  Saving model ...
Validation loss decreased (0.550039 --> 0.549857).  Saving model ...
Validation loss decreased (0.549857 --> 0.549608).  Saving model ...
Validation loss decreased (0.549608 --> 0.549454).  Saving model ...
Validation loss decreased (0.549454 --> 0.549283).  Saving model ...
Validation loss decreased (0.549283 --> 0.549103).  Saving model ...
Validation loss decreased (0.549103 --> 0.548961).  Saving model ...
Validation loss decreased (0.548961 --> 0.548748).  Saving model ...
Validation loss decreased (0.548748 --> 0.548599).  Saving model ...
Validation loss decreased (0.548599 --> 0.548515).  Saving model ...
Validation loss decreased (0.548515 --> 0.548393).  Saving model ...
epoch 301, loss 0.3456, train acc 75.00%, f1 0.7500, precision 0.7500, recall 0.7500, auc 0.7500
Validation loss decreased (0.548393 --> 0.548315).  Saving model ...
Validation loss decreased (0.548315 --> 0.548203).  Saving model ...
Validation loss decreased (0.548203 --> 0.548065).  Saving model ...
Validation loss decreased (0.548065 --> 0.547979).  Saving model ...
Validation loss decreased (0.547979 --> 0.547928).  Saving model ...
Validation loss decreased (0.547928 --> 0.547915).  Saving model ...
Validation loss decreased (0.547915 --> 0.547871).  Saving model ...
Validation loss decreased (0.547871 --> 0.547792).  Saving model ...
Validation loss decreased (0.547792 --> 0.547683).  Saving model ...
Validation loss decreased (0.547683 --> 0.547637).  Saving model ...
Validation loss decreased (0.547637 --> 0.547558).  Saving model ...
Validation loss decreased (0.547558 --> 0.547507).  Saving model ...
Validation loss decreased (0.547507 --> 0.547378).  Saving model ...
Validation loss decreased (0.547378 --> 0.547334).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
Validation loss decreased (0.547334 --> 0.547171).  Saving model ...
Validation loss decreased (0.547171 --> 0.547059).  Saving model ...
Validation loss decreased (0.547059 --> 0.546884).  Saving model ...
Validation loss decreased (0.546884 --> 0.546765).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
Validation loss decreased (0.546765 --> 0.546758).  Saving model ...
Validation loss decreased (0.546758 --> 0.546717).  Saving model ...
Validation loss decreased (0.546717 --> 0.546677).  Saving model ...
Validation loss decreased (0.546677 --> 0.546605).  Saving model ...
Validation loss decreased (0.546605 --> 0.546575).  Saving model ...
Validation loss decreased (0.546575 --> 0.546534).  Saving model ...
Validation loss decreased (0.546534 --> 0.546470).  Saving model ...
Validation loss decreased (0.546470 --> 0.546424).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.546424 --> 0.546357).  Saving model ...
Validation loss decreased (0.546357 --> 0.546196).  Saving model ...
Validation loss decreased (0.546196 --> 0.546098).  Saving model ...
Validation loss decreased (0.546098 --> 0.545987).  Saving model ...
Validation loss decreased (0.545987 --> 0.545950).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.545950 --> 0.545926).  Saving model ...
Validation loss decreased (0.545926 --> 0.545875).  Saving model ...
Validation loss decreased (0.545875 --> 0.545814).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 368, loss 0.4393, train acc 74.50%, f1 0.7450, precision 0.7450, recall 0.7450, auc 0.7450



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_Mirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_2
./test_pima/result_MLP_minus_Mirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5907407407407407

the Fscore is 0.5668449197860963

the precision is 0.39849624060150374

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_2
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6105, train acc 78.49%, f1 0.7850, precision 0.7849, recall 0.7850, auc 0.7849
epoch 201, loss 0.4660, train acc 80.67%, f1 0.8067, precision 0.8067, recall 0.8067, auc 0.8067
epoch 301, loss 0.3598, train acc 82.11%, f1 0.8211, precision 0.8211, recall 0.8211, auc 0.8211
epoch 401, loss 0.3778, train acc 82.99%, f1 0.8299, precision 0.8299, recall 0.8299, auc 0.8299
epoch 501, loss 0.3678, train acc 83.44%, f1 0.8344, precision 0.8344, recall 0.8344, auc 0.8344
epoch 601, loss 0.4627, train acc 83.70%, f1 0.8370, precision 0.8370, recall 0.8370, auc 0.8370
epoch 701, loss 0.3731, train acc 83.90%, f1 0.8390, precision 0.8390, recall 0.8390, auc 0.8390
epoch 801, loss 0.3852, train acc 84.03%, f1 0.8403, precision 0.8403, recall 0.8403, auc 0.8403
epoch 901, loss 0.3455, train acc 84.12%, f1 0.8412, precision 0.8412, recall 0.8412, auc 0.8412
epoch 1001, loss 0.3244, train acc 84.05%, f1 0.8405, precision 0.8405, recall 0.8405, auc 0.8405
epoch 1101, loss 0.3559, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 1201, loss 0.4288, train acc 84.16%, f1 0.8416, precision 0.8416, recall 0.8416, auc 0.8416
epoch 1301, loss 0.5088, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 1401, loss 0.3324, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 1501, loss 0.4218, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 1601, loss 0.3228, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 1701, loss 0.3190, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 1801, loss 0.2908, train acc 84.11%, f1 0.8411, precision 0.8411, recall 0.8411, auc 0.8411
epoch 1901, loss 0.3548, train acc 84.07%, f1 0.8407, precision 0.8407, recall 0.8407, auc 0.8407
epoch 2001, loss 0.4221, train acc 84.11%, f1 0.8411, precision 0.8411, recall 0.8411, auc 0.8411
epoch 2101, loss 0.4007, train acc 84.14%, f1 0.8414, precision 0.8414, recall 0.8414, auc 0.8414
epoch 2201, loss 0.3561, train acc 84.13%, f1 0.8413, precision 0.8413, recall 0.8413, auc 0.8413
epoch 2301, loss 0.2892, train acc 84.12%, f1 0.8412, precision 0.8412, recall 0.8412, auc 0.8412
epoch 2401, loss 0.4271, train acc 84.13%, f1 0.8413, precision 0.8413, recall 0.8413, auc 0.8413
epoch 2501, loss 0.3177, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 2601, loss 0.3241, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 2701, loss 0.3624, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 2801, loss 0.2933, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8418, auc 0.8417
epoch 2901, loss 0.3109, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 3001, loss 0.3569, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 3101, loss 0.2964, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 3201, loss 0.3844, train acc 84.18%, f1 0.8418, precision 0.8417, recall 0.8418, auc 0.8418
epoch 3301, loss 0.3120, train acc 84.18%, f1 0.8417, precision 0.8418, recall 0.8417, auc 0.8418
epoch 3401, loss 0.4531, train acc 84.21%, f1 0.8421, precision 0.8421, recall 0.8421, auc 0.8421
epoch 3501, loss 0.3259, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8417, auc 0.8417
epoch 3601, loss 0.3694, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 3701, loss 0.3914, train acc 84.20%, f1 0.8420, precision 0.8419, recall 0.8420, auc 0.8420
epoch 3801, loss 0.3534, train acc 84.18%, f1 0.8418, precision 0.8417, recall 0.8418, auc 0.8418
epoch 3901, loss 0.3558, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 4001, loss 0.3035, train acc 84.22%, f1 0.8422, precision 0.8422, recall 0.8422, auc 0.8422
epoch 4101, loss 0.2763, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8423, auc 0.8423
epoch 4201, loss 0.3504, train acc 84.29%, f1 0.8429, precision 0.8429, recall 0.8429, auc 0.8429
epoch 4301, loss 0.3965, train acc 84.28%, f1 0.8428, precision 0.8428, recall 0.8428, auc 0.8428
epoch 4401, loss 0.3565, train acc 84.31%, f1 0.8431, precision 0.8431, recall 0.8431, auc 0.8431
epoch 4501, loss 0.3974, train acc 84.29%, f1 0.8429, precision 0.8429, recall 0.8429, auc 0.8429
epoch 4601, loss 0.4730, train acc 84.31%, f1 0.8431, precision 0.8431, recall 0.8430, auc 0.8431
epoch 4701, loss 0.3906, train acc 84.34%, f1 0.8434, precision 0.8434, recall 0.8435, auc 0.8434
epoch 4801, loss 0.3619, train acc 84.32%, f1 0.8432, precision 0.8432, recall 0.8432, auc 0.8432
epoch 4901, loss 0.4040, train acc 84.34%, f1 0.8434, precision 0.8434, recall 0.8434, auc 0.8434
epoch 5001, loss 0.4108, train acc 84.38%, f1 0.8438, precision 0.8438, recall 0.8438, auc 0.8438
epoch 5101, loss 0.4122, train acc 84.36%, f1 0.8436, precision 0.8437, recall 0.8436, auc 0.8436
epoch 5201, loss 0.3809, train acc 84.33%, f1 0.8433, precision 0.8433, recall 0.8433, auc 0.8433
epoch 5301, loss 0.4844, train acc 84.36%, f1 0.8436, precision 0.8436, recall 0.8436, auc 0.8436
epoch 5401, loss 0.2411, train acc 84.33%, f1 0.8433, precision 0.8432, recall 0.8433, auc 0.8433
epoch 5501, loss 0.3042, train acc 84.40%, f1 0.8440, precision 0.8440, recall 0.8440, auc 0.8440
epoch 5601, loss 0.4424, train acc 84.46%, f1 0.8446, precision 0.8446, recall 0.8446, auc 0.8446
epoch 5701, loss 0.4442, train acc 84.45%, f1 0.8445, precision 0.8445, recall 0.8445, auc 0.8445
epoch 5801, loss 0.3367, train acc 84.45%, f1 0.8445, precision 0.8445, recall 0.8445, auc 0.8445
epoch 5901, loss 0.3690, train acc 84.47%, f1 0.8447, precision 0.8447, recall 0.8447, auc 0.8447
epoch 6001, loss 0.3559, train acc 84.48%, f1 0.8448, precision 0.8448, recall 0.8448, auc 0.8448
epoch 6101, loss 0.2914, train acc 84.46%, f1 0.8446, precision 0.8446, recall 0.8445, auc 0.8446
epoch 6201, loss 0.3368, train acc 84.52%, f1 0.8452, precision 0.8452, recall 0.8452, auc 0.8452
epoch 6301, loss 0.3644, train acc 84.51%, f1 0.8451, precision 0.8451, recall 0.8451, auc 0.8451
epoch 6401, loss 0.3844, train acc 84.50%, f1 0.8450, precision 0.8450, recall 0.8450, auc 0.8450
epoch 6501, loss 0.3679, train acc 84.51%, f1 0.8451, precision 0.8451, recall 0.8452, auc 0.8451
epoch 6601, loss 0.3234, train acc 84.52%, f1 0.8452, precision 0.8452, recall 0.8453, auc 0.8452
epoch 6701, loss 0.2635, train acc 84.56%, f1 0.8456, precision 0.8456, recall 0.8456, auc 0.8456
epoch 6801, loss 0.3884, train acc 84.56%, f1 0.8456, precision 0.8456, recall 0.8456, auc 0.8456
epoch 6901, loss 0.3555, train acc 84.60%, f1 0.8460, precision 0.8460, recall 0.8461, auc 0.8460
epoch 7001, loss 0.3761, train acc 84.60%, f1 0.8460, precision 0.8460, recall 0.8460, auc 0.8460
epoch 7101, loss 0.3506, train acc 84.66%, f1 0.8466, precision 0.8466, recall 0.8466, auc 0.8466
epoch 7201, loss 0.2797, train acc 84.68%, f1 0.8468, precision 0.8468, recall 0.8468, auc 0.8468
epoch 7301, loss 0.3086, train acc 84.66%, f1 0.8466, precision 0.8466, recall 0.8466, auc 0.8466
epoch 7401, loss 0.2534, train acc 84.67%, f1 0.8467, precision 0.8467, recall 0.8467, auc 0.8467
epoch 7501, loss 0.3252, train acc 84.68%, f1 0.8468, precision 0.8468, recall 0.8468, auc 0.8468
epoch 7601, loss 0.3628, train acc 84.69%, f1 0.8469, precision 0.8469, recall 0.8468, auc 0.8469
epoch 7701, loss 0.3204, train acc 84.72%, f1 0.8472, precision 0.8472, recall 0.8472, auc 0.8472
epoch 7801, loss 0.2557, train acc 84.71%, f1 0.8471, precision 0.8471, recall 0.8471, auc 0.8471
epoch 7901, loss 0.3887, train acc 84.73%, f1 0.8473, precision 0.8473, recall 0.8473, auc 0.8473
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_Mirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_2
./test_pima/result_MLP_minus_Mirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6007407407407408

the Fscore is 0.572972972972973

the precision is 0.40458015267175573

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_2
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.6028, train acc 78.81%, f1 0.7882, precision 0.7881, recall 0.7882, auc 0.7881
epoch 201, loss 0.4826, train acc 80.88%, f1 0.8088, precision 0.8088, recall 0.8089, auc 0.8088
epoch 301, loss 0.4760, train acc 82.28%, f1 0.8228, precision 0.8228, recall 0.8228, auc 0.8228
epoch 401, loss 0.3477, train acc 83.03%, f1 0.8303, precision 0.8303, recall 0.8303, auc 0.8303
epoch 501, loss 0.4118, train acc 83.57%, f1 0.8357, precision 0.8357, recall 0.8357, auc 0.8357
epoch 601, loss 0.2973, train acc 83.77%, f1 0.8377, precision 0.8377, recall 0.8377, auc 0.8377
epoch 701, loss 0.5549, train acc 83.91%, f1 0.8391, precision 0.8391, recall 0.8391, auc 0.8391
epoch 801, loss 0.4675, train acc 84.00%, f1 0.8400, precision 0.8400, recall 0.8400, auc 0.8400
epoch 901, loss 0.3258, train acc 84.05%, f1 0.8405, precision 0.8405, recall 0.8405, auc 0.8405
epoch 1001, loss 0.3145, train acc 84.09%, f1 0.8409, precision 0.8409, recall 0.8409, auc 0.8409
epoch 1101, loss 0.3993, train acc 84.11%, f1 0.8411, precision 0.8411, recall 0.8411, auc 0.8411
epoch 1201, loss 0.4240, train acc 84.12%, f1 0.8412, precision 0.8412, recall 0.8413, auc 0.8412
epoch 1301, loss 0.2618, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 1401, loss 0.4080, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8423, auc 0.8423
epoch 1501, loss 0.3249, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8416, auc 0.8417
epoch 1601, loss 0.3217, train acc 84.13%, f1 0.8413, precision 0.8413, recall 0.8413, auc 0.8413
epoch 1701, loss 0.4114, train acc 84.14%, f1 0.8414, precision 0.8414, recall 0.8414, auc 0.8414
epoch 1801, loss 0.3822, train acc 84.13%, f1 0.8413, precision 0.8413, recall 0.8413, auc 0.8413
epoch 1901, loss 0.4391, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 2001, loss 0.3750, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 2101, loss 0.4346, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 2201, loss 0.4028, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8416, auc 0.8415
epoch 2301, loss 0.3940, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 2401, loss 0.2780, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 2501, loss 0.4599, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8417, auc 0.8417
epoch 2601, loss 0.4233, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 2701, loss 0.2825, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 2801, loss 0.3923, train acc 84.17%, f1 0.8417, precision 0.8416, recall 0.8418, auc 0.8417
epoch 2901, loss 0.2847, train acc 84.09%, f1 0.8409, precision 0.8409, recall 0.8409, auc 0.8409
epoch 3001, loss 0.3852, train acc 84.11%, f1 0.8411, precision 0.8411, recall 0.8411, auc 0.8411
epoch 3101, loss 0.4211, train acc 84.11%, f1 0.8411, precision 0.8412, recall 0.8410, auc 0.8411
epoch 3201, loss 0.3311, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 3301, loss 0.3963, train acc 84.16%, f1 0.8416, precision 0.8416, recall 0.8416, auc 0.8416
epoch 3401, loss 0.3767, train acc 84.18%, f1 0.8418, precision 0.8417, recall 0.8418, auc 0.8418
epoch 3501, loss 0.4662, train acc 84.17%, f1 0.8417, precision 0.8418, recall 0.8416, auc 0.8417
epoch 3601, loss 0.3819, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 3701, loss 0.3090, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8417, auc 0.8417
epoch 3801, loss 0.4351, train acc 84.16%, f1 0.8416, precision 0.8416, recall 0.8415, auc 0.8416
epoch 3901, loss 0.3639, train acc 84.19%, f1 0.8419, precision 0.8420, recall 0.8419, auc 0.8419
epoch 4001, loss 0.4605, train acc 84.19%, f1 0.8419, precision 0.8420, recall 0.8418, auc 0.8419
epoch 4101, loss 0.3871, train acc 84.18%, f1 0.8418, precision 0.8419, recall 0.8417, auc 0.8418
epoch 4201, loss 0.4217, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8418, auc 0.8417
epoch 4301, loss 0.3668, train acc 84.17%, f1 0.8418, precision 0.8416, recall 0.8419, auc 0.8417
epoch 4401, loss 0.2645, train acc 84.22%, f1 0.8422, precision 0.8422, recall 0.8423, auc 0.8422
epoch 4501, loss 0.3407, train acc 84.22%, f1 0.8422, precision 0.8423, recall 0.8421, auc 0.8422
epoch 4601, loss 0.3884, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 4701, loss 0.3050, train acc 84.22%, f1 0.8422, precision 0.8423, recall 0.8422, auc 0.8422
epoch 4801, loss 0.4009, train acc 84.21%, f1 0.8421, precision 0.8421, recall 0.8420, auc 0.8421
epoch 4901, loss 0.3942, train acc 84.21%, f1 0.8421, precision 0.8422, recall 0.8420, auc 0.8421
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_Mirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_2
./test_pima/result_MLP_minus_Mirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.61

the Fscore is 0.5806451612903226

the precision is 0.4090909090909091

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_2
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.6047, train acc 78.69%, f1 0.7882, precision 0.7834, recall 0.7930, auc 0.7869
epoch 201, loss 0.5356, train acc 80.79%, f1 0.8079, precision 0.8076, recall 0.8083, auc 0.8079
epoch 301, loss 0.3981, train acc 82.33%, f1 0.8232, precision 0.8234, recall 0.8230, auc 0.8233
epoch 401, loss 0.4396, train acc 83.03%, f1 0.8302, precision 0.8307, recall 0.8297, auc 0.8303
epoch 501, loss 0.3713, train acc 83.49%, f1 0.8348, precision 0.8351, recall 0.8344, auc 0.8349
epoch 601, loss 0.3857, train acc 83.83%, f1 0.8383, precision 0.8385, recall 0.8381, auc 0.8383
epoch 701, loss 0.3177, train acc 83.98%, f1 0.8398, precision 0.8399, recall 0.8398, auc 0.8398
epoch 801, loss 0.2588, train acc 84.00%, f1 0.8400, precision 0.8404, recall 0.8396, auc 0.8400
epoch 901, loss 0.4004, train acc 84.06%, f1 0.8406, precision 0.8409, recall 0.8403, auc 0.8406
epoch 1001, loss 0.4160, train acc 84.12%, f1 0.8411, precision 0.8413, recall 0.8409, auc 0.8412
epoch 1101, loss 0.2507, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 1201, loss 0.3270, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 1301, loss 0.3123, train acc 84.15%, f1 0.8415, precision 0.8414, recall 0.8416, auc 0.8415
epoch 1401, loss 0.3419, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8416, auc 0.8417
epoch 1501, loss 0.4138, train acc 84.18%, f1 0.8419, precision 0.8418, recall 0.8419, auc 0.8418
epoch 1601, loss 0.3065, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8417, auc 0.8417
epoch 1701, loss 0.3508, train acc 84.11%, f1 0.8410, precision 0.8411, recall 0.8410, auc 0.8411
epoch 1801, loss 0.3488, train acc 84.16%, f1 0.8416, precision 0.8416, recall 0.8416, auc 0.8416
epoch 1901, loss 0.4002, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_Mirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_2
./test_pima/result_MLP_minus_Mirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6

the Fscore is 0.5744680851063829

the precision is 0.40298507462686567

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_2
----------------------



epoch 1, loss 0.6931, train acc 45.00%, f1 0.6207, precision 0.4500, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.694011).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.694011 --> 0.693876).  Saving model ...
Validation loss decreased (0.693876 --> 0.693525).  Saving model ...
Validation loss decreased (0.693525 --> 0.693177).  Saving model ...
Validation loss decreased (0.693177 --> 0.692779).  Saving model ...
Validation loss decreased (0.692779 --> 0.692390).  Saving model ...
Validation loss decreased (0.692390 --> 0.691977).  Saving model ...
Validation loss decreased (0.691977 --> 0.691624).  Saving model ...
Validation loss decreased (0.691624 --> 0.691256).  Saving model ...
Validation loss decreased (0.691256 --> 0.690938).  Saving model ...
Validation loss decreased (0.690938 --> 0.690646).  Saving model ...
Validation loss decreased (0.690646 --> 0.690455).  Saving model ...
Validation loss decreased (0.690455 --> 0.690322).  Saving model ...
Validation loss decreased (0.690322 --> 0.690189).  Saving model ...
Validation loss decreased (0.690189 --> 0.690111).  Saving model ...
Validation loss decreased (0.690111 --> 0.690035).  Saving model ...
Validation loss decreased (0.690035 --> 0.689954).  Saving model ...
Validation loss decreased (0.689954 --> 0.689896).  Saving model ...
Validation loss decreased (0.689896 --> 0.689787).  Saving model ...
Validation loss decreased (0.689787 --> 0.689680).  Saving model ...
Validation loss decreased (0.689680 --> 0.689553).  Saving model ...
Validation loss decreased (0.689553 --> 0.689403).  Saving model ...
Validation loss decreased (0.689403 --> 0.689210).  Saving model ...
Validation loss decreased (0.689210 --> 0.688987).  Saving model ...
Validation loss decreased (0.688987 --> 0.688687).  Saving model ...
Validation loss decreased (0.688687 --> 0.688331).  Saving model ...
Validation loss decreased (0.688331 --> 0.687998).  Saving model ...
Validation loss decreased (0.687998 --> 0.687648).  Saving model ...
Validation loss decreased (0.687648 --> 0.687271).  Saving model ...
Validation loss decreased (0.687271 --> 0.686884).  Saving model ...
Validation loss decreased (0.686884 --> 0.686482).  Saving model ...
Validation loss decreased (0.686482 --> 0.686034).  Saving model ...
Validation loss decreased (0.686034 --> 0.685590).  Saving model ...
Validation loss decreased (0.685590 --> 0.685109).  Saving model ...
Validation loss decreased (0.685109 --> 0.684577).  Saving model ...
Validation loss decreased (0.684577 --> 0.684036).  Saving model ...
Validation loss decreased (0.684036 --> 0.683446).  Saving model ...
Validation loss decreased (0.683446 --> 0.682772).  Saving model ...
Validation loss decreased (0.682772 --> 0.682054).  Saving model ...
Validation loss decreased (0.682054 --> 0.681302).  Saving model ...
Validation loss decreased (0.681302 --> 0.680528).  Saving model ...
Validation loss decreased (0.680528 --> 0.679721).  Saving model ...
Validation loss decreased (0.679721 --> 0.678850).  Saving model ...
Validation loss decreased (0.678850 --> 0.677949).  Saving model ...
Validation loss decreased (0.677949 --> 0.677025).  Saving model ...
Validation loss decreased (0.677025 --> 0.676064).  Saving model ...
Validation loss decreased (0.676064 --> 0.675048).  Saving model ...
Validation loss decreased (0.675048 --> 0.674013).  Saving model ...
Validation loss decreased (0.674013 --> 0.672934).  Saving model ...
Validation loss decreased (0.672934 --> 0.671815).  Saving model ...
Validation loss decreased (0.671815 --> 0.670676).  Saving model ...
Validation loss decreased (0.670676 --> 0.669532).  Saving model ...
Validation loss decreased (0.669532 --> 0.668356).  Saving model ...
Validation loss decreased (0.668356 --> 0.667164).  Saving model ...
Validation loss decreased (0.667164 --> 0.665939).  Saving model ...
Validation loss decreased (0.665939 --> 0.664747).  Saving model ...
Validation loss decreased (0.664747 --> 0.663596).  Saving model ...
Validation loss decreased (0.663596 --> 0.662374).  Saving model ...
Validation loss decreased (0.662374 --> 0.661122).  Saving model ...
Validation loss decreased (0.661122 --> 0.659802).  Saving model ...
Validation loss decreased (0.659802 --> 0.658439).  Saving model ...
Validation loss decreased (0.658439 --> 0.657084).  Saving model ...
Validation loss decreased (0.657084 --> 0.655714).  Saving model ...
Validation loss decreased (0.655714 --> 0.654277).  Saving model ...
Validation loss decreased (0.654277 --> 0.652816).  Saving model ...
Validation loss decreased (0.652816 --> 0.651323).  Saving model ...
Validation loss decreased (0.651323 --> 0.649765).  Saving model ...
Validation loss decreased (0.649765 --> 0.648139).  Saving model ...
Validation loss decreased (0.648139 --> 0.646473).  Saving model ...
Validation loss decreased (0.646473 --> 0.644803).  Saving model ...
Validation loss decreased (0.644803 --> 0.643120).  Saving model ...
Validation loss decreased (0.643120 --> 0.641405).  Saving model ...
Validation loss decreased (0.641405 --> 0.639660).  Saving model ...
Validation loss decreased (0.639660 --> 0.637859).  Saving model ...
Validation loss decreased (0.637859 --> 0.636067).  Saving model ...
Validation loss decreased (0.636067 --> 0.634235).  Saving model ...
Validation loss decreased (0.634235 --> 0.632455).  Saving model ...
Validation loss decreased (0.632455 --> 0.630660).  Saving model ...
Validation loss decreased (0.630660 --> 0.628846).  Saving model ...
Validation loss decreased (0.628846 --> 0.626947).  Saving model ...
Validation loss decreased (0.626947 --> 0.625030).  Saving model ...
Validation loss decreased (0.625030 --> 0.623100).  Saving model ...
Validation loss decreased (0.623100 --> 0.621168).  Saving model ...
Validation loss decreased (0.621168 --> 0.619237).  Saving model ...
Validation loss decreased (0.619237 --> 0.617285).  Saving model ...
Validation loss decreased (0.617285 --> 0.615270).  Saving model ...
Validation loss decreased (0.615270 --> 0.613258).  Saving model ...
Validation loss decreased (0.613258 --> 0.611250).  Saving model ...
Validation loss decreased (0.611250 --> 0.609195).  Saving model ...
Validation loss decreased (0.609195 --> 0.607113).  Saving model ...
Validation loss decreased (0.607113 --> 0.604979).  Saving model ...
Validation loss decreased (0.604979 --> 0.602981).  Saving model ...
Validation loss decreased (0.602981 --> 0.600970).  Saving model ...
Validation loss decreased (0.600970 --> 0.599044).  Saving model ...
Validation loss decreased (0.599044 --> 0.597109).  Saving model ...
Validation loss decreased (0.597109 --> 0.595175).  Saving model ...
Validation loss decreased (0.595175 --> 0.593214).  Saving model ...
Validation loss decreased (0.593214 --> 0.591203).  Saving model ...
Validation loss decreased (0.591203 --> 0.589197).  Saving model ...
epoch 101, loss 0.6178, train acc 87.00%, f1 0.8571, precision 0.8478, recall 0.8667, auc 0.8697
Validation loss decreased (0.589197 --> 0.587237).  Saving model ...
Validation loss decreased (0.587237 --> 0.585390).  Saving model ...
Validation loss decreased (0.585390 --> 0.583565).  Saving model ...
Validation loss decreased (0.583565 --> 0.581767).  Saving model ...
Validation loss decreased (0.581767 --> 0.579987).  Saving model ...
Validation loss decreased (0.579987 --> 0.578241).  Saving model ...
Validation loss decreased (0.578241 --> 0.576418).  Saving model ...
Validation loss decreased (0.576418 --> 0.574566).  Saving model ...
Validation loss decreased (0.574566 --> 0.572735).  Saving model ...
Validation loss decreased (0.572735 --> 0.570900).  Saving model ...
Validation loss decreased (0.570900 --> 0.569040).  Saving model ...
Validation loss decreased (0.569040 --> 0.567146).  Saving model ...
Validation loss decreased (0.567146 --> 0.565170).  Saving model ...
Validation loss decreased (0.565170 --> 0.563176).  Saving model ...
Validation loss decreased (0.563176 --> 0.561157).  Saving model ...
Validation loss decreased (0.561157 --> 0.559201).  Saving model ...
Validation loss decreased (0.559201 --> 0.557251).  Saving model ...
Validation loss decreased (0.557251 --> 0.555307).  Saving model ...
Validation loss decreased (0.555307 --> 0.553420).  Saving model ...
Validation loss decreased (0.553420 --> 0.551514).  Saving model ...
Validation loss decreased (0.551514 --> 0.549592).  Saving model ...
Validation loss decreased (0.549592 --> 0.547679).  Saving model ...
Validation loss decreased (0.547679 --> 0.545758).  Saving model ...
Validation loss decreased (0.545758 --> 0.543818).  Saving model ...
Validation loss decreased (0.543818 --> 0.542007).  Saving model ...
Validation loss decreased (0.542007 --> 0.540110).  Saving model ...
Validation loss decreased (0.540110 --> 0.538189).  Saving model ...
Validation loss decreased (0.538189 --> 0.536375).  Saving model ...
Validation loss decreased (0.536375 --> 0.534575).  Saving model ...
Validation loss decreased (0.534575 --> 0.532795).  Saving model ...
Validation loss decreased (0.532795 --> 0.531063).  Saving model ...
Validation loss decreased (0.531063 --> 0.529361).  Saving model ...
Validation loss decreased (0.529361 --> 0.527806).  Saving model ...
Validation loss decreased (0.527806 --> 0.526272).  Saving model ...
Validation loss decreased (0.526272 --> 0.524733).  Saving model ...
Validation loss decreased (0.524733 --> 0.523200).  Saving model ...
Validation loss decreased (0.523200 --> 0.521687).  Saving model ...
Validation loss decreased (0.521687 --> 0.520244).  Saving model ...
Validation loss decreased (0.520244 --> 0.518816).  Saving model ...
Validation loss decreased (0.518816 --> 0.517345).  Saving model ...
Validation loss decreased (0.517345 --> 0.515880).  Saving model ...
Validation loss decreased (0.515880 --> 0.514457).  Saving model ...
Validation loss decreased (0.514457 --> 0.512995).  Saving model ...
Validation loss decreased (0.512995 --> 0.511499).  Saving model ...
Validation loss decreased (0.511499 --> 0.510001).  Saving model ...
Validation loss decreased (0.510001 --> 0.508496).  Saving model ...
Validation loss decreased (0.508496 --> 0.506971).  Saving model ...
Validation loss decreased (0.506971 --> 0.505502).  Saving model ...
Validation loss decreased (0.505502 --> 0.504103).  Saving model ...
Validation loss decreased (0.504103 --> 0.502780).  Saving model ...
Validation loss decreased (0.502780 --> 0.501513).  Saving model ...
Validation loss decreased (0.501513 --> 0.500271).  Saving model ...
Validation loss decreased (0.500271 --> 0.499002).  Saving model ...
Validation loss decreased (0.499002 --> 0.497665).  Saving model ...
Validation loss decreased (0.497665 --> 0.496404).  Saving model ...
Validation loss decreased (0.496404 --> 0.495139).  Saving model ...
Validation loss decreased (0.495139 --> 0.493954).  Saving model ...
Validation loss decreased (0.493954 --> 0.492804).  Saving model ...
Validation loss decreased (0.492804 --> 0.491668).  Saving model ...
Validation loss decreased (0.491668 --> 0.490523).  Saving model ...
Validation loss decreased (0.490523 --> 0.489399).  Saving model ...
Validation loss decreased (0.489399 --> 0.488097).  Saving model ...
Validation loss decreased (0.488097 --> 0.486899).  Saving model ...
Validation loss decreased (0.486899 --> 0.485766).  Saving model ...
Validation loss decreased (0.485766 --> 0.484653).  Saving model ...
Validation loss decreased (0.484653 --> 0.483515).  Saving model ...
Validation loss decreased (0.483515 --> 0.482422).  Saving model ...
Validation loss decreased (0.482422 --> 0.481275).  Saving model ...
Validation loss decreased (0.481275 --> 0.480157).  Saving model ...
Validation loss decreased (0.480157 --> 0.479108).  Saving model ...
Validation loss decreased (0.479108 --> 0.478038).  Saving model ...
Validation loss decreased (0.478038 --> 0.476978).  Saving model ...
Validation loss decreased (0.476978 --> 0.475939).  Saving model ...
Validation loss decreased (0.475939 --> 0.474870).  Saving model ...
Validation loss decreased (0.474870 --> 0.473814).  Saving model ...
Validation loss decreased (0.473814 --> 0.472738).  Saving model ...
Validation loss decreased (0.472738 --> 0.471685).  Saving model ...
Validation loss decreased (0.471685 --> 0.470536).  Saving model ...
Validation loss decreased (0.470536 --> 0.469424).  Saving model ...
Validation loss decreased (0.469424 --> 0.468284).  Saving model ...
Validation loss decreased (0.468284 --> 0.467089).  Saving model ...
Validation loss decreased (0.467089 --> 0.465898).  Saving model ...
Validation loss decreased (0.465898 --> 0.464723).  Saving model ...
Validation loss decreased (0.464723 --> 0.463550).  Saving model ...
Validation loss decreased (0.463550 --> 0.462335).  Saving model ...
Validation loss decreased (0.462335 --> 0.461246).  Saving model ...
Validation loss decreased (0.461246 --> 0.460040).  Saving model ...
Validation loss decreased (0.460040 --> 0.458864).  Saving model ...
Validation loss decreased (0.458864 --> 0.457644).  Saving model ...
Validation loss decreased (0.457644 --> 0.456538).  Saving model ...
Validation loss decreased (0.456538 --> 0.455473).  Saving model ...
Validation loss decreased (0.455473 --> 0.454388).  Saving model ...
Validation loss decreased (0.454388 --> 0.453276).  Saving model ...
Validation loss decreased (0.453276 --> 0.452155).  Saving model ...
Validation loss decreased (0.452155 --> 0.451055).  Saving model ...
Validation loss decreased (0.451055 --> 0.449965).  Saving model ...
Validation loss decreased (0.449965 --> 0.448888).  Saving model ...
Validation loss decreased (0.448888 --> 0.447841).  Saving model ...
Validation loss decreased (0.447841 --> 0.446797).  Saving model ...
Validation loss decreased (0.446797 --> 0.445740).  Saving model ...
epoch 201, loss 0.4980, train acc 83.50%, f1 0.8197, precision 0.8065, recall 0.8333, auc 0.8348
Validation loss decreased (0.445740 --> 0.444687).  Saving model ...
Validation loss decreased (0.444687 --> 0.443754).  Saving model ...
Validation loss decreased (0.443754 --> 0.442829).  Saving model ...
Validation loss decreased (0.442829 --> 0.441946).  Saving model ...
Validation loss decreased (0.441946 --> 0.440982).  Saving model ...
Validation loss decreased (0.440982 --> 0.440119).  Saving model ...
Validation loss decreased (0.440119 --> 0.439228).  Saving model ...
Validation loss decreased (0.439228 --> 0.438299).  Saving model ...
Validation loss decreased (0.438299 --> 0.437378).  Saving model ...
Validation loss decreased (0.437378 --> 0.436512).  Saving model ...
Validation loss decreased (0.436512 --> 0.435721).  Saving model ...
Validation loss decreased (0.435721 --> 0.434827).  Saving model ...
Validation loss decreased (0.434827 --> 0.433959).  Saving model ...
Validation loss decreased (0.433959 --> 0.433095).  Saving model ...
Validation loss decreased (0.433095 --> 0.432247).  Saving model ...
Validation loss decreased (0.432247 --> 0.431333).  Saving model ...
Validation loss decreased (0.431333 --> 0.430458).  Saving model ...
Validation loss decreased (0.430458 --> 0.429602).  Saving model ...
Validation loss decreased (0.429602 --> 0.428767).  Saving model ...
Validation loss decreased (0.428767 --> 0.427959).  Saving model ...
Validation loss decreased (0.427959 --> 0.427112).  Saving model ...
Validation loss decreased (0.427112 --> 0.426254).  Saving model ...
Validation loss decreased (0.426254 --> 0.425360).  Saving model ...
Validation loss decreased (0.425360 --> 0.424489).  Saving model ...
Validation loss decreased (0.424489 --> 0.423542).  Saving model ...
Validation loss decreased (0.423542 --> 0.422585).  Saving model ...
Validation loss decreased (0.422585 --> 0.421734).  Saving model ...
Validation loss decreased (0.421734 --> 0.420936).  Saving model ...
Validation loss decreased (0.420936 --> 0.420132).  Saving model ...
Validation loss decreased (0.420132 --> 0.419384).  Saving model ...
Validation loss decreased (0.419384 --> 0.418600).  Saving model ...
Validation loss decreased (0.418600 --> 0.417823).  Saving model ...
Validation loss decreased (0.417823 --> 0.417099).  Saving model ...
Validation loss decreased (0.417099 --> 0.416429).  Saving model ...
Validation loss decreased (0.416429 --> 0.415753).  Saving model ...
Validation loss decreased (0.415753 --> 0.415166).  Saving model ...
Validation loss decreased (0.415166 --> 0.414627).  Saving model ...
Validation loss decreased (0.414627 --> 0.414087).  Saving model ...
Validation loss decreased (0.414087 --> 0.413537).  Saving model ...
Validation loss decreased (0.413537 --> 0.412926).  Saving model ...
Validation loss decreased (0.412926 --> 0.412310).  Saving model ...
Validation loss decreased (0.412310 --> 0.411615).  Saving model ...
Validation loss decreased (0.411615 --> 0.410976).  Saving model ...
Validation loss decreased (0.410976 --> 0.410308).  Saving model ...
Validation loss decreased (0.410308 --> 0.409731).  Saving model ...
Validation loss decreased (0.409731 --> 0.409139).  Saving model ...
Validation loss decreased (0.409139 --> 0.408563).  Saving model ...
Validation loss decreased (0.408563 --> 0.408051).  Saving model ...
Validation loss decreased (0.408051 --> 0.407574).  Saving model ...
Validation loss decreased (0.407574 --> 0.407017).  Saving model ...
Validation loss decreased (0.407017 --> 0.406466).  Saving model ...
Validation loss decreased (0.406466 --> 0.405924).  Saving model ...
Validation loss decreased (0.405924 --> 0.405394).  Saving model ...
Validation loss decreased (0.405394 --> 0.404954).  Saving model ...
Validation loss decreased (0.404954 --> 0.404520).  Saving model ...
Validation loss decreased (0.404520 --> 0.404068).  Saving model ...
Validation loss decreased (0.404068 --> 0.403623).  Saving model ...
Validation loss decreased (0.403623 --> 0.403226).  Saving model ...
Validation loss decreased (0.403226 --> 0.402856).  Saving model ...
Validation loss decreased (0.402856 --> 0.402493).  Saving model ...
Validation loss decreased (0.402493 --> 0.402129).  Saving model ...
Validation loss decreased (0.402129 --> 0.401842).  Saving model ...
Validation loss decreased (0.401842 --> 0.401600).  Saving model ...
Validation loss decreased (0.401600 --> 0.401334).  Saving model ...
Validation loss decreased (0.401334 --> 0.401029).  Saving model ...
Validation loss decreased (0.401029 --> 0.400742).  Saving model ...
Validation loss decreased (0.400742 --> 0.400458).  Saving model ...
Validation loss decreased (0.400458 --> 0.400114).  Saving model ...
Validation loss decreased (0.400114 --> 0.399826).  Saving model ...
Validation loss decreased (0.399826 --> 0.399503).  Saving model ...
Validation loss decreased (0.399503 --> 0.399146).  Saving model ...
Validation loss decreased (0.399146 --> 0.398850).  Saving model ...
Validation loss decreased (0.398850 --> 0.398550).  Saving model ...
Validation loss decreased (0.398550 --> 0.398271).  Saving model ...
Validation loss decreased (0.398271 --> 0.397889).  Saving model ...
Validation loss decreased (0.397889 --> 0.397523).  Saving model ...
Validation loss decreased (0.397523 --> 0.397151).  Saving model ...
Validation loss decreased (0.397151 --> 0.396772).  Saving model ...
Validation loss decreased (0.396772 --> 0.396359).  Saving model ...
Validation loss decreased (0.396359 --> 0.395907).  Saving model ...
Validation loss decreased (0.395907 --> 0.395561).  Saving model ...
Validation loss decreased (0.395561 --> 0.395245).  Saving model ...
Validation loss decreased (0.395245 --> 0.394815).  Saving model ...
Validation loss decreased (0.394815 --> 0.394387).  Saving model ...
Validation loss decreased (0.394387 --> 0.394020).  Saving model ...
Validation loss decreased (0.394020 --> 0.393605).  Saving model ...
Validation loss decreased (0.393605 --> 0.393173).  Saving model ...
Validation loss decreased (0.393173 --> 0.392727).  Saving model ...
Validation loss decreased (0.392727 --> 0.392222).  Saving model ...
Validation loss decreased (0.392222 --> 0.391737).  Saving model ...
Validation loss decreased (0.391737 --> 0.391336).  Saving model ...
Validation loss decreased (0.391336 --> 0.390907).  Saving model ...
Validation loss decreased (0.390907 --> 0.390454).  Saving model ...
Validation loss decreased (0.390454 --> 0.390040).  Saving model ...
Validation loss decreased (0.390040 --> 0.389573).  Saving model ...
Validation loss decreased (0.389573 --> 0.389099).  Saving model ...
Validation loss decreased (0.389099 --> 0.388558).  Saving model ...
Validation loss decreased (0.388558 --> 0.388005).  Saving model ...
Validation loss decreased (0.388005 --> 0.387439).  Saving model ...
Validation loss decreased (0.387439 --> 0.386910).  Saving model ...
epoch 301, loss 0.4556, train acc 85.50%, f1 0.8432, precision 0.8211, recall 0.8667, auc 0.8561
Validation loss decreased (0.386910 --> 0.386457).  Saving model ...
Validation loss decreased (0.386457 --> 0.386025).  Saving model ...
Validation loss decreased (0.386025 --> 0.385546).  Saving model ...
Validation loss decreased (0.385546 --> 0.385059).  Saving model ...
Validation loss decreased (0.385059 --> 0.384616).  Saving model ...
Validation loss decreased (0.384616 --> 0.384154).  Saving model ...
Validation loss decreased (0.384154 --> 0.383677).  Saving model ...
Validation loss decreased (0.383677 --> 0.383214).  Saving model ...
Validation loss decreased (0.383214 --> 0.382736).  Saving model ...
Validation loss decreased (0.382736 --> 0.382314).  Saving model ...
Validation loss decreased (0.382314 --> 0.381914).  Saving model ...
Validation loss decreased (0.381914 --> 0.381518).  Saving model ...
Validation loss decreased (0.381518 --> 0.381175).  Saving model ...
Validation loss decreased (0.381175 --> 0.380809).  Saving model ...
Validation loss decreased (0.380809 --> 0.380444).  Saving model ...
Validation loss decreased (0.380444 --> 0.380100).  Saving model ...
Validation loss decreased (0.380100 --> 0.379662).  Saving model ...
Validation loss decreased (0.379662 --> 0.379256).  Saving model ...
Validation loss decreased (0.379256 --> 0.378875).  Saving model ...
Validation loss decreased (0.378875 --> 0.378457).  Saving model ...
Validation loss decreased (0.378457 --> 0.378089).  Saving model ...
Validation loss decreased (0.378089 --> 0.377657).  Saving model ...
Validation loss decreased (0.377657 --> 0.377198).  Saving model ...
Validation loss decreased (0.377198 --> 0.376764).  Saving model ...
Validation loss decreased (0.376764 --> 0.376336).  Saving model ...
Validation loss decreased (0.376336 --> 0.375900).  Saving model ...
Validation loss decreased (0.375900 --> 0.375541).  Saving model ...
Validation loss decreased (0.375541 --> 0.375094).  Saving model ...
Validation loss decreased (0.375094 --> 0.374675).  Saving model ...
Validation loss decreased (0.374675 --> 0.374325).  Saving model ...
Validation loss decreased (0.374325 --> 0.373916).  Saving model ...
Validation loss decreased (0.373916 --> 0.373551).  Saving model ...
Validation loss decreased (0.373551 --> 0.373141).  Saving model ...
Validation loss decreased (0.373141 --> 0.372784).  Saving model ...
Validation loss decreased (0.372784 --> 0.372337).  Saving model ...
Validation loss decreased (0.372337 --> 0.371942).  Saving model ...
Validation loss decreased (0.371942 --> 0.371573).  Saving model ...
Validation loss decreased (0.371573 --> 0.371265).  Saving model ...
Validation loss decreased (0.371265 --> 0.370968).  Saving model ...
Validation loss decreased (0.370968 --> 0.370670).  Saving model ...
Validation loss decreased (0.370670 --> 0.370424).  Saving model ...
Validation loss decreased (0.370424 --> 0.370193).  Saving model ...
Validation loss decreased (0.370193 --> 0.370007).  Saving model ...
Validation loss decreased (0.370007 --> 0.369764).  Saving model ...
Validation loss decreased (0.369764 --> 0.369616).  Saving model ...
Validation loss decreased (0.369616 --> 0.369462).  Saving model ...
Validation loss decreased (0.369462 --> 0.369298).  Saving model ...
Validation loss decreased (0.369298 --> 0.369094).  Saving model ...
Validation loss decreased (0.369094 --> 0.368815).  Saving model ...
Validation loss decreased (0.368815 --> 0.368602).  Saving model ...
Validation loss decreased (0.368602 --> 0.368418).  Saving model ...
Validation loss decreased (0.368418 --> 0.368185).  Saving model ...
Validation loss decreased (0.368185 --> 0.367972).  Saving model ...
Validation loss decreased (0.367972 --> 0.367610).  Saving model ...
Validation loss decreased (0.367610 --> 0.367302).  Saving model ...
Validation loss decreased (0.367302 --> 0.366987).  Saving model ...
Validation loss decreased (0.366987 --> 0.366726).  Saving model ...
Validation loss decreased (0.366726 --> 0.366490).  Saving model ...
Validation loss decreased (0.366490 --> 0.366286).  Saving model ...
Validation loss decreased (0.366286 --> 0.366074).  Saving model ...
Validation loss decreased (0.366074 --> 0.365889).  Saving model ...
Validation loss decreased (0.365889 --> 0.365784).  Saving model ...
Validation loss decreased (0.365784 --> 0.365684).  Saving model ...
Validation loss decreased (0.365684 --> 0.365570).  Saving model ...
Validation loss decreased (0.365570 --> 0.365489).  Saving model ...
Validation loss decreased (0.365489 --> 0.365437).  Saving model ...
Validation loss decreased (0.365437 --> 0.365370).  Saving model ...
Validation loss decreased (0.365370 --> 0.365251).  Saving model ...
Validation loss decreased (0.365251 --> 0.365001).  Saving model ...
Validation loss decreased (0.365001 --> 0.364762).  Saving model ...
Validation loss decreased (0.364762 --> 0.364564).  Saving model ...
Validation loss decreased (0.364564 --> 0.364385).  Saving model ...
Validation loss decreased (0.364385 --> 0.364236).  Saving model ...
Validation loss decreased (0.364236 --> 0.364025).  Saving model ...
Validation loss decreased (0.364025 --> 0.363902).  Saving model ...
Validation loss decreased (0.363902 --> 0.363832).  Saving model ...
Validation loss decreased (0.363832 --> 0.363803).  Saving model ...
Validation loss decreased (0.363803 --> 0.363748).  Saving model ...
Validation loss decreased (0.363748 --> 0.363704).  Saving model ...
Validation loss decreased (0.363704 --> 0.363692).  Saving model ...
Validation loss decreased (0.363692 --> 0.363681).  Saving model ...
Validation loss decreased (0.363681 --> 0.363642).  Saving model ...
Validation loss decreased (0.363642 --> 0.363556).  Saving model ...
Validation loss decreased (0.363556 --> 0.363373).  Saving model ...
Validation loss decreased (0.363373 --> 0.363245).  Saving model ...
Validation loss decreased (0.363245 --> 0.363068).  Saving model ...
Validation loss decreased (0.363068 --> 0.362884).  Saving model ...
Validation loss decreased (0.362884 --> 0.362737).  Saving model ...
Validation loss decreased (0.362737 --> 0.362639).  Saving model ...
Validation loss decreased (0.362639 --> 0.362606).  Saving model ...
Validation loss decreased (0.362606 --> 0.362599).  Saving model ...
Validation loss decreased (0.362599 --> 0.362563).  Saving model ...
Validation loss decreased (0.362563 --> 0.362481).  Saving model ...
Validation loss decreased (0.362481 --> 0.362392).  Saving model ...
Validation loss decreased (0.362392 --> 0.362356).  Saving model ...
Validation loss decreased (0.362356 --> 0.362303).  Saving model ...
Validation loss decreased (0.362303 --> 0.362127).  Saving model ...
Validation loss decreased (0.362127 --> 0.361953).  Saving model ...
Validation loss decreased (0.361953 --> 0.361770).  Saving model ...
Validation loss decreased (0.361770 --> 0.361550).  Saving model ...
epoch 401, loss 0.4023, train acc 84.50%, f1 0.8306, precision 0.8172, recall 0.8444, auc 0.8449
Validation loss decreased (0.361550 --> 0.361302).  Saving model ...
Validation loss decreased (0.361302 --> 0.361120).  Saving model ...
Validation loss decreased (0.361120 --> 0.361021).  Saving model ...
Validation loss decreased (0.361021 --> 0.360883).  Saving model ...
Validation loss decreased (0.360883 --> 0.360728).  Saving model ...
Validation loss decreased (0.360728 --> 0.360494).  Saving model ...
Validation loss decreased (0.360494 --> 0.360273).  Saving model ...
Validation loss decreased (0.360273 --> 0.360024).  Saving model ...
Validation loss decreased (0.360024 --> 0.359754).  Saving model ...
Validation loss decreased (0.359754 --> 0.359523).  Saving model ...
Validation loss decreased (0.359523 --> 0.359238).  Saving model ...
Validation loss decreased (0.359238 --> 0.358996).  Saving model ...
Validation loss decreased (0.358996 --> 0.358736).  Saving model ...
Validation loss decreased (0.358736 --> 0.358458).  Saving model ...
Validation loss decreased (0.358458 --> 0.358152).  Saving model ...
Validation loss decreased (0.358152 --> 0.357863).  Saving model ...
Validation loss decreased (0.357863 --> 0.357571).  Saving model ...
Validation loss decreased (0.357571 --> 0.357287).  Saving model ...
Validation loss decreased (0.357287 --> 0.356985).  Saving model ...
Validation loss decreased (0.356985 --> 0.356720).  Saving model ...
Validation loss decreased (0.356720 --> 0.356418).  Saving model ...
Validation loss decreased (0.356418 --> 0.356181).  Saving model ...
Validation loss decreased (0.356181 --> 0.355969).  Saving model ...
Validation loss decreased (0.355969 --> 0.355680).  Saving model ...
Validation loss decreased (0.355680 --> 0.355348).  Saving model ...
Validation loss decreased (0.355348 --> 0.354989).  Saving model ...
Validation loss decreased (0.354989 --> 0.354640).  Saving model ...
Validation loss decreased (0.354640 --> 0.354302).  Saving model ...
Validation loss decreased (0.354302 --> 0.354058).  Saving model ...
Validation loss decreased (0.354058 --> 0.353874).  Saving model ...
Validation loss decreased (0.353874 --> 0.353611).  Saving model ...
Validation loss decreased (0.353611 --> 0.353329).  Saving model ...
Validation loss decreased (0.353329 --> 0.353064).  Saving model ...
Validation loss decreased (0.353064 --> 0.352772).  Saving model ...
Validation loss decreased (0.352772 --> 0.352457).  Saving model ...
Validation loss decreased (0.352457 --> 0.352124).  Saving model ...
Validation loss decreased (0.352124 --> 0.351740).  Saving model ...
Validation loss decreased (0.351740 --> 0.351292).  Saving model ...
Validation loss decreased (0.351292 --> 0.350799).  Saving model ...
Validation loss decreased (0.350799 --> 0.350478).  Saving model ...
Validation loss decreased (0.350478 --> 0.350154).  Saving model ...
Validation loss decreased (0.350154 --> 0.349819).  Saving model ...
Validation loss decreased (0.349819 --> 0.349517).  Saving model ...
Validation loss decreased (0.349517 --> 0.349252).  Saving model ...
Validation loss decreased (0.349252 --> 0.349043).  Saving model ...
Validation loss decreased (0.349043 --> 0.348882).  Saving model ...
Validation loss decreased (0.348882 --> 0.348777).  Saving model ...
Validation loss decreased (0.348777 --> 0.348609).  Saving model ...
Validation loss decreased (0.348609 --> 0.348481).  Saving model ...
Validation loss decreased (0.348481 --> 0.348343).  Saving model ...
Validation loss decreased (0.348343 --> 0.348193).  Saving model ...
Validation loss decreased (0.348193 --> 0.348008).  Saving model ...
Validation loss decreased (0.348008 --> 0.347839).  Saving model ...
Validation loss decreased (0.347839 --> 0.347668).  Saving model ...
Validation loss decreased (0.347668 --> 0.347476).  Saving model ...
Validation loss decreased (0.347476 --> 0.347284).  Saving model ...
Validation loss decreased (0.347284 --> 0.347211).  Saving model ...
Validation loss decreased (0.347211 --> 0.347183).  Saving model ...
Validation loss decreased (0.347183 --> 0.347102).  Saving model ...
Validation loss decreased (0.347102 --> 0.346981).  Saving model ...
Validation loss decreased (0.346981 --> 0.346869).  Saving model ...
Validation loss decreased (0.346869 --> 0.346714).  Saving model ...
Validation loss decreased (0.346714 --> 0.346557).  Saving model ...
Validation loss decreased (0.346557 --> 0.346419).  Saving model ...
Validation loss decreased (0.346419 --> 0.346209).  Saving model ...
Validation loss decreased (0.346209 --> 0.345981).  Saving model ...
Validation loss decreased (0.345981 --> 0.345701).  Saving model ...
Validation loss decreased (0.345701 --> 0.345402).  Saving model ...
Validation loss decreased (0.345402 --> 0.345003).  Saving model ...
Validation loss decreased (0.345003 --> 0.344585).  Saving model ...
Validation loss decreased (0.344585 --> 0.344254).  Saving model ...
Validation loss decreased (0.344254 --> 0.343916).  Saving model ...
Validation loss decreased (0.343916 --> 0.343684).  Saving model ...
Validation loss decreased (0.343684 --> 0.343464).  Saving model ...
Validation loss decreased (0.343464 --> 0.343229).  Saving model ...
Validation loss decreased (0.343229 --> 0.342936).  Saving model ...
Validation loss decreased (0.342936 --> 0.342718).  Saving model ...
Validation loss decreased (0.342718 --> 0.342544).  Saving model ...
Validation loss decreased (0.342544 --> 0.342374).  Saving model ...
Validation loss decreased (0.342374 --> 0.342260).  Saving model ...
Validation loss decreased (0.342260 --> 0.342122).  Saving model ...
Validation loss decreased (0.342122 --> 0.342013).  Saving model ...
Validation loss decreased (0.342013 --> 0.341845).  Saving model ...
Validation loss decreased (0.341845 --> 0.341701).  Saving model ...
Validation loss decreased (0.341701 --> 0.341508).  Saving model ...
Validation loss decreased (0.341508 --> 0.341364).  Saving model ...
Validation loss decreased (0.341364 --> 0.341193).  Saving model ...
Validation loss decreased (0.341193 --> 0.341045).  Saving model ...
Validation loss decreased (0.341045 --> 0.340921).  Saving model ...
Validation loss decreased (0.340921 --> 0.340730).  Saving model ...
Validation loss decreased (0.340730 --> 0.340411).  Saving model ...
Validation loss decreased (0.340411 --> 0.340108).  Saving model ...
Validation loss decreased (0.340108 --> 0.339816).  Saving model ...
Validation loss decreased (0.339816 --> 0.339511).  Saving model ...
Validation loss decreased (0.339511 --> 0.339303).  Saving model ...
Validation loss decreased (0.339303 --> 0.339081).  Saving model ...
Validation loss decreased (0.339081 --> 0.338862).  Saving model ...
Validation loss decreased (0.338862 --> 0.338728).  Saving model ...
Validation loss decreased (0.338728 --> 0.338670).  Saving model ...
Validation loss decreased (0.338670 --> 0.338611).  Saving model ...
epoch 501, loss 0.3158, train acc 86.50%, f1 0.8556, precision 0.8247, recall 0.8889, auc 0.8672
Validation loss decreased (0.338611 --> 0.338561).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.338561 --> 0.338437).  Saving model ...
Validation loss decreased (0.338437 --> 0.338365).  Saving model ...
Validation loss decreased (0.338365 --> 0.338346).  Saving model ...
Validation loss decreased (0.338346 --> 0.338237).  Saving model ...
Validation loss decreased (0.338237 --> 0.338216).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.338216 --> 0.338167).  Saving model ...
Validation loss decreased (0.338167 --> 0.338052).  Saving model ...
Validation loss decreased (0.338052 --> 0.337912).  Saving model ...
Validation loss decreased (0.337912 --> 0.337812).  Saving model ...
Validation loss decreased (0.337812 --> 0.337734).  Saving model ...
Validation loss decreased (0.337734 --> 0.337645).  Saving model ...
Validation loss decreased (0.337645 --> 0.337482).  Saving model ...
Validation loss decreased (0.337482 --> 0.337290).  Saving model ...
Validation loss decreased (0.337290 --> 0.337226).  Saving model ...
Validation loss decreased (0.337226 --> 0.337173).  Saving model ...
Validation loss decreased (0.337173 --> 0.337037).  Saving model ...
Validation loss decreased (0.337037 --> 0.336955).  Saving model ...
Validation loss decreased (0.336955 --> 0.336847).  Saving model ...
Validation loss decreased (0.336847 --> 0.336735).  Saving model ...
Validation loss decreased (0.336735 --> 0.336629).  Saving model ...
Validation loss decreased (0.336629 --> 0.336500).  Saving model ...
Validation loss decreased (0.336500 --> 0.336393).  Saving model ...
Validation loss decreased (0.336393 --> 0.336173).  Saving model ...
Validation loss decreased (0.336173 --> 0.335985).  Saving model ...
Validation loss decreased (0.335985 --> 0.335739).  Saving model ...
Validation loss decreased (0.335739 --> 0.335480).  Saving model ...
Validation loss decreased (0.335480 --> 0.335238).  Saving model ...
Validation loss decreased (0.335238 --> 0.335020).  Saving model ...
Validation loss decreased (0.335020 --> 0.334852).  Saving model ...
Validation loss decreased (0.334852 --> 0.334658).  Saving model ...
Validation loss decreased (0.334658 --> 0.334560).  Saving model ...
Validation loss decreased (0.334560 --> 0.334457).  Saving model ...
Validation loss decreased (0.334457 --> 0.334384).  Saving model ...
Validation loss decreased (0.334384 --> 0.334303).  Saving model ...
Validation loss decreased (0.334303 --> 0.334136).  Saving model ...
Validation loss decreased (0.334136 --> 0.334015).  Saving model ...
Validation loss decreased (0.334015 --> 0.333840).  Saving model ...
Validation loss decreased (0.333840 --> 0.333545).  Saving model ...
Validation loss decreased (0.333545 --> 0.333287).  Saving model ...
Validation loss decreased (0.333287 --> 0.333029).  Saving model ...
Validation loss decreased (0.333029 --> 0.332815).  Saving model ...
Validation loss decreased (0.332815 --> 0.332647).  Saving model ...
Validation loss decreased (0.332647 --> 0.332552).  Saving model ...
Validation loss decreased (0.332552 --> 0.332466).  Saving model ...
Validation loss decreased (0.332466 --> 0.332359).  Saving model ...
Validation loss decreased (0.332359 --> 0.332201).  Saving model ...
Validation loss decreased (0.332201 --> 0.332117).  Saving model ...
Validation loss decreased (0.332117 --> 0.332082).  Saving model ...
Validation loss decreased (0.332082 --> 0.332058).  Saving model ...
Validation loss decreased (0.332058 --> 0.332030).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.332030 --> 0.331970).  Saving model ...
Validation loss decreased (0.331970 --> 0.331810).  Saving model ...
Validation loss decreased (0.331810 --> 0.331568).  Saving model ...
Validation loss decreased (0.331568 --> 0.331302).  Saving model ...
Validation loss decreased (0.331302 --> 0.331068).  Saving model ...
Validation loss decreased (0.331068 --> 0.330883).  Saving model ...
Validation loss decreased (0.330883 --> 0.330688).  Saving model ...
Validation loss decreased (0.330688 --> 0.330531).  Saving model ...
Validation loss decreased (0.330531 --> 0.330378).  Saving model ...
Validation loss decreased (0.330378 --> 0.330212).  Saving model ...
Validation loss decreased (0.330212 --> 0.330051).  Saving model ...
Validation loss decreased (0.330051 --> 0.329927).  Saving model ...
Validation loss decreased (0.329927 --> 0.329811).  Saving model ...
Validation loss decreased (0.329811 --> 0.329677).  Saving model ...
Validation loss decreased (0.329677 --> 0.329441).  Saving model ...
Validation loss decreased (0.329441 --> 0.329222).  Saving model ...
Validation loss decreased (0.329222 --> 0.329054).  Saving model ...
Validation loss decreased (0.329054 --> 0.328947).  Saving model ...
Validation loss decreased (0.328947 --> 0.328866).  Saving model ...
Validation loss decreased (0.328866 --> 0.328848).  Saving model ...
Validation loss decreased (0.328848 --> 0.328838).  Saving model ...
Validation loss decreased (0.328838 --> 0.328801).  Saving model ...
Validation loss decreased (0.328801 --> 0.328751).  Saving model ...
Validation loss decreased (0.328751 --> 0.328651).  Saving model ...
Validation loss decreased (0.328651 --> 0.328624).  Saving model ...
Validation loss decreased (0.328624 --> 0.328570).  Saving model ...
Validation loss decreased (0.328570 --> 0.328538).  Saving model ...
Validation loss decreased (0.328538 --> 0.328469).  Saving model ...
Validation loss decreased (0.328469 --> 0.328409).  Saving model ...
Validation loss decreased (0.328409 --> 0.328343).  Saving model ...
Validation loss decreased (0.328343 --> 0.328273).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.328273 --> 0.328166).  Saving model ...
Validation loss decreased (0.328166 --> 0.328012).  Saving model ...
Validation loss decreased (0.328012 --> 0.327913).  Saving model ...
Validation loss decreased (0.327913 --> 0.327818).  Saving model ...
Validation loss decreased (0.327818 --> 0.327747).  Saving model ...
Validation loss decreased (0.327747 --> 0.327637).  Saving model ...
Validation loss decreased (0.327637 --> 0.327524).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.327524 --> 0.327513).  Saving model ...
epoch 601, loss 0.3044, train acc 86.00%, f1 0.8495, precision 0.8229, recall 0.8778, auc 0.8616
Validation loss decreased (0.327513 --> 0.327454).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.327454 --> 0.327424).  Saving model ...
Validation loss decreased (0.327424 --> 0.327271).  Saving model ...
Validation loss decreased (0.327271 --> 0.327054).  Saving model ...
Validation loss decreased (0.327054 --> 0.326872).  Saving model ...
Validation loss decreased (0.326872 --> 0.326648).  Saving model ...
Validation loss decreased (0.326648 --> 0.326508).  Saving model ...
Validation loss decreased (0.326508 --> 0.326344).  Saving model ...
Validation loss decreased (0.326344 --> 0.326170).  Saving model ...
Validation loss decreased (0.326170 --> 0.325979).  Saving model ...
Validation loss decreased (0.325979 --> 0.325836).  Saving model ...
Validation loss decreased (0.325836 --> 0.325704).  Saving model ...
Validation loss decreased (0.325704 --> 0.325517).  Saving model ...
Validation loss decreased (0.325517 --> 0.325369).  Saving model ...
Validation loss decreased (0.325369 --> 0.325175).  Saving model ...
Validation loss decreased (0.325175 --> 0.324995).  Saving model ...
Validation loss decreased (0.324995 --> 0.324844).  Saving model ...
Validation loss decreased (0.324844 --> 0.324683).  Saving model ...
Validation loss decreased (0.324683 --> 0.324457).  Saving model ...
Validation loss decreased (0.324457 --> 0.324209).  Saving model ...
Validation loss decreased (0.324209 --> 0.324007).  Saving model ...
Validation loss decreased (0.324007 --> 0.323838).  Saving model ...
Validation loss decreased (0.323838 --> 0.323665).  Saving model ...
Validation loss decreased (0.323665 --> 0.323546).  Saving model ...
Validation loss decreased (0.323546 --> 0.323457).  Saving model ...
Validation loss decreased (0.323457 --> 0.323288).  Saving model ...
Validation loss decreased (0.323288 --> 0.323047).  Saving model ...
Validation loss decreased (0.323047 --> 0.322722).  Saving model ...
Validation loss decreased (0.322722 --> 0.322430).  Saving model ...
Validation loss decreased (0.322430 --> 0.322085).  Saving model ...
Validation loss decreased (0.322085 --> 0.321798).  Saving model ...
Validation loss decreased (0.321798 --> 0.321550).  Saving model ...
Validation loss decreased (0.321550 --> 0.321316).  Saving model ...
Validation loss decreased (0.321316 --> 0.321148).  Saving model ...
Validation loss decreased (0.321148 --> 0.321048).  Saving model ...
Validation loss decreased (0.321048 --> 0.320909).  Saving model ...
Validation loss decreased (0.320909 --> 0.320764).  Saving model ...
Validation loss decreased (0.320764 --> 0.320710).  Saving model ...
Validation loss decreased (0.320710 --> 0.320592).  Saving model ...
Validation loss decreased (0.320592 --> 0.320488).  Saving model ...
Validation loss decreased (0.320488 --> 0.320328).  Saving model ...
Validation loss decreased (0.320328 --> 0.320092).  Saving model ...
Validation loss decreased (0.320092 --> 0.319866).  Saving model ...
Validation loss decreased (0.319866 --> 0.319595).  Saving model ...
Validation loss decreased (0.319595 --> 0.319383).  Saving model ...
Validation loss decreased (0.319383 --> 0.319179).  Saving model ...
Validation loss decreased (0.319179 --> 0.318943).  Saving model ...
Validation loss decreased (0.318943 --> 0.318679).  Saving model ...
Validation loss decreased (0.318679 --> 0.318370).  Saving model ...
Validation loss decreased (0.318370 --> 0.318114).  Saving model ...
Validation loss decreased (0.318114 --> 0.317851).  Saving model ...
Validation loss decreased (0.317851 --> 0.317596).  Saving model ...
Validation loss decreased (0.317596 --> 0.317436).  Saving model ...
Validation loss decreased (0.317436 --> 0.317286).  Saving model ...
Validation loss decreased (0.317286 --> 0.317125).  Saving model ...
Validation loss decreased (0.317125 --> 0.316924).  Saving model ...
Validation loss decreased (0.316924 --> 0.316815).  Saving model ...
Validation loss decreased (0.316815 --> 0.316649).  Saving model ...
Validation loss decreased (0.316649 --> 0.316511).  Saving model ...
Validation loss decreased (0.316511 --> 0.316363).  Saving model ...
Validation loss decreased (0.316363 --> 0.316223).  Saving model ...
Validation loss decreased (0.316223 --> 0.316080).  Saving model ...
Validation loss decreased (0.316080 --> 0.315986).  Saving model ...
Validation loss decreased (0.315986 --> 0.315950).  Saving model ...
Validation loss decreased (0.315950 --> 0.315928).  Saving model ...
Validation loss decreased (0.315928 --> 0.315898).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 690, loss 0.4274, train acc 85.50%, f1 0.8432, precision 0.8211, recall 0.8667, auc 0.8561



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_notMirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_2
./test_pima/result_MLP_minus_notMirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.62

the Fscore is 0.5869565217391305

the precision is 0.4153846153846154

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_2
----------------------



epoch 1, loss 0.6933, train acc 50.14%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6084, train acc 78.41%, f1 0.7730, precision 0.8124, recall 0.7372, auc 0.7839
epoch 201, loss 0.4989, train acc 80.52%, f1 0.8034, precision 0.8088, recall 0.7981, auc 0.8052
epoch 301, loss 0.3687, train acc 82.28%, f1 0.8224, precision 0.8218, recall 0.8230, auc 0.8228
epoch 401, loss 0.3594, train acc 82.93%, f1 0.8294, precision 0.8264, recall 0.8325, auc 0.8293
epoch 501, loss 0.3469, train acc 83.39%, f1 0.8341, precision 0.8308, recall 0.8375, auc 0.8339
epoch 601, loss 0.3902, train acc 83.75%, f1 0.8376, precision 0.8348, recall 0.8405, auc 0.8375
epoch 701, loss 0.2805, train acc 83.92%, f1 0.8394, precision 0.8357, recall 0.8432, auc 0.8392
epoch 801, loss 0.4152, train acc 83.94%, f1 0.8394, precision 0.8370, recall 0.8418, auc 0.8394
epoch 901, loss 0.3800, train acc 84.03%, f1 0.8405, precision 0.8371, recall 0.8439, auc 0.8403
epoch 1001, loss 0.3790, train acc 84.10%, f1 0.8409, precision 0.8389, recall 0.8430, auc 0.8410
epoch 1101, loss 0.3285, train acc 84.06%, f1 0.8403, precision 0.8397, recall 0.8409, auc 0.8406
epoch 1201, loss 0.3879, train acc 84.10%, f1 0.8407, precision 0.8400, recall 0.8414, auc 0.8410
epoch 1301, loss 0.3929, train acc 84.14%, f1 0.8410, precision 0.8411, recall 0.8408, auc 0.8414
epoch 1401, loss 0.3357, train acc 84.20%, f1 0.8413, precision 0.8427, recall 0.8399, auc 0.8420
epoch 1501, loss 0.2710, train acc 84.20%, f1 0.8414, precision 0.8423, recall 0.8405, auc 0.8420
epoch 1601, loss 0.3626, train acc 84.18%, f1 0.8414, precision 0.8409, recall 0.8420, auc 0.8418
epoch 1701, loss 0.3224, train acc 84.16%, f1 0.8412, precision 0.8410, recall 0.8413, auc 0.8416
epoch 1801, loss 0.3674, train acc 84.15%, f1 0.8414, precision 0.8396, recall 0.8431, auc 0.8415
epoch 1901, loss 0.3059, train acc 84.21%, f1 0.8419, precision 0.8407, recall 0.8432, auc 0.8422
epoch 2001, loss 0.4335, train acc 84.20%, f1 0.8419, precision 0.8403, recall 0.8434, auc 0.8420
epoch 2101, loss 0.2635, train acc 84.22%, f1 0.8420, precision 0.8408, recall 0.8433, auc 0.8422
epoch 2201, loss 0.3413, train acc 84.19%, f1 0.8417, precision 0.8406, recall 0.8429, auc 0.8419
epoch 2301, loss 0.3924, train acc 84.17%, f1 0.8412, precision 0.8413, recall 0.8412, auc 0.8417
epoch 2401, loss 0.3906, train acc 84.19%, f1 0.8415, precision 0.8411, recall 0.8419, auc 0.8419
epoch 2501, loss 0.3457, train acc 84.16%, f1 0.8416, precision 0.8396, recall 0.8436, auc 0.8416
epoch 2601, loss 0.3419, train acc 84.15%, f1 0.8409, precision 0.8421, recall 0.8396, auc 0.8415
epoch 2701, loss 0.3963, train acc 84.16%, f1 0.8409, precision 0.8425, recall 0.8393, auc 0.8416
epoch 2801, loss 0.3851, train acc 84.17%, f1 0.8412, precision 0.8417, recall 0.8407, auc 0.8417
epoch 2901, loss 0.3694, train acc 84.18%, f1 0.8413, precision 0.8418, recall 0.8408, auc 0.8418
epoch 3001, loss 0.2846, train acc 84.11%, f1 0.8409, precision 0.8401, recall 0.8416, auc 0.8411
epoch 3101, loss 0.3453, train acc 84.17%, f1 0.8414, precision 0.8409, recall 0.8419, auc 0.8417
epoch 3201, loss 0.4232, train acc 84.23%, f1 0.8415, precision 0.8434, recall 0.8396, auc 0.8423
epoch 3301, loss 0.2758, train acc 84.21%, f1 0.8416, precision 0.8421, recall 0.8411, auc 0.8421
epoch 3401, loss 0.2592, train acc 84.20%, f1 0.8416, precision 0.8414, recall 0.8417, auc 0.8420
epoch 3501, loss 0.3959, train acc 84.21%, f1 0.8415, precision 0.8422, recall 0.8408, auc 0.8421
epoch 3601, loss 0.3148, train acc 84.18%, f1 0.8413, precision 0.8420, recall 0.8405, auc 0.8418
epoch 3701, loss 0.5051, train acc 84.16%, f1 0.8410, precision 0.8420, recall 0.8401, auc 0.8416
epoch 3801, loss 0.2347, train acc 84.19%, f1 0.8417, precision 0.8408, recall 0.8425, auc 0.8419
epoch 3901, loss 0.3611, train acc 84.21%, f1 0.8415, precision 0.8425, recall 0.8405, auc 0.8421
epoch 4001, loss 0.3071, train acc 84.15%, f1 0.8409, precision 0.8419, recall 0.8399, auc 0.8415
epoch 4101, loss 0.4323, train acc 84.20%, f1 0.8418, precision 0.8404, recall 0.8432, auc 0.8420
epoch 4201, loss 0.2515, train acc 84.14%, f1 0.8413, precision 0.8398, recall 0.8428, auc 0.8414
epoch 4301, loss 0.3675, train acc 84.22%, f1 0.8418, precision 0.8413, recall 0.8423, auc 0.8422
epoch 4401, loss 0.5120, train acc 84.23%, f1 0.8419, precision 0.8420, recall 0.8418, auc 0.8423
epoch 4501, loss 0.4239, train acc 84.23%, f1 0.8417, precision 0.8428, recall 0.8406, auc 0.8423
epoch 4601, loss 0.3037, train acc 84.22%, f1 0.8421, precision 0.8404, recall 0.8438, auc 0.8422
epoch 4701, loss 0.4758, train acc 84.26%, f1 0.8423, precision 0.8415, recall 0.8431, auc 0.8426
epoch 4801, loss 0.3110, train acc 84.31%, f1 0.8427, precision 0.8425, recall 0.8428, auc 0.8431
epoch 4901, loss 0.3801, train acc 84.30%, f1 0.8427, precision 0.8421, recall 0.8434, auc 0.8430
epoch 5001, loss 0.2975, train acc 84.34%, f1 0.8430, precision 0.8426, recall 0.8434, auc 0.8434
epoch 5101, loss 0.4045, train acc 84.34%, f1 0.8430, precision 0.8432, recall 0.8427, auc 0.8434
epoch 5201, loss 0.4082, train acc 84.35%, f1 0.8432, precision 0.8423, recall 0.8442, auc 0.8435
epoch 5301, loss 0.3941, train acc 84.36%, f1 0.8431, precision 0.8434, recall 0.8428, auc 0.8436
epoch 5401, loss 0.3984, train acc 84.40%, f1 0.8437, precision 0.8433, recall 0.8440, auc 0.8440
epoch 5501, loss 0.2901, train acc 84.38%, f1 0.8435, precision 0.8428, recall 0.8442, auc 0.8438
epoch 5601, loss 0.4470, train acc 84.40%, f1 0.8438, precision 0.8426, recall 0.8449, auc 0.8440
epoch 5701, loss 0.2804, train acc 84.41%, f1 0.8439, precision 0.8423, recall 0.8455, auc 0.8441
epoch 5801, loss 0.4324, train acc 84.43%, f1 0.8439, precision 0.8436, recall 0.8442, auc 0.8443
epoch 5901, loss 0.4381, train acc 84.43%, f1 0.8437, precision 0.8446, recall 0.8428, auc 0.8443
epoch 6001, loss 0.4179, train acc 84.44%, f1 0.8439, precision 0.8446, recall 0.8432, auc 0.8444
epoch 6101, loss 0.4476, train acc 84.45%, f1 0.8440, precision 0.8448, recall 0.8431, auc 0.8445
epoch 6201, loss 0.3204, train acc 84.43%, f1 0.8440, precision 0.8432, recall 0.8448, auc 0.8443
epoch 6301, loss 0.4920, train acc 84.50%, f1 0.8445, precision 0.8449, recall 0.8441, auc 0.8450
epoch 6401, loss 0.3304, train acc 84.50%, f1 0.8448, precision 0.8438, recall 0.8458, auc 0.8450
epoch 6501, loss 0.4079, train acc 84.52%, f1 0.8447, precision 0.8449, recall 0.8445, auc 0.8452
epoch 6601, loss 0.3419, train acc 84.54%, f1 0.8451, precision 0.8442, recall 0.8461, auc 0.8454
epoch 6701, loss 0.3945, train acc 84.55%, f1 0.8458, precision 0.8419, recall 0.8497, auc 0.8455
epoch 6801, loss 0.3869, train acc 84.57%, f1 0.8454, precision 0.8446, recall 0.8462, auc 0.8457
epoch 6901, loss 0.4984, train acc 84.62%, f1 0.8460, precision 0.8448, recall 0.8472, auc 0.8462
epoch 7001, loss 0.3739, train acc 84.62%, f1 0.8461, precision 0.8445, recall 0.8477, auc 0.8462
epoch 7101, loss 0.5325, train acc 84.63%, f1 0.8459, precision 0.8455, recall 0.8464, auc 0.8463
epoch 7201, loss 0.3919, train acc 84.69%, f1 0.8462, precision 0.8478, recall 0.8446, auc 0.8469
epoch 7301, loss 0.3388, train acc 84.63%, f1 0.8456, precision 0.8475, recall 0.8436, auc 0.8463
epoch 7401, loss 0.3646, train acc 84.71%, f1 0.8468, precision 0.8463, recall 0.8472, auc 0.8471
epoch 7501, loss 0.3827, train acc 84.72%, f1 0.8469, precision 0.8466, recall 0.8471, auc 0.8472
epoch 7601, loss 0.3953, train acc 84.69%, f1 0.8470, precision 0.8441, recall 0.8500, auc 0.8469
epoch 7701, loss 0.3406, train acc 84.73%, f1 0.8464, precision 0.8493, recall 0.8434, auc 0.8473
epoch 7801, loss 0.4258, train acc 84.75%, f1 0.8468, precision 0.8483, recall 0.8454, auc 0.8475
epoch 7901, loss 0.3519, train acc 84.77%, f1 0.8475, precision 0.8464, recall 0.8486, auc 0.8477
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_notMirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_2
./test_pima/result_MLP_minus_notMirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.615

the Fscore is 0.5837837837837838

the precision is 0.4122137404580153

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_2
----------------------



epoch 1, loss 0.6931, train acc 49.80%, f1 0.6649, precision 0.4980, recall 1.0000, auc 0.5000
epoch 101, loss 0.5773, train acc 77.62%, f1 0.7953, precision 0.7305, recall 0.8726, auc 0.7766
epoch 201, loss 0.4818, train acc 80.72%, f1 0.8094, precision 0.7971, recall 0.8220, auc 0.8072
epoch 301, loss 0.3634, train acc 82.20%, f1 0.8209, precision 0.8226, recall 0.8193, auc 0.8220
epoch 401, loss 0.3771, train acc 83.02%, f1 0.8291, precision 0.8309, recall 0.8272, auc 0.8301
epoch 501, loss 0.3852, train acc 83.41%, f1 0.8328, precision 0.8361, recall 0.8295, auc 0.8341
epoch 601, loss 0.3543, train acc 83.72%, f1 0.8354, precision 0.8410, recall 0.8298, auc 0.8371
epoch 701, loss 0.3083, train acc 83.90%, f1 0.8378, precision 0.8403, recall 0.8354, auc 0.8389
epoch 801, loss 0.3639, train acc 83.97%, f1 0.8383, precision 0.8423, recall 0.8345, auc 0.8397
epoch 901, loss 0.3357, train acc 84.01%, f1 0.8385, precision 0.8434, recall 0.8338, auc 0.8401
epoch 1001, loss 0.3680, train acc 84.12%, f1 0.8400, precision 0.8425, recall 0.8375, auc 0.8411
epoch 1101, loss 0.2254, train acc 84.11%, f1 0.8399, precision 0.8426, recall 0.8372, auc 0.8410
epoch 1201, loss 0.3651, train acc 84.14%, f1 0.8402, precision 0.8431, recall 0.8374, auc 0.8414
epoch 1301, loss 0.2959, train acc 84.13%, f1 0.8401, precision 0.8427, recall 0.8376, auc 0.8412
epoch 1401, loss 0.3350, train acc 84.15%, f1 0.8406, precision 0.8420, recall 0.8392, auc 0.8415
epoch 1501, loss 0.3174, train acc 84.08%, f1 0.8396, precision 0.8424, recall 0.8367, auc 0.8407
epoch 1601, loss 0.3260, train acc 84.11%, f1 0.8401, precision 0.8423, recall 0.8378, auc 0.8411
epoch 1701, loss 0.3764, train acc 84.14%, f1 0.8404, precision 0.8422, recall 0.8386, auc 0.8413
epoch 1801, loss 0.2871, train acc 84.14%, f1 0.8405, precision 0.8415, recall 0.8395, auc 0.8413
epoch 1901, loss 0.4008, train acc 84.17%, f1 0.8410, precision 0.8412, recall 0.8409, auc 0.8417
epoch 2001, loss 0.3237, train acc 84.26%, f1 0.8417, precision 0.8428, recall 0.8407, auc 0.8426
epoch 2101, loss 0.4014, train acc 84.23%, f1 0.8412, precision 0.8436, recall 0.8389, auc 0.8423
epoch 2201, loss 0.4841, train acc 84.13%, f1 0.8407, precision 0.8408, recall 0.8405, auc 0.8413
epoch 2301, loss 0.3335, train acc 84.13%, f1 0.8407, precision 0.8403, recall 0.8411, auc 0.8413
epoch 2401, loss 0.3566, train acc 84.17%, f1 0.8410, precision 0.8413, recall 0.8407, auc 0.8417
epoch 2501, loss 0.3255, train acc 84.19%, f1 0.8411, precision 0.8419, recall 0.8404, auc 0.8419
epoch 2601, loss 0.3158, train acc 84.19%, f1 0.8411, precision 0.8421, recall 0.8401, auc 0.8419
epoch 2701, loss 0.4471, train acc 84.15%, f1 0.8410, precision 0.8406, recall 0.8414, auc 0.8415
epoch 2801, loss 0.4647, train acc 84.18%, f1 0.8409, precision 0.8420, recall 0.8398, auc 0.8418
epoch 2901, loss 0.4387, train acc 84.19%, f1 0.8414, precision 0.8410, recall 0.8417, auc 0.8419
epoch 3001, loss 0.4569, train acc 84.18%, f1 0.8411, precision 0.8413, recall 0.8409, auc 0.8418
epoch 3101, loss 0.3566, train acc 84.16%, f1 0.8411, precision 0.8402, recall 0.8421, auc 0.8416
epoch 3201, loss 0.4405, train acc 84.14%, f1 0.8407, precision 0.8411, recall 0.8403, auc 0.8414
epoch 3301, loss 0.4801, train acc 84.14%, f1 0.8407, precision 0.8411, recall 0.8403, auc 0.8414
epoch 3401, loss 0.3246, train acc 84.13%, f1 0.8406, precision 0.8411, recall 0.8400, auc 0.8413
epoch 3501, loss 0.3220, train acc 84.15%, f1 0.8410, precision 0.8401, recall 0.8420, auc 0.8415
epoch 3601, loss 0.4243, train acc 84.14%, f1 0.8409, precision 0.8400, recall 0.8419, auc 0.8414
epoch 3701, loss 0.3163, train acc 84.18%, f1 0.8415, precision 0.8397, recall 0.8433, auc 0.8418
epoch 3801, loss 0.4536, train acc 84.17%, f1 0.8411, precision 0.8408, recall 0.8414, auc 0.8417
epoch 3901, loss 0.3188, train acc 84.14%, f1 0.8409, precision 0.8405, recall 0.8412, auc 0.8414
epoch 4001, loss 0.5252, train acc 84.21%, f1 0.8416, precision 0.8413, recall 0.8419, auc 0.8421
epoch 4101, loss 0.3016, train acc 84.14%, f1 0.8408, precision 0.8408, recall 0.8408, auc 0.8414
epoch 4201, loss 0.3587, train acc 84.18%, f1 0.8417, precision 0.8390, recall 0.8444, auc 0.8418
epoch 4301, loss 0.3391, train acc 84.22%, f1 0.8419, precision 0.8404, recall 0.8434, auc 0.8422
epoch 4401, loss 0.2910, train acc 84.23%, f1 0.8419, precision 0.8407, recall 0.8430, auc 0.8423
epoch 4501, loss 0.3536, train acc 84.22%, f1 0.8416, precision 0.8414, recall 0.8418, auc 0.8422
epoch 4601, loss 0.2287, train acc 84.21%, f1 0.8413, precision 0.8419, recall 0.8408, auc 0.8421
epoch 4701, loss 0.4049, train acc 84.27%, f1 0.8418, precision 0.8433, recall 0.8404, auc 0.8427
epoch 4801, loss 0.3497, train acc 84.30%, f1 0.8421, precision 0.8433, recall 0.8410, auc 0.8430
epoch 4901, loss 0.3501, train acc 84.30%, f1 0.8424, precision 0.8425, recall 0.8423, auc 0.8430
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_notMirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_2
./test_pima/result_MLP_minus_notMirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.63

the Fscore is 0.5934065934065934

the precision is 0.421875

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_2
----------------------



epoch 1, loss 0.6931, train acc 49.78%, f1 0.6647, precision 0.4978, recall 1.0000, auc 0.5000
epoch 101, loss 0.6504, train acc 78.17%, f1 0.7882, precision 0.7622, recall 0.8160, auc 0.7818
epoch 201, loss 0.4710, train acc 80.74%, f1 0.8072, precision 0.8048, recall 0.8095, auc 0.8075
epoch 301, loss 0.3954, train acc 82.25%, f1 0.8224, precision 0.8195, recall 0.8254, auc 0.8226
epoch 401, loss 0.4012, train acc 82.98%, f1 0.8295, precision 0.8277, recall 0.8312, auc 0.8299
epoch 501, loss 0.3549, train acc 83.50%, f1 0.8343, precision 0.8340, recall 0.8346, auc 0.8350
epoch 601, loss 0.3744, train acc 83.70%, f1 0.8363, precision 0.8365, recall 0.8361, auc 0.8370
epoch 701, loss 0.3323, train acc 83.92%, f1 0.8386, precision 0.8382, recall 0.8389, auc 0.8392
epoch 801, loss 0.4238, train acc 84.02%, f1 0.8395, precision 0.8394, recall 0.8396, auc 0.8402
epoch 901, loss 0.2574, train acc 84.05%, f1 0.8398, precision 0.8400, recall 0.8395, auc 0.8405
epoch 1001, loss 0.3093, train acc 84.09%, f1 0.8401, precision 0.8409, recall 0.8392, auc 0.8409
epoch 1101, loss 0.3606, train acc 84.14%, f1 0.8407, precision 0.8404, recall 0.8410, auc 0.8414
epoch 1201, loss 0.3893, train acc 84.11%, f1 0.8404, precision 0.8401, recall 0.8408, auc 0.8411
epoch 1301, loss 0.2934, train acc 84.08%, f1 0.8405, precision 0.8383, recall 0.8428, auc 0.8408
epoch 1401, loss 0.3137, train acc 84.16%, f1 0.8410, precision 0.8407, recall 0.8412, auc 0.8416
epoch 1501, loss 0.2802, train acc 84.21%, f1 0.8415, precision 0.8409, recall 0.8420, auc 0.8421
epoch 1601, loss 0.3402, train acc 84.14%, f1 0.8406, precision 0.8412, recall 0.8401, auc 0.8414
epoch 1701, loss 0.4207, train acc 84.16%, f1 0.8411, precision 0.8401, recall 0.8421, auc 0.8416
epoch 1801, loss 0.3243, train acc 84.19%, f1 0.8415, precision 0.8402, recall 0.8427, auc 0.8419
epoch 1901, loss 0.4166, train acc 84.20%, f1 0.8413, precision 0.8414, recall 0.8413, auc 0.8420
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_minus_notMirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_2
./test_pima/result_MLP_minus_notMirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6

the Fscore is 0.5744680851063829

the precision is 0.40298507462686567

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_2
----------------------



epoch 1, loss 0.6938, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.692398).  Saving model ...
Validation loss decreased (0.692398 --> 0.691031).  Saving model ...
Validation loss decreased (0.691031 --> 0.689686).  Saving model ...
Validation loss decreased (0.689686 --> 0.688362).  Saving model ...
Validation loss decreased (0.688362 --> 0.687060).  Saving model ...
Validation loss decreased (0.687060 --> 0.685779).  Saving model ...
Validation loss decreased (0.685779 --> 0.684520).  Saving model ...
Validation loss decreased (0.684520 --> 0.683281).  Saving model ...
Validation loss decreased (0.683281 --> 0.682064).  Saving model ...
Validation loss decreased (0.682064 --> 0.680867).  Saving model ...
Validation loss decreased (0.680867 --> 0.679691).  Saving model ...
Validation loss decreased (0.679691 --> 0.678534).  Saving model ...
Validation loss decreased (0.678534 --> 0.677397).  Saving model ...
Validation loss decreased (0.677397 --> 0.676279).  Saving model ...
Validation loss decreased (0.676279 --> 0.675179).  Saving model ...
Validation loss decreased (0.675179 --> 0.674097).  Saving model ...
Validation loss decreased (0.674097 --> 0.673033).  Saving model ...
Validation loss decreased (0.673033 --> 0.671986).  Saving model ...
Validation loss decreased (0.671986 --> 0.670956).  Saving model ...
Validation loss decreased (0.670956 --> 0.669942).  Saving model ...
Validation loss decreased (0.669942 --> 0.668944).  Saving model ...
Validation loss decreased (0.668944 --> 0.667962).  Saving model ...
Validation loss decreased (0.667962 --> 0.666995).  Saving model ...
Validation loss decreased (0.666995 --> 0.666043).  Saving model ...
Validation loss decreased (0.666043 --> 0.665106).  Saving model ...
Validation loss decreased (0.665106 --> 0.664183).  Saving model ...
Validation loss decreased (0.664183 --> 0.663274).  Saving model ...
Validation loss decreased (0.663274 --> 0.662380).  Saving model ...
Validation loss decreased (0.662380 --> 0.661499).  Saving model ...
Validation loss decreased (0.661499 --> 0.660632).  Saving model ...
Validation loss decreased (0.660632 --> 0.659778).  Saving model ...
Validation loss decreased (0.659778 --> 0.658938).  Saving model ...
Validation loss decreased (0.658938 --> 0.658110).  Saving model ...
Validation loss decreased (0.658110 --> 0.657296).  Saving model ...
Validation loss decreased (0.657296 --> 0.656494).  Saving model ...
Validation loss decreased (0.656494 --> 0.655704).  Saving model ...
Validation loss decreased (0.655704 --> 0.654927).  Saving model ...
Validation loss decreased (0.654927 --> 0.654162).  Saving model ...
Validation loss decreased (0.654162 --> 0.653409).  Saving model ...
Validation loss decreased (0.653409 --> 0.652667).  Saving model ...
Validation loss decreased (0.652667 --> 0.651938).  Saving model ...
Validation loss decreased (0.651938 --> 0.651219).  Saving model ...
Validation loss decreased (0.651219 --> 0.650512).  Saving model ...
Validation loss decreased (0.650512 --> 0.649816).  Saving model ...
Validation loss decreased (0.649816 --> 0.649131).  Saving model ...
Validation loss decreased (0.649131 --> 0.648457).  Saving model ...
Validation loss decreased (0.648457 --> 0.647793).  Saving model ...
Validation loss decreased (0.647793 --> 0.647139).  Saving model ...
Validation loss decreased (0.647139 --> 0.646496).  Saving model ...
Validation loss decreased (0.646496 --> 0.645862).  Saving model ...
Validation loss decreased (0.645862 --> 0.645239).  Saving model ...
Validation loss decreased (0.645239 --> 0.644625).  Saving model ...
Validation loss decreased (0.644625 --> 0.644021).  Saving model ...
Validation loss decreased (0.644021 --> 0.643426).  Saving model ...
Validation loss decreased (0.643426 --> 0.642840).  Saving model ...
Validation loss decreased (0.642840 --> 0.642264).  Saving model ...
Validation loss decreased (0.642264 --> 0.641696).  Saving model ...
Validation loss decreased (0.641696 --> 0.641136).  Saving model ...
Validation loss decreased (0.641136 --> 0.640585).  Saving model ...
Validation loss decreased (0.640585 --> 0.640043).  Saving model ...
Validation loss decreased (0.640043 --> 0.639509).  Saving model ...
Validation loss decreased (0.639509 --> 0.638982).  Saving model ...
Validation loss decreased (0.638982 --> 0.638464).  Saving model ...
Validation loss decreased (0.638464 --> 0.637953).  Saving model ...
Validation loss decreased (0.637953 --> 0.637449).  Saving model ...
Validation loss decreased (0.637449 --> 0.636953).  Saving model ...
Validation loss decreased (0.636953 --> 0.636464).  Saving model ...
Validation loss decreased (0.636464 --> 0.635982).  Saving model ...
Validation loss decreased (0.635982 --> 0.635507).  Saving model ...
Validation loss decreased (0.635507 --> 0.635038).  Saving model ...
Validation loss decreased (0.635038 --> 0.634576).  Saving model ...
Validation loss decreased (0.634576 --> 0.634121).  Saving model ...
Validation loss decreased (0.634121 --> 0.633671).  Saving model ...
Validation loss decreased (0.633671 --> 0.633228).  Saving model ...
Validation loss decreased (0.633228 --> 0.632791).  Saving model ...
Validation loss decreased (0.632791 --> 0.632359).  Saving model ...
Validation loss decreased (0.632359 --> 0.631933).  Saving model ...
Validation loss decreased (0.631933 --> 0.631512).  Saving model ...
Validation loss decreased (0.631512 --> 0.631096).  Saving model ...
Validation loss decreased (0.631096 --> 0.630686).  Saving model ...
Validation loss decreased (0.630686 --> 0.630281).  Saving model ...
Validation loss decreased (0.630281 --> 0.629881).  Saving model ...
Validation loss decreased (0.629881 --> 0.629485).  Saving model ...
Validation loss decreased (0.629485 --> 0.629094).  Saving model ...
Validation loss decreased (0.629094 --> 0.628707).  Saving model ...
Validation loss decreased (0.628707 --> 0.628325).  Saving model ...
Validation loss decreased (0.628325 --> 0.627947).  Saving model ...
Validation loss decreased (0.627947 --> 0.627573).  Saving model ...
Validation loss decreased (0.627573 --> 0.627203).  Saving model ...
Validation loss decreased (0.627203 --> 0.626837).  Saving model ...
Validation loss decreased (0.626837 --> 0.626475).  Saving model ...
Validation loss decreased (0.626475 --> 0.626116).  Saving model ...
Validation loss decreased (0.626116 --> 0.625760).  Saving model ...
Validation loss decreased (0.625760 --> 0.625408).  Saving model ...
Validation loss decreased (0.625408 --> 0.625059).  Saving model ...
Validation loss decreased (0.625059 --> 0.624713).  Saving model ...
Validation loss decreased (0.624713 --> 0.624371).  Saving model ...
Validation loss decreased (0.624371 --> 0.624031).  Saving model ...
Validation loss decreased (0.624031 --> 0.623694).  Saving model ...
Validation loss decreased (0.623694 --> 0.623360).  Saving model ...
epoch 101, loss 0.6234, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.623360 --> 0.623028).  Saving model ...
Validation loss decreased (0.623028 --> 0.622699).  Saving model ...
Validation loss decreased (0.622699 --> 0.622372).  Saving model ...
Validation loss decreased (0.622372 --> 0.622048).  Saving model ...
Validation loss decreased (0.622048 --> 0.621726).  Saving model ...
Validation loss decreased (0.621726 --> 0.621406).  Saving model ...
Validation loss decreased (0.621406 --> 0.621088).  Saving model ...
Validation loss decreased (0.621088 --> 0.620772).  Saving model ...
Validation loss decreased (0.620772 --> 0.620458).  Saving model ...
Validation loss decreased (0.620458 --> 0.620146).  Saving model ...
Validation loss decreased (0.620146 --> 0.619836).  Saving model ...
Validation loss decreased (0.619836 --> 0.619528).  Saving model ...
Validation loss decreased (0.619528 --> 0.619221).  Saving model ...
Validation loss decreased (0.619221 --> 0.618916).  Saving model ...
Validation loss decreased (0.618916 --> 0.618612).  Saving model ...
Validation loss decreased (0.618612 --> 0.618310).  Saving model ...
Validation loss decreased (0.618310 --> 0.618009).  Saving model ...
Validation loss decreased (0.618009 --> 0.617710).  Saving model ...
Validation loss decreased (0.617710 --> 0.617412).  Saving model ...
Validation loss decreased (0.617412 --> 0.617115).  Saving model ...
Validation loss decreased (0.617115 --> 0.616819).  Saving model ...
Validation loss decreased (0.616819 --> 0.616525).  Saving model ...
Validation loss decreased (0.616525 --> 0.616232).  Saving model ...
Validation loss decreased (0.616232 --> 0.615939).  Saving model ...
Validation loss decreased (0.615939 --> 0.615648).  Saving model ...
Validation loss decreased (0.615648 --> 0.615358).  Saving model ...
Validation loss decreased (0.615358 --> 0.615069).  Saving model ...
Validation loss decreased (0.615069 --> 0.614781).  Saving model ...
Validation loss decreased (0.614781 --> 0.614494).  Saving model ...
Validation loss decreased (0.614494 --> 0.614207).  Saving model ...
Validation loss decreased (0.614207 --> 0.613922).  Saving model ...
Validation loss decreased (0.613922 --> 0.613637).  Saving model ...
Validation loss decreased (0.613637 --> 0.613353).  Saving model ...
Validation loss decreased (0.613353 --> 0.613070).  Saving model ...
Validation loss decreased (0.613070 --> 0.612787).  Saving model ...
Validation loss decreased (0.612787 --> 0.612505).  Saving model ...
Validation loss decreased (0.612505 --> 0.612224).  Saving model ...
Validation loss decreased (0.612224 --> 0.611943).  Saving model ...
Validation loss decreased (0.611943 --> 0.611664).  Saving model ...
Validation loss decreased (0.611664 --> 0.611384).  Saving model ...
Validation loss decreased (0.611384 --> 0.611106).  Saving model ...
Validation loss decreased (0.611106 --> 0.610827).  Saving model ...
Validation loss decreased (0.610827 --> 0.610550).  Saving model ...
Validation loss decreased (0.610550 --> 0.610273).  Saving model ...
Validation loss decreased (0.610273 --> 0.609996).  Saving model ...
Validation loss decreased (0.609996 --> 0.609720).  Saving model ...
Validation loss decreased (0.609720 --> 0.609444).  Saving model ...
Validation loss decreased (0.609444 --> 0.609169).  Saving model ...
Validation loss decreased (0.609169 --> 0.608894).  Saving model ...
Validation loss decreased (0.608894 --> 0.608619).  Saving model ...
Validation loss decreased (0.608619 --> 0.608345).  Saving model ...
Validation loss decreased (0.608345 --> 0.608071).  Saving model ...
Validation loss decreased (0.608071 --> 0.607798).  Saving model ...
Validation loss decreased (0.607798 --> 0.607525).  Saving model ...
Validation loss decreased (0.607525 --> 0.607252).  Saving model ...
Validation loss decreased (0.607252 --> 0.606980).  Saving model ...
Validation loss decreased (0.606980 --> 0.606707).  Saving model ...
Validation loss decreased (0.606707 --> 0.606435).  Saving model ...
Validation loss decreased (0.606435 --> 0.606164).  Saving model ...
Validation loss decreased (0.606164 --> 0.605892).  Saving model ...
Validation loss decreased (0.605892 --> 0.605621).  Saving model ...
Validation loss decreased (0.605621 --> 0.605350).  Saving model ...
Validation loss decreased (0.605350 --> 0.605079).  Saving model ...
Validation loss decreased (0.605079 --> 0.604809).  Saving model ...
Validation loss decreased (0.604809 --> 0.604538).  Saving model ...
Validation loss decreased (0.604538 --> 0.604268).  Saving model ...
Validation loss decreased (0.604268 --> 0.603998).  Saving model ...
Validation loss decreased (0.603998 --> 0.603728).  Saving model ...
Validation loss decreased (0.603728 --> 0.603458).  Saving model ...
Validation loss decreased (0.603458 --> 0.603188).  Saving model ...
Validation loss decreased (0.603188 --> 0.602919).  Saving model ...
Validation loss decreased (0.602919 --> 0.602649).  Saving model ...
Validation loss decreased (0.602649 --> 0.602380).  Saving model ...
Validation loss decreased (0.602380 --> 0.602110).  Saving model ...
Validation loss decreased (0.602110 --> 0.601841).  Saving model ...
Validation loss decreased (0.601841 --> 0.601572).  Saving model ...
Validation loss decreased (0.601572 --> 0.601303).  Saving model ...
Validation loss decreased (0.601303 --> 0.601033).  Saving model ...
Validation loss decreased (0.601033 --> 0.600764).  Saving model ...
Validation loss decreased (0.600764 --> 0.600495).  Saving model ...
Validation loss decreased (0.600495 --> 0.600226).  Saving model ...
Validation loss decreased (0.600226 --> 0.599957).  Saving model ...
Validation loss decreased (0.599957 --> 0.599688).  Saving model ...
Validation loss decreased (0.599688 --> 0.599418).  Saving model ...
Validation loss decreased (0.599418 --> 0.599149).  Saving model ...
Validation loss decreased (0.599149 --> 0.598880).  Saving model ...
Validation loss decreased (0.598880 --> 0.598611).  Saving model ...
Validation loss decreased (0.598611 --> 0.598342).  Saving model ...
Validation loss decreased (0.598342 --> 0.598072).  Saving model ...
Validation loss decreased (0.598072 --> 0.597803).  Saving model ...
Validation loss decreased (0.597803 --> 0.597534).  Saving model ...
Validation loss decreased (0.597534 --> 0.597264).  Saving model ...
Validation loss decreased (0.597264 --> 0.596995).  Saving model ...
Validation loss decreased (0.596995 --> 0.596725).  Saving model ...
Validation loss decreased (0.596725 --> 0.596455).  Saving model ...
Validation loss decreased (0.596455 --> 0.596186).  Saving model ...
Validation loss decreased (0.596186 --> 0.595916).  Saving model ...
Validation loss decreased (0.595916 --> 0.595646).  Saving model ...
Validation loss decreased (0.595646 --> 0.595376).  Saving model ...
Validation loss decreased (0.595376 --> 0.595106).  Saving model ...
epoch 201, loss 0.5951, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.595106 --> 0.594836).  Saving model ...
Validation loss decreased (0.594836 --> 0.594566).  Saving model ...
Validation loss decreased (0.594566 --> 0.594296).  Saving model ...
Validation loss decreased (0.594296 --> 0.594025).  Saving model ...
Validation loss decreased (0.594025 --> 0.593755).  Saving model ...
Validation loss decreased (0.593755 --> 0.593484).  Saving model ...
Validation loss decreased (0.593484 --> 0.593213).  Saving model ...
Validation loss decreased (0.593213 --> 0.592943).  Saving model ...
Validation loss decreased (0.592943 --> 0.592672).  Saving model ...
Validation loss decreased (0.592672 --> 0.592401).  Saving model ...
Validation loss decreased (0.592401 --> 0.592130).  Saving model ...
Validation loss decreased (0.592130 --> 0.591859).  Saving model ...
Validation loss decreased (0.591859 --> 0.591588).  Saving model ...
Validation loss decreased (0.591588 --> 0.591317).  Saving model ...
Validation loss decreased (0.591317 --> 0.591045).  Saving model ...
Validation loss decreased (0.591045 --> 0.590774).  Saving model ...
Validation loss decreased (0.590774 --> 0.590503).  Saving model ...
Validation loss decreased (0.590503 --> 0.590231).  Saving model ...
Validation loss decreased (0.590231 --> 0.589960).  Saving model ...
Validation loss decreased (0.589960 --> 0.589688).  Saving model ...
Validation loss decreased (0.589688 --> 0.589416).  Saving model ...
Validation loss decreased (0.589416 --> 0.589144).  Saving model ...
Validation loss decreased (0.589144 --> 0.588872).  Saving model ...
Validation loss decreased (0.588872 --> 0.588601).  Saving model ...
Validation loss decreased (0.588601 --> 0.588329).  Saving model ...
Validation loss decreased (0.588329 --> 0.588057).  Saving model ...
Validation loss decreased (0.588057 --> 0.587785).  Saving model ...
Validation loss decreased (0.587785 --> 0.587513).  Saving model ...
Validation loss decreased (0.587513 --> 0.587240).  Saving model ...
Validation loss decreased (0.587240 --> 0.586968).  Saving model ...
Validation loss decreased (0.586968 --> 0.586696).  Saving model ...
Validation loss decreased (0.586696 --> 0.586424).  Saving model ...
Validation loss decreased (0.586424 --> 0.586152).  Saving model ...
Validation loss decreased (0.586152 --> 0.585880).  Saving model ...
Validation loss decreased (0.585880 --> 0.585608).  Saving model ...
Validation loss decreased (0.585608 --> 0.585335).  Saving model ...
Validation loss decreased (0.585335 --> 0.585063).  Saving model ...
Validation loss decreased (0.585063 --> 0.584791).  Saving model ...
Validation loss decreased (0.584791 --> 0.584519).  Saving model ...
Validation loss decreased (0.584519 --> 0.584247).  Saving model ...
Validation loss decreased (0.584247 --> 0.583975).  Saving model ...
Validation loss decreased (0.583975 --> 0.583703).  Saving model ...
Validation loss decreased (0.583703 --> 0.583431).  Saving model ...
Validation loss decreased (0.583431 --> 0.583159).  Saving model ...
Validation loss decreased (0.583159 --> 0.582887).  Saving model ...
Validation loss decreased (0.582887 --> 0.582615).  Saving model ...
Validation loss decreased (0.582615 --> 0.582343).  Saving model ...
Validation loss decreased (0.582343 --> 0.582071).  Saving model ...
Validation loss decreased (0.582071 --> 0.581800).  Saving model ...
Validation loss decreased (0.581800 --> 0.581528).  Saving model ...
Validation loss decreased (0.581528 --> 0.581257).  Saving model ...
Validation loss decreased (0.581257 --> 0.580985).  Saving model ...
Validation loss decreased (0.580985 --> 0.580714).  Saving model ...
Validation loss decreased (0.580714 --> 0.580443).  Saving model ...
Validation loss decreased (0.580443 --> 0.580172).  Saving model ...
Validation loss decreased (0.580172 --> 0.579901).  Saving model ...
Validation loss decreased (0.579901 --> 0.579630).  Saving model ...
Validation loss decreased (0.579630 --> 0.579359).  Saving model ...
Validation loss decreased (0.579359 --> 0.579089).  Saving model ...
Validation loss decreased (0.579089 --> 0.578818).  Saving model ...
Validation loss decreased (0.578818 --> 0.578548).  Saving model ...
Validation loss decreased (0.578548 --> 0.578278).  Saving model ...
Validation loss decreased (0.578278 --> 0.578008).  Saving model ...
Validation loss decreased (0.578008 --> 0.577738).  Saving model ...
Validation loss decreased (0.577738 --> 0.577468).  Saving model ...
Validation loss decreased (0.577468 --> 0.577199).  Saving model ...
Validation loss decreased (0.577199 --> 0.576930).  Saving model ...
Validation loss decreased (0.576930 --> 0.576661).  Saving model ...
Validation loss decreased (0.576661 --> 0.576392).  Saving model ...
Validation loss decreased (0.576392 --> 0.576123).  Saving model ...
Validation loss decreased (0.576123 --> 0.575855).  Saving model ...
Validation loss decreased (0.575855 --> 0.575586).  Saving model ...
Validation loss decreased (0.575586 --> 0.575318).  Saving model ...
Validation loss decreased (0.575318 --> 0.575050).  Saving model ...
Validation loss decreased (0.575050 --> 0.574783).  Saving model ...
Validation loss decreased (0.574783 --> 0.574516).  Saving model ...
Validation loss decreased (0.574516 --> 0.574249).  Saving model ...
Validation loss decreased (0.574249 --> 0.573982).  Saving model ...
Validation loss decreased (0.573982 --> 0.573715).  Saving model ...
Validation loss decreased (0.573715 --> 0.573449).  Saving model ...
Validation loss decreased (0.573449 --> 0.573183).  Saving model ...
Validation loss decreased (0.573183 --> 0.572917).  Saving model ...
Validation loss decreased (0.572917 --> 0.572651).  Saving model ...
Validation loss decreased (0.572651 --> 0.572386).  Saving model ...
Validation loss decreased (0.572386 --> 0.572121).  Saving model ...
Validation loss decreased (0.572121 --> 0.571856).  Saving model ...
Validation loss decreased (0.571856 --> 0.571592).  Saving model ...
Validation loss decreased (0.571592 --> 0.571328).  Saving model ...
Validation loss decreased (0.571328 --> 0.571064).  Saving model ...
Validation loss decreased (0.571064 --> 0.570800).  Saving model ...
Validation loss decreased (0.570800 --> 0.570537).  Saving model ...
Validation loss decreased (0.570537 --> 0.570274).  Saving model ...
Validation loss decreased (0.570274 --> 0.570012).  Saving model ...
Validation loss decreased (0.570012 --> 0.569750).  Saving model ...
Validation loss decreased (0.569750 --> 0.569488).  Saving model ...
Validation loss decreased (0.569488 --> 0.569226).  Saving model ...
Validation loss decreased (0.569226 --> 0.568965).  Saving model ...
Validation loss decreased (0.568965 --> 0.568704).  Saving model ...
Validation loss decreased (0.568704 --> 0.568444).  Saving model ...
Validation loss decreased (0.568444 --> 0.568183).  Saving model ...
epoch 301, loss 0.5682, train acc 65.07%, f1 0.0097, precision 0.5000, recall 0.0049, auc 0.5011
Validation loss decreased (0.568183 --> 0.567923).  Saving model ...
Validation loss decreased (0.567923 --> 0.567664).  Saving model ...
Validation loss decreased (0.567664 --> 0.567405).  Saving model ...
Validation loss decreased (0.567405 --> 0.567146).  Saving model ...
Validation loss decreased (0.567146 --> 0.566888).  Saving model ...
Validation loss decreased (0.566888 --> 0.566630).  Saving model ...
Validation loss decreased (0.566630 --> 0.566372).  Saving model ...
Validation loss decreased (0.566372 --> 0.566115).  Saving model ...
Validation loss decreased (0.566115 --> 0.565858).  Saving model ...
Validation loss decreased (0.565858 --> 0.565602).  Saving model ...
Validation loss decreased (0.565602 --> 0.565346).  Saving model ...
Validation loss decreased (0.565346 --> 0.565090).  Saving model ...
Validation loss decreased (0.565090 --> 0.564835).  Saving model ...
Validation loss decreased (0.564835 --> 0.564580).  Saving model ...
Validation loss decreased (0.564580 --> 0.564325).  Saving model ...
Validation loss decreased (0.564325 --> 0.564071).  Saving model ...
Validation loss decreased (0.564071 --> 0.563818).  Saving model ...
Validation loss decreased (0.563818 --> 0.563564).  Saving model ...
Validation loss decreased (0.563564 --> 0.563312).  Saving model ...
Validation loss decreased (0.563312 --> 0.563059).  Saving model ...
Validation loss decreased (0.563059 --> 0.562807).  Saving model ...
Validation loss decreased (0.562807 --> 0.562556).  Saving model ...
Validation loss decreased (0.562556 --> 0.562305).  Saving model ...
Validation loss decreased (0.562305 --> 0.562054).  Saving model ...
Validation loss decreased (0.562054 --> 0.561804).  Saving model ...
Validation loss decreased (0.561804 --> 0.561554).  Saving model ...
Validation loss decreased (0.561554 --> 0.561305).  Saving model ...
Validation loss decreased (0.561305 --> 0.561056).  Saving model ...
Validation loss decreased (0.561056 --> 0.560807).  Saving model ...
Validation loss decreased (0.560807 --> 0.560559).  Saving model ...
Validation loss decreased (0.560559 --> 0.560312).  Saving model ...
Validation loss decreased (0.560312 --> 0.560064).  Saving model ...
Validation loss decreased (0.560064 --> 0.559818).  Saving model ...
Validation loss decreased (0.559818 --> 0.559572).  Saving model ...
Validation loss decreased (0.559572 --> 0.559326).  Saving model ...
Validation loss decreased (0.559326 --> 0.559081).  Saving model ...
Validation loss decreased (0.559081 --> 0.558836).  Saving model ...
Validation loss decreased (0.558836 --> 0.558591).  Saving model ...
Validation loss decreased (0.558591 --> 0.558347).  Saving model ...
Validation loss decreased (0.558347 --> 0.558104).  Saving model ...
Validation loss decreased (0.558104 --> 0.557861).  Saving model ...
Validation loss decreased (0.557861 --> 0.557618).  Saving model ...
Validation loss decreased (0.557618 --> 0.557377).  Saving model ...
Validation loss decreased (0.557377 --> 0.557135).  Saving model ...
Validation loss decreased (0.557135 --> 0.556894).  Saving model ...
Validation loss decreased (0.556894 --> 0.556653).  Saving model ...
Validation loss decreased (0.556653 --> 0.556413).  Saving model ...
Validation loss decreased (0.556413 --> 0.556173).  Saving model ...
Validation loss decreased (0.556173 --> 0.555934).  Saving model ...
Validation loss decreased (0.555934 --> 0.555696).  Saving model ...
Validation loss decreased (0.555696 --> 0.555457).  Saving model ...
Validation loss decreased (0.555457 --> 0.555220).  Saving model ...
Validation loss decreased (0.555220 --> 0.554982).  Saving model ...
Validation loss decreased (0.554982 --> 0.554746).  Saving model ...
Validation loss decreased (0.554746 --> 0.554510).  Saving model ...
Validation loss decreased (0.554510 --> 0.554274).  Saving model ...
Validation loss decreased (0.554274 --> 0.554038).  Saving model ...
Validation loss decreased (0.554038 --> 0.553804).  Saving model ...
Validation loss decreased (0.553804 --> 0.553569).  Saving model ...
Validation loss decreased (0.553569 --> 0.553336).  Saving model ...
Validation loss decreased (0.553336 --> 0.553102).  Saving model ...
Validation loss decreased (0.553102 --> 0.552870).  Saving model ...
Validation loss decreased (0.552870 --> 0.552637).  Saving model ...
Validation loss decreased (0.552637 --> 0.552406).  Saving model ...
Validation loss decreased (0.552406 --> 0.552174).  Saving model ...
Validation loss decreased (0.552174 --> 0.551944).  Saving model ...
Validation loss decreased (0.551944 --> 0.551713).  Saving model ...
Validation loss decreased (0.551713 --> 0.551483).  Saving model ...
Validation loss decreased (0.551483 --> 0.551254).  Saving model ...
Validation loss decreased (0.551254 --> 0.551025).  Saving model ...
Validation loss decreased (0.551025 --> 0.550797).  Saving model ...
Validation loss decreased (0.550797 --> 0.550570).  Saving model ...
Validation loss decreased (0.550570 --> 0.550342).  Saving model ...
Validation loss decreased (0.550342 --> 0.550116).  Saving model ...
Validation loss decreased (0.550116 --> 0.549889).  Saving model ...
Validation loss decreased (0.549889 --> 0.549664).  Saving model ...
Validation loss decreased (0.549664 --> 0.549438).  Saving model ...
Validation loss decreased (0.549438 --> 0.549214).  Saving model ...
Validation loss decreased (0.549214 --> 0.548990).  Saving model ...
Validation loss decreased (0.548990 --> 0.548766).  Saving model ...
Validation loss decreased (0.548766 --> 0.548543).  Saving model ...
Validation loss decreased (0.548543 --> 0.548320).  Saving model ...
Validation loss decreased (0.548320 --> 0.548098).  Saving model ...
Validation loss decreased (0.548098 --> 0.547876).  Saving model ...
Validation loss decreased (0.547876 --> 0.547655).  Saving model ...
Validation loss decreased (0.547655 --> 0.547435).  Saving model ...
Validation loss decreased (0.547435 --> 0.547215).  Saving model ...
Validation loss decreased (0.547215 --> 0.546995).  Saving model ...
Validation loss decreased (0.546995 --> 0.546776).  Saving model ...
Validation loss decreased (0.546776 --> 0.546557).  Saving model ...
Validation loss decreased (0.546557 --> 0.546339).  Saving model ...
Validation loss decreased (0.546339 --> 0.546122).  Saving model ...
Validation loss decreased (0.546122 --> 0.545905).  Saving model ...
Validation loss decreased (0.545905 --> 0.545688).  Saving model ...
Validation loss decreased (0.545688 --> 0.545473).  Saving model ...
Validation loss decreased (0.545473 --> 0.545257).  Saving model ...
Validation loss decreased (0.545257 --> 0.545042).  Saving model ...
Validation loss decreased (0.545042 --> 0.544828).  Saving model ...
Validation loss decreased (0.544828 --> 0.544614).  Saving model ...
Validation loss decreased (0.544614 --> 0.544401).  Saving model ...
epoch 401, loss 0.5444, train acc 67.12%, f1 0.1504, precision 0.7727, recall 0.0833, auc 0.5351
Validation loss decreased (0.544401 --> 0.544188).  Saving model ...
Validation loss decreased (0.544188 --> 0.543975).  Saving model ...
Validation loss decreased (0.543975 --> 0.543764).  Saving model ...
Validation loss decreased (0.543764 --> 0.543552).  Saving model ...
Validation loss decreased (0.543552 --> 0.543342).  Saving model ...
Validation loss decreased (0.543342 --> 0.543131).  Saving model ...
Validation loss decreased (0.543131 --> 0.542921).  Saving model ...
Validation loss decreased (0.542921 --> 0.542712).  Saving model ...
Validation loss decreased (0.542712 --> 0.542503).  Saving model ...
Validation loss decreased (0.542503 --> 0.542295).  Saving model ...
Validation loss decreased (0.542295 --> 0.542088).  Saving model ...
Validation loss decreased (0.542088 --> 0.541880).  Saving model ...
Validation loss decreased (0.541880 --> 0.541674).  Saving model ...
Validation loss decreased (0.541674 --> 0.541468).  Saving model ...
Validation loss decreased (0.541468 --> 0.541262).  Saving model ...
Validation loss decreased (0.541262 --> 0.541057).  Saving model ...
Validation loss decreased (0.541057 --> 0.540852).  Saving model ...
Validation loss decreased (0.540852 --> 0.540648).  Saving model ...
Validation loss decreased (0.540648 --> 0.540445).  Saving model ...
Validation loss decreased (0.540445 --> 0.540242).  Saving model ...
Validation loss decreased (0.540242 --> 0.540039).  Saving model ...
Validation loss decreased (0.540039 --> 0.539837).  Saving model ...
Validation loss decreased (0.539837 --> 0.539636).  Saving model ...
Validation loss decreased (0.539636 --> 0.539435).  Saving model ...
Validation loss decreased (0.539435 --> 0.539234).  Saving model ...
Validation loss decreased (0.539234 --> 0.539034).  Saving model ...
Validation loss decreased (0.539034 --> 0.538835).  Saving model ...
Validation loss decreased (0.538835 --> 0.538636).  Saving model ...
Validation loss decreased (0.538636 --> 0.538437).  Saving model ...
Validation loss decreased (0.538437 --> 0.538239).  Saving model ...
Validation loss decreased (0.538239 --> 0.538042).  Saving model ...
Validation loss decreased (0.538042 --> 0.537845).  Saving model ...
Validation loss decreased (0.537845 --> 0.537649).  Saving model ...
Validation loss decreased (0.537649 --> 0.537453).  Saving model ...
Validation loss decreased (0.537453 --> 0.537257).  Saving model ...
Validation loss decreased (0.537257 --> 0.537063).  Saving model ...
Validation loss decreased (0.537063 --> 0.536868).  Saving model ...
Validation loss decreased (0.536868 --> 0.536674).  Saving model ...
Validation loss decreased (0.536674 --> 0.536481).  Saving model ...
Validation loss decreased (0.536481 --> 0.536288).  Saving model ...
Validation loss decreased (0.536288 --> 0.536096).  Saving model ...
Validation loss decreased (0.536096 --> 0.535904).  Saving model ...
Validation loss decreased (0.535904 --> 0.535713).  Saving model ...
Validation loss decreased (0.535713 --> 0.535522).  Saving model ...
Validation loss decreased (0.535522 --> 0.535331).  Saving model ...
Validation loss decreased (0.535331 --> 0.535142).  Saving model ...
Validation loss decreased (0.535142 --> 0.534952).  Saving model ...
Validation loss decreased (0.534952 --> 0.534764).  Saving model ...
Validation loss decreased (0.534764 --> 0.534575).  Saving model ...
Validation loss decreased (0.534575 --> 0.534388).  Saving model ...
Validation loss decreased (0.534388 --> 0.534200).  Saving model ...
Validation loss decreased (0.534200 --> 0.534013).  Saving model ...
Validation loss decreased (0.534013 --> 0.533827).  Saving model ...
Validation loss decreased (0.533827 --> 0.533641).  Saving model ...
Validation loss decreased (0.533641 --> 0.533456).  Saving model ...
Validation loss decreased (0.533456 --> 0.533271).  Saving model ...
Validation loss decreased (0.533271 --> 0.533087).  Saving model ...
Validation loss decreased (0.533087 --> 0.532903).  Saving model ...
Validation loss decreased (0.532903 --> 0.532720).  Saving model ...
Validation loss decreased (0.532720 --> 0.532537).  Saving model ...
Validation loss decreased (0.532537 --> 0.532355).  Saving model ...
Validation loss decreased (0.532355 --> 0.532173).  Saving model ...
Validation loss decreased (0.532173 --> 0.531991).  Saving model ...
Validation loss decreased (0.531991 --> 0.531811).  Saving model ...
Validation loss decreased (0.531811 --> 0.531630).  Saving model ...
Validation loss decreased (0.531630 --> 0.531450).  Saving model ...
Validation loss decreased (0.531450 --> 0.531271).  Saving model ...
Validation loss decreased (0.531271 --> 0.531092).  Saving model ...
Validation loss decreased (0.531092 --> 0.530914).  Saving model ...
Validation loss decreased (0.530914 --> 0.530736).  Saving model ...
Validation loss decreased (0.530736 --> 0.530558).  Saving model ...
Validation loss decreased (0.530558 --> 0.530381).  Saving model ...
Validation loss decreased (0.530381 --> 0.530205).  Saving model ...
Validation loss decreased (0.530205 --> 0.530029).  Saving model ...
Validation loss decreased (0.530029 --> 0.529853).  Saving model ...
Validation loss decreased (0.529853 --> 0.529678).  Saving model ...
Validation loss decreased (0.529678 --> 0.529504).  Saving model ...
Validation loss decreased (0.529504 --> 0.529330).  Saving model ...
Validation loss decreased (0.529330 --> 0.529156).  Saving model ...
Validation loss decreased (0.529156 --> 0.528983).  Saving model ...
Validation loss decreased (0.528983 --> 0.528810).  Saving model ...
Validation loss decreased (0.528810 --> 0.528638).  Saving model ...
Validation loss decreased (0.528638 --> 0.528466).  Saving model ...
Validation loss decreased (0.528466 --> 0.528295).  Saving model ...
Validation loss decreased (0.528295 --> 0.528125).  Saving model ...
Validation loss decreased (0.528125 --> 0.527954).  Saving model ...
Validation loss decreased (0.527954 --> 0.527785).  Saving model ...
Validation loss decreased (0.527785 --> 0.527615).  Saving model ...
Validation loss decreased (0.527615 --> 0.527446).  Saving model ...
Validation loss decreased (0.527446 --> 0.527278).  Saving model ...
Validation loss decreased (0.527278 --> 0.527110).  Saving model ...
Validation loss decreased (0.527110 --> 0.526943).  Saving model ...
Validation loss decreased (0.526943 --> 0.526776).  Saving model ...
Validation loss decreased (0.526776 --> 0.526609).  Saving model ...
Validation loss decreased (0.526609 --> 0.526443).  Saving model ...
Validation loss decreased (0.526443 --> 0.526278).  Saving model ...
Validation loss decreased (0.526278 --> 0.526113).  Saving model ...
Validation loss decreased (0.526113 --> 0.525948).  Saving model ...
Validation loss decreased (0.525948 --> 0.525784).  Saving model ...
Validation loss decreased (0.525784 --> 0.525620).  Saving model ...
epoch 501, loss 0.5256, train acc 70.55%, f1 0.3435, precision 0.7759, recall 0.2206, auc 0.5932
Validation loss decreased (0.525620 --> 0.525457).  Saving model ...
Validation loss decreased (0.525457 --> 0.525294).  Saving model ...
Validation loss decreased (0.525294 --> 0.525132).  Saving model ...
Validation loss decreased (0.525132 --> 0.524970).  Saving model ...
Validation loss decreased (0.524970 --> 0.524809).  Saving model ...
Validation loss decreased (0.524809 --> 0.524648).  Saving model ...
Validation loss decreased (0.524648 --> 0.524487).  Saving model ...
Validation loss decreased (0.524487 --> 0.524327).  Saving model ...
Validation loss decreased (0.524327 --> 0.524168).  Saving model ...
Validation loss decreased (0.524168 --> 0.524009).  Saving model ...
Validation loss decreased (0.524009 --> 0.523850).  Saving model ...
Validation loss decreased (0.523850 --> 0.523692).  Saving model ...
Validation loss decreased (0.523692 --> 0.523534).  Saving model ...
Validation loss decreased (0.523534 --> 0.523377).  Saving model ...
Validation loss decreased (0.523377 --> 0.523220).  Saving model ...
Validation loss decreased (0.523220 --> 0.523063).  Saving model ...
Validation loss decreased (0.523063 --> 0.522907).  Saving model ...
Validation loss decreased (0.522907 --> 0.522752).  Saving model ...
Validation loss decreased (0.522752 --> 0.522597).  Saving model ...
Validation loss decreased (0.522597 --> 0.522442).  Saving model ...
Validation loss decreased (0.522442 --> 0.522288).  Saving model ...
Validation loss decreased (0.522288 --> 0.522134).  Saving model ...
Validation loss decreased (0.522134 --> 0.521981).  Saving model ...
Validation loss decreased (0.521981 --> 0.521828).  Saving model ...
Validation loss decreased (0.521828 --> 0.521676).  Saving model ...
Validation loss decreased (0.521676 --> 0.521524).  Saving model ...
Validation loss decreased (0.521524 --> 0.521372).  Saving model ...
Validation loss decreased (0.521372 --> 0.521221).  Saving model ...
Validation loss decreased (0.521221 --> 0.521070).  Saving model ...
Validation loss decreased (0.521070 --> 0.520920).  Saving model ...
Validation loss decreased (0.520920 --> 0.520770).  Saving model ...
Validation loss decreased (0.520770 --> 0.520621).  Saving model ...
Validation loss decreased (0.520621 --> 0.520472).  Saving model ...
Validation loss decreased (0.520472 --> 0.520324).  Saving model ...
Validation loss decreased (0.520324 --> 0.520176).  Saving model ...
Validation loss decreased (0.520176 --> 0.520028).  Saving model ...
Validation loss decreased (0.520028 --> 0.519881).  Saving model ...
Validation loss decreased (0.519881 --> 0.519734).  Saving model ...
Validation loss decreased (0.519734 --> 0.519588).  Saving model ...
Validation loss decreased (0.519588 --> 0.519442).  Saving model ...
Validation loss decreased (0.519442 --> 0.519296).  Saving model ...
Validation loss decreased (0.519296 --> 0.519151).  Saving model ...
Validation loss decreased (0.519151 --> 0.519006).  Saving model ...
Validation loss decreased (0.519006 --> 0.518862).  Saving model ...
Validation loss decreased (0.518862 --> 0.518718).  Saving model ...
Validation loss decreased (0.518718 --> 0.518575).  Saving model ...
Validation loss decreased (0.518575 --> 0.518432).  Saving model ...
Validation loss decreased (0.518432 --> 0.518289).  Saving model ...
Validation loss decreased (0.518289 --> 0.518147).  Saving model ...
Validation loss decreased (0.518147 --> 0.518005).  Saving model ...
Validation loss decreased (0.518005 --> 0.517864).  Saving model ...
Validation loss decreased (0.517864 --> 0.517723).  Saving model ...
Validation loss decreased (0.517723 --> 0.517583).  Saving model ...
Validation loss decreased (0.517583 --> 0.517443).  Saving model ...
Validation loss decreased (0.517443 --> 0.517303).  Saving model ...
Validation loss decreased (0.517303 --> 0.517164).  Saving model ...
Validation loss decreased (0.517164 --> 0.517025).  Saving model ...
Validation loss decreased (0.517025 --> 0.516887).  Saving model ...
Validation loss decreased (0.516887 --> 0.516748).  Saving model ...
Validation loss decreased (0.516748 --> 0.516611).  Saving model ...
Validation loss decreased (0.516611 --> 0.516474).  Saving model ...
Validation loss decreased (0.516474 --> 0.516337).  Saving model ...
Validation loss decreased (0.516337 --> 0.516200).  Saving model ...
Validation loss decreased (0.516200 --> 0.516064).  Saving model ...
Validation loss decreased (0.516064 --> 0.515929).  Saving model ...
Validation loss decreased (0.515929 --> 0.515794).  Saving model ...
Validation loss decreased (0.515794 --> 0.515659).  Saving model ...
Validation loss decreased (0.515659 --> 0.515524).  Saving model ...
Validation loss decreased (0.515524 --> 0.515390).  Saving model ...
Validation loss decreased (0.515390 --> 0.515257).  Saving model ...
Validation loss decreased (0.515257 --> 0.515124).  Saving model ...
Validation loss decreased (0.515124 --> 0.514991).  Saving model ...
Validation loss decreased (0.514991 --> 0.514858).  Saving model ...
Validation loss decreased (0.514858 --> 0.514726).  Saving model ...
Validation loss decreased (0.514726 --> 0.514595).  Saving model ...
Validation loss decreased (0.514595 --> 0.514464).  Saving model ...
Validation loss decreased (0.514464 --> 0.514333).  Saving model ...
Validation loss decreased (0.514333 --> 0.514202).  Saving model ...
Validation loss decreased (0.514202 --> 0.514072).  Saving model ...
Validation loss decreased (0.514072 --> 0.513942).  Saving model ...
Validation loss decreased (0.513942 --> 0.513813).  Saving model ...
Validation loss decreased (0.513813 --> 0.513684).  Saving model ...
Validation loss decreased (0.513684 --> 0.513556).  Saving model ...
Validation loss decreased (0.513556 --> 0.513428).  Saving model ...
Validation loss decreased (0.513428 --> 0.513300).  Saving model ...
Validation loss decreased (0.513300 --> 0.513172).  Saving model ...
Validation loss decreased (0.513172 --> 0.513045).  Saving model ...
Validation loss decreased (0.513045 --> 0.512919).  Saving model ...
Validation loss decreased (0.512919 --> 0.512793).  Saving model ...
Validation loss decreased (0.512793 --> 0.512667).  Saving model ...
Validation loss decreased (0.512667 --> 0.512541).  Saving model ...
Validation loss decreased (0.512541 --> 0.512416).  Saving model ...
Validation loss decreased (0.512416 --> 0.512291).  Saving model ...
Validation loss decreased (0.512291 --> 0.512167).  Saving model ...
Validation loss decreased (0.512167 --> 0.512043).  Saving model ...
Validation loss decreased (0.512043 --> 0.511919).  Saving model ...
Validation loss decreased (0.511919 --> 0.511796).  Saving model ...
Validation loss decreased (0.511796 --> 0.511673).  Saving model ...
Validation loss decreased (0.511673 --> 0.511551).  Saving model ...
Validation loss decreased (0.511551 --> 0.511429).  Saving model ...
epoch 601, loss 0.5114, train acc 74.32%, f1 0.5161, precision 0.7547, recall 0.3922, auc 0.6619
Validation loss decreased (0.511429 --> 0.511307).  Saving model ...
Validation loss decreased (0.511307 --> 0.511186).  Saving model ...
Validation loss decreased (0.511186 --> 0.511065).  Saving model ...
Validation loss decreased (0.511065 --> 0.510944).  Saving model ...
Validation loss decreased (0.510944 --> 0.510824).  Saving model ...
Validation loss decreased (0.510824 --> 0.510704).  Saving model ...
Validation loss decreased (0.510704 --> 0.510584).  Saving model ...
Validation loss decreased (0.510584 --> 0.510465).  Saving model ...
Validation loss decreased (0.510465 --> 0.510346).  Saving model ...
Validation loss decreased (0.510346 --> 0.510227).  Saving model ...
Validation loss decreased (0.510227 --> 0.510109).  Saving model ...
Validation loss decreased (0.510109 --> 0.509992).  Saving model ...
Validation loss decreased (0.509992 --> 0.509874).  Saving model ...
Validation loss decreased (0.509874 --> 0.509757).  Saving model ...
Validation loss decreased (0.509757 --> 0.509640).  Saving model ...
Validation loss decreased (0.509640 --> 0.509524).  Saving model ...
Validation loss decreased (0.509524 --> 0.509408).  Saving model ...
Validation loss decreased (0.509408 --> 0.509292).  Saving model ...
Validation loss decreased (0.509292 --> 0.509177).  Saving model ...
Validation loss decreased (0.509177 --> 0.509062).  Saving model ...
Validation loss decreased (0.509062 --> 0.508947).  Saving model ...
Validation loss decreased (0.508947 --> 0.508833).  Saving model ...
Validation loss decreased (0.508833 --> 0.508719).  Saving model ...
Validation loss decreased (0.508719 --> 0.508606).  Saving model ...
Validation loss decreased (0.508606 --> 0.508492).  Saving model ...
Validation loss decreased (0.508492 --> 0.508380).  Saving model ...
Validation loss decreased (0.508380 --> 0.508267).  Saving model ...
Validation loss decreased (0.508267 --> 0.508155).  Saving model ...
Validation loss decreased (0.508155 --> 0.508043).  Saving model ...
Validation loss decreased (0.508043 --> 0.507931).  Saving model ...
Validation loss decreased (0.507931 --> 0.507820).  Saving model ...
Validation loss decreased (0.507820 --> 0.507709).  Saving model ...
Validation loss decreased (0.507709 --> 0.507599).  Saving model ...
Validation loss decreased (0.507599 --> 0.507489).  Saving model ...
Validation loss decreased (0.507489 --> 0.507379).  Saving model ...
Validation loss decreased (0.507379 --> 0.507270).  Saving model ...
Validation loss decreased (0.507270 --> 0.507160).  Saving model ...
Validation loss decreased (0.507160 --> 0.507051).  Saving model ...
Validation loss decreased (0.507051 --> 0.506943).  Saving model ...
Validation loss decreased (0.506943 --> 0.506835).  Saving model ...
Validation loss decreased (0.506835 --> 0.506727).  Saving model ...
Validation loss decreased (0.506727 --> 0.506620).  Saving model ...
Validation loss decreased (0.506620 --> 0.506512).  Saving model ...
Validation loss decreased (0.506512 --> 0.506406).  Saving model ...
Validation loss decreased (0.506406 --> 0.506299).  Saving model ...
Validation loss decreased (0.506299 --> 0.506193).  Saving model ...
Validation loss decreased (0.506193 --> 0.506087).  Saving model ...
Validation loss decreased (0.506087 --> 0.505982).  Saving model ...
Validation loss decreased (0.505982 --> 0.505876).  Saving model ...
Validation loss decreased (0.505876 --> 0.505771).  Saving model ...
Validation loss decreased (0.505771 --> 0.505667).  Saving model ...
Validation loss decreased (0.505667 --> 0.505562).  Saving model ...
Validation loss decreased (0.505562 --> 0.505459).  Saving model ...
Validation loss decreased (0.505459 --> 0.505355).  Saving model ...
Validation loss decreased (0.505355 --> 0.505252).  Saving model ...
Validation loss decreased (0.505252 --> 0.505149).  Saving model ...
Validation loss decreased (0.505149 --> 0.505046).  Saving model ...
Validation loss decreased (0.505046 --> 0.504944).  Saving model ...
Validation loss decreased (0.504944 --> 0.504842).  Saving model ...
Validation loss decreased (0.504842 --> 0.504740).  Saving model ...
Validation loss decreased (0.504740 --> 0.504639).  Saving model ...
Validation loss decreased (0.504639 --> 0.504537).  Saving model ...
Validation loss decreased (0.504537 --> 0.504437).  Saving model ...
Validation loss decreased (0.504437 --> 0.504336).  Saving model ...
Validation loss decreased (0.504336 --> 0.504236).  Saving model ...
Validation loss decreased (0.504236 --> 0.504136).  Saving model ...
Validation loss decreased (0.504136 --> 0.504037).  Saving model ...
Validation loss decreased (0.504037 --> 0.503937).  Saving model ...
Validation loss decreased (0.503937 --> 0.503838).  Saving model ...
Validation loss decreased (0.503838 --> 0.503740).  Saving model ...
Validation loss decreased (0.503740 --> 0.503641).  Saving model ...
Validation loss decreased (0.503641 --> 0.503543).  Saving model ...
Validation loss decreased (0.503543 --> 0.503446).  Saving model ...
Validation loss decreased (0.503446 --> 0.503348).  Saving model ...
Validation loss decreased (0.503348 --> 0.503251).  Saving model ...
Validation loss decreased (0.503251 --> 0.503154).  Saving model ...
Validation loss decreased (0.503154 --> 0.503058).  Saving model ...
Validation loss decreased (0.503058 --> 0.502962).  Saving model ...
Validation loss decreased (0.502962 --> 0.502866).  Saving model ...
Validation loss decreased (0.502866 --> 0.502770).  Saving model ...
Validation loss decreased (0.502770 --> 0.502675).  Saving model ...
Validation loss decreased (0.502675 --> 0.502580).  Saving model ...
Validation loss decreased (0.502580 --> 0.502485).  Saving model ...
Validation loss decreased (0.502485 --> 0.502390).  Saving model ...
Validation loss decreased (0.502390 --> 0.502296).  Saving model ...
Validation loss decreased (0.502296 --> 0.502202).  Saving model ...
Validation loss decreased (0.502202 --> 0.502109).  Saving model ...
Validation loss decreased (0.502109 --> 0.502016).  Saving model ...
Validation loss decreased (0.502016 --> 0.501923).  Saving model ...
Validation loss decreased (0.501923 --> 0.501830).  Saving model ...
Validation loss decreased (0.501830 --> 0.501737).  Saving model ...
Validation loss decreased (0.501737 --> 0.501645).  Saving model ...
Validation loss decreased (0.501645 --> 0.501553).  Saving model ...
Validation loss decreased (0.501553 --> 0.501462).  Saving model ...
Validation loss decreased (0.501462 --> 0.501371).  Saving model ...
Validation loss decreased (0.501371 --> 0.501280).  Saving model ...
Validation loss decreased (0.501280 --> 0.501189).  Saving model ...
Validation loss decreased (0.501189 --> 0.501098).  Saving model ...
Validation loss decreased (0.501098 --> 0.501008).  Saving model ...
Validation loss decreased (0.501008 --> 0.500918).  Saving model ...
epoch 701, loss 0.5009, train acc 74.83%, f1 0.5612, precision 0.7176, recall 0.4608, auc 0.6817
Validation loss decreased (0.500918 --> 0.500829).  Saving model ...
Validation loss decreased (0.500829 --> 0.500739).  Saving model ...
Validation loss decreased (0.500739 --> 0.500650).  Saving model ...
Validation loss decreased (0.500650 --> 0.500561).  Saving model ...
Validation loss decreased (0.500561 --> 0.500473).  Saving model ...
Validation loss decreased (0.500473 --> 0.500385).  Saving model ...
Validation loss decreased (0.500385 --> 0.500297).  Saving model ...
Validation loss decreased (0.500297 --> 0.500209).  Saving model ...
Validation loss decreased (0.500209 --> 0.500122).  Saving model ...
Validation loss decreased (0.500122 --> 0.500035).  Saving model ...
Validation loss decreased (0.500035 --> 0.499948).  Saving model ...
Validation loss decreased (0.499948 --> 0.499861).  Saving model ...
Validation loss decreased (0.499861 --> 0.499775).  Saving model ...
Validation loss decreased (0.499775 --> 0.499689).  Saving model ...
Validation loss decreased (0.499689 --> 0.499603).  Saving model ...
Validation loss decreased (0.499603 --> 0.499517).  Saving model ...
Validation loss decreased (0.499517 --> 0.499432).  Saving model ...
Validation loss decreased (0.499432 --> 0.499347).  Saving model ...
Validation loss decreased (0.499347 --> 0.499262).  Saving model ...
Validation loss decreased (0.499262 --> 0.499178).  Saving model ...
Validation loss decreased (0.499178 --> 0.499094).  Saving model ...
Validation loss decreased (0.499094 --> 0.499010).  Saving model ...
Validation loss decreased (0.499010 --> 0.498926).  Saving model ...
Validation loss decreased (0.498926 --> 0.498842).  Saving model ...
Validation loss decreased (0.498842 --> 0.498759).  Saving model ...
Validation loss decreased (0.498759 --> 0.498676).  Saving model ...
Validation loss decreased (0.498676 --> 0.498594).  Saving model ...
Validation loss decreased (0.498594 --> 0.498511).  Saving model ...
Validation loss decreased (0.498511 --> 0.498429).  Saving model ...
Validation loss decreased (0.498429 --> 0.498347).  Saving model ...
Validation loss decreased (0.498347 --> 0.498266).  Saving model ...
Validation loss decreased (0.498266 --> 0.498184).  Saving model ...
Validation loss decreased (0.498184 --> 0.498103).  Saving model ...
Validation loss decreased (0.498103 --> 0.498022).  Saving model ...
Validation loss decreased (0.498022 --> 0.497941).  Saving model ...
Validation loss decreased (0.497941 --> 0.497861).  Saving model ...
Validation loss decreased (0.497861 --> 0.497781).  Saving model ...
Validation loss decreased (0.497781 --> 0.497701).  Saving model ...
Validation loss decreased (0.497701 --> 0.497621).  Saving model ...
Validation loss decreased (0.497621 --> 0.497542).  Saving model ...
Validation loss decreased (0.497542 --> 0.497463).  Saving model ...
Validation loss decreased (0.497463 --> 0.497384).  Saving model ...
Validation loss decreased (0.497384 --> 0.497305).  Saving model ...
Validation loss decreased (0.497305 --> 0.497227).  Saving model ...
Validation loss decreased (0.497227 --> 0.497149).  Saving model ...
Validation loss decreased (0.497149 --> 0.497071).  Saving model ...
Validation loss decreased (0.497071 --> 0.496993).  Saving model ...
Validation loss decreased (0.496993 --> 0.496916).  Saving model ...
Validation loss decreased (0.496916 --> 0.496838).  Saving model ...
Validation loss decreased (0.496838 --> 0.496761).  Saving model ...
Validation loss decreased (0.496761 --> 0.496685).  Saving model ...
Validation loss decreased (0.496685 --> 0.496608).  Saving model ...
Validation loss decreased (0.496608 --> 0.496532).  Saving model ...
Validation loss decreased (0.496532 --> 0.496456).  Saving model ...
Validation loss decreased (0.496456 --> 0.496380).  Saving model ...
Validation loss decreased (0.496380 --> 0.496304).  Saving model ...
Validation loss decreased (0.496304 --> 0.496229).  Saving model ...
Validation loss decreased (0.496229 --> 0.496154).  Saving model ...
Validation loss decreased (0.496154 --> 0.496079).  Saving model ...
Validation loss decreased (0.496079 --> 0.496005).  Saving model ...
Validation loss decreased (0.496005 --> 0.495930).  Saving model ...
Validation loss decreased (0.495930 --> 0.495856).  Saving model ...
Validation loss decreased (0.495856 --> 0.495782).  Saving model ...
Validation loss decreased (0.495782 --> 0.495708).  Saving model ...
Validation loss decreased (0.495708 --> 0.495635).  Saving model ...
Validation loss decreased (0.495635 --> 0.495562).  Saving model ...
Validation loss decreased (0.495562 --> 0.495489).  Saving model ...
Validation loss decreased (0.495489 --> 0.495416).  Saving model ...
Validation loss decreased (0.495416 --> 0.495343).  Saving model ...
Validation loss decreased (0.495343 --> 0.495271).  Saving model ...
Validation loss decreased (0.495271 --> 0.495199).  Saving model ...
Validation loss decreased (0.495199 --> 0.495127).  Saving model ...
Validation loss decreased (0.495127 --> 0.495055).  Saving model ...
Validation loss decreased (0.495055 --> 0.494984).  Saving model ...
Validation loss decreased (0.494984 --> 0.494912).  Saving model ...
Validation loss decreased (0.494912 --> 0.494841).  Saving model ...
Validation loss decreased (0.494841 --> 0.494771).  Saving model ...
Validation loss decreased (0.494771 --> 0.494700).  Saving model ...
Validation loss decreased (0.494700 --> 0.494630).  Saving model ...
Validation loss decreased (0.494630 --> 0.494559).  Saving model ...
Validation loss decreased (0.494559 --> 0.494490).  Saving model ...
Validation loss decreased (0.494490 --> 0.494420).  Saving model ...
Validation loss decreased (0.494420 --> 0.494350).  Saving model ...
Validation loss decreased (0.494350 --> 0.494281).  Saving model ...
Validation loss decreased (0.494281 --> 0.494212).  Saving model ...
Validation loss decreased (0.494212 --> 0.494143).  Saving model ...
Validation loss decreased (0.494143 --> 0.494074).  Saving model ...
Validation loss decreased (0.494074 --> 0.494006).  Saving model ...
Validation loss decreased (0.494006 --> 0.493938).  Saving model ...
Validation loss decreased (0.493938 --> 0.493870).  Saving model ...
Validation loss decreased (0.493870 --> 0.493802).  Saving model ...
Validation loss decreased (0.493802 --> 0.493734).  Saving model ...
Validation loss decreased (0.493734 --> 0.493667).  Saving model ...
Validation loss decreased (0.493667 --> 0.493600).  Saving model ...
Validation loss decreased (0.493600 --> 0.493533).  Saving model ...
Validation loss decreased (0.493533 --> 0.493466).  Saving model ...
Validation loss decreased (0.493466 --> 0.493399).  Saving model ...
Validation loss decreased (0.493399 --> 0.493333).  Saving model ...
Validation loss decreased (0.493333 --> 0.493267).  Saving model ...
Validation loss decreased (0.493267 --> 0.493201).  Saving model ...
epoch 801, loss 0.4932, train acc 74.49%, f1 0.5755, precision 0.6871, recall 0.4951, auc 0.6870
Validation loss decreased (0.493201 --> 0.493135).  Saving model ...
Validation loss decreased (0.493135 --> 0.493069).  Saving model ...
Validation loss decreased (0.493069 --> 0.493004).  Saving model ...
Validation loss decreased (0.493004 --> 0.492939).  Saving model ...
Validation loss decreased (0.492939 --> 0.492874).  Saving model ...
Validation loss decreased (0.492874 --> 0.492809).  Saving model ...
Validation loss decreased (0.492809 --> 0.492745).  Saving model ...
Validation loss decreased (0.492745 --> 0.492680).  Saving model ...
Validation loss decreased (0.492680 --> 0.492616).  Saving model ...
Validation loss decreased (0.492616 --> 0.492552).  Saving model ...
Validation loss decreased (0.492552 --> 0.492488).  Saving model ...
Validation loss decreased (0.492488 --> 0.492425).  Saving model ...
Validation loss decreased (0.492425 --> 0.492361).  Saving model ...
Validation loss decreased (0.492361 --> 0.492298).  Saving model ...
Validation loss decreased (0.492298 --> 0.492235).  Saving model ...
Validation loss decreased (0.492235 --> 0.492172).  Saving model ...
Validation loss decreased (0.492172 --> 0.492110).  Saving model ...
Validation loss decreased (0.492110 --> 0.492047).  Saving model ...
Validation loss decreased (0.492047 --> 0.491985).  Saving model ...
Validation loss decreased (0.491985 --> 0.491923).  Saving model ...
Validation loss decreased (0.491923 --> 0.491861).  Saving model ...
Validation loss decreased (0.491861 --> 0.491799).  Saving model ...
Validation loss decreased (0.491799 --> 0.491738).  Saving model ...
Validation loss decreased (0.491738 --> 0.491676).  Saving model ...
Validation loss decreased (0.491676 --> 0.491615).  Saving model ...
Validation loss decreased (0.491615 --> 0.491554).  Saving model ...
Validation loss decreased (0.491554 --> 0.491493).  Saving model ...
Validation loss decreased (0.491493 --> 0.491433).  Saving model ...
Validation loss decreased (0.491433 --> 0.491372).  Saving model ...
Validation loss decreased (0.491372 --> 0.491312).  Saving model ...
Validation loss decreased (0.491312 --> 0.491252).  Saving model ...
Validation loss decreased (0.491252 --> 0.491192).  Saving model ...
Validation loss decreased (0.491192 --> 0.491133).  Saving model ...
Validation loss decreased (0.491133 --> 0.491073).  Saving model ...
Validation loss decreased (0.491073 --> 0.491014).  Saving model ...
Validation loss decreased (0.491014 --> 0.490955).  Saving model ...
Validation loss decreased (0.490955 --> 0.490896).  Saving model ...
Validation loss decreased (0.490896 --> 0.490837).  Saving model ...
Validation loss decreased (0.490837 --> 0.490778).  Saving model ...
Validation loss decreased (0.490778 --> 0.490720).  Saving model ...
Validation loss decreased (0.490720 --> 0.490662).  Saving model ...
Validation loss decreased (0.490662 --> 0.490604).  Saving model ...
Validation loss decreased (0.490604 --> 0.490546).  Saving model ...
Validation loss decreased (0.490546 --> 0.490488).  Saving model ...
Validation loss decreased (0.490488 --> 0.490430).  Saving model ...
Validation loss decreased (0.490430 --> 0.490373).  Saving model ...
Validation loss decreased (0.490373 --> 0.490316).  Saving model ...
Validation loss decreased (0.490316 --> 0.490259).  Saving model ...
Validation loss decreased (0.490259 --> 0.490202).  Saving model ...
Validation loss decreased (0.490202 --> 0.490145).  Saving model ...
Validation loss decreased (0.490145 --> 0.490089).  Saving model ...
Validation loss decreased (0.490089 --> 0.490032).  Saving model ...
Validation loss decreased (0.490032 --> 0.489976).  Saving model ...
Validation loss decreased (0.489976 --> 0.489920).  Saving model ...
Validation loss decreased (0.489920 --> 0.489864).  Saving model ...
Validation loss decreased (0.489864 --> 0.489808).  Saving model ...
Validation loss decreased (0.489808 --> 0.489753).  Saving model ...
Validation loss decreased (0.489753 --> 0.489697).  Saving model ...
Validation loss decreased (0.489697 --> 0.489642).  Saving model ...
Validation loss decreased (0.489642 --> 0.489587).  Saving model ...
Validation loss decreased (0.489587 --> 0.489532).  Saving model ...
Validation loss decreased (0.489532 --> 0.489477).  Saving model ...
Validation loss decreased (0.489477 --> 0.489423).  Saving model ...
Validation loss decreased (0.489423 --> 0.489368).  Saving model ...
Validation loss decreased (0.489368 --> 0.489314).  Saving model ...
Validation loss decreased (0.489314 --> 0.489260).  Saving model ...
Validation loss decreased (0.489260 --> 0.489206).  Saving model ...
Validation loss decreased (0.489206 --> 0.489152).  Saving model ...
Validation loss decreased (0.489152 --> 0.489099).  Saving model ...
Validation loss decreased (0.489099 --> 0.489045).  Saving model ...
Validation loss decreased (0.489045 --> 0.488992).  Saving model ...
Validation loss decreased (0.488992 --> 0.488939).  Saving model ...
Validation loss decreased (0.488939 --> 0.488886).  Saving model ...
Validation loss decreased (0.488886 --> 0.488833).  Saving model ...
Validation loss decreased (0.488833 --> 0.488780).  Saving model ...
Validation loss decreased (0.488780 --> 0.488728).  Saving model ...
Validation loss decreased (0.488728 --> 0.488675).  Saving model ...
Validation loss decreased (0.488675 --> 0.488623).  Saving model ...
Validation loss decreased (0.488623 --> 0.488571).  Saving model ...
Validation loss decreased (0.488571 --> 0.488519).  Saving model ...
Validation loss decreased (0.488519 --> 0.488467).  Saving model ...
Validation loss decreased (0.488467 --> 0.488416).  Saving model ...
Validation loss decreased (0.488416 --> 0.488364).  Saving model ...
Validation loss decreased (0.488364 --> 0.488313).  Saving model ...
Validation loss decreased (0.488313 --> 0.488262).  Saving model ...
Validation loss decreased (0.488262 --> 0.488211).  Saving model ...
Validation loss decreased (0.488211 --> 0.488160).  Saving model ...
Validation loss decreased (0.488160 --> 0.488109).  Saving model ...
Validation loss decreased (0.488109 --> 0.488059).  Saving model ...
Validation loss decreased (0.488059 --> 0.488008).  Saving model ...
Validation loss decreased (0.488008 --> 0.487958).  Saving model ...
Validation loss decreased (0.487958 --> 0.487908).  Saving model ...
Validation loss decreased (0.487908 --> 0.487858).  Saving model ...
Validation loss decreased (0.487858 --> 0.487808).  Saving model ...
Validation loss decreased (0.487808 --> 0.487758).  Saving model ...
Validation loss decreased (0.487758 --> 0.487708).  Saving model ...
Validation loss decreased (0.487708 --> 0.487659).  Saving model ...
Validation loss decreased (0.487659 --> 0.487610).  Saving model ...
Validation loss decreased (0.487610 --> 0.487560).  Saving model ...
Validation loss decreased (0.487560 --> 0.487511).  Saving model ...
epoch 901, loss 0.4875, train acc 75.68%, f1 0.6141, precision 0.6890, recall 0.5539, auc 0.7099
Validation loss decreased (0.487511 --> 0.487462).  Saving model ...
Validation loss decreased (0.487462 --> 0.487414).  Saving model ...
Validation loss decreased (0.487414 --> 0.487365).  Saving model ...
Validation loss decreased (0.487365 --> 0.487317).  Saving model ...
Validation loss decreased (0.487317 --> 0.487268).  Saving model ...
Validation loss decreased (0.487268 --> 0.487220).  Saving model ...
Validation loss decreased (0.487220 --> 0.487172).  Saving model ...
Validation loss decreased (0.487172 --> 0.487124).  Saving model ...
Validation loss decreased (0.487124 --> 0.487076).  Saving model ...
Validation loss decreased (0.487076 --> 0.487028).  Saving model ...
Validation loss decreased (0.487028 --> 0.486981).  Saving model ...
Validation loss decreased (0.486981 --> 0.486933).  Saving model ...
Validation loss decreased (0.486933 --> 0.486886).  Saving model ...
Validation loss decreased (0.486886 --> 0.486839).  Saving model ...
Validation loss decreased (0.486839 --> 0.486792).  Saving model ...
Validation loss decreased (0.486792 --> 0.486745).  Saving model ...
Validation loss decreased (0.486745 --> 0.486698).  Saving model ...
Validation loss decreased (0.486698 --> 0.486652).  Saving model ...
Validation loss decreased (0.486652 --> 0.486605).  Saving model ...
Validation loss decreased (0.486605 --> 0.486559).  Saving model ...
Validation loss decreased (0.486559 --> 0.486513).  Saving model ...
Validation loss decreased (0.486513 --> 0.486466).  Saving model ...
Validation loss decreased (0.486466 --> 0.486420).  Saving model ...
Validation loss decreased (0.486420 --> 0.486375).  Saving model ...
Validation loss decreased (0.486375 --> 0.486329).  Saving model ...
Validation loss decreased (0.486329 --> 0.486283).  Saving model ...
Validation loss decreased (0.486283 --> 0.486238).  Saving model ...
Validation loss decreased (0.486238 --> 0.486192).  Saving model ...
Validation loss decreased (0.486192 --> 0.486147).  Saving model ...
Validation loss decreased (0.486147 --> 0.486102).  Saving model ...
Validation loss decreased (0.486102 --> 0.486057).  Saving model ...
Validation loss decreased (0.486057 --> 0.486012).  Saving model ...
Validation loss decreased (0.486012 --> 0.485967).  Saving model ...
Validation loss decreased (0.485967 --> 0.485923).  Saving model ...
Validation loss decreased (0.485923 --> 0.485878).  Saving model ...
Validation loss decreased (0.485878 --> 0.485834).  Saving model ...
Validation loss decreased (0.485834 --> 0.485789).  Saving model ...
Validation loss decreased (0.485789 --> 0.485745).  Saving model ...
Validation loss decreased (0.485745 --> 0.485701).  Saving model ...
Validation loss decreased (0.485701 --> 0.485657).  Saving model ...
Validation loss decreased (0.485657 --> 0.485613).  Saving model ...
Validation loss decreased (0.485613 --> 0.485570).  Saving model ...
Validation loss decreased (0.485570 --> 0.485526).  Saving model ...
Validation loss decreased (0.485526 --> 0.485482).  Saving model ...
Validation loss decreased (0.485482 --> 0.485439).  Saving model ...
Validation loss decreased (0.485439 --> 0.485396).  Saving model ...
Validation loss decreased (0.485396 --> 0.485353).  Saving model ...
Validation loss decreased (0.485353 --> 0.485310).  Saving model ...
Validation loss decreased (0.485310 --> 0.485267).  Saving model ...
Validation loss decreased (0.485267 --> 0.485224).  Saving model ...
Validation loss decreased (0.485224 --> 0.485181).  Saving model ...
Validation loss decreased (0.485181 --> 0.485139).  Saving model ...
Validation loss decreased (0.485139 --> 0.485096).  Saving model ...
Validation loss decreased (0.485096 --> 0.485054).  Saving model ...
Validation loss decreased (0.485054 --> 0.485011).  Saving model ...
Validation loss decreased (0.485011 --> 0.484969).  Saving model ...
Validation loss decreased (0.484969 --> 0.484927).  Saving model ...
Validation loss decreased (0.484927 --> 0.484885).  Saving model ...
Validation loss decreased (0.484885 --> 0.484844).  Saving model ...
Validation loss decreased (0.484844 --> 0.484802).  Saving model ...
Validation loss decreased (0.484802 --> 0.484760).  Saving model ...
Validation loss decreased (0.484760 --> 0.484719).  Saving model ...
Validation loss decreased (0.484719 --> 0.484677).  Saving model ...
Validation loss decreased (0.484677 --> 0.484636).  Saving model ...
Validation loss decreased (0.484636 --> 0.484595).  Saving model ...
Validation loss decreased (0.484595 --> 0.484554).  Saving model ...
Validation loss decreased (0.484554 --> 0.484513).  Saving model ...
Validation loss decreased (0.484513 --> 0.484472).  Saving model ...
Validation loss decreased (0.484472 --> 0.484431).  Saving model ...
Validation loss decreased (0.484431 --> 0.484390).  Saving model ...
Validation loss decreased (0.484390 --> 0.484349).  Saving model ...
Validation loss decreased (0.484349 --> 0.484309).  Saving model ...
Validation loss decreased (0.484309 --> 0.484269).  Saving model ...
Validation loss decreased (0.484269 --> 0.484228).  Saving model ...
Validation loss decreased (0.484228 --> 0.484188).  Saving model ...
Validation loss decreased (0.484188 --> 0.484148).  Saving model ...
Validation loss decreased (0.484148 --> 0.484108).  Saving model ...
Validation loss decreased (0.484108 --> 0.484068).  Saving model ...
Validation loss decreased (0.484068 --> 0.484028).  Saving model ...
Validation loss decreased (0.484028 --> 0.483988).  Saving model ...
Validation loss decreased (0.483988 --> 0.483949).  Saving model ...
Validation loss decreased (0.483949 --> 0.483909).  Saving model ...
Validation loss decreased (0.483909 --> 0.483870).  Saving model ...
Validation loss decreased (0.483870 --> 0.483830).  Saving model ...
Validation loss decreased (0.483830 --> 0.483791).  Saving model ...
Validation loss decreased (0.483791 --> 0.483752).  Saving model ...
Validation loss decreased (0.483752 --> 0.483713).  Saving model ...
Validation loss decreased (0.483713 --> 0.483674).  Saving model ...
Validation loss decreased (0.483674 --> 0.483635).  Saving model ...
Validation loss decreased (0.483635 --> 0.483596).  Saving model ...
Validation loss decreased (0.483596 --> 0.483557).  Saving model ...
Validation loss decreased (0.483557 --> 0.483519).  Saving model ...
Validation loss decreased (0.483519 --> 0.483480).  Saving model ...
Validation loss decreased (0.483480 --> 0.483442).  Saving model ...
Validation loss decreased (0.483442 --> 0.483403).  Saving model ...
Validation loss decreased (0.483403 --> 0.483365).  Saving model ...
Validation loss decreased (0.483365 --> 0.483327).  Saving model ...
Validation loss decreased (0.483327 --> 0.483289).  Saving model ...
Validation loss decreased (0.483289 --> 0.483251).  Saving model ...
Validation loss decreased (0.483251 --> 0.483213).  Saving model ...
epoch 1001, loss 0.4832, train acc 76.20%, f1 0.6313, precision 0.6879, recall 0.5833, auc 0.7206
Validation loss decreased (0.483213 --> 0.483175).  Saving model ...
Validation loss decreased (0.483175 --> 0.483137).  Saving model ...
Validation loss decreased (0.483137 --> 0.483099).  Saving model ...
Validation loss decreased (0.483099 --> 0.483062).  Saving model ...
Validation loss decreased (0.483062 --> 0.483024).  Saving model ...
Validation loss decreased (0.483024 --> 0.482987).  Saving model ...
Validation loss decreased (0.482987 --> 0.482949).  Saving model ...
Validation loss decreased (0.482949 --> 0.482912).  Saving model ...
Validation loss decreased (0.482912 --> 0.482875).  Saving model ...
Validation loss decreased (0.482875 --> 0.482838).  Saving model ...
Validation loss decreased (0.482838 --> 0.482801).  Saving model ...
Validation loss decreased (0.482801 --> 0.482764).  Saving model ...
Validation loss decreased (0.482764 --> 0.482727).  Saving model ...
Validation loss decreased (0.482727 --> 0.482690).  Saving model ...
Validation loss decreased (0.482690 --> 0.482653).  Saving model ...
Validation loss decreased (0.482653 --> 0.482616).  Saving model ...
Validation loss decreased (0.482616 --> 0.482580).  Saving model ...
Validation loss decreased (0.482580 --> 0.482543).  Saving model ...
Validation loss decreased (0.482543 --> 0.482507).  Saving model ...
Validation loss decreased (0.482507 --> 0.482471).  Saving model ...
Validation loss decreased (0.482471 --> 0.482434).  Saving model ...
Validation loss decreased (0.482434 --> 0.482398).  Saving model ...
Validation loss decreased (0.482398 --> 0.482362).  Saving model ...
Validation loss decreased (0.482362 --> 0.482326).  Saving model ...
Validation loss decreased (0.482326 --> 0.482290).  Saving model ...
Validation loss decreased (0.482290 --> 0.482254).  Saving model ...
Validation loss decreased (0.482254 --> 0.482218).  Saving model ...
Validation loss decreased (0.482218 --> 0.482182).  Saving model ...
Validation loss decreased (0.482182 --> 0.482146).  Saving model ...
Validation loss decreased (0.482146 --> 0.482111).  Saving model ...
Validation loss decreased (0.482111 --> 0.482075).  Saving model ...
Validation loss decreased (0.482075 --> 0.482039).  Saving model ...
Validation loss decreased (0.482039 --> 0.482004).  Saving model ...
Validation loss decreased (0.482004 --> 0.481969).  Saving model ...
Validation loss decreased (0.481969 --> 0.481933).  Saving model ...
Validation loss decreased (0.481933 --> 0.481898).  Saving model ...
Validation loss decreased (0.481898 --> 0.481863).  Saving model ...
Validation loss decreased (0.481863 --> 0.481828).  Saving model ...
Validation loss decreased (0.481828 --> 0.481793).  Saving model ...
Validation loss decreased (0.481793 --> 0.481757).  Saving model ...
Validation loss decreased (0.481757 --> 0.481722).  Saving model ...
Validation loss decreased (0.481722 --> 0.481688).  Saving model ...
Validation loss decreased (0.481688 --> 0.481653).  Saving model ...
Validation loss decreased (0.481653 --> 0.481618).  Saving model ...
Validation loss decreased (0.481618 --> 0.481583).  Saving model ...
Validation loss decreased (0.481583 --> 0.481549).  Saving model ...
Validation loss decreased (0.481549 --> 0.481514).  Saving model ...
Validation loss decreased (0.481514 --> 0.481479).  Saving model ...
Validation loss decreased (0.481479 --> 0.481445).  Saving model ...
Validation loss decreased (0.481445 --> 0.481410).  Saving model ...
Validation loss decreased (0.481410 --> 0.481376).  Saving model ...
Validation loss decreased (0.481376 --> 0.481342).  Saving model ...
Validation loss decreased (0.481342 --> 0.481307).  Saving model ...
Validation loss decreased (0.481307 --> 0.481273).  Saving model ...
Validation loss decreased (0.481273 --> 0.481239).  Saving model ...
Validation loss decreased (0.481239 --> 0.481205).  Saving model ...
Validation loss decreased (0.481205 --> 0.481171).  Saving model ...
Validation loss decreased (0.481171 --> 0.481137).  Saving model ...
Validation loss decreased (0.481137 --> 0.481103).  Saving model ...
Validation loss decreased (0.481103 --> 0.481069).  Saving model ...
Validation loss decreased (0.481069 --> 0.481035).  Saving model ...
Validation loss decreased (0.481035 --> 0.481001).  Saving model ...
Validation loss decreased (0.481001 --> 0.480968).  Saving model ...
Validation loss decreased (0.480968 --> 0.480934).  Saving model ...
Validation loss decreased (0.480934 --> 0.480900).  Saving model ...
Validation loss decreased (0.480900 --> 0.480867).  Saving model ...
Validation loss decreased (0.480867 --> 0.480833).  Saving model ...
Validation loss decreased (0.480833 --> 0.480800).  Saving model ...
Validation loss decreased (0.480800 --> 0.480766).  Saving model ...
Validation loss decreased (0.480766 --> 0.480733).  Saving model ...
Validation loss decreased (0.480733 --> 0.480699).  Saving model ...
Validation loss decreased (0.480699 --> 0.480666).  Saving model ...
Validation loss decreased (0.480666 --> 0.480633).  Saving model ...
Validation loss decreased (0.480633 --> 0.480599).  Saving model ...
Validation loss decreased (0.480599 --> 0.480566).  Saving model ...
Validation loss decreased (0.480566 --> 0.480533).  Saving model ...
Validation loss decreased (0.480533 --> 0.480500).  Saving model ...
Validation loss decreased (0.480500 --> 0.480467).  Saving model ...
Validation loss decreased (0.480467 --> 0.480434).  Saving model ...
Validation loss decreased (0.480434 --> 0.480401).  Saving model ...
Validation loss decreased (0.480401 --> 0.480368).  Saving model ...
Validation loss decreased (0.480368 --> 0.480335).  Saving model ...
Validation loss decreased (0.480335 --> 0.480302).  Saving model ...
Validation loss decreased (0.480302 --> 0.480269).  Saving model ...
Validation loss decreased (0.480269 --> 0.480236).  Saving model ...
Validation loss decreased (0.480236 --> 0.480203).  Saving model ...
Validation loss decreased (0.480203 --> 0.480170).  Saving model ...
Validation loss decreased (0.480170 --> 0.480138).  Saving model ...
Validation loss decreased (0.480138 --> 0.480105).  Saving model ...
Validation loss decreased (0.480105 --> 0.480072).  Saving model ...
Validation loss decreased (0.480072 --> 0.480040).  Saving model ...
Validation loss decreased (0.480040 --> 0.480007).  Saving model ...
Validation loss decreased (0.480007 --> 0.479974).  Saving model ...
Validation loss decreased (0.479974 --> 0.479942).  Saving model ...
Validation loss decreased (0.479942 --> 0.479909).  Saving model ...
Validation loss decreased (0.479909 --> 0.479877).  Saving model ...
Validation loss decreased (0.479877 --> 0.479844).  Saving model ...
Validation loss decreased (0.479844 --> 0.479812).  Saving model ...
Validation loss decreased (0.479812 --> 0.479780).  Saving model ...
Validation loss decreased (0.479780 --> 0.479747).  Saving model ...
epoch 1101, loss 0.4797, train acc 76.20%, f1 0.6352, precision 0.6836, recall 0.5931, auc 0.7229
Validation loss decreased (0.479747 --> 0.479715).  Saving model ...
Validation loss decreased (0.479715 --> 0.479682).  Saving model ...
Validation loss decreased (0.479682 --> 0.479650).  Saving model ...
Validation loss decreased (0.479650 --> 0.479618).  Saving model ...
Validation loss decreased (0.479618 --> 0.479586).  Saving model ...
Validation loss decreased (0.479586 --> 0.479553).  Saving model ...
Validation loss decreased (0.479553 --> 0.479521).  Saving model ...
Validation loss decreased (0.479521 --> 0.479489).  Saving model ...
Validation loss decreased (0.479489 --> 0.479457).  Saving model ...
Validation loss decreased (0.479457 --> 0.479424).  Saving model ...
Validation loss decreased (0.479424 --> 0.479392).  Saving model ...
Validation loss decreased (0.479392 --> 0.479360).  Saving model ...
Validation loss decreased (0.479360 --> 0.479328).  Saving model ...
Validation loss decreased (0.479328 --> 0.479296).  Saving model ...
Validation loss decreased (0.479296 --> 0.479264).  Saving model ...
Validation loss decreased (0.479264 --> 0.479232).  Saving model ...
Validation loss decreased (0.479232 --> 0.479200).  Saving model ...
Validation loss decreased (0.479200 --> 0.479168).  Saving model ...
Validation loss decreased (0.479168 --> 0.479136).  Saving model ...
Validation loss decreased (0.479136 --> 0.479104).  Saving model ...
Validation loss decreased (0.479104 --> 0.479071).  Saving model ...
Validation loss decreased (0.479071 --> 0.479039).  Saving model ...
Validation loss decreased (0.479039 --> 0.479007).  Saving model ...
Validation loss decreased (0.479007 --> 0.478975).  Saving model ...
Validation loss decreased (0.478975 --> 0.478943).  Saving model ...
Validation loss decreased (0.478943 --> 0.478911).  Saving model ...
Validation loss decreased (0.478911 --> 0.478879).  Saving model ...
Validation loss decreased (0.478879 --> 0.478848).  Saving model ...
Validation loss decreased (0.478848 --> 0.478816).  Saving model ...
Validation loss decreased (0.478816 --> 0.478784).  Saving model ...
Validation loss decreased (0.478784 --> 0.478752).  Saving model ...
Validation loss decreased (0.478752 --> 0.478720).  Saving model ...
Validation loss decreased (0.478720 --> 0.478688).  Saving model ...
Validation loss decreased (0.478688 --> 0.478656).  Saving model ...
Validation loss decreased (0.478656 --> 0.478624).  Saving model ...
Validation loss decreased (0.478624 --> 0.478592).  Saving model ...
Validation loss decreased (0.478592 --> 0.478560).  Saving model ...
Validation loss decreased (0.478560 --> 0.478528).  Saving model ...
Validation loss decreased (0.478528 --> 0.478496).  Saving model ...
Validation loss decreased (0.478496 --> 0.478464).  Saving model ...
Validation loss decreased (0.478464 --> 0.478432).  Saving model ...
Validation loss decreased (0.478432 --> 0.478400).  Saving model ...
Validation loss decreased (0.478400 --> 0.478368).  Saving model ...
Validation loss decreased (0.478368 --> 0.478336).  Saving model ...
Validation loss decreased (0.478336 --> 0.478304).  Saving model ...
Validation loss decreased (0.478304 --> 0.478272).  Saving model ...
Validation loss decreased (0.478272 --> 0.478240).  Saving model ...
Validation loss decreased (0.478240 --> 0.478208).  Saving model ...
Validation loss decreased (0.478208 --> 0.478176).  Saving model ...
Validation loss decreased (0.478176 --> 0.478144).  Saving model ...
Validation loss decreased (0.478144 --> 0.478112).  Saving model ...
Validation loss decreased (0.478112 --> 0.478080).  Saving model ...
Validation loss decreased (0.478080 --> 0.478048).  Saving model ...
Validation loss decreased (0.478048 --> 0.478015).  Saving model ...
Validation loss decreased (0.478015 --> 0.477983).  Saving model ...
Validation loss decreased (0.477983 --> 0.477951).  Saving model ...
Validation loss decreased (0.477951 --> 0.477919).  Saving model ...
Validation loss decreased (0.477919 --> 0.477887).  Saving model ...
Validation loss decreased (0.477887 --> 0.477855).  Saving model ...
Validation loss decreased (0.477855 --> 0.477823).  Saving model ...
Validation loss decreased (0.477823 --> 0.477790).  Saving model ...
Validation loss decreased (0.477790 --> 0.477758).  Saving model ...
Validation loss decreased (0.477758 --> 0.477726).  Saving model ...
Validation loss decreased (0.477726 --> 0.477693).  Saving model ...
Validation loss decreased (0.477693 --> 0.477661).  Saving model ...
Validation loss decreased (0.477661 --> 0.477629).  Saving model ...
Validation loss decreased (0.477629 --> 0.477596).  Saving model ...
Validation loss decreased (0.477596 --> 0.477564).  Saving model ...
Validation loss decreased (0.477564 --> 0.477532).  Saving model ...
Validation loss decreased (0.477532 --> 0.477499).  Saving model ...
Validation loss decreased (0.477499 --> 0.477467).  Saving model ...
Validation loss decreased (0.477467 --> 0.477434).  Saving model ...
Validation loss decreased (0.477434 --> 0.477402).  Saving model ...
Validation loss decreased (0.477402 --> 0.477369).  Saving model ...
Validation loss decreased (0.477369 --> 0.477336).  Saving model ...
Validation loss decreased (0.477336 --> 0.477304).  Saving model ...
Validation loss decreased (0.477304 --> 0.477271).  Saving model ...
Validation loss decreased (0.477271 --> 0.477238).  Saving model ...
Validation loss decreased (0.477238 --> 0.477206).  Saving model ...
Validation loss decreased (0.477206 --> 0.477173).  Saving model ...
Validation loss decreased (0.477173 --> 0.477140).  Saving model ...
Validation loss decreased (0.477140 --> 0.477107).  Saving model ...
Validation loss decreased (0.477107 --> 0.477075).  Saving model ...
Validation loss decreased (0.477075 --> 0.477042).  Saving model ...
Validation loss decreased (0.477042 --> 0.477009).  Saving model ...
Validation loss decreased (0.477009 --> 0.476976).  Saving model ...
Validation loss decreased (0.476976 --> 0.476943).  Saving model ...
Validation loss decreased (0.476943 --> 0.476910).  Saving model ...
Validation loss decreased (0.476910 --> 0.476876).  Saving model ...
Validation loss decreased (0.476876 --> 0.476843).  Saving model ...
Validation loss decreased (0.476843 --> 0.476810).  Saving model ...
Validation loss decreased (0.476810 --> 0.476777).  Saving model ...
Validation loss decreased (0.476777 --> 0.476744).  Saving model ...
Validation loss decreased (0.476744 --> 0.476710).  Saving model ...
Validation loss decreased (0.476710 --> 0.476677).  Saving model ...
Validation loss decreased (0.476677 --> 0.476644).  Saving model ...
Validation loss decreased (0.476644 --> 0.476610).  Saving model ...
Validation loss decreased (0.476610 --> 0.476577).  Saving model ...
Validation loss decreased (0.476577 --> 0.476543).  Saving model ...
Validation loss decreased (0.476543 --> 0.476509).  Saving model ...
epoch 1201, loss 0.4765, train acc 76.54%, f1 0.6423, precision 0.6872, recall 0.6029, auc 0.7278
Validation loss decreased (0.476509 --> 0.476476).  Saving model ...
Validation loss decreased (0.476476 --> 0.476442).  Saving model ...
Validation loss decreased (0.476442 --> 0.476408).  Saving model ...
Validation loss decreased (0.476408 --> 0.476374).  Saving model ...
Validation loss decreased (0.476374 --> 0.476341).  Saving model ...
Validation loss decreased (0.476341 --> 0.476307).  Saving model ...
Validation loss decreased (0.476307 --> 0.476273).  Saving model ...
Validation loss decreased (0.476273 --> 0.476239).  Saving model ...
Validation loss decreased (0.476239 --> 0.476205).  Saving model ...
Validation loss decreased (0.476205 --> 0.476170).  Saving model ...
Validation loss decreased (0.476170 --> 0.476136).  Saving model ...
Validation loss decreased (0.476136 --> 0.476102).  Saving model ...
Validation loss decreased (0.476102 --> 0.476068).  Saving model ...
Validation loss decreased (0.476068 --> 0.476033).  Saving model ...
Validation loss decreased (0.476033 --> 0.475999).  Saving model ...
Validation loss decreased (0.475999 --> 0.475964).  Saving model ...
Validation loss decreased (0.475964 --> 0.475930).  Saving model ...
Validation loss decreased (0.475930 --> 0.475895).  Saving model ...
Validation loss decreased (0.475895 --> 0.475861).  Saving model ...
Validation loss decreased (0.475861 --> 0.475826).  Saving model ...
Validation loss decreased (0.475826 --> 0.475791).  Saving model ...
Validation loss decreased (0.475791 --> 0.475756).  Saving model ...
Validation loss decreased (0.475756 --> 0.475722).  Saving model ...
Validation loss decreased (0.475722 --> 0.475687).  Saving model ...
Validation loss decreased (0.475687 --> 0.475651).  Saving model ...
Validation loss decreased (0.475651 --> 0.475616).  Saving model ...
Validation loss decreased (0.475616 --> 0.475581).  Saving model ...
Validation loss decreased (0.475581 --> 0.475546).  Saving model ...
Validation loss decreased (0.475546 --> 0.475511).  Saving model ...
Validation loss decreased (0.475511 --> 0.475475).  Saving model ...
Validation loss decreased (0.475475 --> 0.475440).  Saving model ...
Validation loss decreased (0.475440 --> 0.475405).  Saving model ...
Validation loss decreased (0.475405 --> 0.475369).  Saving model ...
Validation loss decreased (0.475369 --> 0.475333).  Saving model ...
Validation loss decreased (0.475333 --> 0.475298).  Saving model ...
Validation loss decreased (0.475298 --> 0.475262).  Saving model ...
Validation loss decreased (0.475262 --> 0.475226).  Saving model ...
Validation loss decreased (0.475226 --> 0.475190).  Saving model ...
Validation loss decreased (0.475190 --> 0.475154).  Saving model ...
Validation loss decreased (0.475154 --> 0.475118).  Saving model ...
Validation loss decreased (0.475118 --> 0.475082).  Saving model ...
Validation loss decreased (0.475082 --> 0.475046).  Saving model ...
Validation loss decreased (0.475046 --> 0.475010).  Saving model ...
Validation loss decreased (0.475010 --> 0.474973).  Saving model ...
Validation loss decreased (0.474973 --> 0.474937).  Saving model ...
Validation loss decreased (0.474937 --> 0.474901).  Saving model ...
Validation loss decreased (0.474901 --> 0.474864).  Saving model ...
Validation loss decreased (0.474864 --> 0.474827).  Saving model ...
Validation loss decreased (0.474827 --> 0.474791).  Saving model ...
Validation loss decreased (0.474791 --> 0.474754).  Saving model ...
Validation loss decreased (0.474754 --> 0.474717).  Saving model ...
Validation loss decreased (0.474717 --> 0.474680).  Saving model ...
Validation loss decreased (0.474680 --> 0.474643).  Saving model ...
Validation loss decreased (0.474643 --> 0.474606).  Saving model ...
Validation loss decreased (0.474606 --> 0.474569).  Saving model ...
Validation loss decreased (0.474569 --> 0.474532).  Saving model ...
Validation loss decreased (0.474532 --> 0.474495).  Saving model ...
Validation loss decreased (0.474495 --> 0.474457).  Saving model ...
Validation loss decreased (0.474457 --> 0.474420).  Saving model ...
Validation loss decreased (0.474420 --> 0.474383).  Saving model ...
Validation loss decreased (0.474383 --> 0.474345).  Saving model ...
Validation loss decreased (0.474345 --> 0.474307).  Saving model ...
Validation loss decreased (0.474307 --> 0.474270).  Saving model ...
Validation loss decreased (0.474270 --> 0.474232).  Saving model ...
Validation loss decreased (0.474232 --> 0.474194).  Saving model ...
Validation loss decreased (0.474194 --> 0.474156).  Saving model ...
Validation loss decreased (0.474156 --> 0.474118).  Saving model ...
Validation loss decreased (0.474118 --> 0.474080).  Saving model ...
Validation loss decreased (0.474080 --> 0.474042).  Saving model ...
Validation loss decreased (0.474042 --> 0.474004).  Saving model ...
Validation loss decreased (0.474004 --> 0.473965).  Saving model ...
Validation loss decreased (0.473965 --> 0.473927).  Saving model ...
Validation loss decreased (0.473927 --> 0.473889).  Saving model ...
Validation loss decreased (0.473889 --> 0.473850).  Saving model ...
Validation loss decreased (0.473850 --> 0.473812).  Saving model ...
Validation loss decreased (0.473812 --> 0.473773).  Saving model ...
Validation loss decreased (0.473773 --> 0.473734).  Saving model ...
Validation loss decreased (0.473734 --> 0.473695).  Saving model ...
Validation loss decreased (0.473695 --> 0.473656).  Saving model ...
Validation loss decreased (0.473656 --> 0.473618).  Saving model ...
Validation loss decreased (0.473618 --> 0.473579).  Saving model ...
Validation loss decreased (0.473579 --> 0.473539).  Saving model ...
Validation loss decreased (0.473539 --> 0.473500).  Saving model ...
Validation loss decreased (0.473500 --> 0.473461).  Saving model ...
Validation loss decreased (0.473461 --> 0.473422).  Saving model ...
Validation loss decreased (0.473422 --> 0.473382).  Saving model ...
Validation loss decreased (0.473382 --> 0.473343).  Saving model ...
Validation loss decreased (0.473343 --> 0.473303).  Saving model ...
Validation loss decreased (0.473303 --> 0.473264).  Saving model ...
Validation loss decreased (0.473264 --> 0.473224).  Saving model ...
Validation loss decreased (0.473224 --> 0.473184).  Saving model ...
Validation loss decreased (0.473184 --> 0.473145).  Saving model ...
Validation loss decreased (0.473145 --> 0.473105).  Saving model ...
Validation loss decreased (0.473105 --> 0.473065).  Saving model ...
Validation loss decreased (0.473065 --> 0.473025).  Saving model ...
Validation loss decreased (0.473025 --> 0.472985).  Saving model ...
Validation loss decreased (0.472985 --> 0.472944).  Saving model ...
Validation loss decreased (0.472944 --> 0.472904).  Saving model ...
Validation loss decreased (0.472904 --> 0.472864).  Saving model ...
Validation loss decreased (0.472864 --> 0.472823).  Saving model ...
epoch 1301, loss 0.4728, train acc 76.71%, f1 0.6421, precision 0.6932, recall 0.5980, auc 0.7280
Validation loss decreased (0.472823 --> 0.472783).  Saving model ...
Validation loss decreased (0.472783 --> 0.472743).  Saving model ...
Validation loss decreased (0.472743 --> 0.472702).  Saving model ...
Validation loss decreased (0.472702 --> 0.472661).  Saving model ...
Validation loss decreased (0.472661 --> 0.472621).  Saving model ...
Validation loss decreased (0.472621 --> 0.472580).  Saving model ...
Validation loss decreased (0.472580 --> 0.472539).  Saving model ...
Validation loss decreased (0.472539 --> 0.472498).  Saving model ...
Validation loss decreased (0.472498 --> 0.472457).  Saving model ...
Validation loss decreased (0.472457 --> 0.472416).  Saving model ...
Validation loss decreased (0.472416 --> 0.472375).  Saving model ...
Validation loss decreased (0.472375 --> 0.472334).  Saving model ...
Validation loss decreased (0.472334 --> 0.472293).  Saving model ...
Validation loss decreased (0.472293 --> 0.472251).  Saving model ...
Validation loss decreased (0.472251 --> 0.472210).  Saving model ...
Validation loss decreased (0.472210 --> 0.472169).  Saving model ...
Validation loss decreased (0.472169 --> 0.472127).  Saving model ...
Validation loss decreased (0.472127 --> 0.472086).  Saving model ...
Validation loss decreased (0.472086 --> 0.472044).  Saving model ...
Validation loss decreased (0.472044 --> 0.472002).  Saving model ...
Validation loss decreased (0.472002 --> 0.471961).  Saving model ...
Validation loss decreased (0.471961 --> 0.471919).  Saving model ...
Validation loss decreased (0.471919 --> 0.471877).  Saving model ...
Validation loss decreased (0.471877 --> 0.471835).  Saving model ...
Validation loss decreased (0.471835 --> 0.471793).  Saving model ...
Validation loss decreased (0.471793 --> 0.471751).  Saving model ...
Validation loss decreased (0.471751 --> 0.471709).  Saving model ...
Validation loss decreased (0.471709 --> 0.471667).  Saving model ...
Validation loss decreased (0.471667 --> 0.471625).  Saving model ...
Validation loss decreased (0.471625 --> 0.471583).  Saving model ...
Validation loss decreased (0.471583 --> 0.471540).  Saving model ...
Validation loss decreased (0.471540 --> 0.471498).  Saving model ...
Validation loss decreased (0.471498 --> 0.471456).  Saving model ...
Validation loss decreased (0.471456 --> 0.471413).  Saving model ...
Validation loss decreased (0.471413 --> 0.471371).  Saving model ...
Validation loss decreased (0.471371 --> 0.471328).  Saving model ...
Validation loss decreased (0.471328 --> 0.471286).  Saving model ...
Validation loss decreased (0.471286 --> 0.471243).  Saving model ...
Validation loss decreased (0.471243 --> 0.471200).  Saving model ...
Validation loss decreased (0.471200 --> 0.471158).  Saving model ...
Validation loss decreased (0.471158 --> 0.471115).  Saving model ...
Validation loss decreased (0.471115 --> 0.471072).  Saving model ...
Validation loss decreased (0.471072 --> 0.471029).  Saving model ...
Validation loss decreased (0.471029 --> 0.470986).  Saving model ...
Validation loss decreased (0.470986 --> 0.470943).  Saving model ...
Validation loss decreased (0.470943 --> 0.470900).  Saving model ...
Validation loss decreased (0.470900 --> 0.470857).  Saving model ...
Validation loss decreased (0.470857 --> 0.470814).  Saving model ...
Validation loss decreased (0.470814 --> 0.470771).  Saving model ...
Validation loss decreased (0.470771 --> 0.470728).  Saving model ...
Validation loss decreased (0.470728 --> 0.470684).  Saving model ...
Validation loss decreased (0.470684 --> 0.470641).  Saving model ...
Validation loss decreased (0.470641 --> 0.470598).  Saving model ...
Validation loss decreased (0.470598 --> 0.470554).  Saving model ...
Validation loss decreased (0.470554 --> 0.470511).  Saving model ...
Validation loss decreased (0.470511 --> 0.470467).  Saving model ...
Validation loss decreased (0.470467 --> 0.470424).  Saving model ...
Validation loss decreased (0.470424 --> 0.470380).  Saving model ...
Validation loss decreased (0.470380 --> 0.470337).  Saving model ...
Validation loss decreased (0.470337 --> 0.470293).  Saving model ...
Validation loss decreased (0.470293 --> 0.470250).  Saving model ...
Validation loss decreased (0.470250 --> 0.470206).  Saving model ...
Validation loss decreased (0.470206 --> 0.470162).  Saving model ...
Validation loss decreased (0.470162 --> 0.470118).  Saving model ...
Validation loss decreased (0.470118 --> 0.470075).  Saving model ...
Validation loss decreased (0.470075 --> 0.470031).  Saving model ...
Validation loss decreased (0.470031 --> 0.469987).  Saving model ...
Validation loss decreased (0.469987 --> 0.469943).  Saving model ...
Validation loss decreased (0.469943 --> 0.469899).  Saving model ...
Validation loss decreased (0.469899 --> 0.469855).  Saving model ...
Validation loss decreased (0.469855 --> 0.469811).  Saving model ...
Validation loss decreased (0.469811 --> 0.469767).  Saving model ...
Validation loss decreased (0.469767 --> 0.469723).  Saving model ...
Validation loss decreased (0.469723 --> 0.469679).  Saving model ...
Validation loss decreased (0.469679 --> 0.469635).  Saving model ...
Validation loss decreased (0.469635 --> 0.469591).  Saving model ...
Validation loss decreased (0.469591 --> 0.469547).  Saving model ...
Validation loss decreased (0.469547 --> 0.469502).  Saving model ...
Validation loss decreased (0.469502 --> 0.469458).  Saving model ...
Validation loss decreased (0.469458 --> 0.469414).  Saving model ...
Validation loss decreased (0.469414 --> 0.469370).  Saving model ...
Validation loss decreased (0.469370 --> 0.469325).  Saving model ...
Validation loss decreased (0.469325 --> 0.469281).  Saving model ...
Validation loss decreased (0.469281 --> 0.469237).  Saving model ...
Validation loss decreased (0.469237 --> 0.469192).  Saving model ...
Validation loss decreased (0.469192 --> 0.469148).  Saving model ...
Validation loss decreased (0.469148 --> 0.469104).  Saving model ...
Validation loss decreased (0.469104 --> 0.469059).  Saving model ...
Validation loss decreased (0.469059 --> 0.469015).  Saving model ...
Validation loss decreased (0.469015 --> 0.468970).  Saving model ...
Validation loss decreased (0.468970 --> 0.468925).  Saving model ...
Validation loss decreased (0.468925 --> 0.468881).  Saving model ...
Validation loss decreased (0.468881 --> 0.468836).  Saving model ...
Validation loss decreased (0.468836 --> 0.468792).  Saving model ...
Validation loss decreased (0.468792 --> 0.468747).  Saving model ...
Validation loss decreased (0.468747 --> 0.468703).  Saving model ...
Validation loss decreased (0.468703 --> 0.468658).  Saving model ...
Validation loss decreased (0.468658 --> 0.468613).  Saving model ...
Validation loss decreased (0.468613 --> 0.468569).  Saving model ...
Validation loss decreased (0.468569 --> 0.468524).  Saving model ...
epoch 1401, loss 0.4685, train acc 77.91%, f1 0.6596, precision 0.7143, recall 0.6127, auc 0.7406
Validation loss decreased (0.468524 --> 0.468479).  Saving model ...
Validation loss decreased (0.468479 --> 0.468434).  Saving model ...
Validation loss decreased (0.468434 --> 0.468390).  Saving model ...
Validation loss decreased (0.468390 --> 0.468345).  Saving model ...
Validation loss decreased (0.468345 --> 0.468300).  Saving model ...
Validation loss decreased (0.468300 --> 0.468255).  Saving model ...
Validation loss decreased (0.468255 --> 0.468211).  Saving model ...
Validation loss decreased (0.468211 --> 0.468166).  Saving model ...
Validation loss decreased (0.468166 --> 0.468121).  Saving model ...
Validation loss decreased (0.468121 --> 0.468076).  Saving model ...
Validation loss decreased (0.468076 --> 0.468031).  Saving model ...
Validation loss decreased (0.468031 --> 0.467986).  Saving model ...
Validation loss decreased (0.467986 --> 0.467941).  Saving model ...
Validation loss decreased (0.467941 --> 0.467896).  Saving model ...
Validation loss decreased (0.467896 --> 0.467852).  Saving model ...
Validation loss decreased (0.467852 --> 0.467807).  Saving model ...
Validation loss decreased (0.467807 --> 0.467762).  Saving model ...
Validation loss decreased (0.467762 --> 0.467717).  Saving model ...
Validation loss decreased (0.467717 --> 0.467672).  Saving model ...
Validation loss decreased (0.467672 --> 0.467627).  Saving model ...
Validation loss decreased (0.467627 --> 0.467582).  Saving model ...
Validation loss decreased (0.467582 --> 0.467537).  Saving model ...
Validation loss decreased (0.467537 --> 0.467492).  Saving model ...
Validation loss decreased (0.467492 --> 0.467447).  Saving model ...
Validation loss decreased (0.467447 --> 0.467402).  Saving model ...
Validation loss decreased (0.467402 --> 0.467357).  Saving model ...
Validation loss decreased (0.467357 --> 0.467312).  Saving model ...
Validation loss decreased (0.467312 --> 0.467267).  Saving model ...
Validation loss decreased (0.467267 --> 0.467222).  Saving model ...
Validation loss decreased (0.467222 --> 0.467177).  Saving model ...
Validation loss decreased (0.467177 --> 0.467132).  Saving model ...
Validation loss decreased (0.467132 --> 0.467087).  Saving model ...
Validation loss decreased (0.467087 --> 0.467042).  Saving model ...
Validation loss decreased (0.467042 --> 0.466996).  Saving model ...
Validation loss decreased (0.466996 --> 0.466951).  Saving model ...
Validation loss decreased (0.466951 --> 0.466906).  Saving model ...
Validation loss decreased (0.466906 --> 0.466861).  Saving model ...
Validation loss decreased (0.466861 --> 0.466816).  Saving model ...
Validation loss decreased (0.466816 --> 0.466771).  Saving model ...
Validation loss decreased (0.466771 --> 0.466726).  Saving model ...
Validation loss decreased (0.466726 --> 0.466681).  Saving model ...
Validation loss decreased (0.466681 --> 0.466636).  Saving model ...
Validation loss decreased (0.466636 --> 0.466591).  Saving model ...
Validation loss decreased (0.466591 --> 0.466546).  Saving model ...
Validation loss decreased (0.466546 --> 0.466501).  Saving model ...
Validation loss decreased (0.466501 --> 0.466456).  Saving model ...
Validation loss decreased (0.466456 --> 0.466411).  Saving model ...
Validation loss decreased (0.466411 --> 0.466366).  Saving model ...
Validation loss decreased (0.466366 --> 0.466320).  Saving model ...
Validation loss decreased (0.466320 --> 0.466275).  Saving model ...
Validation loss decreased (0.466275 --> 0.466230).  Saving model ...
Validation loss decreased (0.466230 --> 0.466185).  Saving model ...
Validation loss decreased (0.466185 --> 0.466140).  Saving model ...
Validation loss decreased (0.466140 --> 0.466095).  Saving model ...
Validation loss decreased (0.466095 --> 0.466050).  Saving model ...
Validation loss decreased (0.466050 --> 0.466005).  Saving model ...
Validation loss decreased (0.466005 --> 0.465960).  Saving model ...
Validation loss decreased (0.465960 --> 0.465915).  Saving model ...
Validation loss decreased (0.465915 --> 0.465870).  Saving model ...
Validation loss decreased (0.465870 --> 0.465825).  Saving model ...
Validation loss decreased (0.465825 --> 0.465780).  Saving model ...
Validation loss decreased (0.465780 --> 0.465735).  Saving model ...
Validation loss decreased (0.465735 --> 0.465690).  Saving model ...
Validation loss decreased (0.465690 --> 0.465645).  Saving model ...
Validation loss decreased (0.465645 --> 0.465600).  Saving model ...
Validation loss decreased (0.465600 --> 0.465555).  Saving model ...
Validation loss decreased (0.465555 --> 0.465510).  Saving model ...
Validation loss decreased (0.465510 --> 0.465465).  Saving model ...
Validation loss decreased (0.465465 --> 0.465420).  Saving model ...
Validation loss decreased (0.465420 --> 0.465375).  Saving model ...
Validation loss decreased (0.465375 --> 0.465330).  Saving model ...
Validation loss decreased (0.465330 --> 0.465286).  Saving model ...
Validation loss decreased (0.465286 --> 0.465241).  Saving model ...
Validation loss decreased (0.465241 --> 0.465196).  Saving model ...
Validation loss decreased (0.465196 --> 0.465151).  Saving model ...
Validation loss decreased (0.465151 --> 0.465106).  Saving model ...
Validation loss decreased (0.465106 --> 0.465061).  Saving model ...
Validation loss decreased (0.465061 --> 0.465017).  Saving model ...
Validation loss decreased (0.465017 --> 0.464972).  Saving model ...
Validation loss decreased (0.464972 --> 0.464927).  Saving model ...
Validation loss decreased (0.464927 --> 0.464882).  Saving model ...
Validation loss decreased (0.464882 --> 0.464837).  Saving model ...
Validation loss decreased (0.464837 --> 0.464793).  Saving model ...
Validation loss decreased (0.464793 --> 0.464748).  Saving model ...
Validation loss decreased (0.464748 --> 0.464703).  Saving model ...
Validation loss decreased (0.464703 --> 0.464658).  Saving model ...
Validation loss decreased (0.464658 --> 0.464614).  Saving model ...
Validation loss decreased (0.464614 --> 0.464569).  Saving model ...
Validation loss decreased (0.464569 --> 0.464525).  Saving model ...
Validation loss decreased (0.464525 --> 0.464480).  Saving model ...
Validation loss decreased (0.464480 --> 0.464435).  Saving model ...
Validation loss decreased (0.464435 --> 0.464391).  Saving model ...
Validation loss decreased (0.464391 --> 0.464346).  Saving model ...
Validation loss decreased (0.464346 --> 0.464302).  Saving model ...
Validation loss decreased (0.464302 --> 0.464257).  Saving model ...
Validation loss decreased (0.464257 --> 0.464213).  Saving model ...
Validation loss decreased (0.464213 --> 0.464168).  Saving model ...
Validation loss decreased (0.464168 --> 0.464124).  Saving model ...
Validation loss decreased (0.464124 --> 0.464079).  Saving model ...
Validation loss decreased (0.464079 --> 0.464035).  Saving model ...
epoch 1501, loss 0.4640, train acc 78.08%, f1 0.6578, precision 0.7235, recall 0.6029, auc 0.7396
Validation loss decreased (0.464035 --> 0.463991).  Saving model ...
Validation loss decreased (0.463991 --> 0.463946).  Saving model ...
Validation loss decreased (0.463946 --> 0.463902).  Saving model ...
Validation loss decreased (0.463902 --> 0.463857).  Saving model ...
Validation loss decreased (0.463857 --> 0.463813).  Saving model ...
Validation loss decreased (0.463813 --> 0.463769).  Saving model ...
Validation loss decreased (0.463769 --> 0.463725).  Saving model ...
Validation loss decreased (0.463725 --> 0.463680).  Saving model ...
Validation loss decreased (0.463680 --> 0.463636).  Saving model ...
Validation loss decreased (0.463636 --> 0.463592).  Saving model ...
Validation loss decreased (0.463592 --> 0.463548).  Saving model ...
Validation loss decreased (0.463548 --> 0.463504).  Saving model ...
Validation loss decreased (0.463504 --> 0.463460).  Saving model ...
Validation loss decreased (0.463460 --> 0.463416).  Saving model ...
Validation loss decreased (0.463416 --> 0.463372).  Saving model ...
Validation loss decreased (0.463372 --> 0.463328).  Saving model ...
Validation loss decreased (0.463328 --> 0.463284).  Saving model ...
Validation loss decreased (0.463284 --> 0.463240).  Saving model ...
Validation loss decreased (0.463240 --> 0.463196).  Saving model ...
Validation loss decreased (0.463196 --> 0.463152).  Saving model ...
Validation loss decreased (0.463152 --> 0.463108).  Saving model ...
Validation loss decreased (0.463108 --> 0.463065).  Saving model ...
Validation loss decreased (0.463065 --> 0.463021).  Saving model ...
Validation loss decreased (0.463021 --> 0.462977).  Saving model ...
Validation loss decreased (0.462977 --> 0.462934).  Saving model ...
Validation loss decreased (0.462934 --> 0.462890).  Saving model ...
Validation loss decreased (0.462890 --> 0.462846).  Saving model ...
Validation loss decreased (0.462846 --> 0.462803).  Saving model ...
Validation loss decreased (0.462803 --> 0.462759).  Saving model ...
Validation loss decreased (0.462759 --> 0.462716).  Saving model ...
Validation loss decreased (0.462716 --> 0.462672).  Saving model ...
Validation loss decreased (0.462672 --> 0.462629).  Saving model ...
Validation loss decreased (0.462629 --> 0.462585).  Saving model ...
Validation loss decreased (0.462585 --> 0.462542).  Saving model ...
Validation loss decreased (0.462542 --> 0.462499).  Saving model ...
Validation loss decreased (0.462499 --> 0.462455).  Saving model ...
Validation loss decreased (0.462455 --> 0.462412).  Saving model ...
Validation loss decreased (0.462412 --> 0.462369).  Saving model ...
Validation loss decreased (0.462369 --> 0.462326).  Saving model ...
Validation loss decreased (0.462326 --> 0.462283).  Saving model ...
Validation loss decreased (0.462283 --> 0.462240).  Saving model ...
Validation loss decreased (0.462240 --> 0.462196).  Saving model ...
Validation loss decreased (0.462196 --> 0.462153).  Saving model ...
Validation loss decreased (0.462153 --> 0.462111).  Saving model ...
Validation loss decreased (0.462111 --> 0.462068).  Saving model ...
Validation loss decreased (0.462068 --> 0.462025).  Saving model ...
Validation loss decreased (0.462025 --> 0.461982).  Saving model ...
Validation loss decreased (0.461982 --> 0.461939).  Saving model ...
Validation loss decreased (0.461939 --> 0.461896).  Saving model ...
Validation loss decreased (0.461896 --> 0.461854).  Saving model ...
Validation loss decreased (0.461854 --> 0.461811).  Saving model ...
Validation loss decreased (0.461811 --> 0.461768).  Saving model ...
Validation loss decreased (0.461768 --> 0.461726).  Saving model ...
Validation loss decreased (0.461726 --> 0.461683).  Saving model ...
Validation loss decreased (0.461683 --> 0.461641).  Saving model ...
Validation loss decreased (0.461641 --> 0.461598).  Saving model ...
Validation loss decreased (0.461598 --> 0.461556).  Saving model ...
Validation loss decreased (0.461556 --> 0.461514).  Saving model ...
Validation loss decreased (0.461514 --> 0.461471).  Saving model ...
Validation loss decreased (0.461471 --> 0.461429).  Saving model ...
Validation loss decreased (0.461429 --> 0.461387).  Saving model ...
Validation loss decreased (0.461387 --> 0.461345).  Saving model ...
Validation loss decreased (0.461345 --> 0.461303).  Saving model ...
Validation loss decreased (0.461303 --> 0.461261).  Saving model ...
Validation loss decreased (0.461261 --> 0.461219).  Saving model ...
Validation loss decreased (0.461219 --> 0.461177).  Saving model ...
Validation loss decreased (0.461177 --> 0.461135).  Saving model ...
Validation loss decreased (0.461135 --> 0.461093).  Saving model ...
Validation loss decreased (0.461093 --> 0.461051).  Saving model ...
Validation loss decreased (0.461051 --> 0.461009).  Saving model ...
Validation loss decreased (0.461009 --> 0.460968).  Saving model ...
Validation loss decreased (0.460968 --> 0.460926).  Saving model ...
Validation loss decreased (0.460926 --> 0.460884).  Saving model ...
Validation loss decreased (0.460884 --> 0.460843).  Saving model ...
Validation loss decreased (0.460843 --> 0.460801).  Saving model ...
Validation loss decreased (0.460801 --> 0.460760).  Saving model ...
Validation loss decreased (0.460760 --> 0.460718).  Saving model ...
Validation loss decreased (0.460718 --> 0.460677).  Saving model ...
Validation loss decreased (0.460677 --> 0.460636).  Saving model ...
Validation loss decreased (0.460636 --> 0.460595).  Saving model ...
Validation loss decreased (0.460595 --> 0.460553).  Saving model ...
Validation loss decreased (0.460553 --> 0.460512).  Saving model ...
Validation loss decreased (0.460512 --> 0.460471).  Saving model ...
Validation loss decreased (0.460471 --> 0.460430).  Saving model ...
Validation loss decreased (0.460430 --> 0.460389).  Saving model ...
Validation loss decreased (0.460389 --> 0.460348).  Saving model ...
Validation loss decreased (0.460348 --> 0.460308).  Saving model ...
Validation loss decreased (0.460308 --> 0.460267).  Saving model ...
Validation loss decreased (0.460267 --> 0.460226).  Saving model ...
Validation loss decreased (0.460226 --> 0.460185).  Saving model ...
Validation loss decreased (0.460185 --> 0.460145).  Saving model ...
Validation loss decreased (0.460145 --> 0.460104).  Saving model ...
Validation loss decreased (0.460104 --> 0.460064).  Saving model ...
Validation loss decreased (0.460064 --> 0.460023).  Saving model ...
Validation loss decreased (0.460023 --> 0.459983).  Saving model ...
Validation loss decreased (0.459983 --> 0.459942).  Saving model ...
Validation loss decreased (0.459942 --> 0.459902).  Saving model ...
Validation loss decreased (0.459902 --> 0.459862).  Saving model ...
Validation loss decreased (0.459862 --> 0.459822).  Saving model ...
Validation loss decreased (0.459822 --> 0.459782).  Saving model ...
epoch 1601, loss 0.4598, train acc 77.74%, f1 0.6524, precision 0.7176, recall 0.5980, auc 0.7359
Validation loss decreased (0.459782 --> 0.459742).  Saving model ...
Validation loss decreased (0.459742 --> 0.459702).  Saving model ...
Validation loss decreased (0.459702 --> 0.459662).  Saving model ...
Validation loss decreased (0.459662 --> 0.459622).  Saving model ...
Validation loss decreased (0.459622 --> 0.459582).  Saving model ...
Validation loss decreased (0.459582 --> 0.459542).  Saving model ...
Validation loss decreased (0.459542 --> 0.459503).  Saving model ...
Validation loss decreased (0.459503 --> 0.459463).  Saving model ...
Validation loss decreased (0.459463 --> 0.459424).  Saving model ...
Validation loss decreased (0.459424 --> 0.459384).  Saving model ...
Validation loss decreased (0.459384 --> 0.459345).  Saving model ...
Validation loss decreased (0.459345 --> 0.459305).  Saving model ...
Validation loss decreased (0.459305 --> 0.459266).  Saving model ...
Validation loss decreased (0.459266 --> 0.459227).  Saving model ...
Validation loss decreased (0.459227 --> 0.459188).  Saving model ...
Validation loss decreased (0.459188 --> 0.459148).  Saving model ...
Validation loss decreased (0.459148 --> 0.459109).  Saving model ...
Validation loss decreased (0.459109 --> 0.459070).  Saving model ...
Validation loss decreased (0.459070 --> 0.459032).  Saving model ...
Validation loss decreased (0.459032 --> 0.458993).  Saving model ...
Validation loss decreased (0.458993 --> 0.458954).  Saving model ...
Validation loss decreased (0.458954 --> 0.458915).  Saving model ...
Validation loss decreased (0.458915 --> 0.458876).  Saving model ...
Validation loss decreased (0.458876 --> 0.458838).  Saving model ...
Validation loss decreased (0.458838 --> 0.458799).  Saving model ...
Validation loss decreased (0.458799 --> 0.458761).  Saving model ...
Validation loss decreased (0.458761 --> 0.458722).  Saving model ...
Validation loss decreased (0.458722 --> 0.458684).  Saving model ...
Validation loss decreased (0.458684 --> 0.458646).  Saving model ...
Validation loss decreased (0.458646 --> 0.458608).  Saving model ...
Validation loss decreased (0.458608 --> 0.458569).  Saving model ...
Validation loss decreased (0.458569 --> 0.458531).  Saving model ...
Validation loss decreased (0.458531 --> 0.458493).  Saving model ...
Validation loss decreased (0.458493 --> 0.458455).  Saving model ...
Validation loss decreased (0.458455 --> 0.458417).  Saving model ...
Validation loss decreased (0.458417 --> 0.458380).  Saving model ...
Validation loss decreased (0.458380 --> 0.458342).  Saving model ...
Validation loss decreased (0.458342 --> 0.458304).  Saving model ...
Validation loss decreased (0.458304 --> 0.458266).  Saving model ...
Validation loss decreased (0.458266 --> 0.458229).  Saving model ...
Validation loss decreased (0.458229 --> 0.458191).  Saving model ...
Validation loss decreased (0.458191 --> 0.458154).  Saving model ...
Validation loss decreased (0.458154 --> 0.458117).  Saving model ...
Validation loss decreased (0.458117 --> 0.458079).  Saving model ...
Validation loss decreased (0.458079 --> 0.458042).  Saving model ...
Validation loss decreased (0.458042 --> 0.458005).  Saving model ...
Validation loss decreased (0.458005 --> 0.457968).  Saving model ...
Validation loss decreased (0.457968 --> 0.457931).  Saving model ...
Validation loss decreased (0.457931 --> 0.457894).  Saving model ...
Validation loss decreased (0.457894 --> 0.457857).  Saving model ...
Validation loss decreased (0.457857 --> 0.457820).  Saving model ...
Validation loss decreased (0.457820 --> 0.457783).  Saving model ...
Validation loss decreased (0.457783 --> 0.457746).  Saving model ...
Validation loss decreased (0.457746 --> 0.457710).  Saving model ...
Validation loss decreased (0.457710 --> 0.457673).  Saving model ...
Validation loss decreased (0.457673 --> 0.457637).  Saving model ...
Validation loss decreased (0.457637 --> 0.457600).  Saving model ...
Validation loss decreased (0.457600 --> 0.457564).  Saving model ...
Validation loss decreased (0.457564 --> 0.457528).  Saving model ...
Validation loss decreased (0.457528 --> 0.457491).  Saving model ...
Validation loss decreased (0.457491 --> 0.457455).  Saving model ...
Validation loss decreased (0.457455 --> 0.457419).  Saving model ...
Validation loss decreased (0.457419 --> 0.457383).  Saving model ...
Validation loss decreased (0.457383 --> 0.457347).  Saving model ...
Validation loss decreased (0.457347 --> 0.457311).  Saving model ...
Validation loss decreased (0.457311 --> 0.457275).  Saving model ...
Validation loss decreased (0.457275 --> 0.457240).  Saving model ...
Validation loss decreased (0.457240 --> 0.457204).  Saving model ...
Validation loss decreased (0.457204 --> 0.457168).  Saving model ...
Validation loss decreased (0.457168 --> 0.457133).  Saving model ...
Validation loss decreased (0.457133 --> 0.457097).  Saving model ...
Validation loss decreased (0.457097 --> 0.457062).  Saving model ...
Validation loss decreased (0.457062 --> 0.457026).  Saving model ...
Validation loss decreased (0.457026 --> 0.456991).  Saving model ...
Validation loss decreased (0.456991 --> 0.456956).  Saving model ...
Validation loss decreased (0.456956 --> 0.456921).  Saving model ...
Validation loss decreased (0.456921 --> 0.456886).  Saving model ...
Validation loss decreased (0.456886 --> 0.456850).  Saving model ...
Validation loss decreased (0.456850 --> 0.456815).  Saving model ...
Validation loss decreased (0.456815 --> 0.456781).  Saving model ...
Validation loss decreased (0.456781 --> 0.456746).  Saving model ...
Validation loss decreased (0.456746 --> 0.456711).  Saving model ...
Validation loss decreased (0.456711 --> 0.456676).  Saving model ...
Validation loss decreased (0.456676 --> 0.456642).  Saving model ...
Validation loss decreased (0.456642 --> 0.456607).  Saving model ...
Validation loss decreased (0.456607 --> 0.456573).  Saving model ...
Validation loss decreased (0.456573 --> 0.456538).  Saving model ...
Validation loss decreased (0.456538 --> 0.456504).  Saving model ...
Validation loss decreased (0.456504 --> 0.456470).  Saving model ...
Validation loss decreased (0.456470 --> 0.456435).  Saving model ...
Validation loss decreased (0.456435 --> 0.456401).  Saving model ...
Validation loss decreased (0.456401 --> 0.456367).  Saving model ...
Validation loss decreased (0.456367 --> 0.456333).  Saving model ...
Validation loss decreased (0.456333 --> 0.456299).  Saving model ...
Validation loss decreased (0.456299 --> 0.456265).  Saving model ...
Validation loss decreased (0.456265 --> 0.456231).  Saving model ...
Validation loss decreased (0.456231 --> 0.456198).  Saving model ...
Validation loss decreased (0.456198 --> 0.456164).  Saving model ...
Validation loss decreased (0.456164 --> 0.456130).  Saving model ...
Validation loss decreased (0.456130 --> 0.456097).  Saving model ...
epoch 1701, loss 0.4561, train acc 78.25%, f1 0.6613, precision 0.7251, recall 0.6078, auc 0.7421
Validation loss decreased (0.456097 --> 0.456063).  Saving model ...
Validation loss decreased (0.456063 --> 0.456030).  Saving model ...
Validation loss decreased (0.456030 --> 0.455996).  Saving model ...
Validation loss decreased (0.455996 --> 0.455963).  Saving model ...
Validation loss decreased (0.455963 --> 0.455930).  Saving model ...
Validation loss decreased (0.455930 --> 0.455897).  Saving model ...
Validation loss decreased (0.455897 --> 0.455863).  Saving model ...
Validation loss decreased (0.455863 --> 0.455830).  Saving model ...
Validation loss decreased (0.455830 --> 0.455797).  Saving model ...
Validation loss decreased (0.455797 --> 0.455764).  Saving model ...
Validation loss decreased (0.455764 --> 0.455732).  Saving model ...
Validation loss decreased (0.455732 --> 0.455699).  Saving model ...
Validation loss decreased (0.455699 --> 0.455666).  Saving model ...
Validation loss decreased (0.455666 --> 0.455633).  Saving model ...
Validation loss decreased (0.455633 --> 0.455601).  Saving model ...
Validation loss decreased (0.455601 --> 0.455568).  Saving model ...
Validation loss decreased (0.455568 --> 0.455536).  Saving model ...
Validation loss decreased (0.455536 --> 0.455504).  Saving model ...
Validation loss decreased (0.455504 --> 0.455471).  Saving model ...
Validation loss decreased (0.455471 --> 0.455439).  Saving model ...
Validation loss decreased (0.455439 --> 0.455407).  Saving model ...
Validation loss decreased (0.455407 --> 0.455375).  Saving model ...
Validation loss decreased (0.455375 --> 0.455343).  Saving model ...
Validation loss decreased (0.455343 --> 0.455310).  Saving model ...
Validation loss decreased (0.455310 --> 0.455279).  Saving model ...
Validation loss decreased (0.455279 --> 0.455247).  Saving model ...
Validation loss decreased (0.455247 --> 0.455215).  Saving model ...
Validation loss decreased (0.455215 --> 0.455183).  Saving model ...
Validation loss decreased (0.455183 --> 0.455151).  Saving model ...
Validation loss decreased (0.455151 --> 0.455120).  Saving model ...
Validation loss decreased (0.455120 --> 0.455088).  Saving model ...
Validation loss decreased (0.455088 --> 0.455057).  Saving model ...
Validation loss decreased (0.455057 --> 0.455025).  Saving model ...
Validation loss decreased (0.455025 --> 0.454994).  Saving model ...
Validation loss decreased (0.454994 --> 0.454963).  Saving model ...
Validation loss decreased (0.454963 --> 0.454931).  Saving model ...
Validation loss decreased (0.454931 --> 0.454900).  Saving model ...
Validation loss decreased (0.454900 --> 0.454869).  Saving model ...
Validation loss decreased (0.454869 --> 0.454838).  Saving model ...
Validation loss decreased (0.454838 --> 0.454807).  Saving model ...
Validation loss decreased (0.454807 --> 0.454776).  Saving model ...
Validation loss decreased (0.454776 --> 0.454745).  Saving model ...
Validation loss decreased (0.454745 --> 0.454714).  Saving model ...
Validation loss decreased (0.454714 --> 0.454684).  Saving model ...
Validation loss decreased (0.454684 --> 0.454653).  Saving model ...
Validation loss decreased (0.454653 --> 0.454622).  Saving model ...
Validation loss decreased (0.454622 --> 0.454592).  Saving model ...
Validation loss decreased (0.454592 --> 0.454561).  Saving model ...
Validation loss decreased (0.454561 --> 0.454531).  Saving model ...
Validation loss decreased (0.454531 --> 0.454500).  Saving model ...
Validation loss decreased (0.454500 --> 0.454470).  Saving model ...
Validation loss decreased (0.454470 --> 0.454440).  Saving model ...
Validation loss decreased (0.454440 --> 0.454409).  Saving model ...
Validation loss decreased (0.454409 --> 0.454379).  Saving model ...
Validation loss decreased (0.454379 --> 0.454349).  Saving model ...
Validation loss decreased (0.454349 --> 0.454319).  Saving model ...
Validation loss decreased (0.454319 --> 0.454289).  Saving model ...
Validation loss decreased (0.454289 --> 0.454259).  Saving model ...
Validation loss decreased (0.454259 --> 0.454229).  Saving model ...
Validation loss decreased (0.454229 --> 0.454200).  Saving model ...
Validation loss decreased (0.454200 --> 0.454170).  Saving model ...
Validation loss decreased (0.454170 --> 0.454140).  Saving model ...
Validation loss decreased (0.454140 --> 0.454111).  Saving model ...
Validation loss decreased (0.454111 --> 0.454081).  Saving model ...
Validation loss decreased (0.454081 --> 0.454051).  Saving model ...
Validation loss decreased (0.454051 --> 0.454022).  Saving model ...
Validation loss decreased (0.454022 --> 0.453993).  Saving model ...
Validation loss decreased (0.453993 --> 0.453963).  Saving model ...
Validation loss decreased (0.453963 --> 0.453934).  Saving model ...
Validation loss decreased (0.453934 --> 0.453905).  Saving model ...
Validation loss decreased (0.453905 --> 0.453876).  Saving model ...
Validation loss decreased (0.453876 --> 0.453847).  Saving model ...
Validation loss decreased (0.453847 --> 0.453817).  Saving model ...
Validation loss decreased (0.453817 --> 0.453788).  Saving model ...
Validation loss decreased (0.453788 --> 0.453760).  Saving model ...
Validation loss decreased (0.453760 --> 0.453731).  Saving model ...
Validation loss decreased (0.453731 --> 0.453702).  Saving model ...
Validation loss decreased (0.453702 --> 0.453673).  Saving model ...
Validation loss decreased (0.453673 --> 0.453644).  Saving model ...
Validation loss decreased (0.453644 --> 0.453616).  Saving model ...
Validation loss decreased (0.453616 --> 0.453587).  Saving model ...
Validation loss decreased (0.453587 --> 0.453559).  Saving model ...
Validation loss decreased (0.453559 --> 0.453530).  Saving model ...
Validation loss decreased (0.453530 --> 0.453502).  Saving model ...
Validation loss decreased (0.453502 --> 0.453473).  Saving model ...
Validation loss decreased (0.453473 --> 0.453445).  Saving model ...
Validation loss decreased (0.453445 --> 0.453417).  Saving model ...
Validation loss decreased (0.453417 --> 0.453388).  Saving model ...
Validation loss decreased (0.453388 --> 0.453360).  Saving model ...
Validation loss decreased (0.453360 --> 0.453332).  Saving model ...
Validation loss decreased (0.453332 --> 0.453304).  Saving model ...
Validation loss decreased (0.453304 --> 0.453276).  Saving model ...
Validation loss decreased (0.453276 --> 0.453248).  Saving model ...
Validation loss decreased (0.453248 --> 0.453220).  Saving model ...
Validation loss decreased (0.453220 --> 0.453193).  Saving model ...
Validation loss decreased (0.453193 --> 0.453165).  Saving model ...
Validation loss decreased (0.453165 --> 0.453137).  Saving model ...
Validation loss decreased (0.453137 --> 0.453109).  Saving model ...
Validation loss decreased (0.453109 --> 0.453082).  Saving model ...
Validation loss decreased (0.453082 --> 0.453054).  Saving model ...
epoch 1801, loss 0.4531, train acc 78.08%, f1 0.6632, precision 0.7159, recall 0.6176, auc 0.7430
Validation loss decreased (0.453054 --> 0.453027).  Saving model ...
Validation loss decreased (0.453027 --> 0.452999).  Saving model ...
Validation loss decreased (0.452999 --> 0.452972).  Saving model ...
Validation loss decreased (0.452972 --> 0.452944).  Saving model ...
Validation loss decreased (0.452944 --> 0.452917).  Saving model ...
Validation loss decreased (0.452917 --> 0.452890).  Saving model ...
Validation loss decreased (0.452890 --> 0.452863).  Saving model ...
Validation loss decreased (0.452863 --> 0.452835).  Saving model ...
Validation loss decreased (0.452835 --> 0.452808).  Saving model ...
Validation loss decreased (0.452808 --> 0.452781).  Saving model ...
Validation loss decreased (0.452781 --> 0.452754).  Saving model ...
Validation loss decreased (0.452754 --> 0.452727).  Saving model ...
Validation loss decreased (0.452727 --> 0.452700).  Saving model ...
Validation loss decreased (0.452700 --> 0.452673).  Saving model ...
Validation loss decreased (0.452673 --> 0.452647).  Saving model ...
Validation loss decreased (0.452647 --> 0.452620).  Saving model ...
Validation loss decreased (0.452620 --> 0.452593).  Saving model ...
Validation loss decreased (0.452593 --> 0.452566).  Saving model ...
Validation loss decreased (0.452566 --> 0.452540).  Saving model ...
Validation loss decreased (0.452540 --> 0.452513).  Saving model ...
Validation loss decreased (0.452513 --> 0.452487).  Saving model ...
Validation loss decreased (0.452487 --> 0.452460).  Saving model ...
Validation loss decreased (0.452460 --> 0.452434).  Saving model ...
Validation loss decreased (0.452434 --> 0.452407).  Saving model ...
Validation loss decreased (0.452407 --> 0.452381).  Saving model ...
Validation loss decreased (0.452381 --> 0.452355).  Saving model ...
Validation loss decreased (0.452355 --> 0.452328).  Saving model ...
Validation loss decreased (0.452328 --> 0.452302).  Saving model ...
Validation loss decreased (0.452302 --> 0.452276).  Saving model ...
Validation loss decreased (0.452276 --> 0.452250).  Saving model ...
Validation loss decreased (0.452250 --> 0.452224).  Saving model ...
Validation loss decreased (0.452224 --> 0.452198).  Saving model ...
Validation loss decreased (0.452198 --> 0.452172).  Saving model ...
Validation loss decreased (0.452172 --> 0.452146).  Saving model ...
Validation loss decreased (0.452146 --> 0.452120).  Saving model ...
Validation loss decreased (0.452120 --> 0.452094).  Saving model ...
Validation loss decreased (0.452094 --> 0.452069).  Saving model ...
Validation loss decreased (0.452069 --> 0.452043).  Saving model ...
Validation loss decreased (0.452043 --> 0.452017).  Saving model ...
Validation loss decreased (0.452017 --> 0.451991).  Saving model ...
Validation loss decreased (0.451991 --> 0.451966).  Saving model ...
Validation loss decreased (0.451966 --> 0.451940).  Saving model ...
Validation loss decreased (0.451940 --> 0.451915).  Saving model ...
Validation loss decreased (0.451915 --> 0.451889).  Saving model ...
Validation loss decreased (0.451889 --> 0.451864).  Saving model ...
Validation loss decreased (0.451864 --> 0.451838).  Saving model ...
Validation loss decreased (0.451838 --> 0.451813).  Saving model ...
Validation loss decreased (0.451813 --> 0.451788).  Saving model ...
Validation loss decreased (0.451788 --> 0.451763).  Saving model ...
Validation loss decreased (0.451763 --> 0.451737).  Saving model ...
Validation loss decreased (0.451737 --> 0.451712).  Saving model ...
Validation loss decreased (0.451712 --> 0.451687).  Saving model ...
Validation loss decreased (0.451687 --> 0.451662).  Saving model ...
Validation loss decreased (0.451662 --> 0.451637).  Saving model ...
Validation loss decreased (0.451637 --> 0.451612).  Saving model ...
Validation loss decreased (0.451612 --> 0.451587).  Saving model ...
Validation loss decreased (0.451587 --> 0.451562).  Saving model ...
Validation loss decreased (0.451562 --> 0.451537).  Saving model ...
Validation loss decreased (0.451537 --> 0.451512).  Saving model ...
Validation loss decreased (0.451512 --> 0.451488).  Saving model ...
Validation loss decreased (0.451488 --> 0.451463).  Saving model ...
Validation loss decreased (0.451463 --> 0.451438).  Saving model ...
Validation loss decreased (0.451438 --> 0.451413).  Saving model ...
Validation loss decreased (0.451413 --> 0.451389).  Saving model ...
Validation loss decreased (0.451389 --> 0.451364).  Saving model ...
Validation loss decreased (0.451364 --> 0.451340).  Saving model ...
Validation loss decreased (0.451340 --> 0.451315).  Saving model ...
Validation loss decreased (0.451315 --> 0.451291).  Saving model ...
Validation loss decreased (0.451291 --> 0.451266).  Saving model ...
Validation loss decreased (0.451266 --> 0.451242).  Saving model ...
Validation loss decreased (0.451242 --> 0.451217).  Saving model ...
Validation loss decreased (0.451217 --> 0.451193).  Saving model ...
Validation loss decreased (0.451193 --> 0.451169).  Saving model ...
Validation loss decreased (0.451169 --> 0.451144).  Saving model ...
Validation loss decreased (0.451144 --> 0.451120).  Saving model ...
Validation loss decreased (0.451120 --> 0.451096).  Saving model ...
Validation loss decreased (0.451096 --> 0.451072).  Saving model ...
Validation loss decreased (0.451072 --> 0.451048).  Saving model ...
Validation loss decreased (0.451048 --> 0.451024).  Saving model ...
Validation loss decreased (0.451024 --> 0.451000).  Saving model ...
Validation loss decreased (0.451000 --> 0.450976).  Saving model ...
Validation loss decreased (0.450976 --> 0.450952).  Saving model ...
Validation loss decreased (0.450952 --> 0.450928).  Saving model ...
Validation loss decreased (0.450928 --> 0.450904).  Saving model ...
Validation loss decreased (0.450904 --> 0.450880).  Saving model ...
Validation loss decreased (0.450880 --> 0.450856).  Saving model ...
Validation loss decreased (0.450856 --> 0.450832).  Saving model ...
Validation loss decreased (0.450832 --> 0.450809).  Saving model ...
Validation loss decreased (0.450809 --> 0.450785).  Saving model ...
Validation loss decreased (0.450785 --> 0.450761).  Saving model ...
Validation loss decreased (0.450761 --> 0.450738).  Saving model ...
Validation loss decreased (0.450738 --> 0.450714).  Saving model ...
Validation loss decreased (0.450714 --> 0.450690).  Saving model ...
Validation loss decreased (0.450690 --> 0.450667).  Saving model ...
Validation loss decreased (0.450667 --> 0.450643).  Saving model ...
Validation loss decreased (0.450643 --> 0.450620).  Saving model ...
Validation loss decreased (0.450620 --> 0.450596).  Saving model ...
Validation loss decreased (0.450596 --> 0.450573).  Saving model ...
Validation loss decreased (0.450573 --> 0.450550).  Saving model ...
Validation loss decreased (0.450550 --> 0.450526).  Saving model ...
epoch 1901, loss 0.4505, train acc 78.25%, f1 0.6667, precision 0.7175, recall 0.6225, auc 0.7455
Validation loss decreased (0.450526 --> 0.450503).  Saving model ...
Validation loss decreased (0.450503 --> 0.450480).  Saving model ...
Validation loss decreased (0.450480 --> 0.450456).  Saving model ...
Validation loss decreased (0.450456 --> 0.450433).  Saving model ...
Validation loss decreased (0.450433 --> 0.450410).  Saving model ...
Validation loss decreased (0.450410 --> 0.450387).  Saving model ...
Validation loss decreased (0.450387 --> 0.450364).  Saving model ...
Validation loss decreased (0.450364 --> 0.450341).  Saving model ...
Validation loss decreased (0.450341 --> 0.450318).  Saving model ...
Validation loss decreased (0.450318 --> 0.450295).  Saving model ...
Validation loss decreased (0.450295 --> 0.450272).  Saving model ...
Validation loss decreased (0.450272 --> 0.450249).  Saving model ...
Validation loss decreased (0.450249 --> 0.450226).  Saving model ...
Validation loss decreased (0.450226 --> 0.450203).  Saving model ...
Validation loss decreased (0.450203 --> 0.450180).  Saving model ...
Validation loss decreased (0.450180 --> 0.450157).  Saving model ...
Validation loss decreased (0.450157 --> 0.450134).  Saving model ...
Validation loss decreased (0.450134 --> 0.450111).  Saving model ...
Validation loss decreased (0.450111 --> 0.450089).  Saving model ...
Validation loss decreased (0.450089 --> 0.450066).  Saving model ...
Validation loss decreased (0.450066 --> 0.450043).  Saving model ...
Validation loss decreased (0.450043 --> 0.450021).  Saving model ...
Validation loss decreased (0.450021 --> 0.449998).  Saving model ...
Validation loss decreased (0.449998 --> 0.449975).  Saving model ...
Validation loss decreased (0.449975 --> 0.449953).  Saving model ...
Validation loss decreased (0.449953 --> 0.449930).  Saving model ...
Validation loss decreased (0.449930 --> 0.449907).  Saving model ...
Validation loss decreased (0.449907 --> 0.449885).  Saving model ...
Validation loss decreased (0.449885 --> 0.449862).  Saving model ...
Validation loss decreased (0.449862 --> 0.449840).  Saving model ...
Validation loss decreased (0.449840 --> 0.449818).  Saving model ...
Validation loss decreased (0.449818 --> 0.449795).  Saving model ...
Validation loss decreased (0.449795 --> 0.449773).  Saving model ...
Validation loss decreased (0.449773 --> 0.449750).  Saving model ...
Validation loss decreased (0.449750 --> 0.449728).  Saving model ...
Validation loss decreased (0.449728 --> 0.449706).  Saving model ...
Validation loss decreased (0.449706 --> 0.449684).  Saving model ...
Validation loss decreased (0.449684 --> 0.449661).  Saving model ...
Validation loss decreased (0.449661 --> 0.449639).  Saving model ...
Validation loss decreased (0.449639 --> 0.449617).  Saving model ...
Validation loss decreased (0.449617 --> 0.449595).  Saving model ...
Validation loss decreased (0.449595 --> 0.449572).  Saving model ...
Validation loss decreased (0.449572 --> 0.449550).  Saving model ...
Validation loss decreased (0.449550 --> 0.449528).  Saving model ...
Validation loss decreased (0.449528 --> 0.449506).  Saving model ...
Validation loss decreased (0.449506 --> 0.449484).  Saving model ...
Validation loss decreased (0.449484 --> 0.449462).  Saving model ...
Validation loss decreased (0.449462 --> 0.449440).  Saving model ...
Validation loss decreased (0.449440 --> 0.449418).  Saving model ...
Validation loss decreased (0.449418 --> 0.449396).  Saving model ...
Validation loss decreased (0.449396 --> 0.449374).  Saving model ...
Validation loss decreased (0.449374 --> 0.449352).  Saving model ...
Validation loss decreased (0.449352 --> 0.449330).  Saving model ...
Validation loss decreased (0.449330 --> 0.449308).  Saving model ...
Validation loss decreased (0.449308 --> 0.449287).  Saving model ...
Validation loss decreased (0.449287 --> 0.449265).  Saving model ...
Validation loss decreased (0.449265 --> 0.449243).  Saving model ...
Validation loss decreased (0.449243 --> 0.449221).  Saving model ...
Validation loss decreased (0.449221 --> 0.449199).  Saving model ...
Validation loss decreased (0.449199 --> 0.449178).  Saving model ...
Validation loss decreased (0.449178 --> 0.449156).  Saving model ...
Validation loss decreased (0.449156 --> 0.449134).  Saving model ...
Validation loss decreased (0.449134 --> 0.449112).  Saving model ...
Validation loss decreased (0.449112 --> 0.449091).  Saving model ...
Validation loss decreased (0.449091 --> 0.449069).  Saving model ...
Validation loss decreased (0.449069 --> 0.449048).  Saving model ...
Validation loss decreased (0.449048 --> 0.449026).  Saving model ...
Validation loss decreased (0.449026 --> 0.449004).  Saving model ...
Validation loss decreased (0.449004 --> 0.448983).  Saving model ...
Validation loss decreased (0.448983 --> 0.448961).  Saving model ...
Validation loss decreased (0.448961 --> 0.448940).  Saving model ...
Validation loss decreased (0.448940 --> 0.448918).  Saving model ...
Validation loss decreased (0.448918 --> 0.448897).  Saving model ...
Validation loss decreased (0.448897 --> 0.448875).  Saving model ...
Validation loss decreased (0.448875 --> 0.448854).  Saving model ...
Validation loss decreased (0.448854 --> 0.448832).  Saving model ...
Validation loss decreased (0.448832 --> 0.448811).  Saving model ...
Validation loss decreased (0.448811 --> 0.448789).  Saving model ...
Validation loss decreased (0.448789 --> 0.448768).  Saving model ...
Validation loss decreased (0.448768 --> 0.448747).  Saving model ...
Validation loss decreased (0.448747 --> 0.448725).  Saving model ...
Validation loss decreased (0.448725 --> 0.448704).  Saving model ...
Validation loss decreased (0.448704 --> 0.448683).  Saving model ...
Validation loss decreased (0.448683 --> 0.448661).  Saving model ...
Validation loss decreased (0.448661 --> 0.448640).  Saving model ...
Validation loss decreased (0.448640 --> 0.448619).  Saving model ...
Validation loss decreased (0.448619 --> 0.448597).  Saving model ...
Validation loss decreased (0.448597 --> 0.448576).  Saving model ...
Validation loss decreased (0.448576 --> 0.448555).  Saving model ...
Validation loss decreased (0.448555 --> 0.448534).  Saving model ...
Validation loss decreased (0.448534 --> 0.448513).  Saving model ...
Validation loss decreased (0.448513 --> 0.448491).  Saving model ...
Validation loss decreased (0.448491 --> 0.448470).  Saving model ...
Validation loss decreased (0.448470 --> 0.448449).  Saving model ...
Validation loss decreased (0.448449 --> 0.448428).  Saving model ...
Validation loss decreased (0.448428 --> 0.448407).  Saving model ...
Validation loss decreased (0.448407 --> 0.448386).  Saving model ...
Validation loss decreased (0.448386 --> 0.448365).  Saving model ...
Validation loss decreased (0.448365 --> 0.448343).  Saving model ...
Validation loss decreased (0.448343 --> 0.448322).  Saving model ...
epoch 2001, loss 0.4483, train acc 78.42%, f1 0.6684, precision 0.7216, recall 0.6225, auc 0.7468
Validation loss decreased (0.448322 --> 0.448301).  Saving model ...
Validation loss decreased (0.448301 --> 0.448280).  Saving model ...
Validation loss decreased (0.448280 --> 0.448259).  Saving model ...
Validation loss decreased (0.448259 --> 0.448238).  Saving model ...
Validation loss decreased (0.448238 --> 0.448217).  Saving model ...
Validation loss decreased (0.448217 --> 0.448196).  Saving model ...
Validation loss decreased (0.448196 --> 0.448175).  Saving model ...
Validation loss decreased (0.448175 --> 0.448154).  Saving model ...
Validation loss decreased (0.448154 --> 0.448133).  Saving model ...
Validation loss decreased (0.448133 --> 0.448112).  Saving model ...
Validation loss decreased (0.448112 --> 0.448091).  Saving model ...
Validation loss decreased (0.448091 --> 0.448070).  Saving model ...
Validation loss decreased (0.448070 --> 0.448049).  Saving model ...
Validation loss decreased (0.448049 --> 0.448028).  Saving model ...
Validation loss decreased (0.448028 --> 0.448007).  Saving model ...
Validation loss decreased (0.448007 --> 0.447987).  Saving model ...
Validation loss decreased (0.447987 --> 0.447966).  Saving model ...
Validation loss decreased (0.447966 --> 0.447945).  Saving model ...
Validation loss decreased (0.447945 --> 0.447924).  Saving model ...
Validation loss decreased (0.447924 --> 0.447903).  Saving model ...
Validation loss decreased (0.447903 --> 0.447882).  Saving model ...
Validation loss decreased (0.447882 --> 0.447861).  Saving model ...
Validation loss decreased (0.447861 --> 0.447840).  Saving model ...
Validation loss decreased (0.447840 --> 0.447820).  Saving model ...
Validation loss decreased (0.447820 --> 0.447799).  Saving model ...
Validation loss decreased (0.447799 --> 0.447778).  Saving model ...
Validation loss decreased (0.447778 --> 0.447757).  Saving model ...
Validation loss decreased (0.447757 --> 0.447736).  Saving model ...
Validation loss decreased (0.447736 --> 0.447715).  Saving model ...
Validation loss decreased (0.447715 --> 0.447695).  Saving model ...
Validation loss decreased (0.447695 --> 0.447674).  Saving model ...
Validation loss decreased (0.447674 --> 0.447653).  Saving model ...
Validation loss decreased (0.447653 --> 0.447632).  Saving model ...
Validation loss decreased (0.447632 --> 0.447611).  Saving model ...
Validation loss decreased (0.447611 --> 0.447591).  Saving model ...
Validation loss decreased (0.447591 --> 0.447570).  Saving model ...
Validation loss decreased (0.447570 --> 0.447549).  Saving model ...
Validation loss decreased (0.447549 --> 0.447528).  Saving model ...
Validation loss decreased (0.447528 --> 0.447508).  Saving model ...
Validation loss decreased (0.447508 --> 0.447487).  Saving model ...
Validation loss decreased (0.447487 --> 0.447466).  Saving model ...
Validation loss decreased (0.447466 --> 0.447445).  Saving model ...
Validation loss decreased (0.447445 --> 0.447424).  Saving model ...
Validation loss decreased (0.447424 --> 0.447404).  Saving model ...
Validation loss decreased (0.447404 --> 0.447383).  Saving model ...
Validation loss decreased (0.447383 --> 0.447362).  Saving model ...
Validation loss decreased (0.447362 --> 0.447341).  Saving model ...
Validation loss decreased (0.447341 --> 0.447321).  Saving model ...
Validation loss decreased (0.447321 --> 0.447300).  Saving model ...
Validation loss decreased (0.447300 --> 0.447279).  Saving model ...
Validation loss decreased (0.447279 --> 0.447258).  Saving model ...
Validation loss decreased (0.447258 --> 0.447238).  Saving model ...
Validation loss decreased (0.447238 --> 0.447217).  Saving model ...
Validation loss decreased (0.447217 --> 0.447196).  Saving model ...
Validation loss decreased (0.447196 --> 0.447175).  Saving model ...
Validation loss decreased (0.447175 --> 0.447155).  Saving model ...
Validation loss decreased (0.447155 --> 0.447134).  Saving model ...
Validation loss decreased (0.447134 --> 0.447113).  Saving model ...
Validation loss decreased (0.447113 --> 0.447092).  Saving model ...
Validation loss decreased (0.447092 --> 0.447071).  Saving model ...
Validation loss decreased (0.447071 --> 0.447051).  Saving model ...
Validation loss decreased (0.447051 --> 0.447030).  Saving model ...
Validation loss decreased (0.447030 --> 0.447009).  Saving model ...
Validation loss decreased (0.447009 --> 0.446988).  Saving model ...
Validation loss decreased (0.446988 --> 0.446967).  Saving model ...
Validation loss decreased (0.446967 --> 0.446947).  Saving model ...
Validation loss decreased (0.446947 --> 0.446926).  Saving model ...
Validation loss decreased (0.446926 --> 0.446905).  Saving model ...
Validation loss decreased (0.446905 --> 0.446884).  Saving model ...
Validation loss decreased (0.446884 --> 0.446863).  Saving model ...
Validation loss decreased (0.446863 --> 0.446843).  Saving model ...
Validation loss decreased (0.446843 --> 0.446822).  Saving model ...
Validation loss decreased (0.446822 --> 0.446801).  Saving model ...
Validation loss decreased (0.446801 --> 0.446780).  Saving model ...
Validation loss decreased (0.446780 --> 0.446759).  Saving model ...
Validation loss decreased (0.446759 --> 0.446738).  Saving model ...
Validation loss decreased (0.446738 --> 0.446717).  Saving model ...
Validation loss decreased (0.446717 --> 0.446696).  Saving model ...
Validation loss decreased (0.446696 --> 0.446675).  Saving model ...
Validation loss decreased (0.446675 --> 0.446654).  Saving model ...
Validation loss decreased (0.446654 --> 0.446633).  Saving model ...
Validation loss decreased (0.446633 --> 0.446612).  Saving model ...
Validation loss decreased (0.446612 --> 0.446591).  Saving model ...
Validation loss decreased (0.446591 --> 0.446571).  Saving model ...
Validation loss decreased (0.446571 --> 0.446549).  Saving model ...
Validation loss decreased (0.446549 --> 0.446528).  Saving model ...
Validation loss decreased (0.446528 --> 0.446507).  Saving model ...
Validation loss decreased (0.446507 --> 0.446486).  Saving model ...
Validation loss decreased (0.446486 --> 0.446465).  Saving model ...
Validation loss decreased (0.446465 --> 0.446444).  Saving model ...
Validation loss decreased (0.446444 --> 0.446423).  Saving model ...
Validation loss decreased (0.446423 --> 0.446402).  Saving model ...
Validation loss decreased (0.446402 --> 0.446381).  Saving model ...
Validation loss decreased (0.446381 --> 0.446360).  Saving model ...
Validation loss decreased (0.446360 --> 0.446338).  Saving model ...
Validation loss decreased (0.446338 --> 0.446317).  Saving model ...
Validation loss decreased (0.446317 --> 0.446296).  Saving model ...
Validation loss decreased (0.446296 --> 0.446275).  Saving model ...
Validation loss decreased (0.446275 --> 0.446253).  Saving model ...
Validation loss decreased (0.446253 --> 0.446232).  Saving model ...
epoch 2101, loss 0.4462, train acc 78.42%, f1 0.6702, precision 0.7191, recall 0.6275, auc 0.7479
Validation loss decreased (0.446232 --> 0.446211).  Saving model ...
Validation loss decreased (0.446211 --> 0.446189).  Saving model ...
Validation loss decreased (0.446189 --> 0.446168).  Saving model ...
Validation loss decreased (0.446168 --> 0.446147).  Saving model ...
Validation loss decreased (0.446147 --> 0.446125).  Saving model ...
Validation loss decreased (0.446125 --> 0.446104).  Saving model ...
Validation loss decreased (0.446104 --> 0.446082).  Saving model ...
Validation loss decreased (0.446082 --> 0.446061).  Saving model ...
Validation loss decreased (0.446061 --> 0.446039).  Saving model ...
Validation loss decreased (0.446039 --> 0.446018).  Saving model ...
Validation loss decreased (0.446018 --> 0.445996).  Saving model ...
Validation loss decreased (0.445996 --> 0.445974).  Saving model ...
Validation loss decreased (0.445974 --> 0.445953).  Saving model ...
Validation loss decreased (0.445953 --> 0.445931).  Saving model ...
Validation loss decreased (0.445931 --> 0.445909).  Saving model ...
Validation loss decreased (0.445909 --> 0.445888).  Saving model ...
Validation loss decreased (0.445888 --> 0.445866).  Saving model ...
Validation loss decreased (0.445866 --> 0.445844).  Saving model ...
Validation loss decreased (0.445844 --> 0.445822).  Saving model ...
Validation loss decreased (0.445822 --> 0.445800).  Saving model ...
Validation loss decreased (0.445800 --> 0.445778).  Saving model ...
Validation loss decreased (0.445778 --> 0.445756).  Saving model ...
Validation loss decreased (0.445756 --> 0.445734).  Saving model ...
Validation loss decreased (0.445734 --> 0.445712).  Saving model ...
Validation loss decreased (0.445712 --> 0.445690).  Saving model ...
Validation loss decreased (0.445690 --> 0.445668).  Saving model ...
Validation loss decreased (0.445668 --> 0.445646).  Saving model ...
Validation loss decreased (0.445646 --> 0.445623).  Saving model ...
Validation loss decreased (0.445623 --> 0.445601).  Saving model ...
Validation loss decreased (0.445601 --> 0.445579).  Saving model ...
Validation loss decreased (0.445579 --> 0.445557).  Saving model ...
Validation loss decreased (0.445557 --> 0.445534).  Saving model ...
Validation loss decreased (0.445534 --> 0.445512).  Saving model ...
Validation loss decreased (0.445512 --> 0.445489).  Saving model ...
Validation loss decreased (0.445489 --> 0.445467).  Saving model ...
Validation loss decreased (0.445467 --> 0.445444).  Saving model ...
Validation loss decreased (0.445444 --> 0.445422).  Saving model ...
Validation loss decreased (0.445422 --> 0.445399).  Saving model ...
Validation loss decreased (0.445399 --> 0.445377).  Saving model ...
Validation loss decreased (0.445377 --> 0.445354).  Saving model ...
Validation loss decreased (0.445354 --> 0.445331).  Saving model ...
Validation loss decreased (0.445331 --> 0.445308).  Saving model ...
Validation loss decreased (0.445308 --> 0.445286).  Saving model ...
Validation loss decreased (0.445286 --> 0.445263).  Saving model ...
Validation loss decreased (0.445263 --> 0.445240).  Saving model ...
Validation loss decreased (0.445240 --> 0.445217).  Saving model ...
Validation loss decreased (0.445217 --> 0.445194).  Saving model ...
Validation loss decreased (0.445194 --> 0.445171).  Saving model ...
Validation loss decreased (0.445171 --> 0.445148).  Saving model ...
Validation loss decreased (0.445148 --> 0.445125).  Saving model ...
Validation loss decreased (0.445125 --> 0.445102).  Saving model ...
Validation loss decreased (0.445102 --> 0.445079).  Saving model ...
Validation loss decreased (0.445079 --> 0.445056).  Saving model ...
Validation loss decreased (0.445056 --> 0.445032).  Saving model ...
Validation loss decreased (0.445032 --> 0.445009).  Saving model ...
Validation loss decreased (0.445009 --> 0.444986).  Saving model ...
Validation loss decreased (0.444986 --> 0.444963).  Saving model ...
Validation loss decreased (0.444963 --> 0.444939).  Saving model ...
Validation loss decreased (0.444939 --> 0.444916).  Saving model ...
Validation loss decreased (0.444916 --> 0.444893).  Saving model ...
Validation loss decreased (0.444893 --> 0.444870).  Saving model ...
Validation loss decreased (0.444870 --> 0.444846).  Saving model ...
Validation loss decreased (0.444846 --> 0.444823).  Saving model ...
Validation loss decreased (0.444823 --> 0.444800).  Saving model ...
Validation loss decreased (0.444800 --> 0.444776).  Saving model ...
Validation loss decreased (0.444776 --> 0.444753).  Saving model ...
Validation loss decreased (0.444753 --> 0.444729).  Saving model ...
Validation loss decreased (0.444729 --> 0.444706).  Saving model ...
Validation loss decreased (0.444706 --> 0.444683).  Saving model ...
Validation loss decreased (0.444683 --> 0.444659).  Saving model ...
Validation loss decreased (0.444659 --> 0.444636).  Saving model ...
Validation loss decreased (0.444636 --> 0.444612).  Saving model ...
Validation loss decreased (0.444612 --> 0.444589).  Saving model ...
Validation loss decreased (0.444589 --> 0.444566).  Saving model ...
Validation loss decreased (0.444566 --> 0.444542).  Saving model ...
Validation loss decreased (0.444542 --> 0.444519).  Saving model ...
Validation loss decreased (0.444519 --> 0.444495).  Saving model ...
Validation loss decreased (0.444495 --> 0.444472).  Saving model ...
Validation loss decreased (0.444472 --> 0.444449).  Saving model ...
Validation loss decreased (0.444449 --> 0.444425).  Saving model ...
Validation loss decreased (0.444425 --> 0.444402).  Saving model ...
Validation loss decreased (0.444402 --> 0.444379).  Saving model ...
Validation loss decreased (0.444379 --> 0.444356).  Saving model ...
Validation loss decreased (0.444356 --> 0.444332).  Saving model ...
Validation loss decreased (0.444332 --> 0.444309).  Saving model ...
Validation loss decreased (0.444309 --> 0.444286).  Saving model ...
Validation loss decreased (0.444286 --> 0.444263).  Saving model ...
Validation loss decreased (0.444263 --> 0.444240).  Saving model ...
Validation loss decreased (0.444240 --> 0.444216).  Saving model ...
Validation loss decreased (0.444216 --> 0.444193).  Saving model ...
Validation loss decreased (0.444193 --> 0.444170).  Saving model ...
Validation loss decreased (0.444170 --> 0.444147).  Saving model ...
Validation loss decreased (0.444147 --> 0.444124).  Saving model ...
Validation loss decreased (0.444124 --> 0.444101).  Saving model ...
Validation loss decreased (0.444101 --> 0.444078).  Saving model ...
Validation loss decreased (0.444078 --> 0.444055).  Saving model ...
Validation loss decreased (0.444055 --> 0.444032).  Saving model ...
Validation loss decreased (0.444032 --> 0.444009).  Saving model ...
Validation loss decreased (0.444009 --> 0.443986).  Saving model ...
Validation loss decreased (0.443986 --> 0.443964).  Saving model ...
epoch 2201, loss 0.4440, train acc 78.25%, f1 0.6667, precision 0.7175, recall 0.6225, auc 0.7455
Validation loss decreased (0.443964 --> 0.443941).  Saving model ...
Validation loss decreased (0.443941 --> 0.443918).  Saving model ...
Validation loss decreased (0.443918 --> 0.443895).  Saving model ...
Validation loss decreased (0.443895 --> 0.443872).  Saving model ...
Validation loss decreased (0.443872 --> 0.443850).  Saving model ...
Validation loss decreased (0.443850 --> 0.443827).  Saving model ...
Validation loss decreased (0.443827 --> 0.443804).  Saving model ...
Validation loss decreased (0.443804 --> 0.443782).  Saving model ...
Validation loss decreased (0.443782 --> 0.443759).  Saving model ...
Validation loss decreased (0.443759 --> 0.443737).  Saving model ...
Validation loss decreased (0.443737 --> 0.443714).  Saving model ...
Validation loss decreased (0.443714 --> 0.443692).  Saving model ...
Validation loss decreased (0.443692 --> 0.443669).  Saving model ...
Validation loss decreased (0.443669 --> 0.443647).  Saving model ...
Validation loss decreased (0.443647 --> 0.443624).  Saving model ...
Validation loss decreased (0.443624 --> 0.443602).  Saving model ...
Validation loss decreased (0.443602 --> 0.443580).  Saving model ...
Validation loss decreased (0.443580 --> 0.443557).  Saving model ...
Validation loss decreased (0.443557 --> 0.443535).  Saving model ...
Validation loss decreased (0.443535 --> 0.443513).  Saving model ...
Validation loss decreased (0.443513 --> 0.443491).  Saving model ...
Validation loss decreased (0.443491 --> 0.443468).  Saving model ...
Validation loss decreased (0.443468 --> 0.443446).  Saving model ...
Validation loss decreased (0.443446 --> 0.443424).  Saving model ...
Validation loss decreased (0.443424 --> 0.443402).  Saving model ...
Validation loss decreased (0.443402 --> 0.443380).  Saving model ...
Validation loss decreased (0.443380 --> 0.443358).  Saving model ...
Validation loss decreased (0.443358 --> 0.443336).  Saving model ...
Validation loss decreased (0.443336 --> 0.443314).  Saving model ...
Validation loss decreased (0.443314 --> 0.443292).  Saving model ...
Validation loss decreased (0.443292 --> 0.443270).  Saving model ...
Validation loss decreased (0.443270 --> 0.443248).  Saving model ...
Validation loss decreased (0.443248 --> 0.443227).  Saving model ...
Validation loss decreased (0.443227 --> 0.443205).  Saving model ...
Validation loss decreased (0.443205 --> 0.443183).  Saving model ...
Validation loss decreased (0.443183 --> 0.443161).  Saving model ...
Validation loss decreased (0.443161 --> 0.443140).  Saving model ...
Validation loss decreased (0.443140 --> 0.443118).  Saving model ...
Validation loss decreased (0.443118 --> 0.443096).  Saving model ...
Validation loss decreased (0.443096 --> 0.443075).  Saving model ...
Validation loss decreased (0.443075 --> 0.443053).  Saving model ...
Validation loss decreased (0.443053 --> 0.443032).  Saving model ...
Validation loss decreased (0.443032 --> 0.443011).  Saving model ...
Validation loss decreased (0.443011 --> 0.442989).  Saving model ...
Validation loss decreased (0.442989 --> 0.442968).  Saving model ...
Validation loss decreased (0.442968 --> 0.442946).  Saving model ...
Validation loss decreased (0.442946 --> 0.442925).  Saving model ...
Validation loss decreased (0.442925 --> 0.442904).  Saving model ...
Validation loss decreased (0.442904 --> 0.442882).  Saving model ...
Validation loss decreased (0.442882 --> 0.442861).  Saving model ...
Validation loss decreased (0.442861 --> 0.442840).  Saving model ...
Validation loss decreased (0.442840 --> 0.442819).  Saving model ...
Validation loss decreased (0.442819 --> 0.442798).  Saving model ...
Validation loss decreased (0.442798 --> 0.442777).  Saving model ...
Validation loss decreased (0.442777 --> 0.442756).  Saving model ...
Validation loss decreased (0.442756 --> 0.442735).  Saving model ...
Validation loss decreased (0.442735 --> 0.442714).  Saving model ...
Validation loss decreased (0.442714 --> 0.442693).  Saving model ...
Validation loss decreased (0.442693 --> 0.442672).  Saving model ...
Validation loss decreased (0.442672 --> 0.442651).  Saving model ...
Validation loss decreased (0.442651 --> 0.442631).  Saving model ...
Validation loss decreased (0.442631 --> 0.442610).  Saving model ...
Validation loss decreased (0.442610 --> 0.442589).  Saving model ...
Validation loss decreased (0.442589 --> 0.442569).  Saving model ...
Validation loss decreased (0.442569 --> 0.442548).  Saving model ...
Validation loss decreased (0.442548 --> 0.442528).  Saving model ...
Validation loss decreased (0.442528 --> 0.442507).  Saving model ...
Validation loss decreased (0.442507 --> 0.442486).  Saving model ...
Validation loss decreased (0.442486 --> 0.442466).  Saving model ...
Validation loss decreased (0.442466 --> 0.442446).  Saving model ...
Validation loss decreased (0.442446 --> 0.442425).  Saving model ...
Validation loss decreased (0.442425 --> 0.442405).  Saving model ...
Validation loss decreased (0.442405 --> 0.442385).  Saving model ...
Validation loss decreased (0.442385 --> 0.442365).  Saving model ...
Validation loss decreased (0.442365 --> 0.442345).  Saving model ...
Validation loss decreased (0.442345 --> 0.442324).  Saving model ...
Validation loss decreased (0.442324 --> 0.442304).  Saving model ...
Validation loss decreased (0.442304 --> 0.442284).  Saving model ...
Validation loss decreased (0.442284 --> 0.442264).  Saving model ...
Validation loss decreased (0.442264 --> 0.442244).  Saving model ...
Validation loss decreased (0.442244 --> 0.442225).  Saving model ...
Validation loss decreased (0.442225 --> 0.442205).  Saving model ...
Validation loss decreased (0.442205 --> 0.442185).  Saving model ...
Validation loss decreased (0.442185 --> 0.442165).  Saving model ...
Validation loss decreased (0.442165 --> 0.442145).  Saving model ...
Validation loss decreased (0.442145 --> 0.442126).  Saving model ...
Validation loss decreased (0.442126 --> 0.442106).  Saving model ...
Validation loss decreased (0.442106 --> 0.442087).  Saving model ...
Validation loss decreased (0.442087 --> 0.442067).  Saving model ...
Validation loss decreased (0.442067 --> 0.442048).  Saving model ...
Validation loss decreased (0.442048 --> 0.442028).  Saving model ...
Validation loss decreased (0.442028 --> 0.442009).  Saving model ...
Validation loss decreased (0.442009 --> 0.441990).  Saving model ...
Validation loss decreased (0.441990 --> 0.441970).  Saving model ...
Validation loss decreased (0.441970 --> 0.441951).  Saving model ...
Validation loss decreased (0.441951 --> 0.441932).  Saving model ...
Validation loss decreased (0.441932 --> 0.441913).  Saving model ...
Validation loss decreased (0.441913 --> 0.441894).  Saving model ...
Validation loss decreased (0.441894 --> 0.441874).  Saving model ...
Validation loss decreased (0.441874 --> 0.441856).  Saving model ...
epoch 2301, loss 0.4419, train acc 78.25%, f1 0.6667, precision 0.7175, recall 0.6225, auc 0.7455
Validation loss decreased (0.441856 --> 0.441837).  Saving model ...
Validation loss decreased (0.441837 --> 0.441818).  Saving model ...
Validation loss decreased (0.441818 --> 0.441799).  Saving model ...
Validation loss decreased (0.441799 --> 0.441780).  Saving model ...
Validation loss decreased (0.441780 --> 0.441761).  Saving model ...
Validation loss decreased (0.441761 --> 0.441742).  Saving model ...
Validation loss decreased (0.441742 --> 0.441724).  Saving model ...
Validation loss decreased (0.441724 --> 0.441705).  Saving model ...
Validation loss decreased (0.441705 --> 0.441686).  Saving model ...
Validation loss decreased (0.441686 --> 0.441668).  Saving model ...
Validation loss decreased (0.441668 --> 0.441649).  Saving model ...
Validation loss decreased (0.441649 --> 0.441631).  Saving model ...
Validation loss decreased (0.441631 --> 0.441612).  Saving model ...
Validation loss decreased (0.441612 --> 0.441594).  Saving model ...
Validation loss decreased (0.441594 --> 0.441576).  Saving model ...
Validation loss decreased (0.441576 --> 0.441557).  Saving model ...
Validation loss decreased (0.441557 --> 0.441539).  Saving model ...
Validation loss decreased (0.441539 --> 0.441521).  Saving model ...
Validation loss decreased (0.441521 --> 0.441503).  Saving model ...
Validation loss decreased (0.441503 --> 0.441484).  Saving model ...
Validation loss decreased (0.441484 --> 0.441466).  Saving model ...
Validation loss decreased (0.441466 --> 0.441448).  Saving model ...
Validation loss decreased (0.441448 --> 0.441430).  Saving model ...
Validation loss decreased (0.441430 --> 0.441412).  Saving model ...
Validation loss decreased (0.441412 --> 0.441394).  Saving model ...
Validation loss decreased (0.441394 --> 0.441376).  Saving model ...
Validation loss decreased (0.441376 --> 0.441358).  Saving model ...
Validation loss decreased (0.441358 --> 0.441341).  Saving model ...
Validation loss decreased (0.441341 --> 0.441323).  Saving model ...
Validation loss decreased (0.441323 --> 0.441305).  Saving model ...
Validation loss decreased (0.441305 --> 0.441287).  Saving model ...
Validation loss decreased (0.441287 --> 0.441269).  Saving model ...
Validation loss decreased (0.441269 --> 0.441252).  Saving model ...
Validation loss decreased (0.441252 --> 0.441234).  Saving model ...
Validation loss decreased (0.441234 --> 0.441217).  Saving model ...
Validation loss decreased (0.441217 --> 0.441199).  Saving model ...
Validation loss decreased (0.441199 --> 0.441182).  Saving model ...
Validation loss decreased (0.441182 --> 0.441164).  Saving model ...
Validation loss decreased (0.441164 --> 0.441147).  Saving model ...
Validation loss decreased (0.441147 --> 0.441129).  Saving model ...
Validation loss decreased (0.441129 --> 0.441112).  Saving model ...
Validation loss decreased (0.441112 --> 0.441094).  Saving model ...
Validation loss decreased (0.441094 --> 0.441077).  Saving model ...
Validation loss decreased (0.441077 --> 0.441060).  Saving model ...
Validation loss decreased (0.441060 --> 0.441043).  Saving model ...
Validation loss decreased (0.441043 --> 0.441025).  Saving model ...
Validation loss decreased (0.441025 --> 0.441008).  Saving model ...
Validation loss decreased (0.441008 --> 0.440991).  Saving model ...
Validation loss decreased (0.440991 --> 0.440974).  Saving model ...
Validation loss decreased (0.440974 --> 0.440957).  Saving model ...
Validation loss decreased (0.440957 --> 0.440940).  Saving model ...
Validation loss decreased (0.440940 --> 0.440923).  Saving model ...
Validation loss decreased (0.440923 --> 0.440906).  Saving model ...
Validation loss decreased (0.440906 --> 0.440889).  Saving model ...
Validation loss decreased (0.440889 --> 0.440872).  Saving model ...
Validation loss decreased (0.440872 --> 0.440855).  Saving model ...
Validation loss decreased (0.440855 --> 0.440838).  Saving model ...
Validation loss decreased (0.440838 --> 0.440822).  Saving model ...
Validation loss decreased (0.440822 --> 0.440805).  Saving model ...
Validation loss decreased (0.440805 --> 0.440788).  Saving model ...
Validation loss decreased (0.440788 --> 0.440771).  Saving model ...
Validation loss decreased (0.440771 --> 0.440755).  Saving model ...
Validation loss decreased (0.440755 --> 0.440738).  Saving model ...
Validation loss decreased (0.440738 --> 0.440721).  Saving model ...
Validation loss decreased (0.440721 --> 0.440705).  Saving model ...
Validation loss decreased (0.440705 --> 0.440688).  Saving model ...
Validation loss decreased (0.440688 --> 0.440672).  Saving model ...
Validation loss decreased (0.440672 --> 0.440655).  Saving model ...
Validation loss decreased (0.440655 --> 0.440639).  Saving model ...
Validation loss decreased (0.440639 --> 0.440622).  Saving model ...
Validation loss decreased (0.440622 --> 0.440606).  Saving model ...
Validation loss decreased (0.440606 --> 0.440589).  Saving model ...
Validation loss decreased (0.440589 --> 0.440573).  Saving model ...
Validation loss decreased (0.440573 --> 0.440557).  Saving model ...
Validation loss decreased (0.440557 --> 0.440540).  Saving model ...
Validation loss decreased (0.440540 --> 0.440524).  Saving model ...
Validation loss decreased (0.440524 --> 0.440508).  Saving model ...
Validation loss decreased (0.440508 --> 0.440492).  Saving model ...
Validation loss decreased (0.440492 --> 0.440475).  Saving model ...
Validation loss decreased (0.440475 --> 0.440459).  Saving model ...
Validation loss decreased (0.440459 --> 0.440443).  Saving model ...
Validation loss decreased (0.440443 --> 0.440427).  Saving model ...
Validation loss decreased (0.440427 --> 0.440411).  Saving model ...
Validation loss decreased (0.440411 --> 0.440395).  Saving model ...
Validation loss decreased (0.440395 --> 0.440379).  Saving model ...
Validation loss decreased (0.440379 --> 0.440363).  Saving model ...
Validation loss decreased (0.440363 --> 0.440347).  Saving model ...
Validation loss decreased (0.440347 --> 0.440331).  Saving model ...
Validation loss decreased (0.440331 --> 0.440315).  Saving model ...
Validation loss decreased (0.440315 --> 0.440299).  Saving model ...
Validation loss decreased (0.440299 --> 0.440283).  Saving model ...
Validation loss decreased (0.440283 --> 0.440267).  Saving model ...
Validation loss decreased (0.440267 --> 0.440251).  Saving model ...
Validation loss decreased (0.440251 --> 0.440236).  Saving model ...
Validation loss decreased (0.440236 --> 0.440220).  Saving model ...
Validation loss decreased (0.440220 --> 0.440204).  Saving model ...
Validation loss decreased (0.440204 --> 0.440188).  Saving model ...
Validation loss decreased (0.440188 --> 0.440173).  Saving model ...
Validation loss decreased (0.440173 --> 0.440157).  Saving model ...
Validation loss decreased (0.440157 --> 0.440141).  Saving model ...
epoch 2401, loss 0.4401, train acc 78.25%, f1 0.6649, precision 0.7200, recall 0.6176, auc 0.7443
Validation loss decreased (0.440141 --> 0.440126).  Saving model ...
Validation loss decreased (0.440126 --> 0.440110).  Saving model ...
Validation loss decreased (0.440110 --> 0.440095).  Saving model ...
Validation loss decreased (0.440095 --> 0.440079).  Saving model ...
Validation loss decreased (0.440079 --> 0.440063).  Saving model ...
Validation loss decreased (0.440063 --> 0.440048).  Saving model ...
Validation loss decreased (0.440048 --> 0.440032).  Saving model ...
Validation loss decreased (0.440032 --> 0.440017).  Saving model ...
Validation loss decreased (0.440017 --> 0.440001).  Saving model ...
Validation loss decreased (0.440001 --> 0.439986).  Saving model ...
Validation loss decreased (0.439986 --> 0.439971).  Saving model ...
Validation loss decreased (0.439971 --> 0.439955).  Saving model ...
Validation loss decreased (0.439955 --> 0.439940).  Saving model ...
Validation loss decreased (0.439940 --> 0.439925).  Saving model ...
Validation loss decreased (0.439925 --> 0.439909).  Saving model ...
Validation loss decreased (0.439909 --> 0.439894).  Saving model ...
Validation loss decreased (0.439894 --> 0.439879).  Saving model ...
Validation loss decreased (0.439879 --> 0.439864).  Saving model ...
Validation loss decreased (0.439864 --> 0.439848).  Saving model ...
Validation loss decreased (0.439848 --> 0.439833).  Saving model ...
Validation loss decreased (0.439833 --> 0.439818).  Saving model ...
Validation loss decreased (0.439818 --> 0.439803).  Saving model ...
Validation loss decreased (0.439803 --> 0.439788).  Saving model ...
Validation loss decreased (0.439788 --> 0.439773).  Saving model ...
Validation loss decreased (0.439773 --> 0.439757).  Saving model ...
Validation loss decreased (0.439757 --> 0.439742).  Saving model ...
Validation loss decreased (0.439742 --> 0.439727).  Saving model ...
Validation loss decreased (0.439727 --> 0.439712).  Saving model ...
Validation loss decreased (0.439712 --> 0.439697).  Saving model ...
Validation loss decreased (0.439697 --> 0.439682).  Saving model ...
Validation loss decreased (0.439682 --> 0.439667).  Saving model ...
Validation loss decreased (0.439667 --> 0.439652).  Saving model ...
Validation loss decreased (0.439652 --> 0.439637).  Saving model ...
Validation loss decreased (0.439637 --> 0.439622).  Saving model ...
Validation loss decreased (0.439622 --> 0.439608).  Saving model ...
Validation loss decreased (0.439608 --> 0.439593).  Saving model ...
Validation loss decreased (0.439593 --> 0.439578).  Saving model ...
Validation loss decreased (0.439578 --> 0.439563).  Saving model ...
Validation loss decreased (0.439563 --> 0.439548).  Saving model ...
Validation loss decreased (0.439548 --> 0.439533).  Saving model ...
Validation loss decreased (0.439533 --> 0.439519).  Saving model ...
Validation loss decreased (0.439519 --> 0.439504).  Saving model ...
Validation loss decreased (0.439504 --> 0.439489).  Saving model ...
Validation loss decreased (0.439489 --> 0.439474).  Saving model ...
Validation loss decreased (0.439474 --> 0.439460).  Saving model ...
Validation loss decreased (0.439460 --> 0.439445).  Saving model ...
Validation loss decreased (0.439445 --> 0.439430).  Saving model ...
Validation loss decreased (0.439430 --> 0.439415).  Saving model ...
Validation loss decreased (0.439415 --> 0.439401).  Saving model ...
Validation loss decreased (0.439401 --> 0.439386).  Saving model ...
Validation loss decreased (0.439386 --> 0.439372).  Saving model ...
Validation loss decreased (0.439372 --> 0.439357).  Saving model ...
Validation loss decreased (0.439357 --> 0.439342).  Saving model ...
Validation loss decreased (0.439342 --> 0.439328).  Saving model ...
Validation loss decreased (0.439328 --> 0.439313).  Saving model ...
Validation loss decreased (0.439313 --> 0.439299).  Saving model ...
Validation loss decreased (0.439299 --> 0.439284).  Saving model ...
Validation loss decreased (0.439284 --> 0.439270).  Saving model ...
Validation loss decreased (0.439270 --> 0.439255).  Saving model ...
Validation loss decreased (0.439255 --> 0.439241).  Saving model ...
Validation loss decreased (0.439241 --> 0.439226).  Saving model ...
Validation loss decreased (0.439226 --> 0.439212).  Saving model ...
Validation loss decreased (0.439212 --> 0.439197).  Saving model ...
Validation loss decreased (0.439197 --> 0.439183).  Saving model ...
Validation loss decreased (0.439183 --> 0.439168).  Saving model ...
Validation loss decreased (0.439168 --> 0.439154).  Saving model ...
Validation loss decreased (0.439154 --> 0.439140).  Saving model ...
Validation loss decreased (0.439140 --> 0.439125).  Saving model ...
Validation loss decreased (0.439125 --> 0.439111).  Saving model ...
Validation loss decreased (0.439111 --> 0.439097).  Saving model ...
Validation loss decreased (0.439097 --> 0.439082).  Saving model ...
Validation loss decreased (0.439082 --> 0.439068).  Saving model ...
Validation loss decreased (0.439068 --> 0.439054).  Saving model ...
Validation loss decreased (0.439054 --> 0.439039).  Saving model ...
Validation loss decreased (0.439039 --> 0.439025).  Saving model ...
Validation loss decreased (0.439025 --> 0.439011).  Saving model ...
Validation loss decreased (0.439011 --> 0.438997).  Saving model ...
Validation loss decreased (0.438997 --> 0.438982).  Saving model ...
Validation loss decreased (0.438982 --> 0.438968).  Saving model ...
Validation loss decreased (0.438968 --> 0.438954).  Saving model ...
Validation loss decreased (0.438954 --> 0.438940).  Saving model ...
Validation loss decreased (0.438940 --> 0.438925).  Saving model ...
Validation loss decreased (0.438925 --> 0.438911).  Saving model ...
Validation loss decreased (0.438911 --> 0.438897).  Saving model ...
Validation loss decreased (0.438897 --> 0.438883).  Saving model ...
Validation loss decreased (0.438883 --> 0.438869).  Saving model ...
Validation loss decreased (0.438869 --> 0.438855).  Saving model ...
Validation loss decreased (0.438855 --> 0.438840).  Saving model ...
Validation loss decreased (0.438840 --> 0.438826).  Saving model ...
Validation loss decreased (0.438826 --> 0.438812).  Saving model ...
Validation loss decreased (0.438812 --> 0.438798).  Saving model ...
Validation loss decreased (0.438798 --> 0.438784).  Saving model ...
Validation loss decreased (0.438784 --> 0.438770).  Saving model ...
Validation loss decreased (0.438770 --> 0.438756).  Saving model ...
Validation loss decreased (0.438756 --> 0.438742).  Saving model ...
Validation loss decreased (0.438742 --> 0.438727).  Saving model ...
Validation loss decreased (0.438727 --> 0.438713).  Saving model ...
Validation loss decreased (0.438713 --> 0.438699).  Saving model ...
Validation loss decreased (0.438699 --> 0.438685).  Saving model ...
Validation loss decreased (0.438685 --> 0.438671).  Saving model ...
epoch 2501, loss 0.4387, train acc 78.42%, f1 0.6684, precision 0.7216, recall 0.6225, auc 0.7468
Validation loss decreased (0.438671 --> 0.438657).  Saving model ...
Validation loss decreased (0.438657 --> 0.438643).  Saving model ...
Validation loss decreased (0.438643 --> 0.438629).  Saving model ...
Validation loss decreased (0.438629 --> 0.438615).  Saving model ...
Validation loss decreased (0.438615 --> 0.438601).  Saving model ...
Validation loss decreased (0.438601 --> 0.438587).  Saving model ...
Validation loss decreased (0.438587 --> 0.438573).  Saving model ...
Validation loss decreased (0.438573 --> 0.438559).  Saving model ...
Validation loss decreased (0.438559 --> 0.438545).  Saving model ...
Validation loss decreased (0.438545 --> 0.438531).  Saving model ...
Validation loss decreased (0.438531 --> 0.438517).  Saving model ...
Validation loss decreased (0.438517 --> 0.438503).  Saving model ...
Validation loss decreased (0.438503 --> 0.438489).  Saving model ...
Validation loss decreased (0.438489 --> 0.438475).  Saving model ...
Validation loss decreased (0.438475 --> 0.438461).  Saving model ...
Validation loss decreased (0.438461 --> 0.438447).  Saving model ...
Validation loss decreased (0.438447 --> 0.438433).  Saving model ...
Validation loss decreased (0.438433 --> 0.438419).  Saving model ...
Validation loss decreased (0.438419 --> 0.438405).  Saving model ...
Validation loss decreased (0.438405 --> 0.438391).  Saving model ...
Validation loss decreased (0.438391 --> 0.438377).  Saving model ...
Validation loss decreased (0.438377 --> 0.438364).  Saving model ...
Validation loss decreased (0.438364 --> 0.438350).  Saving model ...
Validation loss decreased (0.438350 --> 0.438336).  Saving model ...
Validation loss decreased (0.438336 --> 0.438322).  Saving model ...
Validation loss decreased (0.438322 --> 0.438308).  Saving model ...
Validation loss decreased (0.438308 --> 0.438294).  Saving model ...
Validation loss decreased (0.438294 --> 0.438280).  Saving model ...
Validation loss decreased (0.438280 --> 0.438266).  Saving model ...
Validation loss decreased (0.438266 --> 0.438252).  Saving model ...
Validation loss decreased (0.438252 --> 0.438238).  Saving model ...
Validation loss decreased (0.438238 --> 0.438224).  Saving model ...
Validation loss decreased (0.438224 --> 0.438210).  Saving model ...
Validation loss decreased (0.438210 --> 0.438196).  Saving model ...
Validation loss decreased (0.438196 --> 0.438182).  Saving model ...
Validation loss decreased (0.438182 --> 0.438168).  Saving model ...
Validation loss decreased (0.438168 --> 0.438154).  Saving model ...
Validation loss decreased (0.438154 --> 0.438140).  Saving model ...
Validation loss decreased (0.438140 --> 0.438127).  Saving model ...
Validation loss decreased (0.438127 --> 0.438113).  Saving model ...
Validation loss decreased (0.438113 --> 0.438099).  Saving model ...
Validation loss decreased (0.438099 --> 0.438085).  Saving model ...
Validation loss decreased (0.438085 --> 0.438071).  Saving model ...
Validation loss decreased (0.438071 --> 0.438057).  Saving model ...
Validation loss decreased (0.438057 --> 0.438043).  Saving model ...
Validation loss decreased (0.438043 --> 0.438029).  Saving model ...
Validation loss decreased (0.438029 --> 0.438015).  Saving model ...
Validation loss decreased (0.438015 --> 0.438001).  Saving model ...
Validation loss decreased (0.438001 --> 0.437987).  Saving model ...
Validation loss decreased (0.437987 --> 0.437973).  Saving model ...
Validation loss decreased (0.437973 --> 0.437959).  Saving model ...
Validation loss decreased (0.437959 --> 0.437945).  Saving model ...
Validation loss decreased (0.437945 --> 0.437931).  Saving model ...
Validation loss decreased (0.437931 --> 0.437917).  Saving model ...
Validation loss decreased (0.437917 --> 0.437903).  Saving model ...
Validation loss decreased (0.437903 --> 0.437889).  Saving model ...
Validation loss decreased (0.437889 --> 0.437875).  Saving model ...
Validation loss decreased (0.437875 --> 0.437861).  Saving model ...
Validation loss decreased (0.437861 --> 0.437847).  Saving model ...
Validation loss decreased (0.437847 --> 0.437833).  Saving model ...
Validation loss decreased (0.437833 --> 0.437819).  Saving model ...
Validation loss decreased (0.437819 --> 0.437805).  Saving model ...
Validation loss decreased (0.437805 --> 0.437791).  Saving model ...
Validation loss decreased (0.437791 --> 0.437777).  Saving model ...
Validation loss decreased (0.437777 --> 0.437763).  Saving model ...
Validation loss decreased (0.437763 --> 0.437749).  Saving model ...
Validation loss decreased (0.437749 --> 0.437735).  Saving model ...
Validation loss decreased (0.437735 --> 0.437721).  Saving model ...
Validation loss decreased (0.437721 --> 0.437707).  Saving model ...
Validation loss decreased (0.437707 --> 0.437693).  Saving model ...
Validation loss decreased (0.437693 --> 0.437679).  Saving model ...
Validation loss decreased (0.437679 --> 0.437665).  Saving model ...
Validation loss decreased (0.437665 --> 0.437650).  Saving model ...
Validation loss decreased (0.437650 --> 0.437636).  Saving model ...
Validation loss decreased (0.437636 --> 0.437622).  Saving model ...
Validation loss decreased (0.437622 --> 0.437608).  Saving model ...
Validation loss decreased (0.437608 --> 0.437594).  Saving model ...
Validation loss decreased (0.437594 --> 0.437580).  Saving model ...
Validation loss decreased (0.437580 --> 0.437566).  Saving model ...
Validation loss decreased (0.437566 --> 0.437552).  Saving model ...
Validation loss decreased (0.437552 --> 0.437538).  Saving model ...
Validation loss decreased (0.437538 --> 0.437523).  Saving model ...
Validation loss decreased (0.437523 --> 0.437509).  Saving model ...
Validation loss decreased (0.437509 --> 0.437495).  Saving model ...
Validation loss decreased (0.437495 --> 0.437481).  Saving model ...
Validation loss decreased (0.437481 --> 0.437467).  Saving model ...
Validation loss decreased (0.437467 --> 0.437453).  Saving model ...
Validation loss decreased (0.437453 --> 0.437438).  Saving model ...
Validation loss decreased (0.437438 --> 0.437424).  Saving model ...
Validation loss decreased (0.437424 --> 0.437410).  Saving model ...
Validation loss decreased (0.437410 --> 0.437396).  Saving model ...
Validation loss decreased (0.437396 --> 0.437382).  Saving model ...
Validation loss decreased (0.437382 --> 0.437368).  Saving model ...
Validation loss decreased (0.437368 --> 0.437353).  Saving model ...
Validation loss decreased (0.437353 --> 0.437339).  Saving model ...
Validation loss decreased (0.437339 --> 0.437325).  Saving model ...
Validation loss decreased (0.437325 --> 0.437311).  Saving model ...
Validation loss decreased (0.437311 --> 0.437296).  Saving model ...
Validation loss decreased (0.437296 --> 0.437282).  Saving model ...
Validation loss decreased (0.437282 --> 0.437268).  Saving model ...
epoch 2601, loss 0.4373, train acc 78.77%, f1 0.6754, precision 0.7247, recall 0.6324, auc 0.7517
Validation loss decreased (0.437268 --> 0.437254).  Saving model ...
Validation loss decreased (0.437254 --> 0.437239).  Saving model ...
Validation loss decreased (0.437239 --> 0.437225).  Saving model ...
Validation loss decreased (0.437225 --> 0.437211).  Saving model ...
Validation loss decreased (0.437211 --> 0.437197).  Saving model ...
Validation loss decreased (0.437197 --> 0.437182).  Saving model ...
Validation loss decreased (0.437182 --> 0.437168).  Saving model ...
Validation loss decreased (0.437168 --> 0.437154).  Saving model ...
Validation loss decreased (0.437154 --> 0.437140).  Saving model ...
Validation loss decreased (0.437140 --> 0.437125).  Saving model ...
Validation loss decreased (0.437125 --> 0.437111).  Saving model ...
Validation loss decreased (0.437111 --> 0.437097).  Saving model ...
Validation loss decreased (0.437097 --> 0.437083).  Saving model ...
Validation loss decreased (0.437083 --> 0.437068).  Saving model ...
Validation loss decreased (0.437068 --> 0.437054).  Saving model ...
Validation loss decreased (0.437054 --> 0.437040).  Saving model ...
Validation loss decreased (0.437040 --> 0.437025).  Saving model ...
Validation loss decreased (0.437025 --> 0.437011).  Saving model ...
Validation loss decreased (0.437011 --> 0.436997).  Saving model ...
Validation loss decreased (0.436997 --> 0.436983).  Saving model ...
Validation loss decreased (0.436983 --> 0.436968).  Saving model ...
Validation loss decreased (0.436968 --> 0.436954).  Saving model ...
Validation loss decreased (0.436954 --> 0.436940).  Saving model ...
Validation loss decreased (0.436940 --> 0.436926).  Saving model ...
Validation loss decreased (0.436926 --> 0.436911).  Saving model ...
Validation loss decreased (0.436911 --> 0.436897).  Saving model ...
Validation loss decreased (0.436897 --> 0.436883).  Saving model ...
Validation loss decreased (0.436883 --> 0.436868).  Saving model ...
Validation loss decreased (0.436868 --> 0.436854).  Saving model ...
Validation loss decreased (0.436854 --> 0.436840).  Saving model ...
Validation loss decreased (0.436840 --> 0.436826).  Saving model ...
Validation loss decreased (0.436826 --> 0.436811).  Saving model ...
Validation loss decreased (0.436811 --> 0.436797).  Saving model ...
Validation loss decreased (0.436797 --> 0.436783).  Saving model ...
Validation loss decreased (0.436783 --> 0.436769).  Saving model ...
Validation loss decreased (0.436769 --> 0.436755).  Saving model ...
Validation loss decreased (0.436755 --> 0.436740).  Saving model ...
Validation loss decreased (0.436740 --> 0.436726).  Saving model ...
Validation loss decreased (0.436726 --> 0.436712).  Saving model ...
Validation loss decreased (0.436712 --> 0.436698).  Saving model ...
Validation loss decreased (0.436698 --> 0.436683).  Saving model ...
Validation loss decreased (0.436683 --> 0.436669).  Saving model ...
Validation loss decreased (0.436669 --> 0.436655).  Saving model ...
Validation loss decreased (0.436655 --> 0.436641).  Saving model ...
Validation loss decreased (0.436641 --> 0.436627).  Saving model ...
Validation loss decreased (0.436627 --> 0.436613).  Saving model ...
Validation loss decreased (0.436613 --> 0.436598).  Saving model ...
Validation loss decreased (0.436598 --> 0.436584).  Saving model ...
Validation loss decreased (0.436584 --> 0.436570).  Saving model ...
Validation loss decreased (0.436570 --> 0.436556).  Saving model ...
Validation loss decreased (0.436556 --> 0.436542).  Saving model ...
Validation loss decreased (0.436542 --> 0.436528).  Saving model ...
Validation loss decreased (0.436528 --> 0.436514).  Saving model ...
Validation loss decreased (0.436514 --> 0.436500).  Saving model ...
Validation loss decreased (0.436500 --> 0.436485).  Saving model ...
Validation loss decreased (0.436485 --> 0.436471).  Saving model ...
Validation loss decreased (0.436471 --> 0.436457).  Saving model ...
Validation loss decreased (0.436457 --> 0.436443).  Saving model ...
Validation loss decreased (0.436443 --> 0.436429).  Saving model ...
Validation loss decreased (0.436429 --> 0.436415).  Saving model ...
Validation loss decreased (0.436415 --> 0.436401).  Saving model ...
Validation loss decreased (0.436401 --> 0.436387).  Saving model ...
Validation loss decreased (0.436387 --> 0.436373).  Saving model ...
Validation loss decreased (0.436373 --> 0.436359).  Saving model ...
Validation loss decreased (0.436359 --> 0.436345).  Saving model ...
Validation loss decreased (0.436345 --> 0.436331).  Saving model ...
Validation loss decreased (0.436331 --> 0.436317).  Saving model ...
Validation loss decreased (0.436317 --> 0.436303).  Saving model ...
Validation loss decreased (0.436303 --> 0.436289).  Saving model ...
Validation loss decreased (0.436289 --> 0.436275).  Saving model ...
Validation loss decreased (0.436275 --> 0.436261).  Saving model ...
Validation loss decreased (0.436261 --> 0.436247).  Saving model ...
Validation loss decreased (0.436247 --> 0.436234).  Saving model ...
Validation loss decreased (0.436234 --> 0.436220).  Saving model ...
Validation loss decreased (0.436220 --> 0.436206).  Saving model ...
Validation loss decreased (0.436206 --> 0.436192).  Saving model ...
Validation loss decreased (0.436192 --> 0.436178).  Saving model ...
Validation loss decreased (0.436178 --> 0.436164).  Saving model ...
Validation loss decreased (0.436164 --> 0.436150).  Saving model ...
Validation loss decreased (0.436150 --> 0.436137).  Saving model ...
Validation loss decreased (0.436137 --> 0.436123).  Saving model ...
Validation loss decreased (0.436123 --> 0.436109).  Saving model ...
Validation loss decreased (0.436109 --> 0.436095).  Saving model ...
Validation loss decreased (0.436095 --> 0.436081).  Saving model ...
Validation loss decreased (0.436081 --> 0.436068).  Saving model ...
Validation loss decreased (0.436068 --> 0.436054).  Saving model ...
Validation loss decreased (0.436054 --> 0.436040).  Saving model ...
Validation loss decreased (0.436040 --> 0.436026).  Saving model ...
Validation loss decreased (0.436026 --> 0.436013).  Saving model ...
Validation loss decreased (0.436013 --> 0.435999).  Saving model ...
Validation loss decreased (0.435999 --> 0.435985).  Saving model ...
Validation loss decreased (0.435985 --> 0.435972).  Saving model ...
Validation loss decreased (0.435972 --> 0.435958).  Saving model ...
Validation loss decreased (0.435958 --> 0.435944).  Saving model ...
Validation loss decreased (0.435944 --> 0.435930).  Saving model ...
Validation loss decreased (0.435930 --> 0.435917).  Saving model ...
Validation loss decreased (0.435917 --> 0.435903).  Saving model ...
Validation loss decreased (0.435903 --> 0.435890).  Saving model ...
Validation loss decreased (0.435890 --> 0.435876).  Saving model ...
Validation loss decreased (0.435876 --> 0.435862).  Saving model ...
epoch 2701, loss 0.4359, train acc 78.94%, f1 0.6772, precision 0.7288, recall 0.6324, auc 0.7530
Validation loss decreased (0.435862 --> 0.435849).  Saving model ...
Validation loss decreased (0.435849 --> 0.435835).  Saving model ...
Validation loss decreased (0.435835 --> 0.435821).  Saving model ...
Validation loss decreased (0.435821 --> 0.435808).  Saving model ...
Validation loss decreased (0.435808 --> 0.435794).  Saving model ...
Validation loss decreased (0.435794 --> 0.435781).  Saving model ...
Validation loss decreased (0.435781 --> 0.435767).  Saving model ...
Validation loss decreased (0.435767 --> 0.435754).  Saving model ...
Validation loss decreased (0.435754 --> 0.435740).  Saving model ...
Validation loss decreased (0.435740 --> 0.435727).  Saving model ...
Validation loss decreased (0.435727 --> 0.435713).  Saving model ...
Validation loss decreased (0.435713 --> 0.435699).  Saving model ...
Validation loss decreased (0.435699 --> 0.435686).  Saving model ...
Validation loss decreased (0.435686 --> 0.435672).  Saving model ...
Validation loss decreased (0.435672 --> 0.435659).  Saving model ...
Validation loss decreased (0.435659 --> 0.435645).  Saving model ...
Validation loss decreased (0.435645 --> 0.435632).  Saving model ...
Validation loss decreased (0.435632 --> 0.435618).  Saving model ...
Validation loss decreased (0.435618 --> 0.435605).  Saving model ...
Validation loss decreased (0.435605 --> 0.435591).  Saving model ...
Validation loss decreased (0.435591 --> 0.435578).  Saving model ...
Validation loss decreased (0.435578 --> 0.435565).  Saving model ...
Validation loss decreased (0.435565 --> 0.435551).  Saving model ...
Validation loss decreased (0.435551 --> 0.435538).  Saving model ...
Validation loss decreased (0.435538 --> 0.435524).  Saving model ...
Validation loss decreased (0.435524 --> 0.435511).  Saving model ...
Validation loss decreased (0.435511 --> 0.435497).  Saving model ...
Validation loss decreased (0.435497 --> 0.435484).  Saving model ...
Validation loss decreased (0.435484 --> 0.435470).  Saving model ...
Validation loss decreased (0.435470 --> 0.435457).  Saving model ...
Validation loss decreased (0.435457 --> 0.435444).  Saving model ...
Validation loss decreased (0.435444 --> 0.435430).  Saving model ...
Validation loss decreased (0.435430 --> 0.435417).  Saving model ...
Validation loss decreased (0.435417 --> 0.435403).  Saving model ...
Validation loss decreased (0.435403 --> 0.435390).  Saving model ...
Validation loss decreased (0.435390 --> 0.435376).  Saving model ...
Validation loss decreased (0.435376 --> 0.435363).  Saving model ...
Validation loss decreased (0.435363 --> 0.435350).  Saving model ...
Validation loss decreased (0.435350 --> 0.435336).  Saving model ...
Validation loss decreased (0.435336 --> 0.435323).  Saving model ...
Validation loss decreased (0.435323 --> 0.435309).  Saving model ...
Validation loss decreased (0.435309 --> 0.435296).  Saving model ...
Validation loss decreased (0.435296 --> 0.435283).  Saving model ...
Validation loss decreased (0.435283 --> 0.435269).  Saving model ...
Validation loss decreased (0.435269 --> 0.435256).  Saving model ...
Validation loss decreased (0.435256 --> 0.435242).  Saving model ...
Validation loss decreased (0.435242 --> 0.435229).  Saving model ...
Validation loss decreased (0.435229 --> 0.435216).  Saving model ...
Validation loss decreased (0.435216 --> 0.435202).  Saving model ...
Validation loss decreased (0.435202 --> 0.435189).  Saving model ...
Validation loss decreased (0.435189 --> 0.435175).  Saving model ...
Validation loss decreased (0.435175 --> 0.435162).  Saving model ...
Validation loss decreased (0.435162 --> 0.435148).  Saving model ...
Validation loss decreased (0.435148 --> 0.435135).  Saving model ...
Validation loss decreased (0.435135 --> 0.435122).  Saving model ...
Validation loss decreased (0.435122 --> 0.435108).  Saving model ...
Validation loss decreased (0.435108 --> 0.435095).  Saving model ...
Validation loss decreased (0.435095 --> 0.435081).  Saving model ...
Validation loss decreased (0.435081 --> 0.435068).  Saving model ...
Validation loss decreased (0.435068 --> 0.435054).  Saving model ...
Validation loss decreased (0.435054 --> 0.435041).  Saving model ...
Validation loss decreased (0.435041 --> 0.435028).  Saving model ...
Validation loss decreased (0.435028 --> 0.435014).  Saving model ...
Validation loss decreased (0.435014 --> 0.435001).  Saving model ...
Validation loss decreased (0.435001 --> 0.434987).  Saving model ...
Validation loss decreased (0.434987 --> 0.434974).  Saving model ...
Validation loss decreased (0.434974 --> 0.434960).  Saving model ...
Validation loss decreased (0.434960 --> 0.434947).  Saving model ...
Validation loss decreased (0.434947 --> 0.434933).  Saving model ...
Validation loss decreased (0.434933 --> 0.434920).  Saving model ...
Validation loss decreased (0.434920 --> 0.434906).  Saving model ...
Validation loss decreased (0.434906 --> 0.434893).  Saving model ...
Validation loss decreased (0.434893 --> 0.434879).  Saving model ...
Validation loss decreased (0.434879 --> 0.434866).  Saving model ...
Validation loss decreased (0.434866 --> 0.434852).  Saving model ...
Validation loss decreased (0.434852 --> 0.434839).  Saving model ...
Validation loss decreased (0.434839 --> 0.434825).  Saving model ...
Validation loss decreased (0.434825 --> 0.434812).  Saving model ...
Validation loss decreased (0.434812 --> 0.434798).  Saving model ...
Validation loss decreased (0.434798 --> 0.434785).  Saving model ...
Validation loss decreased (0.434785 --> 0.434771).  Saving model ...
Validation loss decreased (0.434771 --> 0.434757).  Saving model ...
Validation loss decreased (0.434757 --> 0.434744).  Saving model ...
Validation loss decreased (0.434744 --> 0.434730).  Saving model ...
Validation loss decreased (0.434730 --> 0.434717).  Saving model ...
Validation loss decreased (0.434717 --> 0.434703).  Saving model ...
Validation loss decreased (0.434703 --> 0.434689).  Saving model ...
Validation loss decreased (0.434689 --> 0.434676).  Saving model ...
Validation loss decreased (0.434676 --> 0.434662).  Saving model ...
Validation loss decreased (0.434662 --> 0.434649).  Saving model ...
Validation loss decreased (0.434649 --> 0.434635).  Saving model ...
Validation loss decreased (0.434635 --> 0.434621).  Saving model ...
Validation loss decreased (0.434621 --> 0.434608).  Saving model ...
Validation loss decreased (0.434608 --> 0.434594).  Saving model ...
Validation loss decreased (0.434594 --> 0.434580).  Saving model ...
Validation loss decreased (0.434580 --> 0.434567).  Saving model ...
Validation loss decreased (0.434567 --> 0.434553).  Saving model ...
Validation loss decreased (0.434553 --> 0.434539).  Saving model ...
Validation loss decreased (0.434539 --> 0.434525).  Saving model ...
Validation loss decreased (0.434525 --> 0.434512).  Saving model ...
epoch 2801, loss 0.4345, train acc 79.11%, f1 0.6806, precision 0.7303, recall 0.6373, auc 0.7555
Validation loss decreased (0.434512 --> 0.434498).  Saving model ...
Validation loss decreased (0.434498 --> 0.434484).  Saving model ...
Validation loss decreased (0.434484 --> 0.434470).  Saving model ...
Validation loss decreased (0.434470 --> 0.434457).  Saving model ...
Validation loss decreased (0.434457 --> 0.434443).  Saving model ...
Validation loss decreased (0.434443 --> 0.434429).  Saving model ...
Validation loss decreased (0.434429 --> 0.434415).  Saving model ...
Validation loss decreased (0.434415 --> 0.434401).  Saving model ...
Validation loss decreased (0.434401 --> 0.434388).  Saving model ...
Validation loss decreased (0.434388 --> 0.434374).  Saving model ...
Validation loss decreased (0.434374 --> 0.434360).  Saving model ...
Validation loss decreased (0.434360 --> 0.434346).  Saving model ...
Validation loss decreased (0.434346 --> 0.434332).  Saving model ...
Validation loss decreased (0.434332 --> 0.434318).  Saving model ...
Validation loss decreased (0.434318 --> 0.434304).  Saving model ...
Validation loss decreased (0.434304 --> 0.434290).  Saving model ...
Validation loss decreased (0.434290 --> 0.434277).  Saving model ...
Validation loss decreased (0.434277 --> 0.434263).  Saving model ...
Validation loss decreased (0.434263 --> 0.434249).  Saving model ...
Validation loss decreased (0.434249 --> 0.434235).  Saving model ...
Validation loss decreased (0.434235 --> 0.434221).  Saving model ...
Validation loss decreased (0.434221 --> 0.434207).  Saving model ...
Validation loss decreased (0.434207 --> 0.434193).  Saving model ...
Validation loss decreased (0.434193 --> 0.434179).  Saving model ...
Validation loss decreased (0.434179 --> 0.434165).  Saving model ...
Validation loss decreased (0.434165 --> 0.434151).  Saving model ...
Validation loss decreased (0.434151 --> 0.434137).  Saving model ...
Validation loss decreased (0.434137 --> 0.434123).  Saving model ...
Validation loss decreased (0.434123 --> 0.434109).  Saving model ...
Validation loss decreased (0.434109 --> 0.434094).  Saving model ...
Validation loss decreased (0.434094 --> 0.434080).  Saving model ...
Validation loss decreased (0.434080 --> 0.434066).  Saving model ...
Validation loss decreased (0.434066 --> 0.434052).  Saving model ...
Validation loss decreased (0.434052 --> 0.434038).  Saving model ...
Validation loss decreased (0.434038 --> 0.434024).  Saving model ...
Validation loss decreased (0.434024 --> 0.434010).  Saving model ...
Validation loss decreased (0.434010 --> 0.433996).  Saving model ...
Validation loss decreased (0.433996 --> 0.433981).  Saving model ...
Validation loss decreased (0.433981 --> 0.433967).  Saving model ...
Validation loss decreased (0.433967 --> 0.433953).  Saving model ...
Validation loss decreased (0.433953 --> 0.433939).  Saving model ...
Validation loss decreased (0.433939 --> 0.433925).  Saving model ...
Validation loss decreased (0.433925 --> 0.433910).  Saving model ...
Validation loss decreased (0.433910 --> 0.433896).  Saving model ...
Validation loss decreased (0.433896 --> 0.433882).  Saving model ...
Validation loss decreased (0.433882 --> 0.433868).  Saving model ...
Validation loss decreased (0.433868 --> 0.433854).  Saving model ...
Validation loss decreased (0.433854 --> 0.433839).  Saving model ...
Validation loss decreased (0.433839 --> 0.433825).  Saving model ...
Validation loss decreased (0.433825 --> 0.433811).  Saving model ...
Validation loss decreased (0.433811 --> 0.433796).  Saving model ...
Validation loss decreased (0.433796 --> 0.433782).  Saving model ...
Validation loss decreased (0.433782 --> 0.433768).  Saving model ...
Validation loss decreased (0.433768 --> 0.433753).  Saving model ...
Validation loss decreased (0.433753 --> 0.433739).  Saving model ...
Validation loss decreased (0.433739 --> 0.433725).  Saving model ...
Validation loss decreased (0.433725 --> 0.433710).  Saving model ...
Validation loss decreased (0.433710 --> 0.433696).  Saving model ...
Validation loss decreased (0.433696 --> 0.433681).  Saving model ...
Validation loss decreased (0.433681 --> 0.433667).  Saving model ...
Validation loss decreased (0.433667 --> 0.433653).  Saving model ...
Validation loss decreased (0.433653 --> 0.433638).  Saving model ...
Validation loss decreased (0.433638 --> 0.433624).  Saving model ...
Validation loss decreased (0.433624 --> 0.433609).  Saving model ...
Validation loss decreased (0.433609 --> 0.433595).  Saving model ...
Validation loss decreased (0.433595 --> 0.433580).  Saving model ...
Validation loss decreased (0.433580 --> 0.433566).  Saving model ...
Validation loss decreased (0.433566 --> 0.433552).  Saving model ...
Validation loss decreased (0.433552 --> 0.433537).  Saving model ...
Validation loss decreased (0.433537 --> 0.433523).  Saving model ...
Validation loss decreased (0.433523 --> 0.433508).  Saving model ...
Validation loss decreased (0.433508 --> 0.433494).  Saving model ...
Validation loss decreased (0.433494 --> 0.433479).  Saving model ...
Validation loss decreased (0.433479 --> 0.433464).  Saving model ...
Validation loss decreased (0.433464 --> 0.433450).  Saving model ...
Validation loss decreased (0.433450 --> 0.433435).  Saving model ...
Validation loss decreased (0.433435 --> 0.433421).  Saving model ...
Validation loss decreased (0.433421 --> 0.433406).  Saving model ...
Validation loss decreased (0.433406 --> 0.433392).  Saving model ...
Validation loss decreased (0.433392 --> 0.433377).  Saving model ...
Validation loss decreased (0.433377 --> 0.433363).  Saving model ...
Validation loss decreased (0.433363 --> 0.433348).  Saving model ...
Validation loss decreased (0.433348 --> 0.433333).  Saving model ...
Validation loss decreased (0.433333 --> 0.433319).  Saving model ...
Validation loss decreased (0.433319 --> 0.433304).  Saving model ...
Validation loss decreased (0.433304 --> 0.433290).  Saving model ...
Validation loss decreased (0.433290 --> 0.433275).  Saving model ...
Validation loss decreased (0.433275 --> 0.433260).  Saving model ...
Validation loss decreased (0.433260 --> 0.433246).  Saving model ...
Validation loss decreased (0.433246 --> 0.433231).  Saving model ...
Validation loss decreased (0.433231 --> 0.433216).  Saving model ...
Validation loss decreased (0.433216 --> 0.433202).  Saving model ...
Validation loss decreased (0.433202 --> 0.433187).  Saving model ...
Validation loss decreased (0.433187 --> 0.433172).  Saving model ...
Validation loss decreased (0.433172 --> 0.433158).  Saving model ...
Validation loss decreased (0.433158 --> 0.433143).  Saving model ...
Validation loss decreased (0.433143 --> 0.433128).  Saving model ...
Validation loss decreased (0.433128 --> 0.433113).  Saving model ...
Validation loss decreased (0.433113 --> 0.433099).  Saving model ...
Validation loss decreased (0.433099 --> 0.433084).  Saving model ...
epoch 2901, loss 0.4331, train acc 78.94%, f1 0.6772, precision 0.7288, recall 0.6324, auc 0.7530
Validation loss decreased (0.433084 --> 0.433069).  Saving model ...
Validation loss decreased (0.433069 --> 0.433054).  Saving model ...
Validation loss decreased (0.433054 --> 0.433040).  Saving model ...
Validation loss decreased (0.433040 --> 0.433025).  Saving model ...
Validation loss decreased (0.433025 --> 0.433010).  Saving model ...
Validation loss decreased (0.433010 --> 0.432995).  Saving model ...
Validation loss decreased (0.432995 --> 0.432980).  Saving model ...
Validation loss decreased (0.432980 --> 0.432966).  Saving model ...
Validation loss decreased (0.432966 --> 0.432951).  Saving model ...
Validation loss decreased (0.432951 --> 0.432936).  Saving model ...
Validation loss decreased (0.432936 --> 0.432921).  Saving model ...
Validation loss decreased (0.432921 --> 0.432906).  Saving model ...
Validation loss decreased (0.432906 --> 0.432891).  Saving model ...
Validation loss decreased (0.432891 --> 0.432877).  Saving model ...
Validation loss decreased (0.432877 --> 0.432862).  Saving model ...
Validation loss decreased (0.432862 --> 0.432847).  Saving model ...
Validation loss decreased (0.432847 --> 0.432832).  Saving model ...
Validation loss decreased (0.432832 --> 0.432817).  Saving model ...
Validation loss decreased (0.432817 --> 0.432802).  Saving model ...
Validation loss decreased (0.432802 --> 0.432787).  Saving model ...
Validation loss decreased (0.432787 --> 0.432772).  Saving model ...
Validation loss decreased (0.432772 --> 0.432757).  Saving model ...
Validation loss decreased (0.432757 --> 0.432742).  Saving model ...
Validation loss decreased (0.432742 --> 0.432727).  Saving model ...
Validation loss decreased (0.432727 --> 0.432712).  Saving model ...
Validation loss decreased (0.432712 --> 0.432697).  Saving model ...
Validation loss decreased (0.432697 --> 0.432682).  Saving model ...
Validation loss decreased (0.432682 --> 0.432667).  Saving model ...
Validation loss decreased (0.432667 --> 0.432652).  Saving model ...
Validation loss decreased (0.432652 --> 0.432637).  Saving model ...
Validation loss decreased (0.432637 --> 0.432622).  Saving model ...
Validation loss decreased (0.432622 --> 0.432607).  Saving model ...
Validation loss decreased (0.432607 --> 0.432592).  Saving model ...
Validation loss decreased (0.432592 --> 0.432577).  Saving model ...
Validation loss decreased (0.432577 --> 0.432562).  Saving model ...
Validation loss decreased (0.432562 --> 0.432547).  Saving model ...
Validation loss decreased (0.432547 --> 0.432532).  Saving model ...
Validation loss decreased (0.432532 --> 0.432517).  Saving model ...
Validation loss decreased (0.432517 --> 0.432502).  Saving model ...
Validation loss decreased (0.432502 --> 0.432487).  Saving model ...
Validation loss decreased (0.432487 --> 0.432471).  Saving model ...
Validation loss decreased (0.432471 --> 0.432456).  Saving model ...
Validation loss decreased (0.432456 --> 0.432441).  Saving model ...
Validation loss decreased (0.432441 --> 0.432426).  Saving model ...
Validation loss decreased (0.432426 --> 0.432411).  Saving model ...
Validation loss decreased (0.432411 --> 0.432395).  Saving model ...
Validation loss decreased (0.432395 --> 0.432380).  Saving model ...
Validation loss decreased (0.432380 --> 0.432365).  Saving model ...
Validation loss decreased (0.432365 --> 0.432350).  Saving model ...
Validation loss decreased (0.432350 --> 0.432334).  Saving model ...
Validation loss decreased (0.432334 --> 0.432319).  Saving model ...
Validation loss decreased (0.432319 --> 0.432304).  Saving model ...
Validation loss decreased (0.432304 --> 0.432289).  Saving model ...
Validation loss decreased (0.432289 --> 0.432273).  Saving model ...
Validation loss decreased (0.432273 --> 0.432258).  Saving model ...
Validation loss decreased (0.432258 --> 0.432243).  Saving model ...
Validation loss decreased (0.432243 --> 0.432227).  Saving model ...
Validation loss decreased (0.432227 --> 0.432212).  Saving model ...
Validation loss decreased (0.432212 --> 0.432196).  Saving model ...
Validation loss decreased (0.432196 --> 0.432181).  Saving model ...
Validation loss decreased (0.432181 --> 0.432166).  Saving model ...
Validation loss decreased (0.432166 --> 0.432150).  Saving model ...
Validation loss decreased (0.432150 --> 0.432135).  Saving model ...
Validation loss decreased (0.432135 --> 0.432119).  Saving model ...
Validation loss decreased (0.432119 --> 0.432104).  Saving model ...
Validation loss decreased (0.432104 --> 0.432088).  Saving model ...
Validation loss decreased (0.432088 --> 0.432073).  Saving model ...
Validation loss decreased (0.432073 --> 0.432057).  Saving model ...
Validation loss decreased (0.432057 --> 0.432042).  Saving model ...
Validation loss decreased (0.432042 --> 0.432026).  Saving model ...
Validation loss decreased (0.432026 --> 0.432010).  Saving model ...
Validation loss decreased (0.432010 --> 0.431995).  Saving model ...
Validation loss decreased (0.431995 --> 0.431979).  Saving model ...
Validation loss decreased (0.431979 --> 0.431963).  Saving model ...
Validation loss decreased (0.431963 --> 0.431948).  Saving model ...
Validation loss decreased (0.431948 --> 0.431932).  Saving model ...
Validation loss decreased (0.431932 --> 0.431916).  Saving model ...
Validation loss decreased (0.431916 --> 0.431901).  Saving model ...
Validation loss decreased (0.431901 --> 0.431885).  Saving model ...
Validation loss decreased (0.431885 --> 0.431869).  Saving model ...
Validation loss decreased (0.431869 --> 0.431853).  Saving model ...
Validation loss decreased (0.431853 --> 0.431838).  Saving model ...
Validation loss decreased (0.431838 --> 0.431822).  Saving model ...
Validation loss decreased (0.431822 --> 0.431806).  Saving model ...
Validation loss decreased (0.431806 --> 0.431790).  Saving model ...
Validation loss decreased (0.431790 --> 0.431774).  Saving model ...
Validation loss decreased (0.431774 --> 0.431758).  Saving model ...
Validation loss decreased (0.431758 --> 0.431742).  Saving model ...
Validation loss decreased (0.431742 --> 0.431726).  Saving model ...
Validation loss decreased (0.431726 --> 0.431710).  Saving model ...
Validation loss decreased (0.431710 --> 0.431694).  Saving model ...
Validation loss decreased (0.431694 --> 0.431678).  Saving model ...
Validation loss decreased (0.431678 --> 0.431662).  Saving model ...
Validation loss decreased (0.431662 --> 0.431646).  Saving model ...
Validation loss decreased (0.431646 --> 0.431630).  Saving model ...
Validation loss decreased (0.431630 --> 0.431614).  Saving model ...
Validation loss decreased (0.431614 --> 0.431598).  Saving model ...
Validation loss decreased (0.431598 --> 0.431582).  Saving model ...
Validation loss decreased (0.431582 --> 0.431566).  Saving model ...
Validation loss decreased (0.431566 --> 0.431549).  Saving model ...
epoch 3001, loss 0.4315, train acc 78.94%, f1 0.6772, precision 0.7288, recall 0.6324, auc 0.7530
Validation loss decreased (0.431549 --> 0.431533).  Saving model ...
Validation loss decreased (0.431533 --> 0.431517).  Saving model ...
Validation loss decreased (0.431517 --> 0.431500).  Saving model ...
Validation loss decreased (0.431500 --> 0.431484).  Saving model ...
Validation loss decreased (0.431484 --> 0.431468).  Saving model ...
Validation loss decreased (0.431468 --> 0.431451).  Saving model ...
Validation loss decreased (0.431451 --> 0.431435).  Saving model ...
Validation loss decreased (0.431435 --> 0.431419).  Saving model ...
Validation loss decreased (0.431419 --> 0.431402).  Saving model ...
Validation loss decreased (0.431402 --> 0.431386).  Saving model ...
Validation loss decreased (0.431386 --> 0.431369).  Saving model ...
Validation loss decreased (0.431369 --> 0.431353).  Saving model ...
Validation loss decreased (0.431353 --> 0.431336).  Saving model ...
Validation loss decreased (0.431336 --> 0.431320).  Saving model ...
Validation loss decreased (0.431320 --> 0.431303).  Saving model ...
Validation loss decreased (0.431303 --> 0.431286).  Saving model ...
Validation loss decreased (0.431286 --> 0.431270).  Saving model ...
Validation loss decreased (0.431270 --> 0.431253).  Saving model ...
Validation loss decreased (0.431253 --> 0.431236).  Saving model ...
Validation loss decreased (0.431236 --> 0.431220).  Saving model ...
Validation loss decreased (0.431220 --> 0.431203).  Saving model ...
Validation loss decreased (0.431203 --> 0.431186).  Saving model ...
Validation loss decreased (0.431186 --> 0.431169).  Saving model ...
Validation loss decreased (0.431169 --> 0.431152).  Saving model ...
Validation loss decreased (0.431152 --> 0.431136).  Saving model ...
Validation loss decreased (0.431136 --> 0.431119).  Saving model ...
Validation loss decreased (0.431119 --> 0.431102).  Saving model ...
Validation loss decreased (0.431102 --> 0.431085).  Saving model ...
Validation loss decreased (0.431085 --> 0.431068).  Saving model ...
Validation loss decreased (0.431068 --> 0.431051).  Saving model ...
Validation loss decreased (0.431051 --> 0.431034).  Saving model ...
Validation loss decreased (0.431034 --> 0.431017).  Saving model ...
Validation loss decreased (0.431017 --> 0.431000).  Saving model ...
Validation loss decreased (0.431000 --> 0.430982).  Saving model ...
Validation loss decreased (0.430982 --> 0.430965).  Saving model ...
Validation loss decreased (0.430965 --> 0.430948).  Saving model ...
Validation loss decreased (0.430948 --> 0.430931).  Saving model ...
Validation loss decreased (0.430931 --> 0.430914).  Saving model ...
Validation loss decreased (0.430914 --> 0.430896).  Saving model ...
Validation loss decreased (0.430896 --> 0.430879).  Saving model ...
Validation loss decreased (0.430879 --> 0.430862).  Saving model ...
Validation loss decreased (0.430862 --> 0.430844).  Saving model ...
Validation loss decreased (0.430844 --> 0.430827).  Saving model ...
Validation loss decreased (0.430827 --> 0.430809).  Saving model ...
Validation loss decreased (0.430809 --> 0.430792).  Saving model ...
Validation loss decreased (0.430792 --> 0.430774).  Saving model ...
Validation loss decreased (0.430774 --> 0.430757).  Saving model ...
Validation loss decreased (0.430757 --> 0.430739).  Saving model ...
Validation loss decreased (0.430739 --> 0.430722).  Saving model ...
Validation loss decreased (0.430722 --> 0.430704).  Saving model ...
Validation loss decreased (0.430704 --> 0.430686).  Saving model ...
Validation loss decreased (0.430686 --> 0.430669).  Saving model ...
Validation loss decreased (0.430669 --> 0.430651).  Saving model ...
Validation loss decreased (0.430651 --> 0.430633).  Saving model ...
Validation loss decreased (0.430633 --> 0.430615).  Saving model ...
Validation loss decreased (0.430615 --> 0.430597).  Saving model ...
Validation loss decreased (0.430597 --> 0.430580).  Saving model ...
Validation loss decreased (0.430580 --> 0.430562).  Saving model ...
Validation loss decreased (0.430562 --> 0.430544).  Saving model ...
Validation loss decreased (0.430544 --> 0.430526).  Saving model ...
Validation loss decreased (0.430526 --> 0.430508).  Saving model ...
Validation loss decreased (0.430508 --> 0.430490).  Saving model ...
Validation loss decreased (0.430490 --> 0.430472).  Saving model ...
Validation loss decreased (0.430472 --> 0.430454).  Saving model ...
Validation loss decreased (0.430454 --> 0.430436).  Saving model ...
Validation loss decreased (0.430436 --> 0.430418).  Saving model ...
Validation loss decreased (0.430418 --> 0.430399).  Saving model ...
Validation loss decreased (0.430399 --> 0.430381).  Saving model ...
Validation loss decreased (0.430381 --> 0.430363).  Saving model ...
Validation loss decreased (0.430363 --> 0.430345).  Saving model ...
Validation loss decreased (0.430345 --> 0.430326).  Saving model ...
Validation loss decreased (0.430326 --> 0.430308).  Saving model ...
Validation loss decreased (0.430308 --> 0.430290).  Saving model ...
Validation loss decreased (0.430290 --> 0.430272).  Saving model ...
Validation loss decreased (0.430272 --> 0.430253).  Saving model ...
Validation loss decreased (0.430253 --> 0.430235).  Saving model ...
Validation loss decreased (0.430235 --> 0.430216).  Saving model ...
Validation loss decreased (0.430216 --> 0.430198).  Saving model ...
Validation loss decreased (0.430198 --> 0.430179).  Saving model ...
Validation loss decreased (0.430179 --> 0.430161).  Saving model ...
Validation loss decreased (0.430161 --> 0.430142).  Saving model ...
Validation loss decreased (0.430142 --> 0.430124).  Saving model ...
Validation loss decreased (0.430124 --> 0.430105).  Saving model ...
Validation loss decreased (0.430105 --> 0.430086).  Saving model ...
Validation loss decreased (0.430086 --> 0.430068).  Saving model ...
Validation loss decreased (0.430068 --> 0.430049).  Saving model ...
Validation loss decreased (0.430049 --> 0.430030).  Saving model ...
Validation loss decreased (0.430030 --> 0.430012).  Saving model ...
Validation loss decreased (0.430012 --> 0.429993).  Saving model ...
Validation loss decreased (0.429993 --> 0.429974).  Saving model ...
Validation loss decreased (0.429974 --> 0.429955).  Saving model ...
Validation loss decreased (0.429955 --> 0.429936).  Saving model ...
Validation loss decreased (0.429936 --> 0.429918).  Saving model ...
Validation loss decreased (0.429918 --> 0.429899).  Saving model ...
Validation loss decreased (0.429899 --> 0.429880).  Saving model ...
Validation loss decreased (0.429880 --> 0.429861).  Saving model ...
Validation loss decreased (0.429861 --> 0.429842).  Saving model ...
Validation loss decreased (0.429842 --> 0.429823).  Saving model ...
Validation loss decreased (0.429823 --> 0.429804).  Saving model ...
Validation loss decreased (0.429804 --> 0.429785).  Saving model ...
epoch 3101, loss 0.4298, train acc 79.28%, f1 0.6824, precision 0.7345, recall 0.6373, auc 0.7568
Validation loss decreased (0.429785 --> 0.429766).  Saving model ...
Validation loss decreased (0.429766 --> 0.429747).  Saving model ...
Validation loss decreased (0.429747 --> 0.429728).  Saving model ...
Validation loss decreased (0.429728 --> 0.429709).  Saving model ...
Validation loss decreased (0.429709 --> 0.429690).  Saving model ...
Validation loss decreased (0.429690 --> 0.429671).  Saving model ...
Validation loss decreased (0.429671 --> 0.429651).  Saving model ...
Validation loss decreased (0.429651 --> 0.429632).  Saving model ...
Validation loss decreased (0.429632 --> 0.429613).  Saving model ...
Validation loss decreased (0.429613 --> 0.429594).  Saving model ...
Validation loss decreased (0.429594 --> 0.429575).  Saving model ...
Validation loss decreased (0.429575 --> 0.429556).  Saving model ...
Validation loss decreased (0.429556 --> 0.429536).  Saving model ...
Validation loss decreased (0.429536 --> 0.429517).  Saving model ...
Validation loss decreased (0.429517 --> 0.429498).  Saving model ...
Validation loss decreased (0.429498 --> 0.429479).  Saving model ...
Validation loss decreased (0.429479 --> 0.429459).  Saving model ...
Validation loss decreased (0.429459 --> 0.429440).  Saving model ...
Validation loss decreased (0.429440 --> 0.429421).  Saving model ...
Validation loss decreased (0.429421 --> 0.429401).  Saving model ...
Validation loss decreased (0.429401 --> 0.429382).  Saving model ...
Validation loss decreased (0.429382 --> 0.429363).  Saving model ...
Validation loss decreased (0.429363 --> 0.429343).  Saving model ...
Validation loss decreased (0.429343 --> 0.429324).  Saving model ...
Validation loss decreased (0.429324 --> 0.429305).  Saving model ...
Validation loss decreased (0.429305 --> 0.429285).  Saving model ...
Validation loss decreased (0.429285 --> 0.429266).  Saving model ...
Validation loss decreased (0.429266 --> 0.429246).  Saving model ...
Validation loss decreased (0.429246 --> 0.429227).  Saving model ...
Validation loss decreased (0.429227 --> 0.429208).  Saving model ...
Validation loss decreased (0.429208 --> 0.429188).  Saving model ...
Validation loss decreased (0.429188 --> 0.429169).  Saving model ...
Validation loss decreased (0.429169 --> 0.429149).  Saving model ...
Validation loss decreased (0.429149 --> 0.429130).  Saving model ...
Validation loss decreased (0.429130 --> 0.429111).  Saving model ...
Validation loss decreased (0.429111 --> 0.429091).  Saving model ...
Validation loss decreased (0.429091 --> 0.429072).  Saving model ...
Validation loss decreased (0.429072 --> 0.429052).  Saving model ...
Validation loss decreased (0.429052 --> 0.429033).  Saving model ...
Validation loss decreased (0.429033 --> 0.429013).  Saving model ...
Validation loss decreased (0.429013 --> 0.428994).  Saving model ...
Validation loss decreased (0.428994 --> 0.428974).  Saving model ...
Validation loss decreased (0.428974 --> 0.428955).  Saving model ...
Validation loss decreased (0.428955 --> 0.428935).  Saving model ...
Validation loss decreased (0.428935 --> 0.428916).  Saving model ...
Validation loss decreased (0.428916 --> 0.428896).  Saving model ...
Validation loss decreased (0.428896 --> 0.428877).  Saving model ...
Validation loss decreased (0.428877 --> 0.428857).  Saving model ...
Validation loss decreased (0.428857 --> 0.428838).  Saving model ...
Validation loss decreased (0.428838 --> 0.428818).  Saving model ...
Validation loss decreased (0.428818 --> 0.428799).  Saving model ...
Validation loss decreased (0.428799 --> 0.428779).  Saving model ...
Validation loss decreased (0.428779 --> 0.428760).  Saving model ...
Validation loss decreased (0.428760 --> 0.428741).  Saving model ...
Validation loss decreased (0.428741 --> 0.428721).  Saving model ...
Validation loss decreased (0.428721 --> 0.428702).  Saving model ...
Validation loss decreased (0.428702 --> 0.428682).  Saving model ...
Validation loss decreased (0.428682 --> 0.428663).  Saving model ...
Validation loss decreased (0.428663 --> 0.428643).  Saving model ...
Validation loss decreased (0.428643 --> 0.428624).  Saving model ...
Validation loss decreased (0.428624 --> 0.428604).  Saving model ...
Validation loss decreased (0.428604 --> 0.428585).  Saving model ...
Validation loss decreased (0.428585 --> 0.428565).  Saving model ...
Validation loss decreased (0.428565 --> 0.428546).  Saving model ...
Validation loss decreased (0.428546 --> 0.428526).  Saving model ...
Validation loss decreased (0.428526 --> 0.428507).  Saving model ...
Validation loss decreased (0.428507 --> 0.428488).  Saving model ...
Validation loss decreased (0.428488 --> 0.428468).  Saving model ...
Validation loss decreased (0.428468 --> 0.428449).  Saving model ...
Validation loss decreased (0.428449 --> 0.428429).  Saving model ...
Validation loss decreased (0.428429 --> 0.428410).  Saving model ...
Validation loss decreased (0.428410 --> 0.428391).  Saving model ...
Validation loss decreased (0.428391 --> 0.428371).  Saving model ...
Validation loss decreased (0.428371 --> 0.428352).  Saving model ...
Validation loss decreased (0.428352 --> 0.428332).  Saving model ...
Validation loss decreased (0.428332 --> 0.428313).  Saving model ...
Validation loss decreased (0.428313 --> 0.428294).  Saving model ...
Validation loss decreased (0.428294 --> 0.428274).  Saving model ...
Validation loss decreased (0.428274 --> 0.428255).  Saving model ...
Validation loss decreased (0.428255 --> 0.428236).  Saving model ...
Validation loss decreased (0.428236 --> 0.428216).  Saving model ...
Validation loss decreased (0.428216 --> 0.428197).  Saving model ...
Validation loss decreased (0.428197 --> 0.428178).  Saving model ...
Validation loss decreased (0.428178 --> 0.428158).  Saving model ...
Validation loss decreased (0.428158 --> 0.428139).  Saving model ...
Validation loss decreased (0.428139 --> 0.428120).  Saving model ...
Validation loss decreased (0.428120 --> 0.428101).  Saving model ...
Validation loss decreased (0.428101 --> 0.428081).  Saving model ...
Validation loss decreased (0.428081 --> 0.428062).  Saving model ...
Validation loss decreased (0.428062 --> 0.428043).  Saving model ...
Validation loss decreased (0.428043 --> 0.428024).  Saving model ...
Validation loss decreased (0.428024 --> 0.428004).  Saving model ...
Validation loss decreased (0.428004 --> 0.427985).  Saving model ...
Validation loss decreased (0.427985 --> 0.427966).  Saving model ...
Validation loss decreased (0.427966 --> 0.427947).  Saving model ...
Validation loss decreased (0.427947 --> 0.427928).  Saving model ...
Validation loss decreased (0.427928 --> 0.427909).  Saving model ...
Validation loss decreased (0.427909 --> 0.427889).  Saving model ...
Validation loss decreased (0.427889 --> 0.427870).  Saving model ...
Validation loss decreased (0.427870 --> 0.427851).  Saving model ...
epoch 3201, loss 0.4279, train acc 79.79%, f1 0.6895, precision 0.7443, recall 0.6422, auc 0.7619
Validation loss decreased (0.427851 --> 0.427832).  Saving model ...
Validation loss decreased (0.427832 --> 0.427813).  Saving model ...
Validation loss decreased (0.427813 --> 0.427794).  Saving model ...
Validation loss decreased (0.427794 --> 0.427775).  Saving model ...
Validation loss decreased (0.427775 --> 0.427756).  Saving model ...
Validation loss decreased (0.427756 --> 0.427737).  Saving model ...
Validation loss decreased (0.427737 --> 0.427718).  Saving model ...
Validation loss decreased (0.427718 --> 0.427699).  Saving model ...
Validation loss decreased (0.427699 --> 0.427680).  Saving model ...
Validation loss decreased (0.427680 --> 0.427661).  Saving model ...
Validation loss decreased (0.427661 --> 0.427642).  Saving model ...
Validation loss decreased (0.427642 --> 0.427623).  Saving model ...
Validation loss decreased (0.427623 --> 0.427604).  Saving model ...
Validation loss decreased (0.427604 --> 0.427585).  Saving model ...
Validation loss decreased (0.427585 --> 0.427566).  Saving model ...
Validation loss decreased (0.427566 --> 0.427547).  Saving model ...
Validation loss decreased (0.427547 --> 0.427528).  Saving model ...
Validation loss decreased (0.427528 --> 0.427509).  Saving model ...
Validation loss decreased (0.427509 --> 0.427490).  Saving model ...
Validation loss decreased (0.427490 --> 0.427471).  Saving model ...
Validation loss decreased (0.427471 --> 0.427453).  Saving model ...
Validation loss decreased (0.427453 --> 0.427434).  Saving model ...
Validation loss decreased (0.427434 --> 0.427415).  Saving model ...
Validation loss decreased (0.427415 --> 0.427396).  Saving model ...
Validation loss decreased (0.427396 --> 0.427377).  Saving model ...
Validation loss decreased (0.427377 --> 0.427359).  Saving model ...
Validation loss decreased (0.427359 --> 0.427340).  Saving model ...
Validation loss decreased (0.427340 --> 0.427321).  Saving model ...
Validation loss decreased (0.427321 --> 0.427302).  Saving model ...
Validation loss decreased (0.427302 --> 0.427284).  Saving model ...
Validation loss decreased (0.427284 --> 0.427265).  Saving model ...
Validation loss decreased (0.427265 --> 0.427246).  Saving model ...
Validation loss decreased (0.427246 --> 0.427228).  Saving model ...
Validation loss decreased (0.427228 --> 0.427209).  Saving model ...
Validation loss decreased (0.427209 --> 0.427190).  Saving model ...
Validation loss decreased (0.427190 --> 0.427172).  Saving model ...
Validation loss decreased (0.427172 --> 0.427153).  Saving model ...
Validation loss decreased (0.427153 --> 0.427135).  Saving model ...
Validation loss decreased (0.427135 --> 0.427116).  Saving model ...
Validation loss decreased (0.427116 --> 0.427097).  Saving model ...
Validation loss decreased (0.427097 --> 0.427079).  Saving model ...
Validation loss decreased (0.427079 --> 0.427060).  Saving model ...
Validation loss decreased (0.427060 --> 0.427042).  Saving model ...
Validation loss decreased (0.427042 --> 0.427023).  Saving model ...
Validation loss decreased (0.427023 --> 0.427005).  Saving model ...
Validation loss decreased (0.427005 --> 0.426986).  Saving model ...
Validation loss decreased (0.426986 --> 0.426968).  Saving model ...
Validation loss decreased (0.426968 --> 0.426950).  Saving model ...
Validation loss decreased (0.426950 --> 0.426931).  Saving model ...
Validation loss decreased (0.426931 --> 0.426913).  Saving model ...
Validation loss decreased (0.426913 --> 0.426894).  Saving model ...
Validation loss decreased (0.426894 --> 0.426876).  Saving model ...
Validation loss decreased (0.426876 --> 0.426858).  Saving model ...
Validation loss decreased (0.426858 --> 0.426839).  Saving model ...
Validation loss decreased (0.426839 --> 0.426821).  Saving model ...
Validation loss decreased (0.426821 --> 0.426803).  Saving model ...
Validation loss decreased (0.426803 --> 0.426784).  Saving model ...
Validation loss decreased (0.426784 --> 0.426766).  Saving model ...
Validation loss decreased (0.426766 --> 0.426748).  Saving model ...
Validation loss decreased (0.426748 --> 0.426730).  Saving model ...
Validation loss decreased (0.426730 --> 0.426711).  Saving model ...
Validation loss decreased (0.426711 --> 0.426693).  Saving model ...
Validation loss decreased (0.426693 --> 0.426675).  Saving model ...
Validation loss decreased (0.426675 --> 0.426657).  Saving model ...
Validation loss decreased (0.426657 --> 0.426638).  Saving model ...
Validation loss decreased (0.426638 --> 0.426620).  Saving model ...
Validation loss decreased (0.426620 --> 0.426602).  Saving model ...
Validation loss decreased (0.426602 --> 0.426584).  Saving model ...
Validation loss decreased (0.426584 --> 0.426566).  Saving model ...
Validation loss decreased (0.426566 --> 0.426548).  Saving model ...
Validation loss decreased (0.426548 --> 0.426530).  Saving model ...
Validation loss decreased (0.426530 --> 0.426512).  Saving model ...
Validation loss decreased (0.426512 --> 0.426494).  Saving model ...
Validation loss decreased (0.426494 --> 0.426475).  Saving model ...
Validation loss decreased (0.426475 --> 0.426457).  Saving model ...
Validation loss decreased (0.426457 --> 0.426440).  Saving model ...
Validation loss decreased (0.426440 --> 0.426421).  Saving model ...
Validation loss decreased (0.426421 --> 0.426403).  Saving model ...
Validation loss decreased (0.426403 --> 0.426386).  Saving model ...
Validation loss decreased (0.426386 --> 0.426368).  Saving model ...
Validation loss decreased (0.426368 --> 0.426350).  Saving model ...
Validation loss decreased (0.426350 --> 0.426332).  Saving model ...
Validation loss decreased (0.426332 --> 0.426314).  Saving model ...
Validation loss decreased (0.426314 --> 0.426296).  Saving model ...
Validation loss decreased (0.426296 --> 0.426278).  Saving model ...
Validation loss decreased (0.426278 --> 0.426260).  Saving model ...
Validation loss decreased (0.426260 --> 0.426242).  Saving model ...
Validation loss decreased (0.426242 --> 0.426224).  Saving model ...
Validation loss decreased (0.426224 --> 0.426207).  Saving model ...
Validation loss decreased (0.426207 --> 0.426189).  Saving model ...
Validation loss decreased (0.426189 --> 0.426171).  Saving model ...
Validation loss decreased (0.426171 --> 0.426153).  Saving model ...
Validation loss decreased (0.426153 --> 0.426136).  Saving model ...
Validation loss decreased (0.426136 --> 0.426118).  Saving model ...
Validation loss decreased (0.426118 --> 0.426100).  Saving model ...
Validation loss decreased (0.426100 --> 0.426082).  Saving model ...
Validation loss decreased (0.426082 --> 0.426065).  Saving model ...
Validation loss decreased (0.426065 --> 0.426047).  Saving model ...
Validation loss decreased (0.426047 --> 0.426029).  Saving model ...
Validation loss decreased (0.426029 --> 0.426012).  Saving model ...
epoch 3301, loss 0.4260, train acc 79.45%, f1 0.6859, precision 0.7360, recall 0.6422, auc 0.7592
Validation loss decreased (0.426012 --> 0.425994).  Saving model ...
Validation loss decreased (0.425994 --> 0.425976).  Saving model ...
Validation loss decreased (0.425976 --> 0.425959).  Saving model ...
Validation loss decreased (0.425959 --> 0.425941).  Saving model ...
Validation loss decreased (0.425941 --> 0.425923).  Saving model ...
Validation loss decreased (0.425923 --> 0.425906).  Saving model ...
Validation loss decreased (0.425906 --> 0.425888).  Saving model ...
Validation loss decreased (0.425888 --> 0.425871).  Saving model ...
Validation loss decreased (0.425871 --> 0.425853).  Saving model ...
Validation loss decreased (0.425853 --> 0.425836).  Saving model ...
Validation loss decreased (0.425836 --> 0.425818).  Saving model ...
Validation loss decreased (0.425818 --> 0.425801).  Saving model ...
Validation loss decreased (0.425801 --> 0.425783).  Saving model ...
Validation loss decreased (0.425783 --> 0.425766).  Saving model ...
Validation loss decreased (0.425766 --> 0.425748).  Saving model ...
Validation loss decreased (0.425748 --> 0.425731).  Saving model ...
Validation loss decreased (0.425731 --> 0.425713).  Saving model ...
Validation loss decreased (0.425713 --> 0.425696).  Saving model ...
Validation loss decreased (0.425696 --> 0.425678).  Saving model ...
Validation loss decreased (0.425678 --> 0.425661).  Saving model ...
Validation loss decreased (0.425661 --> 0.425644).  Saving model ...
Validation loss decreased (0.425644 --> 0.425626).  Saving model ...
Validation loss decreased (0.425626 --> 0.425609).  Saving model ...
Validation loss decreased (0.425609 --> 0.425591).  Saving model ...
Validation loss decreased (0.425591 --> 0.425574).  Saving model ...
Validation loss decreased (0.425574 --> 0.425557).  Saving model ...
Validation loss decreased (0.425557 --> 0.425540).  Saving model ...
Validation loss decreased (0.425540 --> 0.425522).  Saving model ...
Validation loss decreased (0.425522 --> 0.425505).  Saving model ...
Validation loss decreased (0.425505 --> 0.425488).  Saving model ...
Validation loss decreased (0.425488 --> 0.425470).  Saving model ...
Validation loss decreased (0.425470 --> 0.425453).  Saving model ...
Validation loss decreased (0.425453 --> 0.425436).  Saving model ...
Validation loss decreased (0.425436 --> 0.425419).  Saving model ...
Validation loss decreased (0.425419 --> 0.425401).  Saving model ...
Validation loss decreased (0.425401 --> 0.425384).  Saving model ...
Validation loss decreased (0.425384 --> 0.425367).  Saving model ...
Validation loss decreased (0.425367 --> 0.425350).  Saving model ...
Validation loss decreased (0.425350 --> 0.425333).  Saving model ...
Validation loss decreased (0.425333 --> 0.425315).  Saving model ...
Validation loss decreased (0.425315 --> 0.425298).  Saving model ...
Validation loss decreased (0.425298 --> 0.425281).  Saving model ...
Validation loss decreased (0.425281 --> 0.425264).  Saving model ...
Validation loss decreased (0.425264 --> 0.425247).  Saving model ...
Validation loss decreased (0.425247 --> 0.425230).  Saving model ...
Validation loss decreased (0.425230 --> 0.425213).  Saving model ...
Validation loss decreased (0.425213 --> 0.425195).  Saving model ...
Validation loss decreased (0.425195 --> 0.425178).  Saving model ...
Validation loss decreased (0.425178 --> 0.425161).  Saving model ...
Validation loss decreased (0.425161 --> 0.425144).  Saving model ...
Validation loss decreased (0.425144 --> 0.425127).  Saving model ...
Validation loss decreased (0.425127 --> 0.425110).  Saving model ...
Validation loss decreased (0.425110 --> 0.425093).  Saving model ...
Validation loss decreased (0.425093 --> 0.425076).  Saving model ...
Validation loss decreased (0.425076 --> 0.425059).  Saving model ...
Validation loss decreased (0.425059 --> 0.425042).  Saving model ...
Validation loss decreased (0.425042 --> 0.425025).  Saving model ...
Validation loss decreased (0.425025 --> 0.425008).  Saving model ...
Validation loss decreased (0.425008 --> 0.424991).  Saving model ...
Validation loss decreased (0.424991 --> 0.424974).  Saving model ...
Validation loss decreased (0.424974 --> 0.424957).  Saving model ...
Validation loss decreased (0.424957 --> 0.424940).  Saving model ...
Validation loss decreased (0.424940 --> 0.424923).  Saving model ...
Validation loss decreased (0.424923 --> 0.424906).  Saving model ...
Validation loss decreased (0.424906 --> 0.424889).  Saving model ...
Validation loss decreased (0.424889 --> 0.424872).  Saving model ...
Validation loss decreased (0.424872 --> 0.424855).  Saving model ...
Validation loss decreased (0.424855 --> 0.424838).  Saving model ...
Validation loss decreased (0.424838 --> 0.424821).  Saving model ...
Validation loss decreased (0.424821 --> 0.424805).  Saving model ...
Validation loss decreased (0.424805 --> 0.424788).  Saving model ...
Validation loss decreased (0.424788 --> 0.424771).  Saving model ...
Validation loss decreased (0.424771 --> 0.424754).  Saving model ...
Validation loss decreased (0.424754 --> 0.424737).  Saving model ...
Validation loss decreased (0.424737 --> 0.424720).  Saving model ...
Validation loss decreased (0.424720 --> 0.424703).  Saving model ...
Validation loss decreased (0.424703 --> 0.424686).  Saving model ...
Validation loss decreased (0.424686 --> 0.424670).  Saving model ...
Validation loss decreased (0.424670 --> 0.424653).  Saving model ...
Validation loss decreased (0.424653 --> 0.424636).  Saving model ...
Validation loss decreased (0.424636 --> 0.424619).  Saving model ...
Validation loss decreased (0.424619 --> 0.424602).  Saving model ...
Validation loss decreased (0.424602 --> 0.424585).  Saving model ...
Validation loss decreased (0.424585 --> 0.424569).  Saving model ...
Validation loss decreased (0.424569 --> 0.424552).  Saving model ...
Validation loss decreased (0.424552 --> 0.424535).  Saving model ...
Validation loss decreased (0.424535 --> 0.424518).  Saving model ...
Validation loss decreased (0.424518 --> 0.424501).  Saving model ...
Validation loss decreased (0.424501 --> 0.424485).  Saving model ...
Validation loss decreased (0.424485 --> 0.424468).  Saving model ...
Validation loss decreased (0.424468 --> 0.424451).  Saving model ...
Validation loss decreased (0.424451 --> 0.424434).  Saving model ...
Validation loss decreased (0.424434 --> 0.424418).  Saving model ...
Validation loss decreased (0.424418 --> 0.424401).  Saving model ...
Validation loss decreased (0.424401 --> 0.424384).  Saving model ...
Validation loss decreased (0.424384 --> 0.424367).  Saving model ...
Validation loss decreased (0.424367 --> 0.424351).  Saving model ...
Validation loss decreased (0.424351 --> 0.424334).  Saving model ...
Validation loss decreased (0.424334 --> 0.424317).  Saving model ...
Validation loss decreased (0.424317 --> 0.424300).  Saving model ...
epoch 3401, loss 0.4243, train acc 79.45%, f1 0.6875, precision 0.7333, recall 0.6471, auc 0.7604
Validation loss decreased (0.424300 --> 0.424284).  Saving model ...
Validation loss decreased (0.424284 --> 0.424267).  Saving model ...
Validation loss decreased (0.424267 --> 0.424250).  Saving model ...
Validation loss decreased (0.424250 --> 0.424233).  Saving model ...
Validation loss decreased (0.424233 --> 0.424217).  Saving model ...
Validation loss decreased (0.424217 --> 0.424200).  Saving model ...
Validation loss decreased (0.424200 --> 0.424183).  Saving model ...
Validation loss decreased (0.424183 --> 0.424166).  Saving model ...
Validation loss decreased (0.424166 --> 0.424150).  Saving model ...
Validation loss decreased (0.424150 --> 0.424133).  Saving model ...
Validation loss decreased (0.424133 --> 0.424116).  Saving model ...
Validation loss decreased (0.424116 --> 0.424100).  Saving model ...
Validation loss decreased (0.424100 --> 0.424083).  Saving model ...
Validation loss decreased (0.424083 --> 0.424066).  Saving model ...
Validation loss decreased (0.424066 --> 0.424049).  Saving model ...
Validation loss decreased (0.424049 --> 0.424033).  Saving model ...
Validation loss decreased (0.424033 --> 0.424016).  Saving model ...
Validation loss decreased (0.424016 --> 0.423999).  Saving model ...
Validation loss decreased (0.423999 --> 0.423983).  Saving model ...
Validation loss decreased (0.423983 --> 0.423966).  Saving model ...
Validation loss decreased (0.423966 --> 0.423949).  Saving model ...
Validation loss decreased (0.423949 --> 0.423933).  Saving model ...
Validation loss decreased (0.423933 --> 0.423916).  Saving model ...
Validation loss decreased (0.423916 --> 0.423899).  Saving model ...
Validation loss decreased (0.423899 --> 0.423882).  Saving model ...
Validation loss decreased (0.423882 --> 0.423866).  Saving model ...
Validation loss decreased (0.423866 --> 0.423849).  Saving model ...
Validation loss decreased (0.423849 --> 0.423832).  Saving model ...
Validation loss decreased (0.423832 --> 0.423816).  Saving model ...
Validation loss decreased (0.423816 --> 0.423799).  Saving model ...
Validation loss decreased (0.423799 --> 0.423782).  Saving model ...
Validation loss decreased (0.423782 --> 0.423766).  Saving model ...
Validation loss decreased (0.423766 --> 0.423749).  Saving model ...
Validation loss decreased (0.423749 --> 0.423732).  Saving model ...
Validation loss decreased (0.423732 --> 0.423715).  Saving model ...
Validation loss decreased (0.423715 --> 0.423699).  Saving model ...
Validation loss decreased (0.423699 --> 0.423682).  Saving model ...
Validation loss decreased (0.423682 --> 0.423665).  Saving model ...
Validation loss decreased (0.423665 --> 0.423649).  Saving model ...
Validation loss decreased (0.423649 --> 0.423632).  Saving model ...
Validation loss decreased (0.423632 --> 0.423615).  Saving model ...
Validation loss decreased (0.423615 --> 0.423598).  Saving model ...
Validation loss decreased (0.423598 --> 0.423582).  Saving model ...
Validation loss decreased (0.423582 --> 0.423565).  Saving model ...
Validation loss decreased (0.423565 --> 0.423548).  Saving model ...
Validation loss decreased (0.423548 --> 0.423532).  Saving model ...
Validation loss decreased (0.423532 --> 0.423515).  Saving model ...
Validation loss decreased (0.423515 --> 0.423498).  Saving model ...
Validation loss decreased (0.423498 --> 0.423481).  Saving model ...
Validation loss decreased (0.423481 --> 0.423465).  Saving model ...
Validation loss decreased (0.423465 --> 0.423448).  Saving model ...
Validation loss decreased (0.423448 --> 0.423431).  Saving model ...
Validation loss decreased (0.423431 --> 0.423414).  Saving model ...
Validation loss decreased (0.423414 --> 0.423398).  Saving model ...
Validation loss decreased (0.423398 --> 0.423381).  Saving model ...
Validation loss decreased (0.423381 --> 0.423364).  Saving model ...
Validation loss decreased (0.423364 --> 0.423347).  Saving model ...
Validation loss decreased (0.423347 --> 0.423331).  Saving model ...
Validation loss decreased (0.423331 --> 0.423314).  Saving model ...
Validation loss decreased (0.423314 --> 0.423297).  Saving model ...
Validation loss decreased (0.423297 --> 0.423280).  Saving model ...
Validation loss decreased (0.423280 --> 0.423263).  Saving model ...
Validation loss decreased (0.423263 --> 0.423247).  Saving model ...
Validation loss decreased (0.423247 --> 0.423230).  Saving model ...
Validation loss decreased (0.423230 --> 0.423213).  Saving model ...
Validation loss decreased (0.423213 --> 0.423196).  Saving model ...
Validation loss decreased (0.423196 --> 0.423179).  Saving model ...
Validation loss decreased (0.423179 --> 0.423163).  Saving model ...
Validation loss decreased (0.423163 --> 0.423146).  Saving model ...
Validation loss decreased (0.423146 --> 0.423129).  Saving model ...
Validation loss decreased (0.423129 --> 0.423112).  Saving model ...
Validation loss decreased (0.423112 --> 0.423095).  Saving model ...
Validation loss decreased (0.423095 --> 0.423079).  Saving model ...
Validation loss decreased (0.423079 --> 0.423062).  Saving model ...
Validation loss decreased (0.423062 --> 0.423045).  Saving model ...
Validation loss decreased (0.423045 --> 0.423028).  Saving model ...
Validation loss decreased (0.423028 --> 0.423011).  Saving model ...
Validation loss decreased (0.423011 --> 0.422994).  Saving model ...
Validation loss decreased (0.422994 --> 0.422978).  Saving model ...
Validation loss decreased (0.422978 --> 0.422961).  Saving model ...
Validation loss decreased (0.422961 --> 0.422944).  Saving model ...
Validation loss decreased (0.422944 --> 0.422927).  Saving model ...
Validation loss decreased (0.422927 --> 0.422910).  Saving model ...
Validation loss decreased (0.422910 --> 0.422893).  Saving model ...
Validation loss decreased (0.422893 --> 0.422876).  Saving model ...
Validation loss decreased (0.422876 --> 0.422860).  Saving model ...
Validation loss decreased (0.422860 --> 0.422843).  Saving model ...
Validation loss decreased (0.422843 --> 0.422826).  Saving model ...
Validation loss decreased (0.422826 --> 0.422809).  Saving model ...
Validation loss decreased (0.422809 --> 0.422792).  Saving model ...
Validation loss decreased (0.422792 --> 0.422775).  Saving model ...
Validation loss decreased (0.422775 --> 0.422758).  Saving model ...
Validation loss decreased (0.422758 --> 0.422741).  Saving model ...
Validation loss decreased (0.422741 --> 0.422724).  Saving model ...
Validation loss decreased (0.422724 --> 0.422708).  Saving model ...
Validation loss decreased (0.422708 --> 0.422691).  Saving model ...
Validation loss decreased (0.422691 --> 0.422674).  Saving model ...
Validation loss decreased (0.422674 --> 0.422657).  Saving model ...
Validation loss decreased (0.422657 --> 0.422640).  Saving model ...
Validation loss decreased (0.422640 --> 0.422623).  Saving model ...
epoch 3501, loss 0.4226, train acc 79.79%, f1 0.6943, precision 0.7363, recall 0.6569, auc 0.7653
Validation loss decreased (0.422623 --> 0.422606).  Saving model ...
Validation loss decreased (0.422606 --> 0.422589).  Saving model ...
Validation loss decreased (0.422589 --> 0.422572).  Saving model ...
Validation loss decreased (0.422572 --> 0.422555).  Saving model ...
Validation loss decreased (0.422555 --> 0.422538).  Saving model ...
Validation loss decreased (0.422538 --> 0.422522).  Saving model ...
Validation loss decreased (0.422522 --> 0.422505).  Saving model ...
Validation loss decreased (0.422505 --> 0.422488).  Saving model ...
Validation loss decreased (0.422488 --> 0.422471).  Saving model ...
Validation loss decreased (0.422471 --> 0.422454).  Saving model ...
Validation loss decreased (0.422454 --> 0.422437).  Saving model ...
Validation loss decreased (0.422437 --> 0.422420).  Saving model ...
Validation loss decreased (0.422420 --> 0.422403).  Saving model ...
Validation loss decreased (0.422403 --> 0.422386).  Saving model ...
Validation loss decreased (0.422386 --> 0.422369).  Saving model ...
Validation loss decreased (0.422369 --> 0.422352).  Saving model ...
Validation loss decreased (0.422352 --> 0.422335).  Saving model ...
Validation loss decreased (0.422335 --> 0.422318).  Saving model ...
Validation loss decreased (0.422318 --> 0.422301).  Saving model ...
Validation loss decreased (0.422301 --> 0.422284).  Saving model ...
Validation loss decreased (0.422284 --> 0.422268).  Saving model ...
Validation loss decreased (0.422268 --> 0.422251).  Saving model ...
Validation loss decreased (0.422251 --> 0.422234).  Saving model ...
Validation loss decreased (0.422234 --> 0.422217).  Saving model ...
Validation loss decreased (0.422217 --> 0.422200).  Saving model ...
Validation loss decreased (0.422200 --> 0.422183).  Saving model ...
Validation loss decreased (0.422183 --> 0.422166).  Saving model ...
Validation loss decreased (0.422166 --> 0.422149).  Saving model ...
Validation loss decreased (0.422149 --> 0.422132).  Saving model ...
Validation loss decreased (0.422132 --> 0.422115).  Saving model ...
Validation loss decreased (0.422115 --> 0.422098).  Saving model ...
Validation loss decreased (0.422098 --> 0.422081).  Saving model ...
Validation loss decreased (0.422081 --> 0.422064).  Saving model ...
Validation loss decreased (0.422064 --> 0.422047).  Saving model ...
Validation loss decreased (0.422047 --> 0.422030).  Saving model ...
Validation loss decreased (0.422030 --> 0.422013).  Saving model ...
Validation loss decreased (0.422013 --> 0.421996).  Saving model ...
Validation loss decreased (0.421996 --> 0.421979).  Saving model ...
Validation loss decreased (0.421979 --> 0.421962).  Saving model ...
Validation loss decreased (0.421962 --> 0.421946).  Saving model ...
Validation loss decreased (0.421946 --> 0.421929).  Saving model ...
Validation loss decreased (0.421929 --> 0.421912).  Saving model ...
Validation loss decreased (0.421912 --> 0.421895).  Saving model ...
Validation loss decreased (0.421895 --> 0.421878).  Saving model ...
Validation loss decreased (0.421878 --> 0.421861).  Saving model ...
Validation loss decreased (0.421861 --> 0.421844).  Saving model ...
Validation loss decreased (0.421844 --> 0.421827).  Saving model ...
Validation loss decreased (0.421827 --> 0.421810).  Saving model ...
Validation loss decreased (0.421810 --> 0.421793).  Saving model ...
Validation loss decreased (0.421793 --> 0.421776).  Saving model ...
Validation loss decreased (0.421776 --> 0.421759).  Saving model ...
Validation loss decreased (0.421759 --> 0.421742).  Saving model ...
Validation loss decreased (0.421742 --> 0.421725).  Saving model ...
Validation loss decreased (0.421725 --> 0.421708).  Saving model ...
Validation loss decreased (0.421708 --> 0.421691).  Saving model ...
Validation loss decreased (0.421691 --> 0.421674).  Saving model ...
Validation loss decreased (0.421674 --> 0.421657).  Saving model ...
Validation loss decreased (0.421657 --> 0.421640).  Saving model ...
Validation loss decreased (0.421640 --> 0.421623).  Saving model ...
Validation loss decreased (0.421623 --> 0.421606).  Saving model ...
Validation loss decreased (0.421606 --> 0.421589).  Saving model ...
Validation loss decreased (0.421589 --> 0.421572).  Saving model ...
Validation loss decreased (0.421572 --> 0.421556).  Saving model ...
Validation loss decreased (0.421556 --> 0.421539).  Saving model ...
Validation loss decreased (0.421539 --> 0.421522).  Saving model ...
Validation loss decreased (0.421522 --> 0.421505).  Saving model ...
Validation loss decreased (0.421505 --> 0.421488).  Saving model ...
Validation loss decreased (0.421488 --> 0.421471).  Saving model ...
Validation loss decreased (0.421471 --> 0.421454).  Saving model ...
Validation loss decreased (0.421454 --> 0.421437).  Saving model ...
Validation loss decreased (0.421437 --> 0.421420).  Saving model ...
Validation loss decreased (0.421420 --> 0.421403).  Saving model ...
Validation loss decreased (0.421403 --> 0.421386).  Saving model ...
Validation loss decreased (0.421386 --> 0.421369).  Saving model ...
Validation loss decreased (0.421369 --> 0.421352).  Saving model ...
Validation loss decreased (0.421352 --> 0.421335).  Saving model ...
Validation loss decreased (0.421335 --> 0.421318).  Saving model ...
Validation loss decreased (0.421318 --> 0.421301).  Saving model ...
Validation loss decreased (0.421301 --> 0.421284).  Saving model ...
Validation loss decreased (0.421284 --> 0.421267).  Saving model ...
Validation loss decreased (0.421267 --> 0.421250).  Saving model ...
Validation loss decreased (0.421250 --> 0.421233).  Saving model ...
Validation loss decreased (0.421233 --> 0.421217).  Saving model ...
Validation loss decreased (0.421217 --> 0.421200).  Saving model ...
Validation loss decreased (0.421200 --> 0.421183).  Saving model ...
Validation loss decreased (0.421183 --> 0.421166).  Saving model ...
Validation loss decreased (0.421166 --> 0.421149).  Saving model ...
Validation loss decreased (0.421149 --> 0.421132).  Saving model ...
Validation loss decreased (0.421132 --> 0.421115).  Saving model ...
Validation loss decreased (0.421115 --> 0.421098).  Saving model ...
Validation loss decreased (0.421098 --> 0.421081).  Saving model ...
Validation loss decreased (0.421081 --> 0.421064).  Saving model ...
Validation loss decreased (0.421064 --> 0.421047).  Saving model ...
Validation loss decreased (0.421047 --> 0.421030).  Saving model ...
Validation loss decreased (0.421030 --> 0.421013).  Saving model ...
Validation loss decreased (0.421013 --> 0.420996).  Saving model ...
Validation loss decreased (0.420996 --> 0.420979).  Saving model ...
Validation loss decreased (0.420979 --> 0.420962).  Saving model ...
Validation loss decreased (0.420962 --> 0.420945).  Saving model ...
Validation loss decreased (0.420945 --> 0.420928).  Saving model ...
epoch 3601, loss 0.4209, train acc 79.62%, f1 0.6909, precision 0.7348, recall 0.6520, auc 0.7628
Validation loss decreased (0.420928 --> 0.420912).  Saving model ...
Validation loss decreased (0.420912 --> 0.420895).  Saving model ...
Validation loss decreased (0.420895 --> 0.420878).  Saving model ...
Validation loss decreased (0.420878 --> 0.420861).  Saving model ...
Validation loss decreased (0.420861 --> 0.420844).  Saving model ...
Validation loss decreased (0.420844 --> 0.420827).  Saving model ...
Validation loss decreased (0.420827 --> 0.420810).  Saving model ...
Validation loss decreased (0.420810 --> 0.420793).  Saving model ...
Validation loss decreased (0.420793 --> 0.420776).  Saving model ...
Validation loss decreased (0.420776 --> 0.420759).  Saving model ...
Validation loss decreased (0.420759 --> 0.420742).  Saving model ...
Validation loss decreased (0.420742 --> 0.420725).  Saving model ...
Validation loss decreased (0.420725 --> 0.420708).  Saving model ...
Validation loss decreased (0.420708 --> 0.420691).  Saving model ...
Validation loss decreased (0.420691 --> 0.420674).  Saving model ...
Validation loss decreased (0.420674 --> 0.420657).  Saving model ...
Validation loss decreased (0.420657 --> 0.420641).  Saving model ...
Validation loss decreased (0.420641 --> 0.420624).  Saving model ...
Validation loss decreased (0.420624 --> 0.420607).  Saving model ...
Validation loss decreased (0.420607 --> 0.420590).  Saving model ...
Validation loss decreased (0.420590 --> 0.420573).  Saving model ...
Validation loss decreased (0.420573 --> 0.420556).  Saving model ...
Validation loss decreased (0.420556 --> 0.420539).  Saving model ...
Validation loss decreased (0.420539 --> 0.420522).  Saving model ...
Validation loss decreased (0.420522 --> 0.420505).  Saving model ...
Validation loss decreased (0.420505 --> 0.420488).  Saving model ...
Validation loss decreased (0.420488 --> 0.420471).  Saving model ...
Validation loss decreased (0.420471 --> 0.420454).  Saving model ...
Validation loss decreased (0.420454 --> 0.420437).  Saving model ...
Validation loss decreased (0.420437 --> 0.420421).  Saving model ...
Validation loss decreased (0.420421 --> 0.420404).  Saving model ...
Validation loss decreased (0.420404 --> 0.420387).  Saving model ...
Validation loss decreased (0.420387 --> 0.420370).  Saving model ...
Validation loss decreased (0.420370 --> 0.420353).  Saving model ...
Validation loss decreased (0.420353 --> 0.420336).  Saving model ...
Validation loss decreased (0.420336 --> 0.420319).  Saving model ...
Validation loss decreased (0.420319 --> 0.420302).  Saving model ...
Validation loss decreased (0.420302 --> 0.420285).  Saving model ...
Validation loss decreased (0.420285 --> 0.420268).  Saving model ...
Validation loss decreased (0.420268 --> 0.420252).  Saving model ...
Validation loss decreased (0.420252 --> 0.420235).  Saving model ...
Validation loss decreased (0.420235 --> 0.420218).  Saving model ...
Validation loss decreased (0.420218 --> 0.420201).  Saving model ...
Validation loss decreased (0.420201 --> 0.420184).  Saving model ...
Validation loss decreased (0.420184 --> 0.420167).  Saving model ...
Validation loss decreased (0.420167 --> 0.420150).  Saving model ...
Validation loss decreased (0.420150 --> 0.420133).  Saving model ...
Validation loss decreased (0.420133 --> 0.420116).  Saving model ...
Validation loss decreased (0.420116 --> 0.420099).  Saving model ...
Validation loss decreased (0.420099 --> 0.420083).  Saving model ...
Validation loss decreased (0.420083 --> 0.420066).  Saving model ...
Validation loss decreased (0.420066 --> 0.420049).  Saving model ...
Validation loss decreased (0.420049 --> 0.420032).  Saving model ...
Validation loss decreased (0.420032 --> 0.420015).  Saving model ...
Validation loss decreased (0.420015 --> 0.419998).  Saving model ...
Validation loss decreased (0.419998 --> 0.419981).  Saving model ...
Validation loss decreased (0.419981 --> 0.419964).  Saving model ...
Validation loss decreased (0.419964 --> 0.419948).  Saving model ...
Validation loss decreased (0.419948 --> 0.419931).  Saving model ...
Validation loss decreased (0.419931 --> 0.419914).  Saving model ...
Validation loss decreased (0.419914 --> 0.419897).  Saving model ...
Validation loss decreased (0.419897 --> 0.419880).  Saving model ...
Validation loss decreased (0.419880 --> 0.419863).  Saving model ...
Validation loss decreased (0.419863 --> 0.419846).  Saving model ...
Validation loss decreased (0.419846 --> 0.419829).  Saving model ...
Validation loss decreased (0.419829 --> 0.419813).  Saving model ...
Validation loss decreased (0.419813 --> 0.419796).  Saving model ...
Validation loss decreased (0.419796 --> 0.419779).  Saving model ...
Validation loss decreased (0.419779 --> 0.419762).  Saving model ...
Validation loss decreased (0.419762 --> 0.419745).  Saving model ...
Validation loss decreased (0.419745 --> 0.419728).  Saving model ...
Validation loss decreased (0.419728 --> 0.419711).  Saving model ...
Validation loss decreased (0.419711 --> 0.419695).  Saving model ...
Validation loss decreased (0.419695 --> 0.419678).  Saving model ...
Validation loss decreased (0.419678 --> 0.419661).  Saving model ...
Validation loss decreased (0.419661 --> 0.419644).  Saving model ...
Validation loss decreased (0.419644 --> 0.419627).  Saving model ...
Validation loss decreased (0.419627 --> 0.419610).  Saving model ...
Validation loss decreased (0.419610 --> 0.419593).  Saving model ...
Validation loss decreased (0.419593 --> 0.419577).  Saving model ...
Validation loss decreased (0.419577 --> 0.419560).  Saving model ...
Validation loss decreased (0.419560 --> 0.419543).  Saving model ...
Validation loss decreased (0.419543 --> 0.419526).  Saving model ...
Validation loss decreased (0.419526 --> 0.419509).  Saving model ...
Validation loss decreased (0.419509 --> 0.419493).  Saving model ...
Validation loss decreased (0.419493 --> 0.419476).  Saving model ...
Validation loss decreased (0.419476 --> 0.419459).  Saving model ...
Validation loss decreased (0.419459 --> 0.419442).  Saving model ...
Validation loss decreased (0.419442 --> 0.419425).  Saving model ...
Validation loss decreased (0.419425 --> 0.419408).  Saving model ...
Validation loss decreased (0.419408 --> 0.419392).  Saving model ...
Validation loss decreased (0.419392 --> 0.419375).  Saving model ...
Validation loss decreased (0.419375 --> 0.419358).  Saving model ...
Validation loss decreased (0.419358 --> 0.419341).  Saving model ...
Validation loss decreased (0.419341 --> 0.419324).  Saving model ...
Validation loss decreased (0.419324 --> 0.419308).  Saving model ...
Validation loss decreased (0.419308 --> 0.419291).  Saving model ...
Validation loss decreased (0.419291 --> 0.419274).  Saving model ...
Validation loss decreased (0.419274 --> 0.419257).  Saving model ...
Validation loss decreased (0.419257 --> 0.419240).  Saving model ...
epoch 3701, loss 0.4192, train acc 79.79%, f1 0.6927, precision 0.7389, recall 0.6520, auc 0.7641
Validation loss decreased (0.419240 --> 0.419224).  Saving model ...
Validation loss decreased (0.419224 --> 0.419207).  Saving model ...
Validation loss decreased (0.419207 --> 0.419190).  Saving model ...
Validation loss decreased (0.419190 --> 0.419173).  Saving model ...
Validation loss decreased (0.419173 --> 0.419157).  Saving model ...
Validation loss decreased (0.419157 --> 0.419140).  Saving model ...
Validation loss decreased (0.419140 --> 0.419123).  Saving model ...
Validation loss decreased (0.419123 --> 0.419106).  Saving model ...
Validation loss decreased (0.419106 --> 0.419089).  Saving model ...
Validation loss decreased (0.419089 --> 0.419073).  Saving model ...
Validation loss decreased (0.419073 --> 0.419056).  Saving model ...
Validation loss decreased (0.419056 --> 0.419039).  Saving model ...
Validation loss decreased (0.419039 --> 0.419023).  Saving model ...
Validation loss decreased (0.419023 --> 0.419006).  Saving model ...
Validation loss decreased (0.419006 --> 0.418989).  Saving model ...
Validation loss decreased (0.418989 --> 0.418972).  Saving model ...
Validation loss decreased (0.418972 --> 0.418956).  Saving model ...
Validation loss decreased (0.418956 --> 0.418939).  Saving model ...
Validation loss decreased (0.418939 --> 0.418922).  Saving model ...
Validation loss decreased (0.418922 --> 0.418905).  Saving model ...
Validation loss decreased (0.418905 --> 0.418889).  Saving model ...
Validation loss decreased (0.418889 --> 0.418872).  Saving model ...
Validation loss decreased (0.418872 --> 0.418855).  Saving model ...
Validation loss decreased (0.418855 --> 0.418838).  Saving model ...
Validation loss decreased (0.418838 --> 0.418822).  Saving model ...
Validation loss decreased (0.418822 --> 0.418805).  Saving model ...
Validation loss decreased (0.418805 --> 0.418788).  Saving model ...
Validation loss decreased (0.418788 --> 0.418772).  Saving model ...
Validation loss decreased (0.418772 --> 0.418755).  Saving model ...
Validation loss decreased (0.418755 --> 0.418738).  Saving model ...
Validation loss decreased (0.418738 --> 0.418722).  Saving model ...
Validation loss decreased (0.418722 --> 0.418705).  Saving model ...
Validation loss decreased (0.418705 --> 0.418688).  Saving model ...
Validation loss decreased (0.418688 --> 0.418671).  Saving model ...
Validation loss decreased (0.418671 --> 0.418655).  Saving model ...
Validation loss decreased (0.418655 --> 0.418638).  Saving model ...
Validation loss decreased (0.418638 --> 0.418621).  Saving model ...
Validation loss decreased (0.418621 --> 0.418605).  Saving model ...
Validation loss decreased (0.418605 --> 0.418588).  Saving model ...
Validation loss decreased (0.418588 --> 0.418571).  Saving model ...
Validation loss decreased (0.418571 --> 0.418555).  Saving model ...
Validation loss decreased (0.418555 --> 0.418538).  Saving model ...
Validation loss decreased (0.418538 --> 0.418521).  Saving model ...
Validation loss decreased (0.418521 --> 0.418505).  Saving model ...
Validation loss decreased (0.418505 --> 0.418488).  Saving model ...
Validation loss decreased (0.418488 --> 0.418472).  Saving model ...
Validation loss decreased (0.418472 --> 0.418455).  Saving model ...
Validation loss decreased (0.418455 --> 0.418438).  Saving model ...
Validation loss decreased (0.418438 --> 0.418422).  Saving model ...
Validation loss decreased (0.418422 --> 0.418405).  Saving model ...
Validation loss decreased (0.418405 --> 0.418388).  Saving model ...
Validation loss decreased (0.418388 --> 0.418372).  Saving model ...
Validation loss decreased (0.418372 --> 0.418355).  Saving model ...
Validation loss decreased (0.418355 --> 0.418339).  Saving model ...
Validation loss decreased (0.418339 --> 0.418322).  Saving model ...
Validation loss decreased (0.418322 --> 0.418305).  Saving model ...
Validation loss decreased (0.418305 --> 0.418289).  Saving model ...
Validation loss decreased (0.418289 --> 0.418272).  Saving model ...
Validation loss decreased (0.418272 --> 0.418256).  Saving model ...
Validation loss decreased (0.418256 --> 0.418239).  Saving model ...
Validation loss decreased (0.418239 --> 0.418222).  Saving model ...
Validation loss decreased (0.418222 --> 0.418206).  Saving model ...
Validation loss decreased (0.418206 --> 0.418189).  Saving model ...
Validation loss decreased (0.418189 --> 0.418173).  Saving model ...
Validation loss decreased (0.418173 --> 0.418156).  Saving model ...
Validation loss decreased (0.418156 --> 0.418139).  Saving model ...
Validation loss decreased (0.418139 --> 0.418123).  Saving model ...
Validation loss decreased (0.418123 --> 0.418106).  Saving model ...
Validation loss decreased (0.418106 --> 0.418090).  Saving model ...
Validation loss decreased (0.418090 --> 0.418073).  Saving model ...
Validation loss decreased (0.418073 --> 0.418057).  Saving model ...
Validation loss decreased (0.418057 --> 0.418040).  Saving model ...
Validation loss decreased (0.418040 --> 0.418024).  Saving model ...
Validation loss decreased (0.418024 --> 0.418007).  Saving model ...
Validation loss decreased (0.418007 --> 0.417991).  Saving model ...
Validation loss decreased (0.417991 --> 0.417974).  Saving model ...
Validation loss decreased (0.417974 --> 0.417958).  Saving model ...
Validation loss decreased (0.417958 --> 0.417941).  Saving model ...
Validation loss decreased (0.417941 --> 0.417924).  Saving model ...
Validation loss decreased (0.417924 --> 0.417908).  Saving model ...
Validation loss decreased (0.417908 --> 0.417892).  Saving model ...
Validation loss decreased (0.417892 --> 0.417875).  Saving model ...
Validation loss decreased (0.417875 --> 0.417859).  Saving model ...
Validation loss decreased (0.417859 --> 0.417842).  Saving model ...
Validation loss decreased (0.417842 --> 0.417826).  Saving model ...
Validation loss decreased (0.417826 --> 0.417809).  Saving model ...
Validation loss decreased (0.417809 --> 0.417793).  Saving model ...
Validation loss decreased (0.417793 --> 0.417776).  Saving model ...
Validation loss decreased (0.417776 --> 0.417760).  Saving model ...
Validation loss decreased (0.417760 --> 0.417743).  Saving model ...
Validation loss decreased (0.417743 --> 0.417727).  Saving model ...
Validation loss decreased (0.417727 --> 0.417710).  Saving model ...
Validation loss decreased (0.417710 --> 0.417694).  Saving model ...
Validation loss decreased (0.417694 --> 0.417677).  Saving model ...
Validation loss decreased (0.417677 --> 0.417661).  Saving model ...
Validation loss decreased (0.417661 --> 0.417644).  Saving model ...
Validation loss decreased (0.417644 --> 0.417628).  Saving model ...
Validation loss decreased (0.417628 --> 0.417612).  Saving model ...
Validation loss decreased (0.417612 --> 0.417595).  Saving model ...
Validation loss decreased (0.417595 --> 0.417579).  Saving model ...
epoch 3801, loss 0.4176, train acc 79.79%, f1 0.6927, precision 0.7389, recall 0.6520, auc 0.7641
Validation loss decreased (0.417579 --> 0.417562).  Saving model ...
Validation loss decreased (0.417562 --> 0.417546).  Saving model ...
Validation loss decreased (0.417546 --> 0.417529).  Saving model ...
Validation loss decreased (0.417529 --> 0.417513).  Saving model ...
Validation loss decreased (0.417513 --> 0.417497).  Saving model ...
Validation loss decreased (0.417497 --> 0.417480).  Saving model ...
Validation loss decreased (0.417480 --> 0.417464).  Saving model ...
Validation loss decreased (0.417464 --> 0.417448).  Saving model ...
Validation loss decreased (0.417448 --> 0.417431).  Saving model ...
Validation loss decreased (0.417431 --> 0.417415).  Saving model ...
Validation loss decreased (0.417415 --> 0.417398).  Saving model ...
Validation loss decreased (0.417398 --> 0.417382).  Saving model ...
Validation loss decreased (0.417382 --> 0.417366).  Saving model ...
Validation loss decreased (0.417366 --> 0.417349).  Saving model ...
Validation loss decreased (0.417349 --> 0.417333).  Saving model ...
Validation loss decreased (0.417333 --> 0.417317).  Saving model ...
Validation loss decreased (0.417317 --> 0.417300).  Saving model ...
Validation loss decreased (0.417300 --> 0.417284).  Saving model ...
Validation loss decreased (0.417284 --> 0.417267).  Saving model ...
Validation loss decreased (0.417267 --> 0.417251).  Saving model ...
Validation loss decreased (0.417251 --> 0.417235).  Saving model ...
Validation loss decreased (0.417235 --> 0.417219).  Saving model ...
Validation loss decreased (0.417219 --> 0.417202).  Saving model ...
Validation loss decreased (0.417202 --> 0.417186).  Saving model ...
Validation loss decreased (0.417186 --> 0.417170).  Saving model ...
Validation loss decreased (0.417170 --> 0.417153).  Saving model ...
Validation loss decreased (0.417153 --> 0.417137).  Saving model ...
Validation loss decreased (0.417137 --> 0.417121).  Saving model ...
Validation loss decreased (0.417121 --> 0.417104).  Saving model ...
Validation loss decreased (0.417104 --> 0.417088).  Saving model ...
Validation loss decreased (0.417088 --> 0.417072).  Saving model ...
Validation loss decreased (0.417072 --> 0.417055).  Saving model ...
Validation loss decreased (0.417055 --> 0.417039).  Saving model ...
Validation loss decreased (0.417039 --> 0.417023).  Saving model ...
Validation loss decreased (0.417023 --> 0.417007).  Saving model ...
Validation loss decreased (0.417007 --> 0.416990).  Saving model ...
Validation loss decreased (0.416990 --> 0.416974).  Saving model ...
Validation loss decreased (0.416974 --> 0.416958).  Saving model ...
Validation loss decreased (0.416958 --> 0.416942).  Saving model ...
Validation loss decreased (0.416942 --> 0.416925).  Saving model ...
Validation loss decreased (0.416925 --> 0.416909).  Saving model ...
Validation loss decreased (0.416909 --> 0.416893).  Saving model ...
Validation loss decreased (0.416893 --> 0.416877).  Saving model ...
Validation loss decreased (0.416877 --> 0.416860).  Saving model ...
Validation loss decreased (0.416860 --> 0.416844).  Saving model ...
Validation loss decreased (0.416844 --> 0.416828).  Saving model ...
Validation loss decreased (0.416828 --> 0.416812).  Saving model ...
Validation loss decreased (0.416812 --> 0.416795).  Saving model ...
Validation loss decreased (0.416795 --> 0.416779).  Saving model ...
Validation loss decreased (0.416779 --> 0.416763).  Saving model ...
Validation loss decreased (0.416763 --> 0.416747).  Saving model ...
Validation loss decreased (0.416747 --> 0.416731).  Saving model ...
Validation loss decreased (0.416731 --> 0.416714).  Saving model ...
Validation loss decreased (0.416714 --> 0.416698).  Saving model ...
Validation loss decreased (0.416698 --> 0.416682).  Saving model ...
Validation loss decreased (0.416682 --> 0.416666).  Saving model ...
Validation loss decreased (0.416666 --> 0.416650).  Saving model ...
Validation loss decreased (0.416650 --> 0.416634).  Saving model ...
Validation loss decreased (0.416634 --> 0.416617).  Saving model ...
Validation loss decreased (0.416617 --> 0.416601).  Saving model ...
Validation loss decreased (0.416601 --> 0.416585).  Saving model ...
Validation loss decreased (0.416585 --> 0.416569).  Saving model ...
Validation loss decreased (0.416569 --> 0.416553).  Saving model ...
Validation loss decreased (0.416553 --> 0.416537).  Saving model ...
Validation loss decreased (0.416537 --> 0.416521).  Saving model ...
Validation loss decreased (0.416521 --> 0.416504).  Saving model ...
Validation loss decreased (0.416504 --> 0.416488).  Saving model ...
Validation loss decreased (0.416488 --> 0.416472).  Saving model ...
Validation loss decreased (0.416472 --> 0.416456).  Saving model ...
Validation loss decreased (0.416456 --> 0.416440).  Saving model ...
Validation loss decreased (0.416440 --> 0.416424).  Saving model ...
Validation loss decreased (0.416424 --> 0.416408).  Saving model ...
Validation loss decreased (0.416408 --> 0.416391).  Saving model ...
Validation loss decreased (0.416391 --> 0.416375).  Saving model ...
Validation loss decreased (0.416375 --> 0.416359).  Saving model ...
Validation loss decreased (0.416359 --> 0.416343).  Saving model ...
Validation loss decreased (0.416343 --> 0.416327).  Saving model ...
Validation loss decreased (0.416327 --> 0.416311).  Saving model ...
Validation loss decreased (0.416311 --> 0.416295).  Saving model ...
Validation loss decreased (0.416295 --> 0.416279).  Saving model ...
Validation loss decreased (0.416279 --> 0.416263).  Saving model ...
Validation loss decreased (0.416263 --> 0.416247).  Saving model ...
Validation loss decreased (0.416247 --> 0.416231).  Saving model ...
Validation loss decreased (0.416231 --> 0.416215).  Saving model ...
Validation loss decreased (0.416215 --> 0.416198).  Saving model ...
Validation loss decreased (0.416198 --> 0.416182).  Saving model ...
Validation loss decreased (0.416182 --> 0.416166).  Saving model ...
Validation loss decreased (0.416166 --> 0.416150).  Saving model ...
Validation loss decreased (0.416150 --> 0.416134).  Saving model ...
Validation loss decreased (0.416134 --> 0.416118).  Saving model ...
Validation loss decreased (0.416118 --> 0.416102).  Saving model ...
Validation loss decreased (0.416102 --> 0.416086).  Saving model ...
Validation loss decreased (0.416086 --> 0.416070).  Saving model ...
Validation loss decreased (0.416070 --> 0.416054).  Saving model ...
Validation loss decreased (0.416054 --> 0.416038).  Saving model ...
Validation loss decreased (0.416038 --> 0.416022).  Saving model ...
Validation loss decreased (0.416022 --> 0.416006).  Saving model ...
Validation loss decreased (0.416006 --> 0.415990).  Saving model ...
Validation loss decreased (0.415990 --> 0.415974).  Saving model ...
Validation loss decreased (0.415974 --> 0.415958).  Saving model ...
epoch 3901, loss 0.4160, train acc 79.97%, f1 0.6945, precision 0.7430, recall 0.6520, auc 0.7655
Validation loss decreased (0.415958 --> 0.415942).  Saving model ...
Validation loss decreased (0.415942 --> 0.415926).  Saving model ...
Validation loss decreased (0.415926 --> 0.415910).  Saving model ...
Validation loss decreased (0.415910 --> 0.415894).  Saving model ...
Validation loss decreased (0.415894 --> 0.415878).  Saving model ...
Validation loss decreased (0.415878 --> 0.415862).  Saving model ...
Validation loss decreased (0.415862 --> 0.415846).  Saving model ...
Validation loss decreased (0.415846 --> 0.415830).  Saving model ...
Validation loss decreased (0.415830 --> 0.415814).  Saving model ...
Validation loss decreased (0.415814 --> 0.415798).  Saving model ...
Validation loss decreased (0.415798 --> 0.415782).  Saving model ...
Validation loss decreased (0.415782 --> 0.415766).  Saving model ...
Validation loss decreased (0.415766 --> 0.415750).  Saving model ...
Validation loss decreased (0.415750 --> 0.415734).  Saving model ...
Validation loss decreased (0.415734 --> 0.415718).  Saving model ...
Validation loss decreased (0.415718 --> 0.415702).  Saving model ...
Validation loss decreased (0.415702 --> 0.415686).  Saving model ...
Validation loss decreased (0.415686 --> 0.415670).  Saving model ...
Validation loss decreased (0.415670 --> 0.415654).  Saving model ...
Validation loss decreased (0.415654 --> 0.415638).  Saving model ...
Validation loss decreased (0.415638 --> 0.415623).  Saving model ...
Validation loss decreased (0.415623 --> 0.415607).  Saving model ...
Validation loss decreased (0.415607 --> 0.415591).  Saving model ...
Validation loss decreased (0.415591 --> 0.415575).  Saving model ...
Validation loss decreased (0.415575 --> 0.415559).  Saving model ...
Validation loss decreased (0.415559 --> 0.415543).  Saving model ...
Validation loss decreased (0.415543 --> 0.415527).  Saving model ...
Validation loss decreased (0.415527 --> 0.415511).  Saving model ...
Validation loss decreased (0.415511 --> 0.415495).  Saving model ...
Validation loss decreased (0.415495 --> 0.415479).  Saving model ...
Validation loss decreased (0.415479 --> 0.415463).  Saving model ...
Validation loss decreased (0.415463 --> 0.415447).  Saving model ...
Validation loss decreased (0.415447 --> 0.415431).  Saving model ...
Validation loss decreased (0.415431 --> 0.415415).  Saving model ...
Validation loss decreased (0.415415 --> 0.415400).  Saving model ...
Validation loss decreased (0.415400 --> 0.415384).  Saving model ...
Validation loss decreased (0.415384 --> 0.415368).  Saving model ...
Validation loss decreased (0.415368 --> 0.415352).  Saving model ...
Validation loss decreased (0.415352 --> 0.415336).  Saving model ...
Validation loss decreased (0.415336 --> 0.415320).  Saving model ...
Validation loss decreased (0.415320 --> 0.415304).  Saving model ...
Validation loss decreased (0.415304 --> 0.415288).  Saving model ...
Validation loss decreased (0.415288 --> 0.415272).  Saving model ...
Validation loss decreased (0.415272 --> 0.415256).  Saving model ...
Validation loss decreased (0.415256 --> 0.415241).  Saving model ...
Validation loss decreased (0.415241 --> 0.415225).  Saving model ...
Validation loss decreased (0.415225 --> 0.415209).  Saving model ...
Validation loss decreased (0.415209 --> 0.415193).  Saving model ...
Validation loss decreased (0.415193 --> 0.415177).  Saving model ...
Validation loss decreased (0.415177 --> 0.415161).  Saving model ...
Validation loss decreased (0.415161 --> 0.415145).  Saving model ...
Validation loss decreased (0.415145 --> 0.415129).  Saving model ...
Validation loss decreased (0.415129 --> 0.415113).  Saving model ...
Validation loss decreased (0.415113 --> 0.415098).  Saving model ...
Validation loss decreased (0.415098 --> 0.415082).  Saving model ...
Validation loss decreased (0.415082 --> 0.415066).  Saving model ...
Validation loss decreased (0.415066 --> 0.415050).  Saving model ...
Validation loss decreased (0.415050 --> 0.415034).  Saving model ...
Validation loss decreased (0.415034 --> 0.415018).  Saving model ...
Validation loss decreased (0.415018 --> 0.415002).  Saving model ...
Validation loss decreased (0.415002 --> 0.414987).  Saving model ...
Validation loss decreased (0.414987 --> 0.414971).  Saving model ...
Validation loss decreased (0.414971 --> 0.414955).  Saving model ...
Validation loss decreased (0.414955 --> 0.414939).  Saving model ...
Validation loss decreased (0.414939 --> 0.414923).  Saving model ...
Validation loss decreased (0.414923 --> 0.414907).  Saving model ...
Validation loss decreased (0.414907 --> 0.414891).  Saving model ...
Validation loss decreased (0.414891 --> 0.414875).  Saving model ...
Validation loss decreased (0.414875 --> 0.414860).  Saving model ...
Validation loss decreased (0.414860 --> 0.414844).  Saving model ...
Validation loss decreased (0.414844 --> 0.414828).  Saving model ...
Validation loss decreased (0.414828 --> 0.414812).  Saving model ...
Validation loss decreased (0.414812 --> 0.414796).  Saving model ...
Validation loss decreased (0.414796 --> 0.414780).  Saving model ...
Validation loss decreased (0.414780 --> 0.414764).  Saving model ...
Validation loss decreased (0.414764 --> 0.414748).  Saving model ...
Validation loss decreased (0.414748 --> 0.414733).  Saving model ...
Validation loss decreased (0.414733 --> 0.414717).  Saving model ...
Validation loss decreased (0.414717 --> 0.414701).  Saving model ...
Validation loss decreased (0.414701 --> 0.414685).  Saving model ...
Validation loss decreased (0.414685 --> 0.414669).  Saving model ...
Validation loss decreased (0.414669 --> 0.414653).  Saving model ...
Validation loss decreased (0.414653 --> 0.414637).  Saving model ...
Validation loss decreased (0.414637 --> 0.414622).  Saving model ...
Validation loss decreased (0.414622 --> 0.414606).  Saving model ...
Validation loss decreased (0.414606 --> 0.414590).  Saving model ...
Validation loss decreased (0.414590 --> 0.414574).  Saving model ...
Validation loss decreased (0.414574 --> 0.414558).  Saving model ...
Validation loss decreased (0.414558 --> 0.414542).  Saving model ...
Validation loss decreased (0.414542 --> 0.414526).  Saving model ...
Validation loss decreased (0.414526 --> 0.414510).  Saving model ...
Validation loss decreased (0.414510 --> 0.414495).  Saving model ...
Validation loss decreased (0.414495 --> 0.414479).  Saving model ...
Validation loss decreased (0.414479 --> 0.414463).  Saving model ...
Validation loss decreased (0.414463 --> 0.414447).  Saving model ...
Validation loss decreased (0.414447 --> 0.414431).  Saving model ...
Validation loss decreased (0.414431 --> 0.414415).  Saving model ...
Validation loss decreased (0.414415 --> 0.414399).  Saving model ...
Validation loss decreased (0.414399 --> 0.414383).  Saving model ...
Validation loss decreased (0.414383 --> 0.414367).  Saving model ...
epoch 4001, loss 0.4144, train acc 79.79%, f1 0.6911, precision 0.7416, recall 0.6471, auc 0.7630
Validation loss decreased (0.414367 --> 0.414351).  Saving model ...
Validation loss decreased (0.414351 --> 0.414336).  Saving model ...
Validation loss decreased (0.414336 --> 0.414320).  Saving model ...
Validation loss decreased (0.414320 --> 0.414304).  Saving model ...
Validation loss decreased (0.414304 --> 0.414288).  Saving model ...
Validation loss decreased (0.414288 --> 0.414272).  Saving model ...
Validation loss decreased (0.414272 --> 0.414256).  Saving model ...
Validation loss decreased (0.414256 --> 0.414240).  Saving model ...
Validation loss decreased (0.414240 --> 0.414224).  Saving model ...
Validation loss decreased (0.414224 --> 0.414208).  Saving model ...
Validation loss decreased (0.414208 --> 0.414192).  Saving model ...
Validation loss decreased (0.414192 --> 0.414176).  Saving model ...
Validation loss decreased (0.414176 --> 0.414160).  Saving model ...
Validation loss decreased (0.414160 --> 0.414144).  Saving model ...
Validation loss decreased (0.414144 --> 0.414129).  Saving model ...
Validation loss decreased (0.414129 --> 0.414113).  Saving model ...
Validation loss decreased (0.414113 --> 0.414097).  Saving model ...
Validation loss decreased (0.414097 --> 0.414081).  Saving model ...
Validation loss decreased (0.414081 --> 0.414065).  Saving model ...
Validation loss decreased (0.414065 --> 0.414049).  Saving model ...
Validation loss decreased (0.414049 --> 0.414033).  Saving model ...
Validation loss decreased (0.414033 --> 0.414017).  Saving model ...
Validation loss decreased (0.414017 --> 0.414001).  Saving model ...
Validation loss decreased (0.414001 --> 0.413985).  Saving model ...
Validation loss decreased (0.413985 --> 0.413969).  Saving model ...
Validation loss decreased (0.413969 --> 0.413953).  Saving model ...
Validation loss decreased (0.413953 --> 0.413937).  Saving model ...
Validation loss decreased (0.413937 --> 0.413921).  Saving model ...
Validation loss decreased (0.413921 --> 0.413905).  Saving model ...
Validation loss decreased (0.413905 --> 0.413889).  Saving model ...
Validation loss decreased (0.413889 --> 0.413873).  Saving model ...
Validation loss decreased (0.413873 --> 0.413857).  Saving model ...
Validation loss decreased (0.413857 --> 0.413841).  Saving model ...
Validation loss decreased (0.413841 --> 0.413824).  Saving model ...
Validation loss decreased (0.413824 --> 0.413808).  Saving model ...
Validation loss decreased (0.413808 --> 0.413792).  Saving model ...
Validation loss decreased (0.413792 --> 0.413776).  Saving model ...
Validation loss decreased (0.413776 --> 0.413760).  Saving model ...
Validation loss decreased (0.413760 --> 0.413744).  Saving model ...
Validation loss decreased (0.413744 --> 0.413728).  Saving model ...
Validation loss decreased (0.413728 --> 0.413712).  Saving model ...
Validation loss decreased (0.413712 --> 0.413696).  Saving model ...
Validation loss decreased (0.413696 --> 0.413680).  Saving model ...
Validation loss decreased (0.413680 --> 0.413663).  Saving model ...
Validation loss decreased (0.413663 --> 0.413647).  Saving model ...
Validation loss decreased (0.413647 --> 0.413631).  Saving model ...
Validation loss decreased (0.413631 --> 0.413615).  Saving model ...
Validation loss decreased (0.413615 --> 0.413599).  Saving model ...
Validation loss decreased (0.413599 --> 0.413583).  Saving model ...
Validation loss decreased (0.413583 --> 0.413566).  Saving model ...
Validation loss decreased (0.413566 --> 0.413550).  Saving model ...
Validation loss decreased (0.413550 --> 0.413534).  Saving model ...
Validation loss decreased (0.413534 --> 0.413518).  Saving model ...
Validation loss decreased (0.413518 --> 0.413502).  Saving model ...
Validation loss decreased (0.413502 --> 0.413485).  Saving model ...
Validation loss decreased (0.413485 --> 0.413469).  Saving model ...
Validation loss decreased (0.413469 --> 0.413453).  Saving model ...
Validation loss decreased (0.413453 --> 0.413437).  Saving model ...
Validation loss decreased (0.413437 --> 0.413420).  Saving model ...
Validation loss decreased (0.413420 --> 0.413404).  Saving model ...
Validation loss decreased (0.413404 --> 0.413388).  Saving model ...
Validation loss decreased (0.413388 --> 0.413372).  Saving model ...
Validation loss decreased (0.413372 --> 0.413355).  Saving model ...
Validation loss decreased (0.413355 --> 0.413339).  Saving model ...
Validation loss decreased (0.413339 --> 0.413323).  Saving model ...
Validation loss decreased (0.413323 --> 0.413306).  Saving model ...
Validation loss decreased (0.413306 --> 0.413290).  Saving model ...
Validation loss decreased (0.413290 --> 0.413273).  Saving model ...
Validation loss decreased (0.413273 --> 0.413257).  Saving model ...
Validation loss decreased (0.413257 --> 0.413241).  Saving model ...
Validation loss decreased (0.413241 --> 0.413224).  Saving model ...
Validation loss decreased (0.413224 --> 0.413208).  Saving model ...
Validation loss decreased (0.413208 --> 0.413191).  Saving model ...
Validation loss decreased (0.413191 --> 0.413175).  Saving model ...
Validation loss decreased (0.413175 --> 0.413159).  Saving model ...
Validation loss decreased (0.413159 --> 0.413142).  Saving model ...
Validation loss decreased (0.413142 --> 0.413126).  Saving model ...
Validation loss decreased (0.413126 --> 0.413109).  Saving model ...
Validation loss decreased (0.413109 --> 0.413093).  Saving model ...
Validation loss decreased (0.413093 --> 0.413076).  Saving model ...
Validation loss decreased (0.413076 --> 0.413060).  Saving model ...
Validation loss decreased (0.413060 --> 0.413043).  Saving model ...
Validation loss decreased (0.413043 --> 0.413026).  Saving model ...
Validation loss decreased (0.413026 --> 0.413010).  Saving model ...
Validation loss decreased (0.413010 --> 0.412993).  Saving model ...
Validation loss decreased (0.412993 --> 0.412977).  Saving model ...
Validation loss decreased (0.412977 --> 0.412960).  Saving model ...
Validation loss decreased (0.412960 --> 0.412944).  Saving model ...
Validation loss decreased (0.412944 --> 0.412927).  Saving model ...
Validation loss decreased (0.412927 --> 0.412910).  Saving model ...
Validation loss decreased (0.412910 --> 0.412894).  Saving model ...
Validation loss decreased (0.412894 --> 0.412877).  Saving model ...
Validation loss decreased (0.412877 --> 0.412860).  Saving model ...
Validation loss decreased (0.412860 --> 0.412844).  Saving model ...
Validation loss decreased (0.412844 --> 0.412827).  Saving model ...
Validation loss decreased (0.412827 --> 0.412810).  Saving model ...
Validation loss decreased (0.412810 --> 0.412794).  Saving model ...
Validation loss decreased (0.412794 --> 0.412777).  Saving model ...
Validation loss decreased (0.412777 --> 0.412760).  Saving model ...
Validation loss decreased (0.412760 --> 0.412743).  Saving model ...
epoch 4101, loss 0.4127, train acc 79.62%, f1 0.6877, precision 0.7401, recall 0.6422, auc 0.7606
Validation loss decreased (0.412743 --> 0.412727).  Saving model ...
Validation loss decreased (0.412727 --> 0.412710).  Saving model ...
Validation loss decreased (0.412710 --> 0.412693).  Saving model ...
Validation loss decreased (0.412693 --> 0.412676).  Saving model ...
Validation loss decreased (0.412676 --> 0.412659).  Saving model ...
Validation loss decreased (0.412659 --> 0.412643).  Saving model ...
Validation loss decreased (0.412643 --> 0.412626).  Saving model ...
Validation loss decreased (0.412626 --> 0.412609).  Saving model ...
Validation loss decreased (0.412609 --> 0.412592).  Saving model ...
Validation loss decreased (0.412592 --> 0.412575).  Saving model ...
Validation loss decreased (0.412575 --> 0.412558).  Saving model ...
Validation loss decreased (0.412558 --> 0.412541).  Saving model ...
Validation loss decreased (0.412541 --> 0.412524).  Saving model ...
Validation loss decreased (0.412524 --> 0.412508).  Saving model ...
Validation loss decreased (0.412508 --> 0.412491).  Saving model ...
Validation loss decreased (0.412491 --> 0.412474).  Saving model ...
Validation loss decreased (0.412474 --> 0.412457).  Saving model ...
Validation loss decreased (0.412457 --> 0.412440).  Saving model ...
Validation loss decreased (0.412440 --> 0.412423).  Saving model ...
Validation loss decreased (0.412423 --> 0.412406).  Saving model ...
Validation loss decreased (0.412406 --> 0.412389).  Saving model ...
Validation loss decreased (0.412389 --> 0.412372).  Saving model ...
Validation loss decreased (0.412372 --> 0.412355).  Saving model ...
Validation loss decreased (0.412355 --> 0.412338).  Saving model ...
Validation loss decreased (0.412338 --> 0.412321).  Saving model ...
Validation loss decreased (0.412321 --> 0.412304).  Saving model ...
Validation loss decreased (0.412304 --> 0.412287).  Saving model ...
Validation loss decreased (0.412287 --> 0.412270).  Saving model ...
Validation loss decreased (0.412270 --> 0.412253).  Saving model ...
Validation loss decreased (0.412253 --> 0.412236).  Saving model ...
Validation loss decreased (0.412236 --> 0.412219).  Saving model ...
Validation loss decreased (0.412219 --> 0.412202).  Saving model ...
Validation loss decreased (0.412202 --> 0.412185).  Saving model ...
Validation loss decreased (0.412185 --> 0.412168).  Saving model ...
Validation loss decreased (0.412168 --> 0.412151).  Saving model ...
Validation loss decreased (0.412151 --> 0.412134).  Saving model ...
Validation loss decreased (0.412134 --> 0.412116).  Saving model ...
Validation loss decreased (0.412116 --> 0.412099).  Saving model ...
Validation loss decreased (0.412099 --> 0.412082).  Saving model ...
Validation loss decreased (0.412082 --> 0.412065).  Saving model ...
Validation loss decreased (0.412065 --> 0.412048).  Saving model ...
Validation loss decreased (0.412048 --> 0.412031).  Saving model ...
Validation loss decreased (0.412031 --> 0.412014).  Saving model ...
Validation loss decreased (0.412014 --> 0.411997).  Saving model ...
Validation loss decreased (0.411997 --> 0.411980).  Saving model ...
Validation loss decreased (0.411980 --> 0.411963).  Saving model ...
Validation loss decreased (0.411963 --> 0.411946).  Saving model ...
Validation loss decreased (0.411946 --> 0.411929).  Saving model ...
Validation loss decreased (0.411929 --> 0.411912).  Saving model ...
Validation loss decreased (0.411912 --> 0.411895).  Saving model ...
Validation loss decreased (0.411895 --> 0.411877).  Saving model ...
Validation loss decreased (0.411877 --> 0.411860).  Saving model ...
Validation loss decreased (0.411860 --> 0.411843).  Saving model ...
Validation loss decreased (0.411843 --> 0.411826).  Saving model ...
Validation loss decreased (0.411826 --> 0.411809).  Saving model ...
Validation loss decreased (0.411809 --> 0.411792).  Saving model ...
Validation loss decreased (0.411792 --> 0.411775).  Saving model ...
Validation loss decreased (0.411775 --> 0.411758).  Saving model ...
Validation loss decreased (0.411758 --> 0.411741).  Saving model ...
Validation loss decreased (0.411741 --> 0.411724).  Saving model ...
Validation loss decreased (0.411724 --> 0.411707).  Saving model ...
Validation loss decreased (0.411707 --> 0.411690).  Saving model ...
Validation loss decreased (0.411690 --> 0.411673).  Saving model ...
Validation loss decreased (0.411673 --> 0.411656).  Saving model ...
Validation loss decreased (0.411656 --> 0.411639).  Saving model ...
Validation loss decreased (0.411639 --> 0.411622).  Saving model ...
Validation loss decreased (0.411622 --> 0.411605).  Saving model ...
Validation loss decreased (0.411605 --> 0.411587).  Saving model ...
Validation loss decreased (0.411587 --> 0.411571).  Saving model ...
Validation loss decreased (0.411571 --> 0.411553).  Saving model ...
Validation loss decreased (0.411553 --> 0.411536).  Saving model ...
Validation loss decreased (0.411536 --> 0.411519).  Saving model ...
Validation loss decreased (0.411519 --> 0.411503).  Saving model ...
Validation loss decreased (0.411503 --> 0.411486).  Saving model ...
Validation loss decreased (0.411486 --> 0.411469).  Saving model ...
Validation loss decreased (0.411469 --> 0.411452).  Saving model ...
Validation loss decreased (0.411452 --> 0.411435).  Saving model ...
Validation loss decreased (0.411435 --> 0.411418).  Saving model ...
Validation loss decreased (0.411418 --> 0.411401).  Saving model ...
Validation loss decreased (0.411401 --> 0.411384).  Saving model ...
Validation loss decreased (0.411384 --> 0.411367).  Saving model ...
Validation loss decreased (0.411367 --> 0.411350).  Saving model ...
Validation loss decreased (0.411350 --> 0.411333).  Saving model ...
Validation loss decreased (0.411333 --> 0.411316).  Saving model ...
Validation loss decreased (0.411316 --> 0.411299).  Saving model ...
Validation loss decreased (0.411299 --> 0.411283).  Saving model ...
Validation loss decreased (0.411283 --> 0.411266).  Saving model ...
Validation loss decreased (0.411266 --> 0.411249).  Saving model ...
Validation loss decreased (0.411249 --> 0.411232).  Saving model ...
Validation loss decreased (0.411232 --> 0.411215).  Saving model ...
Validation loss decreased (0.411215 --> 0.411198).  Saving model ...
Validation loss decreased (0.411198 --> 0.411181).  Saving model ...
Validation loss decreased (0.411181 --> 0.411165).  Saving model ...
Validation loss decreased (0.411165 --> 0.411148).  Saving model ...
Validation loss decreased (0.411148 --> 0.411131).  Saving model ...
Validation loss decreased (0.411131 --> 0.411114).  Saving model ...
Validation loss decreased (0.411114 --> 0.411098).  Saving model ...
Validation loss decreased (0.411098 --> 0.411081).  Saving model ...
Validation loss decreased (0.411081 --> 0.411064).  Saving model ...
Validation loss decreased (0.411064 --> 0.411047).  Saving model ...
epoch 4201, loss 0.4110, train acc 79.45%, f1 0.6842, precision 0.7386, recall 0.6373, auc 0.7581
Validation loss decreased (0.411047 --> 0.411031).  Saving model ...
Validation loss decreased (0.411031 --> 0.411014).  Saving model ...
Validation loss decreased (0.411014 --> 0.410997).  Saving model ...
Validation loss decreased (0.410997 --> 0.410980).  Saving model ...
Validation loss decreased (0.410980 --> 0.410964).  Saving model ...
Validation loss decreased (0.410964 --> 0.410947).  Saving model ...
Validation loss decreased (0.410947 --> 0.410931).  Saving model ...
Validation loss decreased (0.410931 --> 0.410914).  Saving model ...
Validation loss decreased (0.410914 --> 0.410897).  Saving model ...
Validation loss decreased (0.410897 --> 0.410881).  Saving model ...
Validation loss decreased (0.410881 --> 0.410864).  Saving model ...
Validation loss decreased (0.410864 --> 0.410847).  Saving model ...
Validation loss decreased (0.410847 --> 0.410831).  Saving model ...
Validation loss decreased (0.410831 --> 0.410814).  Saving model ...
Validation loss decreased (0.410814 --> 0.410798).  Saving model ...
Validation loss decreased (0.410798 --> 0.410781).  Saving model ...
Validation loss decreased (0.410781 --> 0.410765).  Saving model ...
Validation loss decreased (0.410765 --> 0.410748).  Saving model ...
Validation loss decreased (0.410748 --> 0.410731).  Saving model ...
Validation loss decreased (0.410731 --> 0.410715).  Saving model ...
Validation loss decreased (0.410715 --> 0.410698).  Saving model ...
Validation loss decreased (0.410698 --> 0.410682).  Saving model ...
Validation loss decreased (0.410682 --> 0.410665).  Saving model ...
Validation loss decreased (0.410665 --> 0.410649).  Saving model ...
Validation loss decreased (0.410649 --> 0.410633).  Saving model ...
Validation loss decreased (0.410633 --> 0.410616).  Saving model ...
Validation loss decreased (0.410616 --> 0.410600).  Saving model ...
Validation loss decreased (0.410600 --> 0.410583).  Saving model ...
Validation loss decreased (0.410583 --> 0.410567).  Saving model ...
Validation loss decreased (0.410567 --> 0.410550).  Saving model ...
Validation loss decreased (0.410550 --> 0.410534).  Saving model ...
Validation loss decreased (0.410534 --> 0.410517).  Saving model ...
Validation loss decreased (0.410517 --> 0.410501).  Saving model ...
Validation loss decreased (0.410501 --> 0.410485).  Saving model ...
Validation loss decreased (0.410485 --> 0.410468).  Saving model ...
Validation loss decreased (0.410468 --> 0.410452).  Saving model ...
Validation loss decreased (0.410452 --> 0.410436).  Saving model ...
Validation loss decreased (0.410436 --> 0.410419).  Saving model ...
Validation loss decreased (0.410419 --> 0.410403).  Saving model ...
Validation loss decreased (0.410403 --> 0.410387).  Saving model ...
Validation loss decreased (0.410387 --> 0.410370).  Saving model ...
Validation loss decreased (0.410370 --> 0.410354).  Saving model ...
Validation loss decreased (0.410354 --> 0.410338).  Saving model ...
Validation loss decreased (0.410338 --> 0.410321).  Saving model ...
Validation loss decreased (0.410321 --> 0.410305).  Saving model ...
Validation loss decreased (0.410305 --> 0.410289).  Saving model ...
Validation loss decreased (0.410289 --> 0.410272).  Saving model ...
Validation loss decreased (0.410272 --> 0.410256).  Saving model ...
Validation loss decreased (0.410256 --> 0.410240).  Saving model ...
Validation loss decreased (0.410240 --> 0.410224).  Saving model ...
Validation loss decreased (0.410224 --> 0.410207).  Saving model ...
Validation loss decreased (0.410207 --> 0.410191).  Saving model ...
Validation loss decreased (0.410191 --> 0.410175).  Saving model ...
Validation loss decreased (0.410175 --> 0.410159).  Saving model ...
Validation loss decreased (0.410159 --> 0.410142).  Saving model ...
Validation loss decreased (0.410142 --> 0.410126).  Saving model ...
Validation loss decreased (0.410126 --> 0.410110).  Saving model ...
Validation loss decreased (0.410110 --> 0.410094).  Saving model ...
Validation loss decreased (0.410094 --> 0.410078).  Saving model ...
Validation loss decreased (0.410078 --> 0.410061).  Saving model ...
Validation loss decreased (0.410061 --> 0.410045).  Saving model ...
Validation loss decreased (0.410045 --> 0.410029).  Saving model ...
Validation loss decreased (0.410029 --> 0.410013).  Saving model ...
Validation loss decreased (0.410013 --> 0.409997).  Saving model ...
Validation loss decreased (0.409997 --> 0.409981).  Saving model ...
Validation loss decreased (0.409981 --> 0.409964).  Saving model ...
Validation loss decreased (0.409964 --> 0.409948).  Saving model ...
Validation loss decreased (0.409948 --> 0.409932).  Saving model ...
Validation loss decreased (0.409932 --> 0.409916).  Saving model ...
Validation loss decreased (0.409916 --> 0.409900).  Saving model ...
Validation loss decreased (0.409900 --> 0.409884).  Saving model ...
Validation loss decreased (0.409884 --> 0.409868).  Saving model ...
Validation loss decreased (0.409868 --> 0.409851).  Saving model ...
Validation loss decreased (0.409851 --> 0.409835).  Saving model ...
Validation loss decreased (0.409835 --> 0.409819).  Saving model ...
Validation loss decreased (0.409819 --> 0.409803).  Saving model ...
Validation loss decreased (0.409803 --> 0.409787).  Saving model ...
Validation loss decreased (0.409787 --> 0.409771).  Saving model ...
Validation loss decreased (0.409771 --> 0.409755).  Saving model ...
Validation loss decreased (0.409755 --> 0.409739).  Saving model ...
Validation loss decreased (0.409739 --> 0.409722).  Saving model ...
Validation loss decreased (0.409722 --> 0.409706).  Saving model ...
Validation loss decreased (0.409706 --> 0.409690).  Saving model ...
Validation loss decreased (0.409690 --> 0.409674).  Saving model ...
Validation loss decreased (0.409674 --> 0.409658).  Saving model ...
Validation loss decreased (0.409658 --> 0.409642).  Saving model ...
Validation loss decreased (0.409642 --> 0.409626).  Saving model ...
Validation loss decreased (0.409626 --> 0.409610).  Saving model ...
Validation loss decreased (0.409610 --> 0.409594).  Saving model ...
Validation loss decreased (0.409594 --> 0.409578).  Saving model ...
Validation loss decreased (0.409578 --> 0.409562).  Saving model ...
Validation loss decreased (0.409562 --> 0.409545).  Saving model ...
Validation loss decreased (0.409545 --> 0.409529).  Saving model ...
Validation loss decreased (0.409529 --> 0.409513).  Saving model ...
Validation loss decreased (0.409513 --> 0.409497).  Saving model ...
Validation loss decreased (0.409497 --> 0.409481).  Saving model ...
Validation loss decreased (0.409481 --> 0.409465).  Saving model ...
Validation loss decreased (0.409465 --> 0.409449).  Saving model ...
Validation loss decreased (0.409449 --> 0.409433).  Saving model ...
Validation loss decreased (0.409433 --> 0.409417).  Saving model ...
epoch 4301, loss 0.4094, train acc 79.45%, f1 0.6842, precision 0.7386, recall 0.6373, auc 0.7581
Validation loss decreased (0.409417 --> 0.409401).  Saving model ...
Validation loss decreased (0.409401 --> 0.409385).  Saving model ...
Validation loss decreased (0.409385 --> 0.409369).  Saving model ...
Validation loss decreased (0.409369 --> 0.409353).  Saving model ...
Validation loss decreased (0.409353 --> 0.409336).  Saving model ...
Validation loss decreased (0.409336 --> 0.409320).  Saving model ...
Validation loss decreased (0.409320 --> 0.409304).  Saving model ...
Validation loss decreased (0.409304 --> 0.409288).  Saving model ...
Validation loss decreased (0.409288 --> 0.409272).  Saving model ...
Validation loss decreased (0.409272 --> 0.409256).  Saving model ...
Validation loss decreased (0.409256 --> 0.409240).  Saving model ...
Validation loss decreased (0.409240 --> 0.409224).  Saving model ...
Validation loss decreased (0.409224 --> 0.409208).  Saving model ...
Validation loss decreased (0.409208 --> 0.409192).  Saving model ...
Validation loss decreased (0.409192 --> 0.409176).  Saving model ...
Validation loss decreased (0.409176 --> 0.409160).  Saving model ...
Validation loss decreased (0.409160 --> 0.409143).  Saving model ...
Validation loss decreased (0.409143 --> 0.409127).  Saving model ...
Validation loss decreased (0.409127 --> 0.409111).  Saving model ...
Validation loss decreased (0.409111 --> 0.409095).  Saving model ...
Validation loss decreased (0.409095 --> 0.409079).  Saving model ...
Validation loss decreased (0.409079 --> 0.409063).  Saving model ...
Validation loss decreased (0.409063 --> 0.409047).  Saving model ...
Validation loss decreased (0.409047 --> 0.409031).  Saving model ...
Validation loss decreased (0.409031 --> 0.409015).  Saving model ...
Validation loss decreased (0.409015 --> 0.408998).  Saving model ...
Validation loss decreased (0.408998 --> 0.408982).  Saving model ...
Validation loss decreased (0.408982 --> 0.408966).  Saving model ...
Validation loss decreased (0.408966 --> 0.408950).  Saving model ...
Validation loss decreased (0.408950 --> 0.408934).  Saving model ...
Validation loss decreased (0.408934 --> 0.408918).  Saving model ...
Validation loss decreased (0.408918 --> 0.408902).  Saving model ...
Validation loss decreased (0.408902 --> 0.408885).  Saving model ...
Validation loss decreased (0.408885 --> 0.408869).  Saving model ...
Validation loss decreased (0.408869 --> 0.408853).  Saving model ...
Validation loss decreased (0.408853 --> 0.408837).  Saving model ...
Validation loss decreased (0.408837 --> 0.408821).  Saving model ...
Validation loss decreased (0.408821 --> 0.408805).  Saving model ...
Validation loss decreased (0.408805 --> 0.408788).  Saving model ...
Validation loss decreased (0.408788 --> 0.408772).  Saving model ...
Validation loss decreased (0.408772 --> 0.408756).  Saving model ...
Validation loss decreased (0.408756 --> 0.408740).  Saving model ...
Validation loss decreased (0.408740 --> 0.408723).  Saving model ...
Validation loss decreased (0.408723 --> 0.408707).  Saving model ...
Validation loss decreased (0.408707 --> 0.408691).  Saving model ...
Validation loss decreased (0.408691 --> 0.408675).  Saving model ...
Validation loss decreased (0.408675 --> 0.408658).  Saving model ...
Validation loss decreased (0.408658 --> 0.408642).  Saving model ...
Validation loss decreased (0.408642 --> 0.408626).  Saving model ...
Validation loss decreased (0.408626 --> 0.408610).  Saving model ...
Validation loss decreased (0.408610 --> 0.408593).  Saving model ...
Validation loss decreased (0.408593 --> 0.408577).  Saving model ...
Validation loss decreased (0.408577 --> 0.408561).  Saving model ...
Validation loss decreased (0.408561 --> 0.408544).  Saving model ...
Validation loss decreased (0.408544 --> 0.408528).  Saving model ...
Validation loss decreased (0.408528 --> 0.408512).  Saving model ...
Validation loss decreased (0.408512 --> 0.408495).  Saving model ...
Validation loss decreased (0.408495 --> 0.408479).  Saving model ...
Validation loss decreased (0.408479 --> 0.408462).  Saving model ...
Validation loss decreased (0.408462 --> 0.408446).  Saving model ...
Validation loss decreased (0.408446 --> 0.408430).  Saving model ...
Validation loss decreased (0.408430 --> 0.408413).  Saving model ...
Validation loss decreased (0.408413 --> 0.408397).  Saving model ...
Validation loss decreased (0.408397 --> 0.408380).  Saving model ...
Validation loss decreased (0.408380 --> 0.408363).  Saving model ...
Validation loss decreased (0.408363 --> 0.408347).  Saving model ...
Validation loss decreased (0.408347 --> 0.408330).  Saving model ...
Validation loss decreased (0.408330 --> 0.408314).  Saving model ...
Validation loss decreased (0.408314 --> 0.408297).  Saving model ...
Validation loss decreased (0.408297 --> 0.408281).  Saving model ...
Validation loss decreased (0.408281 --> 0.408264).  Saving model ...
Validation loss decreased (0.408264 --> 0.408247).  Saving model ...
Validation loss decreased (0.408247 --> 0.408230).  Saving model ...
Validation loss decreased (0.408230 --> 0.408214).  Saving model ...
Validation loss decreased (0.408214 --> 0.408197).  Saving model ...
Validation loss decreased (0.408197 --> 0.408180).  Saving model ...
Validation loss decreased (0.408180 --> 0.408163).  Saving model ...
Validation loss decreased (0.408163 --> 0.408146).  Saving model ...
Validation loss decreased (0.408146 --> 0.408130).  Saving model ...
Validation loss decreased (0.408130 --> 0.408113).  Saving model ...
Validation loss decreased (0.408113 --> 0.408096).  Saving model ...
Validation loss decreased (0.408096 --> 0.408079).  Saving model ...
Validation loss decreased (0.408079 --> 0.408062).  Saving model ...
Validation loss decreased (0.408062 --> 0.408045).  Saving model ...
Validation loss decreased (0.408045 --> 0.408027).  Saving model ...
Validation loss decreased (0.408027 --> 0.408010).  Saving model ...
Validation loss decreased (0.408010 --> 0.407993).  Saving model ...
Validation loss decreased (0.407993 --> 0.407976).  Saving model ...
Validation loss decreased (0.407976 --> 0.407959).  Saving model ...
Validation loss decreased (0.407959 --> 0.407941).  Saving model ...
Validation loss decreased (0.407941 --> 0.407924).  Saving model ...
Validation loss decreased (0.407924 --> 0.407907).  Saving model ...
Validation loss decreased (0.407907 --> 0.407889).  Saving model ...
Validation loss decreased (0.407889 --> 0.407871).  Saving model ...
Validation loss decreased (0.407871 --> 0.407854).  Saving model ...
Validation loss decreased (0.407854 --> 0.407836).  Saving model ...
Validation loss decreased (0.407836 --> 0.407819).  Saving model ...
Validation loss decreased (0.407819 --> 0.407801).  Saving model ...
Validation loss decreased (0.407801 --> 0.407783).  Saving model ...
Validation loss decreased (0.407783 --> 0.407765).  Saving model ...
epoch 4401, loss 0.4078, train acc 79.28%, f1 0.6824, precision 0.7345, recall 0.6373, auc 0.7568
Validation loss decreased (0.407765 --> 0.407747).  Saving model ...
Validation loss decreased (0.407747 --> 0.407729).  Saving model ...
Validation loss decreased (0.407729 --> 0.407711).  Saving model ...
Validation loss decreased (0.407711 --> 0.407693).  Saving model ...
Validation loss decreased (0.407693 --> 0.407675).  Saving model ...
Validation loss decreased (0.407675 --> 0.407657).  Saving model ...
Validation loss decreased (0.407657 --> 0.407638).  Saving model ...
Validation loss decreased (0.407638 --> 0.407620).  Saving model ...
Validation loss decreased (0.407620 --> 0.407602).  Saving model ...
Validation loss decreased (0.407602 --> 0.407583).  Saving model ...
Validation loss decreased (0.407583 --> 0.407564).  Saving model ...
Validation loss decreased (0.407564 --> 0.407546).  Saving model ...
Validation loss decreased (0.407546 --> 0.407527).  Saving model ...
Validation loss decreased (0.407527 --> 0.407508).  Saving model ...
Validation loss decreased (0.407508 --> 0.407489).  Saving model ...
Validation loss decreased (0.407489 --> 0.407470).  Saving model ...
Validation loss decreased (0.407470 --> 0.407451).  Saving model ...
Validation loss decreased (0.407451 --> 0.407432).  Saving model ...
Validation loss decreased (0.407432 --> 0.407413).  Saving model ...
Validation loss decreased (0.407413 --> 0.407393).  Saving model ...
Validation loss decreased (0.407393 --> 0.407374).  Saving model ...
Validation loss decreased (0.407374 --> 0.407355).  Saving model ...
Validation loss decreased (0.407355 --> 0.407335).  Saving model ...
Validation loss decreased (0.407335 --> 0.407315).  Saving model ...
Validation loss decreased (0.407315 --> 0.407296).  Saving model ...
Validation loss decreased (0.407296 --> 0.407276).  Saving model ...
Validation loss decreased (0.407276 --> 0.407256).  Saving model ...
Validation loss decreased (0.407256 --> 0.407236).  Saving model ...
Validation loss decreased (0.407236 --> 0.407216).  Saving model ...
Validation loss decreased (0.407216 --> 0.407195).  Saving model ...
Validation loss decreased (0.407195 --> 0.407175).  Saving model ...
Validation loss decreased (0.407175 --> 0.407155).  Saving model ...
Validation loss decreased (0.407155 --> 0.407134).  Saving model ...
Validation loss decreased (0.407134 --> 0.407114).  Saving model ...
Validation loss decreased (0.407114 --> 0.407093).  Saving model ...
Validation loss decreased (0.407093 --> 0.407072).  Saving model ...
Validation loss decreased (0.407072 --> 0.407052).  Saving model ...
Validation loss decreased (0.407052 --> 0.407031).  Saving model ...
Validation loss decreased (0.407031 --> 0.407010).  Saving model ...
Validation loss decreased (0.407010 --> 0.406988).  Saving model ...
Validation loss decreased (0.406988 --> 0.406967).  Saving model ...
Validation loss decreased (0.406967 --> 0.406946).  Saving model ...
Validation loss decreased (0.406946 --> 0.406925).  Saving model ...
Validation loss decreased (0.406925 --> 0.406903).  Saving model ...
Validation loss decreased (0.406903 --> 0.406882).  Saving model ...
Validation loss decreased (0.406882 --> 0.406860).  Saving model ...
Validation loss decreased (0.406860 --> 0.406839).  Saving model ...
Validation loss decreased (0.406839 --> 0.406817).  Saving model ...
Validation loss decreased (0.406817 --> 0.406795).  Saving model ...
Validation loss decreased (0.406795 --> 0.406773).  Saving model ...
Validation loss decreased (0.406773 --> 0.406751).  Saving model ...
Validation loss decreased (0.406751 --> 0.406729).  Saving model ...
Validation loss decreased (0.406729 --> 0.406707).  Saving model ...
Validation loss decreased (0.406707 --> 0.406685).  Saving model ...
Validation loss decreased (0.406685 --> 0.406662).  Saving model ...
Validation loss decreased (0.406662 --> 0.406640).  Saving model ...
Validation loss decreased (0.406640 --> 0.406618).  Saving model ...
Validation loss decreased (0.406618 --> 0.406595).  Saving model ...
Validation loss decreased (0.406595 --> 0.406573).  Saving model ...
Validation loss decreased (0.406573 --> 0.406550).  Saving model ...
Validation loss decreased (0.406550 --> 0.406527).  Saving model ...
Validation loss decreased (0.406527 --> 0.406505).  Saving model ...
Validation loss decreased (0.406505 --> 0.406482).  Saving model ...
Validation loss decreased (0.406482 --> 0.406459).  Saving model ...
Validation loss decreased (0.406459 --> 0.406436).  Saving model ...
Validation loss decreased (0.406436 --> 0.406414).  Saving model ...
Validation loss decreased (0.406414 --> 0.406391).  Saving model ...
Validation loss decreased (0.406391 --> 0.406368).  Saving model ...
Validation loss decreased (0.406368 --> 0.406345).  Saving model ...
Validation loss decreased (0.406345 --> 0.406322).  Saving model ...
Validation loss decreased (0.406322 --> 0.406298).  Saving model ...
Validation loss decreased (0.406298 --> 0.406275).  Saving model ...
Validation loss decreased (0.406275 --> 0.406252).  Saving model ...
Validation loss decreased (0.406252 --> 0.406229).  Saving model ...
Validation loss decreased (0.406229 --> 0.406206).  Saving model ...
Validation loss decreased (0.406206 --> 0.406182).  Saving model ...
Validation loss decreased (0.406182 --> 0.406159).  Saving model ...
Validation loss decreased (0.406159 --> 0.406136).  Saving model ...
Validation loss decreased (0.406136 --> 0.406112).  Saving model ...
Validation loss decreased (0.406112 --> 0.406089).  Saving model ...
Validation loss decreased (0.406089 --> 0.406066).  Saving model ...
Validation loss decreased (0.406066 --> 0.406042).  Saving model ...
Validation loss decreased (0.406042 --> 0.406019).  Saving model ...
Validation loss decreased (0.406019 --> 0.405995).  Saving model ...
Validation loss decreased (0.405995 --> 0.405972).  Saving model ...
Validation loss decreased (0.405972 --> 0.405948).  Saving model ...
Validation loss decreased (0.405948 --> 0.405925).  Saving model ...
Validation loss decreased (0.405925 --> 0.405901).  Saving model ...
Validation loss decreased (0.405901 --> 0.405878).  Saving model ...
Validation loss decreased (0.405878 --> 0.405854).  Saving model ...
Validation loss decreased (0.405854 --> 0.405831).  Saving model ...
Validation loss decreased (0.405831 --> 0.405807).  Saving model ...
Validation loss decreased (0.405807 --> 0.405783).  Saving model ...
Validation loss decreased (0.405783 --> 0.405760).  Saving model ...
Validation loss decreased (0.405760 --> 0.405736).  Saving model ...
Validation loss decreased (0.405736 --> 0.405713).  Saving model ...
Validation loss decreased (0.405713 --> 0.405689).  Saving model ...
Validation loss decreased (0.405689 --> 0.405665).  Saving model ...
Validation loss decreased (0.405665 --> 0.405642).  Saving model ...
Validation loss decreased (0.405642 --> 0.405618).  Saving model ...
epoch 4501, loss 0.4056, train acc 79.28%, f1 0.6841, precision 0.7318, recall 0.6422, auc 0.7579
Validation loss decreased (0.405618 --> 0.405594).  Saving model ...
Validation loss decreased (0.405594 --> 0.405571).  Saving model ...
Validation loss decreased (0.405571 --> 0.405547).  Saving model ...
Validation loss decreased (0.405547 --> 0.405524).  Saving model ...
Validation loss decreased (0.405524 --> 0.405500).  Saving model ...
Validation loss decreased (0.405500 --> 0.405476).  Saving model ...
Validation loss decreased (0.405476 --> 0.405453).  Saving model ...
Validation loss decreased (0.405453 --> 0.405429).  Saving model ...
Validation loss decreased (0.405429 --> 0.405406).  Saving model ...
Validation loss decreased (0.405406 --> 0.405382).  Saving model ...
Validation loss decreased (0.405382 --> 0.405358).  Saving model ...
Validation loss decreased (0.405358 --> 0.405335).  Saving model ...
Validation loss decreased (0.405335 --> 0.405311).  Saving model ...
Validation loss decreased (0.405311 --> 0.405288).  Saving model ...
Validation loss decreased (0.405288 --> 0.405264).  Saving model ...
Validation loss decreased (0.405264 --> 0.405241).  Saving model ...
Validation loss decreased (0.405241 --> 0.405217).  Saving model ...
Validation loss decreased (0.405217 --> 0.405193).  Saving model ...
Validation loss decreased (0.405193 --> 0.405170).  Saving model ...
Validation loss decreased (0.405170 --> 0.405146).  Saving model ...
Validation loss decreased (0.405146 --> 0.405123).  Saving model ...
Validation loss decreased (0.405123 --> 0.405099).  Saving model ...
Validation loss decreased (0.405099 --> 0.405076).  Saving model ...
Validation loss decreased (0.405076 --> 0.405052).  Saving model ...
Validation loss decreased (0.405052 --> 0.405029).  Saving model ...
Validation loss decreased (0.405029 --> 0.405005).  Saving model ...
Validation loss decreased (0.405005 --> 0.404982).  Saving model ...
Validation loss decreased (0.404982 --> 0.404958).  Saving model ...
Validation loss decreased (0.404958 --> 0.404935).  Saving model ...
Validation loss decreased (0.404935 --> 0.404912).  Saving model ...
Validation loss decreased (0.404912 --> 0.404888).  Saving model ...
Validation loss decreased (0.404888 --> 0.404865).  Saving model ...
Validation loss decreased (0.404865 --> 0.404841).  Saving model ...
Validation loss decreased (0.404841 --> 0.404818).  Saving model ...
Validation loss decreased (0.404818 --> 0.404794).  Saving model ...
Validation loss decreased (0.404794 --> 0.404771).  Saving model ...
Validation loss decreased (0.404771 --> 0.404748).  Saving model ...
Validation loss decreased (0.404748 --> 0.404724).  Saving model ...
Validation loss decreased (0.404724 --> 0.404701).  Saving model ...
Validation loss decreased (0.404701 --> 0.404678).  Saving model ...
Validation loss decreased (0.404678 --> 0.404654).  Saving model ...
Validation loss decreased (0.404654 --> 0.404631).  Saving model ...
Validation loss decreased (0.404631 --> 0.404607).  Saving model ...
Validation loss decreased (0.404607 --> 0.404584).  Saving model ...
Validation loss decreased (0.404584 --> 0.404561).  Saving model ...
Validation loss decreased (0.404561 --> 0.404537).  Saving model ...
Validation loss decreased (0.404537 --> 0.404514).  Saving model ...
Validation loss decreased (0.404514 --> 0.404491).  Saving model ...
Validation loss decreased (0.404491 --> 0.404467).  Saving model ...
Validation loss decreased (0.404467 --> 0.404444).  Saving model ...
Validation loss decreased (0.404444 --> 0.404421).  Saving model ...
Validation loss decreased (0.404421 --> 0.404397).  Saving model ...
Validation loss decreased (0.404397 --> 0.404374).  Saving model ...
Validation loss decreased (0.404374 --> 0.404351).  Saving model ...
Validation loss decreased (0.404351 --> 0.404327).  Saving model ...
Validation loss decreased (0.404327 --> 0.404304).  Saving model ...
Validation loss decreased (0.404304 --> 0.404281).  Saving model ...
Validation loss decreased (0.404281 --> 0.404257).  Saving model ...
Validation loss decreased (0.404257 --> 0.404234).  Saving model ...
Validation loss decreased (0.404234 --> 0.404211).  Saving model ...
Validation loss decreased (0.404211 --> 0.404187).  Saving model ...
Validation loss decreased (0.404187 --> 0.404164).  Saving model ...
Validation loss decreased (0.404164 --> 0.404141).  Saving model ...
Validation loss decreased (0.404141 --> 0.404117).  Saving model ...
Validation loss decreased (0.404117 --> 0.404094).  Saving model ...
Validation loss decreased (0.404094 --> 0.404070).  Saving model ...
Validation loss decreased (0.404070 --> 0.404047).  Saving model ...
Validation loss decreased (0.404047 --> 0.404024).  Saving model ...
Validation loss decreased (0.404024 --> 0.404000).  Saving model ...
Validation loss decreased (0.404000 --> 0.403977).  Saving model ...
Validation loss decreased (0.403977 --> 0.403953).  Saving model ...
Validation loss decreased (0.403953 --> 0.403930).  Saving model ...
Validation loss decreased (0.403930 --> 0.403906).  Saving model ...
Validation loss decreased (0.403906 --> 0.403883).  Saving model ...
Validation loss decreased (0.403883 --> 0.403860).  Saving model ...
Validation loss decreased (0.403860 --> 0.403836).  Saving model ...
Validation loss decreased (0.403836 --> 0.403813).  Saving model ...
Validation loss decreased (0.403813 --> 0.403789).  Saving model ...
Validation loss decreased (0.403789 --> 0.403766).  Saving model ...
Validation loss decreased (0.403766 --> 0.403742).  Saving model ...
Validation loss decreased (0.403742 --> 0.403719).  Saving model ...
Validation loss decreased (0.403719 --> 0.403695).  Saving model ...
Validation loss decreased (0.403695 --> 0.403672).  Saving model ...
Validation loss decreased (0.403672 --> 0.403648).  Saving model ...
Validation loss decreased (0.403648 --> 0.403624).  Saving model ...
Validation loss decreased (0.403624 --> 0.403601).  Saving model ...
Validation loss decreased (0.403601 --> 0.403577).  Saving model ...
Validation loss decreased (0.403577 --> 0.403553).  Saving model ...
Validation loss decreased (0.403553 --> 0.403530).  Saving model ...
Validation loss decreased (0.403530 --> 0.403506).  Saving model ...
Validation loss decreased (0.403506 --> 0.403482).  Saving model ...
Validation loss decreased (0.403482 --> 0.403459).  Saving model ...
Validation loss decreased (0.403459 --> 0.403435).  Saving model ...
Validation loss decreased (0.403435 --> 0.403411).  Saving model ...
Validation loss decreased (0.403411 --> 0.403387).  Saving model ...
Validation loss decreased (0.403387 --> 0.403364).  Saving model ...
Validation loss decreased (0.403364 --> 0.403340).  Saving model ...
Validation loss decreased (0.403340 --> 0.403316).  Saving model ...
Validation loss decreased (0.403316 --> 0.403292).  Saving model ...
Validation loss decreased (0.403292 --> 0.403268).  Saving model ...
epoch 4601, loss 0.4033, train acc 79.97%, f1 0.6913, precision 0.7486, recall 0.6422, auc 0.7632
Validation loss decreased (0.403268 --> 0.403244).  Saving model ...
Validation loss decreased (0.403244 --> 0.403220).  Saving model ...
Validation loss decreased (0.403220 --> 0.403196).  Saving model ...
Validation loss decreased (0.403196 --> 0.403173).  Saving model ...
Validation loss decreased (0.403173 --> 0.403148).  Saving model ...
Validation loss decreased (0.403148 --> 0.403124).  Saving model ...
Validation loss decreased (0.403124 --> 0.403100).  Saving model ...
Validation loss decreased (0.403100 --> 0.403076).  Saving model ...
Validation loss decreased (0.403076 --> 0.403052).  Saving model ...
Validation loss decreased (0.403052 --> 0.403028).  Saving model ...
Validation loss decreased (0.403028 --> 0.403004).  Saving model ...
Validation loss decreased (0.403004 --> 0.402980).  Saving model ...
Validation loss decreased (0.402980 --> 0.402956).  Saving model ...
Validation loss decreased (0.402956 --> 0.402931).  Saving model ...
Validation loss decreased (0.402931 --> 0.402907).  Saving model ...
Validation loss decreased (0.402907 --> 0.402883).  Saving model ...
Validation loss decreased (0.402883 --> 0.402858).  Saving model ...
Validation loss decreased (0.402858 --> 0.402834).  Saving model ...
Validation loss decreased (0.402834 --> 0.402810).  Saving model ...
Validation loss decreased (0.402810 --> 0.402785).  Saving model ...
Validation loss decreased (0.402785 --> 0.402761).  Saving model ...
Validation loss decreased (0.402761 --> 0.402737).  Saving model ...
Validation loss decreased (0.402737 --> 0.402712).  Saving model ...
Validation loss decreased (0.402712 --> 0.402688).  Saving model ...
Validation loss decreased (0.402688 --> 0.402663).  Saving model ...
Validation loss decreased (0.402663 --> 0.402638).  Saving model ...
Validation loss decreased (0.402638 --> 0.402614).  Saving model ...
Validation loss decreased (0.402614 --> 0.402589).  Saving model ...
Validation loss decreased (0.402589 --> 0.402565).  Saving model ...
Validation loss decreased (0.402565 --> 0.402540).  Saving model ...
Validation loss decreased (0.402540 --> 0.402515).  Saving model ...
Validation loss decreased (0.402515 --> 0.402490).  Saving model ...
Validation loss decreased (0.402490 --> 0.402466).  Saving model ...
Validation loss decreased (0.402466 --> 0.402441).  Saving model ...
Validation loss decreased (0.402441 --> 0.402416).  Saving model ...
Validation loss decreased (0.402416 --> 0.402391).  Saving model ...
Validation loss decreased (0.402391 --> 0.402366).  Saving model ...
Validation loss decreased (0.402366 --> 0.402341).  Saving model ...
Validation loss decreased (0.402341 --> 0.402316).  Saving model ...
Validation loss decreased (0.402316 --> 0.402292).  Saving model ...
Validation loss decreased (0.402292 --> 0.402266).  Saving model ...
Validation loss decreased (0.402266 --> 0.402241).  Saving model ...
Validation loss decreased (0.402241 --> 0.402216).  Saving model ...
Validation loss decreased (0.402216 --> 0.402191).  Saving model ...
Validation loss decreased (0.402191 --> 0.402166).  Saving model ...
Validation loss decreased (0.402166 --> 0.402141).  Saving model ...
Validation loss decreased (0.402141 --> 0.402116).  Saving model ...
Validation loss decreased (0.402116 --> 0.402091).  Saving model ...
Validation loss decreased (0.402091 --> 0.402065).  Saving model ...
Validation loss decreased (0.402065 --> 0.402040).  Saving model ...
Validation loss decreased (0.402040 --> 0.402015).  Saving model ...
Validation loss decreased (0.402015 --> 0.401989).  Saving model ...
Validation loss decreased (0.401989 --> 0.401964).  Saving model ...
Validation loss decreased (0.401964 --> 0.401939).  Saving model ...
Validation loss decreased (0.401939 --> 0.401913).  Saving model ...
Validation loss decreased (0.401913 --> 0.401888).  Saving model ...
Validation loss decreased (0.401888 --> 0.401862).  Saving model ...
Validation loss decreased (0.401862 --> 0.401837).  Saving model ...
Validation loss decreased (0.401837 --> 0.401811).  Saving model ...
Validation loss decreased (0.401811 --> 0.401786).  Saving model ...
Validation loss decreased (0.401786 --> 0.401760).  Saving model ...
Validation loss decreased (0.401760 --> 0.401734).  Saving model ...
Validation loss decreased (0.401734 --> 0.401709).  Saving model ...
Validation loss decreased (0.401709 --> 0.401683).  Saving model ...
Validation loss decreased (0.401683 --> 0.401657).  Saving model ...
Validation loss decreased (0.401657 --> 0.401632).  Saving model ...
Validation loss decreased (0.401632 --> 0.401606).  Saving model ...
Validation loss decreased (0.401606 --> 0.401580).  Saving model ...
Validation loss decreased (0.401580 --> 0.401554).  Saving model ...
Validation loss decreased (0.401554 --> 0.401528).  Saving model ...
Validation loss decreased (0.401528 --> 0.401502).  Saving model ...
Validation loss decreased (0.401502 --> 0.401477).  Saving model ...
Validation loss decreased (0.401477 --> 0.401451).  Saving model ...
Validation loss decreased (0.401451 --> 0.401425).  Saving model ...
Validation loss decreased (0.401425 --> 0.401399).  Saving model ...
Validation loss decreased (0.401399 --> 0.401373).  Saving model ...
Validation loss decreased (0.401373 --> 0.401346).  Saving model ...
Validation loss decreased (0.401346 --> 0.401320).  Saving model ...
Validation loss decreased (0.401320 --> 0.401294).  Saving model ...
Validation loss decreased (0.401294 --> 0.401268).  Saving model ...
Validation loss decreased (0.401268 --> 0.401242).  Saving model ...
Validation loss decreased (0.401242 --> 0.401216).  Saving model ...
Validation loss decreased (0.401216 --> 0.401189).  Saving model ...
Validation loss decreased (0.401189 --> 0.401163).  Saving model ...
Validation loss decreased (0.401163 --> 0.401137).  Saving model ...
Validation loss decreased (0.401137 --> 0.401110).  Saving model ...
Validation loss decreased (0.401110 --> 0.401084).  Saving model ...
Validation loss decreased (0.401084 --> 0.401058).  Saving model ...
Validation loss decreased (0.401058 --> 0.401031).  Saving model ...
Validation loss decreased (0.401031 --> 0.401005).  Saving model ...
Validation loss decreased (0.401005 --> 0.400978).  Saving model ...
Validation loss decreased (0.400978 --> 0.400952).  Saving model ...
Validation loss decreased (0.400952 --> 0.400925).  Saving model ...
Validation loss decreased (0.400925 --> 0.400899).  Saving model ...
Validation loss decreased (0.400899 --> 0.400872).  Saving model ...
Validation loss decreased (0.400872 --> 0.400845).  Saving model ...
Validation loss decreased (0.400845 --> 0.400819).  Saving model ...
Validation loss decreased (0.400819 --> 0.400792).  Saving model ...
Validation loss decreased (0.400792 --> 0.400765).  Saving model ...
Validation loss decreased (0.400765 --> 0.400738).  Saving model ...
epoch 4701, loss 0.4007, train acc 79.97%, f1 0.6945, precision 0.7430, recall 0.6520, auc 0.7655
Validation loss decreased (0.400738 --> 0.400712).  Saving model ...
Validation loss decreased (0.400712 --> 0.400685).  Saving model ...
Validation loss decreased (0.400685 --> 0.400658).  Saving model ...
Validation loss decreased (0.400658 --> 0.400631).  Saving model ...
Validation loss decreased (0.400631 --> 0.400604).  Saving model ...
Validation loss decreased (0.400604 --> 0.400577).  Saving model ...
Validation loss decreased (0.400577 --> 0.400550).  Saving model ...
Validation loss decreased (0.400550 --> 0.400523).  Saving model ...
Validation loss decreased (0.400523 --> 0.400496).  Saving model ...
Validation loss decreased (0.400496 --> 0.400469).  Saving model ...
Validation loss decreased (0.400469 --> 0.400441).  Saving model ...
Validation loss decreased (0.400441 --> 0.400414).  Saving model ...
Validation loss decreased (0.400414 --> 0.400387).  Saving model ...
Validation loss decreased (0.400387 --> 0.400360).  Saving model ...
Validation loss decreased (0.400360 --> 0.400332).  Saving model ...
Validation loss decreased (0.400332 --> 0.400305).  Saving model ...
Validation loss decreased (0.400305 --> 0.400277).  Saving model ...
Validation loss decreased (0.400277 --> 0.400250).  Saving model ...
Validation loss decreased (0.400250 --> 0.400222).  Saving model ...
Validation loss decreased (0.400222 --> 0.400195).  Saving model ...
Validation loss decreased (0.400195 --> 0.400167).  Saving model ...
Validation loss decreased (0.400167 --> 0.400140).  Saving model ...
Validation loss decreased (0.400140 --> 0.400112).  Saving model ...
Validation loss decreased (0.400112 --> 0.400084).  Saving model ...
Validation loss decreased (0.400084 --> 0.400056).  Saving model ...
Validation loss decreased (0.400056 --> 0.400028).  Saving model ...
Validation loss decreased (0.400028 --> 0.400000).  Saving model ...
Validation loss decreased (0.400000 --> 0.399972).  Saving model ...
Validation loss decreased (0.399972 --> 0.399944).  Saving model ...
Validation loss decreased (0.399944 --> 0.399916).  Saving model ...
Validation loss decreased (0.399916 --> 0.399888).  Saving model ...
Validation loss decreased (0.399888 --> 0.399860).  Saving model ...
Validation loss decreased (0.399860 --> 0.399832).  Saving model ...
Validation loss decreased (0.399832 --> 0.399803).  Saving model ...
Validation loss decreased (0.399803 --> 0.399775).  Saving model ...
Validation loss decreased (0.399775 --> 0.399746).  Saving model ...
Validation loss decreased (0.399746 --> 0.399718).  Saving model ...
Validation loss decreased (0.399718 --> 0.399689).  Saving model ...
Validation loss decreased (0.399689 --> 0.399660).  Saving model ...
Validation loss decreased (0.399660 --> 0.399632).  Saving model ...
Validation loss decreased (0.399632 --> 0.399603).  Saving model ...
Validation loss decreased (0.399603 --> 0.399574).  Saving model ...
Validation loss decreased (0.399574 --> 0.399545).  Saving model ...
Validation loss decreased (0.399545 --> 0.399516).  Saving model ...
Validation loss decreased (0.399516 --> 0.399487).  Saving model ...
Validation loss decreased (0.399487 --> 0.399457).  Saving model ...
Validation loss decreased (0.399457 --> 0.399428).  Saving model ...
Validation loss decreased (0.399428 --> 0.399398).  Saving model ...
Validation loss decreased (0.399398 --> 0.399369).  Saving model ...
Validation loss decreased (0.399369 --> 0.399339).  Saving model ...
Validation loss decreased (0.399339 --> 0.399309).  Saving model ...
Validation loss decreased (0.399309 --> 0.399280).  Saving model ...
Validation loss decreased (0.399280 --> 0.399250).  Saving model ...
Validation loss decreased (0.399250 --> 0.399220).  Saving model ...
Validation loss decreased (0.399220 --> 0.399189).  Saving model ...
Validation loss decreased (0.399189 --> 0.399159).  Saving model ...
Validation loss decreased (0.399159 --> 0.399129).  Saving model ...
Validation loss decreased (0.399129 --> 0.399098).  Saving model ...
Validation loss decreased (0.399098 --> 0.399067).  Saving model ...
Validation loss decreased (0.399067 --> 0.399037).  Saving model ...
Validation loss decreased (0.399037 --> 0.399006).  Saving model ...
Validation loss decreased (0.399006 --> 0.398975).  Saving model ...
Validation loss decreased (0.398975 --> 0.398943).  Saving model ...
Validation loss decreased (0.398943 --> 0.398912).  Saving model ...
Validation loss decreased (0.398912 --> 0.398881).  Saving model ...
Validation loss decreased (0.398881 --> 0.398849).  Saving model ...
Validation loss decreased (0.398849 --> 0.398817).  Saving model ...
Validation loss decreased (0.398817 --> 0.398785).  Saving model ...
Validation loss decreased (0.398785 --> 0.398753).  Saving model ...
Validation loss decreased (0.398753 --> 0.398721).  Saving model ...
Validation loss decreased (0.398721 --> 0.398688).  Saving model ...
Validation loss decreased (0.398688 --> 0.398656).  Saving model ...
Validation loss decreased (0.398656 --> 0.398623).  Saving model ...
Validation loss decreased (0.398623 --> 0.398590).  Saving model ...
Validation loss decreased (0.398590 --> 0.398557).  Saving model ...
Validation loss decreased (0.398557 --> 0.398524).  Saving model ...
Validation loss decreased (0.398524 --> 0.398491).  Saving model ...
Validation loss decreased (0.398491 --> 0.398457).  Saving model ...
Validation loss decreased (0.398457 --> 0.398423).  Saving model ...
Validation loss decreased (0.398423 --> 0.398389).  Saving model ...
Validation loss decreased (0.398389 --> 0.398355).  Saving model ...
Validation loss decreased (0.398355 --> 0.398321).  Saving model ...
Validation loss decreased (0.398321 --> 0.398286).  Saving model ...
Validation loss decreased (0.398286 --> 0.398252).  Saving model ...
Validation loss decreased (0.398252 --> 0.398217).  Saving model ...
Validation loss decreased (0.398217 --> 0.398182).  Saving model ...
Validation loss decreased (0.398182 --> 0.398147).  Saving model ...
Validation loss decreased (0.398147 --> 0.398111).  Saving model ...
Validation loss decreased (0.398111 --> 0.398076).  Saving model ...
Validation loss decreased (0.398076 --> 0.398040).  Saving model ...
Validation loss decreased (0.398040 --> 0.398004).  Saving model ...
Validation loss decreased (0.398004 --> 0.397968).  Saving model ...
Validation loss decreased (0.397968 --> 0.397932).  Saving model ...
Validation loss decreased (0.397932 --> 0.397896).  Saving model ...
Validation loss decreased (0.397896 --> 0.397859).  Saving model ...
Validation loss decreased (0.397859 --> 0.397822).  Saving model ...
Validation loss decreased (0.397822 --> 0.397786).  Saving model ...
Validation loss decreased (0.397786 --> 0.397749).  Saving model ...
Validation loss decreased (0.397749 --> 0.397712).  Saving model ...
Validation loss decreased (0.397712 --> 0.397674).  Saving model ...
epoch 4801, loss 0.3977, train acc 80.31%, f1 0.7013, precision 0.7459, recall 0.6618, auc 0.7704
Validation loss decreased (0.397674 --> 0.397637).  Saving model ...
Validation loss decreased (0.397637 --> 0.397599).  Saving model ...
Validation loss decreased (0.397599 --> 0.397562).  Saving model ...
Validation loss decreased (0.397562 --> 0.397524).  Saving model ...
Validation loss decreased (0.397524 --> 0.397486).  Saving model ...
Validation loss decreased (0.397486 --> 0.397448).  Saving model ...
Validation loss decreased (0.397448 --> 0.397410).  Saving model ...
Validation loss decreased (0.397410 --> 0.397371).  Saving model ...
Validation loss decreased (0.397371 --> 0.397333).  Saving model ...
Validation loss decreased (0.397333 --> 0.397294).  Saving model ...
Validation loss decreased (0.397294 --> 0.397256).  Saving model ...
Validation loss decreased (0.397256 --> 0.397217).  Saving model ...
Validation loss decreased (0.397217 --> 0.397178).  Saving model ...
Validation loss decreased (0.397178 --> 0.397139).  Saving model ...
Validation loss decreased (0.397139 --> 0.397100).  Saving model ...
Validation loss decreased (0.397100 --> 0.397061).  Saving model ...
Validation loss decreased (0.397061 --> 0.397022).  Saving model ...
Validation loss decreased (0.397022 --> 0.396983).  Saving model ...
Validation loss decreased (0.396983 --> 0.396943).  Saving model ...
Validation loss decreased (0.396943 --> 0.396904).  Saving model ...
Validation loss decreased (0.396904 --> 0.396864).  Saving model ...
Validation loss decreased (0.396864 --> 0.396825).  Saving model ...
Validation loss decreased (0.396825 --> 0.396785).  Saving model ...
Validation loss decreased (0.396785 --> 0.396745).  Saving model ...
Validation loss decreased (0.396745 --> 0.396705).  Saving model ...
Validation loss decreased (0.396705 --> 0.396665).  Saving model ...
Validation loss decreased (0.396665 --> 0.396625).  Saving model ...
Validation loss decreased (0.396625 --> 0.396585).  Saving model ...
Validation loss decreased (0.396585 --> 0.396545).  Saving model ...
Validation loss decreased (0.396545 --> 0.396504).  Saving model ...
Validation loss decreased (0.396504 --> 0.396464).  Saving model ...
Validation loss decreased (0.396464 --> 0.396424).  Saving model ...
Validation loss decreased (0.396424 --> 0.396383).  Saving model ...
Validation loss decreased (0.396383 --> 0.396342).  Saving model ...
Validation loss decreased (0.396342 --> 0.396302).  Saving model ...
Validation loss decreased (0.396302 --> 0.396261).  Saving model ...
Validation loss decreased (0.396261 --> 0.396220).  Saving model ...
Validation loss decreased (0.396220 --> 0.396179).  Saving model ...
Validation loss decreased (0.396179 --> 0.396138).  Saving model ...
Validation loss decreased (0.396138 --> 0.396097).  Saving model ...
Validation loss decreased (0.396097 --> 0.396056).  Saving model ...
Validation loss decreased (0.396056 --> 0.396014).  Saving model ...
Validation loss decreased (0.396014 --> 0.395973).  Saving model ...
Validation loss decreased (0.395973 --> 0.395931).  Saving model ...
Validation loss decreased (0.395931 --> 0.395889).  Saving model ...
Validation loss decreased (0.395889 --> 0.395848).  Saving model ...
Validation loss decreased (0.395848 --> 0.395806).  Saving model ...
Validation loss decreased (0.395806 --> 0.395764).  Saving model ...
Validation loss decreased (0.395764 --> 0.395722).  Saving model ...
Validation loss decreased (0.395722 --> 0.395679).  Saving model ...
Validation loss decreased (0.395679 --> 0.395637).  Saving model ...
Validation loss decreased (0.395637 --> 0.395595).  Saving model ...
Validation loss decreased (0.395595 --> 0.395552).  Saving model ...
Validation loss decreased (0.395552 --> 0.395509).  Saving model ...
Validation loss decreased (0.395509 --> 0.395466).  Saving model ...
Validation loss decreased (0.395466 --> 0.395423).  Saving model ...
Validation loss decreased (0.395423 --> 0.395380).  Saving model ...
Validation loss decreased (0.395380 --> 0.395337).  Saving model ...
Validation loss decreased (0.395337 --> 0.395294).  Saving model ...
Validation loss decreased (0.395294 --> 0.395250).  Saving model ...
Validation loss decreased (0.395250 --> 0.395207).  Saving model ...
Validation loss decreased (0.395207 --> 0.395163).  Saving model ...
Validation loss decreased (0.395163 --> 0.395119).  Saving model ...
Validation loss decreased (0.395119 --> 0.395075).  Saving model ...
Validation loss decreased (0.395075 --> 0.395031).  Saving model ...
Validation loss decreased (0.395031 --> 0.394987).  Saving model ...
Validation loss decreased (0.394987 --> 0.394943).  Saving model ...
Validation loss decreased (0.394943 --> 0.394898).  Saving model ...
Validation loss decreased (0.394898 --> 0.394854).  Saving model ...
Validation loss decreased (0.394854 --> 0.394809).  Saving model ...
Validation loss decreased (0.394809 --> 0.394764).  Saving model ...
Validation loss decreased (0.394764 --> 0.394720).  Saving model ...
Validation loss decreased (0.394720 --> 0.394675).  Saving model ...
Validation loss decreased (0.394675 --> 0.394630).  Saving model ...
Validation loss decreased (0.394630 --> 0.394584).  Saving model ...
Validation loss decreased (0.394584 --> 0.394539).  Saving model ...
Validation loss decreased (0.394539 --> 0.394494).  Saving model ...
Validation loss decreased (0.394494 --> 0.394448).  Saving model ...
Validation loss decreased (0.394448 --> 0.394403).  Saving model ...
Validation loss decreased (0.394403 --> 0.394357).  Saving model ...
Validation loss decreased (0.394357 --> 0.394312).  Saving model ...
Validation loss decreased (0.394312 --> 0.394266).  Saving model ...
Validation loss decreased (0.394266 --> 0.394220).  Saving model ...
Validation loss decreased (0.394220 --> 0.394174).  Saving model ...
Validation loss decreased (0.394174 --> 0.394128).  Saving model ...
Validation loss decreased (0.394128 --> 0.394082).  Saving model ...
Validation loss decreased (0.394082 --> 0.394036).  Saving model ...
Validation loss decreased (0.394036 --> 0.393990).  Saving model ...
Validation loss decreased (0.393990 --> 0.393944).  Saving model ...
Validation loss decreased (0.393944 --> 0.393898).  Saving model ...
Validation loss decreased (0.393898 --> 0.393852).  Saving model ...
Validation loss decreased (0.393852 --> 0.393806).  Saving model ...
Validation loss decreased (0.393806 --> 0.393760).  Saving model ...
Validation loss decreased (0.393760 --> 0.393714).  Saving model ...
Validation loss decreased (0.393714 --> 0.393668).  Saving model ...
Validation loss decreased (0.393668 --> 0.393622).  Saving model ...
Validation loss decreased (0.393622 --> 0.393576).  Saving model ...
Validation loss decreased (0.393576 --> 0.393530).  Saving model ...
Validation loss decreased (0.393530 --> 0.393485).  Saving model ...
Validation loss decreased (0.393485 --> 0.393439).  Saving model ...
epoch 4901, loss 0.3934, train acc 80.99%, f1 0.7147, precision 0.7514, recall 0.6814, auc 0.7802
Validation loss decreased (0.393439 --> 0.393393).  Saving model ...
Validation loss decreased (0.393393 --> 0.393348).  Saving model ...
Validation loss decreased (0.393348 --> 0.393302).  Saving model ...
Validation loss decreased (0.393302 --> 0.393256).  Saving model ...
Validation loss decreased (0.393256 --> 0.393211).  Saving model ...
Validation loss decreased (0.393211 --> 0.393166).  Saving model ...
Validation loss decreased (0.393166 --> 0.393121).  Saving model ...
Validation loss decreased (0.393121 --> 0.393076).  Saving model ...
Validation loss decreased (0.393076 --> 0.393031).  Saving model ...
Validation loss decreased (0.393031 --> 0.392986).  Saving model ...
Validation loss decreased (0.392986 --> 0.392941).  Saving model ...
Validation loss decreased (0.392941 --> 0.392897).  Saving model ...
Validation loss decreased (0.392897 --> 0.392852).  Saving model ...
Validation loss decreased (0.392852 --> 0.392808).  Saving model ...
Validation loss decreased (0.392808 --> 0.392764).  Saving model ...
Validation loss decreased (0.392764 --> 0.392720).  Saving model ...
Validation loss decreased (0.392720 --> 0.392676).  Saving model ...
Validation loss decreased (0.392676 --> 0.392632).  Saving model ...
Validation loss decreased (0.392632 --> 0.392589).  Saving model ...
Validation loss decreased (0.392589 --> 0.392545).  Saving model ...
Validation loss decreased (0.392545 --> 0.392502).  Saving model ...
Validation loss decreased (0.392502 --> 0.392459).  Saving model ...
Validation loss decreased (0.392459 --> 0.392416).  Saving model ...
Validation loss decreased (0.392416 --> 0.392374).  Saving model ...
Validation loss decreased (0.392374 --> 0.392331).  Saving model ...
Validation loss decreased (0.392331 --> 0.392289).  Saving model ...
Validation loss decreased (0.392289 --> 0.392247).  Saving model ...
Validation loss decreased (0.392247 --> 0.392205).  Saving model ...
Validation loss decreased (0.392205 --> 0.392163).  Saving model ...
Validation loss decreased (0.392163 --> 0.392121).  Saving model ...
Validation loss decreased (0.392121 --> 0.392080).  Saving model ...
Validation loss decreased (0.392080 --> 0.392038).  Saving model ...
Validation loss decreased (0.392038 --> 0.391997).  Saving model ...
Validation loss decreased (0.391997 --> 0.391956).  Saving model ...
Validation loss decreased (0.391956 --> 0.391916).  Saving model ...
Validation loss decreased (0.391916 --> 0.391875).  Saving model ...
Validation loss decreased (0.391875 --> 0.391834).  Saving model ...
Validation loss decreased (0.391834 --> 0.391794).  Saving model ...
Validation loss decreased (0.391794 --> 0.391754).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.391754 --> 0.391714).  Saving model ...
Validation loss decreased (0.391714 --> 0.391674).  Saving model ...
Validation loss decreased (0.391674 --> 0.391634).  Saving model ...
Validation loss decreased (0.391634 --> 0.391594).  Saving model ...
Validation loss decreased (0.391594 --> 0.391555).  Saving model ...
Validation loss decreased (0.391555 --> 0.391516).  Saving model ...
Validation loss decreased (0.391516 --> 0.391476).  Saving model ...
Validation loss decreased (0.391476 --> 0.391437).  Saving model ...
Validation loss decreased (0.391437 --> 0.391398).  Saving model ...
Validation loss decreased (0.391398 --> 0.391359).  Saving model ...
Validation loss decreased (0.391359 --> 0.391321).  Saving model ...
Validation loss decreased (0.391321 --> 0.391282).  Saving model ...
Validation loss decreased (0.391282 --> 0.391244).  Saving model ...
Validation loss decreased (0.391244 --> 0.391205).  Saving model ...
Validation loss decreased (0.391205 --> 0.391167).  Saving model ...
Validation loss decreased (0.391167 --> 0.391129).  Saving model ...
Validation loss decreased (0.391129 --> 0.391090).  Saving model ...
Validation loss decreased (0.391090 --> 0.391052).  Saving model ...
Validation loss decreased (0.391052 --> 0.391014).  Saving model ...
Validation loss decreased (0.391014 --> 0.390977).  Saving model ...
Validation loss decreased (0.390977 --> 0.390939).  Saving model ...
Validation loss decreased (0.390939 --> 0.390901).  Saving model ...
Validation loss decreased (0.390901 --> 0.390864).  Saving model ...
Validation loss decreased (0.390864 --> 0.390826).  Saving model ...
Validation loss decreased (0.390826 --> 0.390788).  Saving model ...
Validation loss decreased (0.390788 --> 0.390751).  Saving model ...
Validation loss decreased (0.390751 --> 0.390714).  Saving model ...
Validation loss decreased (0.390714 --> 0.390676).  Saving model ...
Validation loss decreased (0.390676 --> 0.390639).  Saving model ...
Validation loss decreased (0.390639 --> 0.390602).  Saving model ...
Validation loss decreased (0.390602 --> 0.390565).  Saving model ...
Validation loss decreased (0.390565 --> 0.390528).  Saving model ...
Validation loss decreased (0.390528 --> 0.390491).  Saving model ...
Validation loss decreased (0.390491 --> 0.390454).  Saving model ...
Validation loss decreased (0.390454 --> 0.390417).  Saving model ...
Validation loss decreased (0.390417 --> 0.390380).  Saving model ...
Validation loss decreased (0.390380 --> 0.390343).  Saving model ...
Validation loss decreased (0.390343 --> 0.390306).  Saving model ...
Validation loss decreased (0.390306 --> 0.390269).  Saving model ...
Validation loss decreased (0.390269 --> 0.390233).  Saving model ...
Validation loss decreased (0.390233 --> 0.390196).  Saving model ...
Validation loss decreased (0.390196 --> 0.390159).  Saving model ...
Validation loss decreased (0.390159 --> 0.390122).  Saving model ...
Validation loss decreased (0.390122 --> 0.390086).  Saving model ...
Validation loss decreased (0.390086 --> 0.390049).  Saving model ...
Validation loss decreased (0.390049 --> 0.390012).  Saving model ...
Validation loss decreased (0.390012 --> 0.389976).  Saving model ...
Validation loss decreased (0.389976 --> 0.389939).  Saving model ...
Validation loss decreased (0.389939 --> 0.389903).  Saving model ...
Validation loss decreased (0.389903 --> 0.389866).  Saving model ...
Validation loss decreased (0.389866 --> 0.389830).  Saving model ...
Validation loss decreased (0.389830 --> 0.389793).  Saving model ...
Validation loss decreased (0.389793 --> 0.389757).  Saving model ...
Validation loss decreased (0.389757 --> 0.389720).  Saving model ...
Validation loss decreased (0.389720 --> 0.389684).  Saving model ...
Validation loss decreased (0.389684 --> 0.389647).  Saving model ...
Validation loss decreased (0.389647 --> 0.389611).  Saving model ...
Validation loss decreased (0.389611 --> 0.389574).  Saving model ...
Validation loss decreased (0.389574 --> 0.389537).  Saving model ...
Validation loss decreased (0.389537 --> 0.389501).  Saving model ...
Validation loss decreased (0.389501 --> 0.389464).  Saving model ...
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_2.csv
./test_pima/standlization_data/pima_std_test_2.csv
MLP_normal_True
normal_normal
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_2
./test_pima/result_MLP_normal_True_normal_normal/record_1/
----------------------



Traceback (most recent call last):
  File "./classifier_MLP/test.py", line 193, in <module>
    transform_method, ref_data_type, ref_num_type, ref_times, boundary_type = get_test_info(test_method)
  File "./classifier_MLP/test.py", line 137, in get_test_info
    return transform_method, ref_data_type, ref_num_type, ref_times, boundary_type
UnboundLocalError: local variable 'transform_method' referenced before assignment
