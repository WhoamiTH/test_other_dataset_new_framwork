nohup: ignoring input
./test_abalone19/standlization_data/abalone19_std_train_3.csv
./test_abalone19/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_3
----------------------



epoch 1, loss 0.6934, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693145).  Saving model ...
Validation loss decreased (0.693145 --> 0.692861).  Saving model ...
Validation loss decreased (0.692861 --> 0.692597).  Saving model ...
Validation loss decreased (0.692597 --> 0.692318).  Saving model ...
Validation loss decreased (0.692318 --> 0.692009).  Saving model ...
Validation loss decreased (0.692009 --> 0.691662).  Saving model ...
Validation loss decreased (0.691662 --> 0.691271).  Saving model ...
Validation loss decreased (0.691271 --> 0.690829).  Saving model ...
Validation loss decreased (0.690829 --> 0.690327).  Saving model ...
Validation loss decreased (0.690327 --> 0.689758).  Saving model ...
Validation loss decreased (0.689758 --> 0.689118).  Saving model ...
Validation loss decreased (0.689118 --> 0.688402).  Saving model ...
Validation loss decreased (0.688402 --> 0.687608).  Saving model ...
Validation loss decreased (0.687608 --> 0.686732).  Saving model ...
Validation loss decreased (0.686732 --> 0.685772).  Saving model ...
Validation loss decreased (0.685772 --> 0.684726).  Saving model ...
Validation loss decreased (0.684726 --> 0.683592).  Saving model ...
Validation loss decreased (0.683592 --> 0.682366).  Saving model ...
Validation loss decreased (0.682366 --> 0.681049).  Saving model ...
Validation loss decreased (0.681049 --> 0.679637).  Saving model ...
Validation loss decreased (0.679637 --> 0.678129).  Saving model ...
Validation loss decreased (0.678129 --> 0.676524).  Saving model ...
Validation loss decreased (0.676524 --> 0.674820).  Saving model ...
Validation loss decreased (0.674820 --> 0.673017).  Saving model ...
Validation loss decreased (0.673017 --> 0.671114).  Saving model ...
Validation loss decreased (0.671114 --> 0.669110).  Saving model ...
Validation loss decreased (0.669110 --> 0.667005).  Saving model ...
Validation loss decreased (0.667005 --> 0.664800).  Saving model ...
Validation loss decreased (0.664800 --> 0.662494).  Saving model ...
Validation loss decreased (0.662494 --> 0.660087).  Saving model ...
Validation loss decreased (0.660087 --> 0.657582).  Saving model ...
Validation loss decreased (0.657582 --> 0.654978).  Saving model ...
Validation loss decreased (0.654978 --> 0.652277).  Saving model ...
Validation loss decreased (0.652277 --> 0.649480).  Saving model ...
Validation loss decreased (0.649480 --> 0.646590).  Saving model ...
Validation loss decreased (0.646590 --> 0.643608).  Saving model ...
Validation loss decreased (0.643608 --> 0.640537).  Saving model ...
Validation loss decreased (0.640537 --> 0.637378).  Saving model ...
Validation loss decreased (0.637378 --> 0.634135).  Saving model ...
Validation loss decreased (0.634135 --> 0.630812).  Saving model ...
Validation loss decreased (0.630812 --> 0.627410).  Saving model ...
Validation loss decreased (0.627410 --> 0.623934).  Saving model ...
Validation loss decreased (0.623934 --> 0.620387).  Saving model ...
Validation loss decreased (0.620387 --> 0.616771).  Saving model ...
Validation loss decreased (0.616771 --> 0.613092).  Saving model ...
Validation loss decreased (0.613092 --> 0.609353).  Saving model ...
Validation loss decreased (0.609353 --> 0.605558).  Saving model ...
Validation loss decreased (0.605558 --> 0.601711).  Saving model ...
Validation loss decreased (0.601711 --> 0.597816).  Saving model ...
Validation loss decreased (0.597816 --> 0.593878).  Saving model ...
Validation loss decreased (0.593878 --> 0.589901).  Saving model ...
Validation loss decreased (0.589901 --> 0.585889).  Saving model ...
Validation loss decreased (0.585889 --> 0.581847).  Saving model ...
Validation loss decreased (0.581847 --> 0.577779).  Saving model ...
Validation loss decreased (0.577779 --> 0.573690).  Saving model ...
Validation loss decreased (0.573690 --> 0.569582).  Saving model ...
Validation loss decreased (0.569582 --> 0.565461).  Saving model ...
Validation loss decreased (0.565461 --> 0.561332).  Saving model ...
Validation loss decreased (0.561332 --> 0.557199).  Saving model ...
Validation loss decreased (0.557199 --> 0.553065).  Saving model ...
Validation loss decreased (0.553065 --> 0.548934).  Saving model ...
Validation loss decreased (0.548934 --> 0.544810).  Saving model ...
Validation loss decreased (0.544810 --> 0.540697).  Saving model ...
Validation loss decreased (0.540697 --> 0.536599).  Saving model ...
Validation loss decreased (0.536599 --> 0.532519).  Saving model ...
Validation loss decreased (0.532519 --> 0.528462).  Saving model ...
Validation loss decreased (0.528462 --> 0.524429).  Saving model ...
Validation loss decreased (0.524429 --> 0.520425).  Saving model ...
Validation loss decreased (0.520425 --> 0.516451).  Saving model ...
Validation loss decreased (0.516451 --> 0.512511).  Saving model ...
Validation loss decreased (0.512511 --> 0.508608).  Saving model ...
Validation loss decreased (0.508608 --> 0.504741).  Saving model ...
Validation loss decreased (0.504741 --> 0.500915).  Saving model ...
Validation loss decreased (0.500915 --> 0.497131).  Saving model ...
Validation loss decreased (0.497131 --> 0.493390).  Saving model ...
Validation loss decreased (0.493390 --> 0.489696).  Saving model ...
Validation loss decreased (0.489696 --> 0.486050).  Saving model ...
Validation loss decreased (0.486050 --> 0.482451).  Saving model ...
Validation loss decreased (0.482451 --> 0.478900).  Saving model ...
Validation loss decreased (0.478900 --> 0.475399).  Saving model ...
Validation loss decreased (0.475399 --> 0.471949).  Saving model ...
Validation loss decreased (0.471949 --> 0.468551).  Saving model ...
Validation loss decreased (0.468551 --> 0.465205).  Saving model ...
Validation loss decreased (0.465205 --> 0.461911).  Saving model ...
Validation loss decreased (0.461911 --> 0.458671).  Saving model ...
Validation loss decreased (0.458671 --> 0.455484).  Saving model ...
Validation loss decreased (0.455484 --> 0.452350).  Saving model ...
Validation loss decreased (0.452350 --> 0.449269).  Saving model ...
Validation loss decreased (0.449269 --> 0.446242).  Saving model ...
Validation loss decreased (0.446242 --> 0.443266).  Saving model ...
Validation loss decreased (0.443266 --> 0.440344).  Saving model ...
Validation loss decreased (0.440344 --> 0.437473).  Saving model ...
Validation loss decreased (0.437473 --> 0.434655).  Saving model ...
Validation loss decreased (0.434655 --> 0.431887).  Saving model ...
Validation loss decreased (0.431887 --> 0.429170).  Saving model ...
Validation loss decreased (0.429170 --> 0.426503).  Saving model ...
Validation loss decreased (0.426503 --> 0.423885).  Saving model ...
Validation loss decreased (0.423885 --> 0.421314).  Saving model ...
Validation loss decreased (0.421314 --> 0.418790).  Saving model ...
Validation loss decreased (0.418790 --> 0.416311).  Saving model ...
epoch 101, loss 0.5377, train acc 87.88%, f1 0.8788, precision 0.8788, recall 0.8788, auc 0.8788
Validation loss decreased (0.416311 --> 0.413877).  Saving model ...
Validation loss decreased (0.413877 --> 0.411488).  Saving model ...
Validation loss decreased (0.411488 --> 0.409141).  Saving model ...
Validation loss decreased (0.409141 --> 0.406838).  Saving model ...
Validation loss decreased (0.406838 --> 0.404576).  Saving model ...
Validation loss decreased (0.404576 --> 0.402354).  Saving model ...
Validation loss decreased (0.402354 --> 0.400171).  Saving model ...
Validation loss decreased (0.400171 --> 0.398027).  Saving model ...
Validation loss decreased (0.398027 --> 0.395919).  Saving model ...
Validation loss decreased (0.395919 --> 0.393847).  Saving model ...
Validation loss decreased (0.393847 --> 0.391811).  Saving model ...
Validation loss decreased (0.391811 --> 0.389809).  Saving model ...
Validation loss decreased (0.389809 --> 0.387841).  Saving model ...
Validation loss decreased (0.387841 --> 0.385908).  Saving model ...
Validation loss decreased (0.385908 --> 0.384007).  Saving model ...
Validation loss decreased (0.384007 --> 0.382139).  Saving model ...
Validation loss decreased (0.382139 --> 0.380299).  Saving model ...
Validation loss decreased (0.380299 --> 0.378490).  Saving model ...
Validation loss decreased (0.378490 --> 0.376710).  Saving model ...
Validation loss decreased (0.376710 --> 0.374958).  Saving model ...
Validation loss decreased (0.374958 --> 0.373233).  Saving model ...
Validation loss decreased (0.373233 --> 0.371537).  Saving model ...
Validation loss decreased (0.371537 --> 0.369867).  Saving model ...
Validation loss decreased (0.369867 --> 0.368222).  Saving model ...
Validation loss decreased (0.368222 --> 0.366603).  Saving model ...
Validation loss decreased (0.366603 --> 0.365008).  Saving model ...
Validation loss decreased (0.365008 --> 0.363437).  Saving model ...
Validation loss decreased (0.363437 --> 0.361888).  Saving model ...
Validation loss decreased (0.361888 --> 0.360360).  Saving model ...
Validation loss decreased (0.360360 --> 0.358853).  Saving model ...
Validation loss decreased (0.358853 --> 0.357366).  Saving model ...
Validation loss decreased (0.357366 --> 0.355900).  Saving model ...
Validation loss decreased (0.355900 --> 0.354454).  Saving model ...
Validation loss decreased (0.354454 --> 0.353027).  Saving model ...
Validation loss decreased (0.353027 --> 0.351619).  Saving model ...
Validation loss decreased (0.351619 --> 0.350230).  Saving model ...
Validation loss decreased (0.350230 --> 0.348858).  Saving model ...
Validation loss decreased (0.348858 --> 0.347504).  Saving model ...
Validation loss decreased (0.347504 --> 0.346167).  Saving model ...
Validation loss decreased (0.346167 --> 0.344846).  Saving model ...
Validation loss decreased (0.344846 --> 0.343539).  Saving model ...
Validation loss decreased (0.343539 --> 0.342247).  Saving model ...
Validation loss decreased (0.342247 --> 0.340967).  Saving model ...
Validation loss decreased (0.340967 --> 0.339703).  Saving model ...
Validation loss decreased (0.339703 --> 0.338454).  Saving model ...
Validation loss decreased (0.338454 --> 0.337219).  Saving model ...
Validation loss decreased (0.337219 --> 0.335997).  Saving model ...
Validation loss decreased (0.335997 --> 0.334789).  Saving model ...
Validation loss decreased (0.334789 --> 0.333594).  Saving model ...
Validation loss decreased (0.333594 --> 0.332411).  Saving model ...
Validation loss decreased (0.332411 --> 0.331239).  Saving model ...
Validation loss decreased (0.331239 --> 0.330079).  Saving model ...
Validation loss decreased (0.330079 --> 0.328929).  Saving model ...
Validation loss decreased (0.328929 --> 0.327789).  Saving model ...
Validation loss decreased (0.327789 --> 0.326661).  Saving model ...
Validation loss decreased (0.326661 --> 0.325542).  Saving model ...
Validation loss decreased (0.325542 --> 0.324433).  Saving model ...
Validation loss decreased (0.324433 --> 0.323331).  Saving model ...
Validation loss decreased (0.323331 --> 0.322238).  Saving model ...
Validation loss decreased (0.322238 --> 0.321153).  Saving model ...
Validation loss decreased (0.321153 --> 0.320077).  Saving model ...
Validation loss decreased (0.320077 --> 0.319008).  Saving model ...
Validation loss decreased (0.319008 --> 0.317947).  Saving model ...
Validation loss decreased (0.317947 --> 0.316895).  Saving model ...
Validation loss decreased (0.316895 --> 0.315849).  Saving model ...
Validation loss decreased (0.315849 --> 0.314810).  Saving model ...
Validation loss decreased (0.314810 --> 0.313778).  Saving model ...
Validation loss decreased (0.313778 --> 0.312752).  Saving model ...
Validation loss decreased (0.312752 --> 0.311734).  Saving model ...
Validation loss decreased (0.311734 --> 0.310722).  Saving model ...
Validation loss decreased (0.310722 --> 0.309717).  Saving model ...
Validation loss decreased (0.309717 --> 0.308718).  Saving model ...
Validation loss decreased (0.308718 --> 0.307725).  Saving model ...
Validation loss decreased (0.307725 --> 0.306738).  Saving model ...
Validation loss decreased (0.306738 --> 0.305755).  Saving model ...
Validation loss decreased (0.305755 --> 0.304777).  Saving model ...
Validation loss decreased (0.304777 --> 0.303805).  Saving model ...
Validation loss decreased (0.303805 --> 0.302837).  Saving model ...
Validation loss decreased (0.302837 --> 0.301873).  Saving model ...
Validation loss decreased (0.301873 --> 0.300915).  Saving model ...
Validation loss decreased (0.300915 --> 0.299961).  Saving model ...
Validation loss decreased (0.299961 --> 0.299011).  Saving model ...
Validation loss decreased (0.299011 --> 0.298064).  Saving model ...
Validation loss decreased (0.298064 --> 0.297120).  Saving model ...
Validation loss decreased (0.297120 --> 0.296179).  Saving model ...
Validation loss decreased (0.296179 --> 0.295241).  Saving model ...
Validation loss decreased (0.295241 --> 0.294306).  Saving model ...
Validation loss decreased (0.294306 --> 0.293373).  Saving model ...
Validation loss decreased (0.293373 --> 0.292443).  Saving model ...
Validation loss decreased (0.292443 --> 0.291517).  Saving model ...
Validation loss decreased (0.291517 --> 0.290593).  Saving model ...
Validation loss decreased (0.290593 --> 0.289672).  Saving model ...
Validation loss decreased (0.289672 --> 0.288755).  Saving model ...
Validation loss decreased (0.288755 --> 0.287838).  Saving model ...
Validation loss decreased (0.287838 --> 0.286925).  Saving model ...
Validation loss decreased (0.286925 --> 0.286013).  Saving model ...
Validation loss decreased (0.286013 --> 0.285104).  Saving model ...
Validation loss decreased (0.285104 --> 0.284197).  Saving model ...
Validation loss decreased (0.284197 --> 0.283291).  Saving model ...
Validation loss decreased (0.283291 --> 0.282388).  Saving model ...
epoch 201, loss 0.4562, train acc 93.33%, f1 0.9333, precision 0.9333, recall 0.9333, auc 0.9333
Validation loss decreased (0.282388 --> 0.281485).  Saving model ...
Validation loss decreased (0.281485 --> 0.280584).  Saving model ...
Validation loss decreased (0.280584 --> 0.279683).  Saving model ...
Validation loss decreased (0.279683 --> 0.278785).  Saving model ...
Validation loss decreased (0.278785 --> 0.277889).  Saving model ...
Validation loss decreased (0.277889 --> 0.276995).  Saving model ...
Validation loss decreased (0.276995 --> 0.276102).  Saving model ...
Validation loss decreased (0.276102 --> 0.275211).  Saving model ...
Validation loss decreased (0.275211 --> 0.274321).  Saving model ...
Validation loss decreased (0.274321 --> 0.273433).  Saving model ...
Validation loss decreased (0.273433 --> 0.272547).  Saving model ...
Validation loss decreased (0.272547 --> 0.271661).  Saving model ...
Validation loss decreased (0.271661 --> 0.270775).  Saving model ...
Validation loss decreased (0.270775 --> 0.269891).  Saving model ...
Validation loss decreased (0.269891 --> 0.269008).  Saving model ...
Validation loss decreased (0.269008 --> 0.268125).  Saving model ...
Validation loss decreased (0.268125 --> 0.267245).  Saving model ...
Validation loss decreased (0.267245 --> 0.266364).  Saving model ...
Validation loss decreased (0.266364 --> 0.265485).  Saving model ...
Validation loss decreased (0.265485 --> 0.264604).  Saving model ...
Validation loss decreased (0.264604 --> 0.263724).  Saving model ...
Validation loss decreased (0.263724 --> 0.262845).  Saving model ...
Validation loss decreased (0.262845 --> 0.261966).  Saving model ...
Validation loss decreased (0.261966 --> 0.261090).  Saving model ...
Validation loss decreased (0.261090 --> 0.260215).  Saving model ...
Validation loss decreased (0.260215 --> 0.259340).  Saving model ...
Validation loss decreased (0.259340 --> 0.258467).  Saving model ...
Validation loss decreased (0.258467 --> 0.257593).  Saving model ...
Validation loss decreased (0.257593 --> 0.256718).  Saving model ...
Validation loss decreased (0.256718 --> 0.255841).  Saving model ...
Validation loss decreased (0.255841 --> 0.254965).  Saving model ...
Validation loss decreased (0.254965 --> 0.254087).  Saving model ...
Validation loss decreased (0.254087 --> 0.253210).  Saving model ...
Validation loss decreased (0.253210 --> 0.252332).  Saving model ...
Validation loss decreased (0.252332 --> 0.251454).  Saving model ...
Validation loss decreased (0.251454 --> 0.250573).  Saving model ...
Validation loss decreased (0.250573 --> 0.249693).  Saving model ...
Validation loss decreased (0.249693 --> 0.248814).  Saving model ...
Validation loss decreased (0.248814 --> 0.247935).  Saving model ...
Validation loss decreased (0.247935 --> 0.247057).  Saving model ...
Validation loss decreased (0.247057 --> 0.246178).  Saving model ...
Validation loss decreased (0.246178 --> 0.245301).  Saving model ...
Validation loss decreased (0.245301 --> 0.244423).  Saving model ...
Validation loss decreased (0.244423 --> 0.243547).  Saving model ...
Validation loss decreased (0.243547 --> 0.242670).  Saving model ...
Validation loss decreased (0.242670 --> 0.241793).  Saving model ...
Validation loss decreased (0.241793 --> 0.240912).  Saving model ...
Validation loss decreased (0.240912 --> 0.240031).  Saving model ...
Validation loss decreased (0.240031 --> 0.239150).  Saving model ...
Validation loss decreased (0.239150 --> 0.238268).  Saving model ...
Validation loss decreased (0.238268 --> 0.237385).  Saving model ...
Validation loss decreased (0.237385 --> 0.236501).  Saving model ...
Validation loss decreased (0.236501 --> 0.235617).  Saving model ...
Validation loss decreased (0.235617 --> 0.234730).  Saving model ...
Validation loss decreased (0.234730 --> 0.233843).  Saving model ...
Validation loss decreased (0.233843 --> 0.232955).  Saving model ...
Validation loss decreased (0.232955 --> 0.232066).  Saving model ...
Validation loss decreased (0.232066 --> 0.231174).  Saving model ...
Validation loss decreased (0.231174 --> 0.230282).  Saving model ...
Validation loss decreased (0.230282 --> 0.229390).  Saving model ...
Validation loss decreased (0.229390 --> 0.228498).  Saving model ...
Validation loss decreased (0.228498 --> 0.227607).  Saving model ...
Validation loss decreased (0.227607 --> 0.226714).  Saving model ...
Validation loss decreased (0.226714 --> 0.225819).  Saving model ...
Validation loss decreased (0.225819 --> 0.224922).  Saving model ...
Validation loss decreased (0.224922 --> 0.224025).  Saving model ...
Validation loss decreased (0.224025 --> 0.223127).  Saving model ...
Validation loss decreased (0.223127 --> 0.222227).  Saving model ...
Validation loss decreased (0.222227 --> 0.221329).  Saving model ...
Validation loss decreased (0.221329 --> 0.220430).  Saving model ...
Validation loss decreased (0.220430 --> 0.219531).  Saving model ...
Validation loss decreased (0.219531 --> 0.218630).  Saving model ...
Validation loss decreased (0.218630 --> 0.217729).  Saving model ...
Validation loss decreased (0.217729 --> 0.216826).  Saving model ...
Validation loss decreased (0.216826 --> 0.215923).  Saving model ...
Validation loss decreased (0.215923 --> 0.215021).  Saving model ...
Validation loss decreased (0.215021 --> 0.214117).  Saving model ...
Validation loss decreased (0.214117 --> 0.213213).  Saving model ...
Validation loss decreased (0.213213 --> 0.212306).  Saving model ...
Validation loss decreased (0.212306 --> 0.211398).  Saving model ...
Validation loss decreased (0.211398 --> 0.210492).  Saving model ...
Validation loss decreased (0.210492 --> 0.209585).  Saving model ...
Validation loss decreased (0.209585 --> 0.208680).  Saving model ...
Validation loss decreased (0.208680 --> 0.207772).  Saving model ...
Validation loss decreased (0.207772 --> 0.206866).  Saving model ...
Validation loss decreased (0.206866 --> 0.205962).  Saving model ...
Validation loss decreased (0.205962 --> 0.205058).  Saving model ...
Validation loss decreased (0.205058 --> 0.204156).  Saving model ...
Validation loss decreased (0.204156 --> 0.203253).  Saving model ...
Validation loss decreased (0.203253 --> 0.202353).  Saving model ...
Validation loss decreased (0.202353 --> 0.201453).  Saving model ...
Validation loss decreased (0.201453 --> 0.200555).  Saving model ...
Validation loss decreased (0.200555 --> 0.199659).  Saving model ...
Validation loss decreased (0.199659 --> 0.198767).  Saving model ...
Validation loss decreased (0.198767 --> 0.197877).  Saving model ...
Validation loss decreased (0.197877 --> 0.196988).  Saving model ...
Validation loss decreased (0.196988 --> 0.196101).  Saving model ...
Validation loss decreased (0.196101 --> 0.195217).  Saving model ...
Validation loss decreased (0.195217 --> 0.194333).  Saving model ...
Validation loss decreased (0.194333 --> 0.193450).  Saving model ...
epoch 301, loss 0.3621, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.193450 --> 0.192569).  Saving model ...
Validation loss decreased (0.192569 --> 0.191690).  Saving model ...
Validation loss decreased (0.191690 --> 0.190812).  Saving model ...
Validation loss decreased (0.190812 --> 0.189937).  Saving model ...
Validation loss decreased (0.189937 --> 0.189065).  Saving model ...
Validation loss decreased (0.189065 --> 0.188196).  Saving model ...
Validation loss decreased (0.188196 --> 0.187329).  Saving model ...
Validation loss decreased (0.187329 --> 0.186465).  Saving model ...
Validation loss decreased (0.186465 --> 0.185604).  Saving model ...
Validation loss decreased (0.185604 --> 0.184743).  Saving model ...
Validation loss decreased (0.184743 --> 0.183885).  Saving model ...
Validation loss decreased (0.183885 --> 0.183031).  Saving model ...
Validation loss decreased (0.183031 --> 0.182177).  Saving model ...
Validation loss decreased (0.182177 --> 0.181326).  Saving model ...
Validation loss decreased (0.181326 --> 0.180476).  Saving model ...
Validation loss decreased (0.180476 --> 0.179630).  Saving model ...
Validation loss decreased (0.179630 --> 0.178785).  Saving model ...
Validation loss decreased (0.178785 --> 0.177944).  Saving model ...
Validation loss decreased (0.177944 --> 0.177105).  Saving model ...
Validation loss decreased (0.177105 --> 0.176269).  Saving model ...
Validation loss decreased (0.176269 --> 0.175437).  Saving model ...
Validation loss decreased (0.175437 --> 0.174606).  Saving model ...
Validation loss decreased (0.174606 --> 0.173778).  Saving model ...
Validation loss decreased (0.173778 --> 0.172953).  Saving model ...
Validation loss decreased (0.172953 --> 0.172132).  Saving model ...
Validation loss decreased (0.172132 --> 0.171314).  Saving model ...
Validation loss decreased (0.171314 --> 0.170501).  Saving model ...
Validation loss decreased (0.170501 --> 0.169692).  Saving model ...
Validation loss decreased (0.169692 --> 0.168884).  Saving model ...
Validation loss decreased (0.168884 --> 0.168078).  Saving model ...
Validation loss decreased (0.168078 --> 0.167278).  Saving model ...
Validation loss decreased (0.167278 --> 0.166482).  Saving model ...
Validation loss decreased (0.166482 --> 0.165689).  Saving model ...
Validation loss decreased (0.165689 --> 0.164901).  Saving model ...
Validation loss decreased (0.164901 --> 0.164118).  Saving model ...
Validation loss decreased (0.164118 --> 0.163338).  Saving model ...
Validation loss decreased (0.163338 --> 0.162562).  Saving model ...
Validation loss decreased (0.162562 --> 0.161790).  Saving model ...
Validation loss decreased (0.161790 --> 0.161023).  Saving model ...
Validation loss decreased (0.161023 --> 0.160262).  Saving model ...
Validation loss decreased (0.160262 --> 0.159505).  Saving model ...
Validation loss decreased (0.159505 --> 0.158750).  Saving model ...
Validation loss decreased (0.158750 --> 0.158002).  Saving model ...
Validation loss decreased (0.158002 --> 0.157257).  Saving model ...
Validation loss decreased (0.157257 --> 0.156517).  Saving model ...
Validation loss decreased (0.156517 --> 0.155781).  Saving model ...
Validation loss decreased (0.155781 --> 0.155049).  Saving model ...
Validation loss decreased (0.155049 --> 0.154323).  Saving model ...
Validation loss decreased (0.154323 --> 0.153601).  Saving model ...
Validation loss decreased (0.153601 --> 0.152884).  Saving model ...
Validation loss decreased (0.152884 --> 0.152171).  Saving model ...
Validation loss decreased (0.152171 --> 0.151465).  Saving model ...
Validation loss decreased (0.151465 --> 0.150766).  Saving model ...
Validation loss decreased (0.150766 --> 0.150072).  Saving model ...
Validation loss decreased (0.150072 --> 0.149382).  Saving model ...
Validation loss decreased (0.149382 --> 0.148697).  Saving model ...
Validation loss decreased (0.148697 --> 0.148016).  Saving model ...
Validation loss decreased (0.148016 --> 0.147341).  Saving model ...
Validation loss decreased (0.147341 --> 0.146671).  Saving model ...
Validation loss decreased (0.146671 --> 0.146005).  Saving model ...
Validation loss decreased (0.146005 --> 0.145344).  Saving model ...
Validation loss decreased (0.145344 --> 0.144688).  Saving model ...
Validation loss decreased (0.144688 --> 0.144036).  Saving model ...
Validation loss decreased (0.144036 --> 0.143390).  Saving model ...
Validation loss decreased (0.143390 --> 0.142748).  Saving model ...
Validation loss decreased (0.142748 --> 0.142111).  Saving model ...
Validation loss decreased (0.142111 --> 0.141478).  Saving model ...
Validation loss decreased (0.141478 --> 0.140850).  Saving model ...
Validation loss decreased (0.140850 --> 0.140226).  Saving model ...
Validation loss decreased (0.140226 --> 0.139606).  Saving model ...
Validation loss decreased (0.139606 --> 0.138991).  Saving model ...
Validation loss decreased (0.138991 --> 0.138378).  Saving model ...
Validation loss decreased (0.138378 --> 0.137772).  Saving model ...
Validation loss decreased (0.137772 --> 0.137168).  Saving model ...
Validation loss decreased (0.137168 --> 0.136568).  Saving model ...
Validation loss decreased (0.136568 --> 0.135972).  Saving model ...
Validation loss decreased (0.135972 --> 0.135380).  Saving model ...
Validation loss decreased (0.135380 --> 0.134792).  Saving model ...
Validation loss decreased (0.134792 --> 0.134210).  Saving model ...
Validation loss decreased (0.134210 --> 0.133632).  Saving model ...
Validation loss decreased (0.133632 --> 0.133058).  Saving model ...
Validation loss decreased (0.133058 --> 0.132488).  Saving model ...
Validation loss decreased (0.132488 --> 0.131924).  Saving model ...
Validation loss decreased (0.131924 --> 0.131364).  Saving model ...
Validation loss decreased (0.131364 --> 0.130811).  Saving model ...
Validation loss decreased (0.130811 --> 0.130259).  Saving model ...
Validation loss decreased (0.130259 --> 0.129711).  Saving model ...
Validation loss decreased (0.129711 --> 0.129165).  Saving model ...
Validation loss decreased (0.129165 --> 0.128621).  Saving model ...
Validation loss decreased (0.128621 --> 0.128083).  Saving model ...
Validation loss decreased (0.128083 --> 0.127552).  Saving model ...
Validation loss decreased (0.127552 --> 0.127025).  Saving model ...
Validation loss decreased (0.127025 --> 0.126503).  Saving model ...
Validation loss decreased (0.126503 --> 0.125985).  Saving model ...
Validation loss decreased (0.125985 --> 0.125474).  Saving model ...
Validation loss decreased (0.125474 --> 0.124965).  Saving model ...
Validation loss decreased (0.124965 --> 0.124462).  Saving model ...
Validation loss decreased (0.124462 --> 0.123964).  Saving model ...
Validation loss decreased (0.123964 --> 0.123471).  Saving model ...
Validation loss decreased (0.123471 --> 0.122984).  Saving model ...
epoch 401, loss 0.2893, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.122984 --> 0.122500).  Saving model ...
Validation loss decreased (0.122500 --> 0.122019).  Saving model ...
Validation loss decreased (0.122019 --> 0.121543).  Saving model ...
Validation loss decreased (0.121543 --> 0.121071).  Saving model ...
Validation loss decreased (0.121071 --> 0.120602).  Saving model ...
Validation loss decreased (0.120602 --> 0.120137).  Saving model ...
Validation loss decreased (0.120137 --> 0.119677).  Saving model ...
Validation loss decreased (0.119677 --> 0.119220).  Saving model ...
Validation loss decreased (0.119220 --> 0.118767).  Saving model ...
Validation loss decreased (0.118767 --> 0.118317).  Saving model ...
Validation loss decreased (0.118317 --> 0.117870).  Saving model ...
Validation loss decreased (0.117870 --> 0.117428).  Saving model ...
Validation loss decreased (0.117428 --> 0.116991).  Saving model ...
Validation loss decreased (0.116991 --> 0.116554).  Saving model ...
Validation loss decreased (0.116554 --> 0.116121).  Saving model ...
Validation loss decreased (0.116121 --> 0.115692).  Saving model ...
Validation loss decreased (0.115692 --> 0.115266).  Saving model ...
Validation loss decreased (0.115266 --> 0.114845).  Saving model ...
Validation loss decreased (0.114845 --> 0.114426).  Saving model ...
Validation loss decreased (0.114426 --> 0.114012).  Saving model ...
Validation loss decreased (0.114012 --> 0.113601).  Saving model ...
Validation loss decreased (0.113601 --> 0.113193).  Saving model ...
Validation loss decreased (0.113193 --> 0.112787).  Saving model ...
Validation loss decreased (0.112787 --> 0.112387).  Saving model ...
Validation loss decreased (0.112387 --> 0.111990).  Saving model ...
Validation loss decreased (0.111990 --> 0.111597).  Saving model ...
Validation loss decreased (0.111597 --> 0.111206).  Saving model ...
Validation loss decreased (0.111206 --> 0.110819).  Saving model ...
Validation loss decreased (0.110819 --> 0.110432).  Saving model ...
Validation loss decreased (0.110432 --> 0.110049).  Saving model ...
Validation loss decreased (0.110049 --> 0.109669).  Saving model ...
Validation loss decreased (0.109669 --> 0.109291).  Saving model ...
Validation loss decreased (0.109291 --> 0.108917).  Saving model ...
Validation loss decreased (0.108917 --> 0.108547).  Saving model ...
Validation loss decreased (0.108547 --> 0.108178).  Saving model ...
Validation loss decreased (0.108178 --> 0.107812).  Saving model ...
Validation loss decreased (0.107812 --> 0.107448).  Saving model ...
Validation loss decreased (0.107448 --> 0.107090).  Saving model ...
Validation loss decreased (0.107090 --> 0.106732).  Saving model ...
Validation loss decreased (0.106732 --> 0.106379).  Saving model ...
Validation loss decreased (0.106379 --> 0.106027).  Saving model ...
Validation loss decreased (0.106027 --> 0.105678).  Saving model ...
Validation loss decreased (0.105678 --> 0.105332).  Saving model ...
Validation loss decreased (0.105332 --> 0.104990).  Saving model ...
Validation loss decreased (0.104990 --> 0.104651).  Saving model ...
Validation loss decreased (0.104651 --> 0.104315).  Saving model ...
Validation loss decreased (0.104315 --> 0.103981).  Saving model ...
Validation loss decreased (0.103981 --> 0.103651).  Saving model ...
Validation loss decreased (0.103651 --> 0.103325).  Saving model ...
Validation loss decreased (0.103325 --> 0.103002).  Saving model ...
Validation loss decreased (0.103002 --> 0.102681).  Saving model ...
Validation loss decreased (0.102681 --> 0.102364).  Saving model ...
Validation loss decreased (0.102364 --> 0.102051).  Saving model ...
Validation loss decreased (0.102051 --> 0.101743).  Saving model ...
Validation loss decreased (0.101743 --> 0.101437).  Saving model ...
Validation loss decreased (0.101437 --> 0.101134).  Saving model ...
Validation loss decreased (0.101134 --> 0.100834).  Saving model ...
Validation loss decreased (0.100834 --> 0.100536).  Saving model ...
Validation loss decreased (0.100536 --> 0.100238).  Saving model ...
Validation loss decreased (0.100238 --> 0.099944).  Saving model ...
Validation loss decreased (0.099944 --> 0.099652).  Saving model ...
Validation loss decreased (0.099652 --> 0.099362).  Saving model ...
Validation loss decreased (0.099362 --> 0.099073).  Saving model ...
Validation loss decreased (0.099073 --> 0.098786).  Saving model ...
Validation loss decreased (0.098786 --> 0.098502).  Saving model ...
Validation loss decreased (0.098502 --> 0.098220).  Saving model ...
Validation loss decreased (0.098220 --> 0.097939).  Saving model ...
Validation loss decreased (0.097939 --> 0.097662).  Saving model ...
Validation loss decreased (0.097662 --> 0.097386).  Saving model ...
Validation loss decreased (0.097386 --> 0.097112).  Saving model ...
Validation loss decreased (0.097112 --> 0.096841).  Saving model ...
Validation loss decreased (0.096841 --> 0.096573).  Saving model ...
Validation loss decreased (0.096573 --> 0.096306).  Saving model ...
Validation loss decreased (0.096306 --> 0.096042).  Saving model ...
Validation loss decreased (0.096042 --> 0.095778).  Saving model ...
Validation loss decreased (0.095778 --> 0.095514).  Saving model ...
Validation loss decreased (0.095514 --> 0.095253).  Saving model ...
Validation loss decreased (0.095253 --> 0.094993).  Saving model ...
Validation loss decreased (0.094993 --> 0.094736).  Saving model ...
Validation loss decreased (0.094736 --> 0.094482).  Saving model ...
Validation loss decreased (0.094482 --> 0.094229).  Saving model ...
Validation loss decreased (0.094229 --> 0.093978).  Saving model ...
Validation loss decreased (0.093978 --> 0.093731).  Saving model ...
Validation loss decreased (0.093731 --> 0.093483).  Saving model ...
Validation loss decreased (0.093483 --> 0.093237).  Saving model ...
Validation loss decreased (0.093237 --> 0.092995).  Saving model ...
Validation loss decreased (0.092995 --> 0.092754).  Saving model ...
Validation loss decreased (0.092754 --> 0.092515).  Saving model ...
Validation loss decreased (0.092515 --> 0.092276).  Saving model ...
Validation loss decreased (0.092276 --> 0.092040).  Saving model ...
Validation loss decreased (0.092040 --> 0.091806).  Saving model ...
Validation loss decreased (0.091806 --> 0.091574).  Saving model ...
Validation loss decreased (0.091574 --> 0.091345).  Saving model ...
Validation loss decreased (0.091345 --> 0.091119).  Saving model ...
Validation loss decreased (0.091119 --> 0.090895).  Saving model ...
Validation loss decreased (0.090895 --> 0.090673).  Saving model ...
Validation loss decreased (0.090673 --> 0.090454).  Saving model ...
Validation loss decreased (0.090454 --> 0.090235).  Saving model ...
Validation loss decreased (0.090235 --> 0.090017).  Saving model ...
Validation loss decreased (0.090017 --> 0.089804).  Saving model ...
epoch 501, loss 0.2518, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.089804 --> 0.089590).  Saving model ...
Validation loss decreased (0.089590 --> 0.089378).  Saving model ...
Validation loss decreased (0.089378 --> 0.089167).  Saving model ...
Validation loss decreased (0.089167 --> 0.088958).  Saving model ...
Validation loss decreased (0.088958 --> 0.088753).  Saving model ...
Validation loss decreased (0.088753 --> 0.088549).  Saving model ...
Validation loss decreased (0.088549 --> 0.088347).  Saving model ...
Validation loss decreased (0.088347 --> 0.088147).  Saving model ...
Validation loss decreased (0.088147 --> 0.087946).  Saving model ...
Validation loss decreased (0.087946 --> 0.087747).  Saving model ...
Validation loss decreased (0.087747 --> 0.087552).  Saving model ...
Validation loss decreased (0.087552 --> 0.087359).  Saving model ...
Validation loss decreased (0.087359 --> 0.087169).  Saving model ...
Validation loss decreased (0.087169 --> 0.086979).  Saving model ...
Validation loss decreased (0.086979 --> 0.086791).  Saving model ...
Validation loss decreased (0.086791 --> 0.086604).  Saving model ...
Validation loss decreased (0.086604 --> 0.086420).  Saving model ...
Validation loss decreased (0.086420 --> 0.086237).  Saving model ...
Validation loss decreased (0.086237 --> 0.086055).  Saving model ...
Validation loss decreased (0.086055 --> 0.085876).  Saving model ...
Validation loss decreased (0.085876 --> 0.085698).  Saving model ...
Validation loss decreased (0.085698 --> 0.085521).  Saving model ...
Validation loss decreased (0.085521 --> 0.085346).  Saving model ...
Validation loss decreased (0.085346 --> 0.085169).  Saving model ...
Validation loss decreased (0.085169 --> 0.084994).  Saving model ...
Validation loss decreased (0.084994 --> 0.084820).  Saving model ...
Validation loss decreased (0.084820 --> 0.084646).  Saving model ...
Validation loss decreased (0.084646 --> 0.084474).  Saving model ...
Validation loss decreased (0.084474 --> 0.084302).  Saving model ...
Validation loss decreased (0.084302 --> 0.084130).  Saving model ...
Validation loss decreased (0.084130 --> 0.083960).  Saving model ...
Validation loss decreased (0.083960 --> 0.083792).  Saving model ...
Validation loss decreased (0.083792 --> 0.083627).  Saving model ...
Validation loss decreased (0.083627 --> 0.083464).  Saving model ...
Validation loss decreased (0.083464 --> 0.083302).  Saving model ...
Validation loss decreased (0.083302 --> 0.083142).  Saving model ...
Validation loss decreased (0.083142 --> 0.082983).  Saving model ...
Validation loss decreased (0.082983 --> 0.082823).  Saving model ...
Validation loss decreased (0.082823 --> 0.082664).  Saving model ...
Validation loss decreased (0.082664 --> 0.082505).  Saving model ...
Validation loss decreased (0.082505 --> 0.082349).  Saving model ...
Validation loss decreased (0.082349 --> 0.082193).  Saving model ...
Validation loss decreased (0.082193 --> 0.082039).  Saving model ...
Validation loss decreased (0.082039 --> 0.081887).  Saving model ...
Validation loss decreased (0.081887 --> 0.081736).  Saving model ...
Validation loss decreased (0.081736 --> 0.081587).  Saving model ...
Validation loss decreased (0.081587 --> 0.081438).  Saving model ...
Validation loss decreased (0.081438 --> 0.081291).  Saving model ...
Validation loss decreased (0.081291 --> 0.081146).  Saving model ...
Validation loss decreased (0.081146 --> 0.081002).  Saving model ...
Validation loss decreased (0.081002 --> 0.080861).  Saving model ...
Validation loss decreased (0.080861 --> 0.080721).  Saving model ...
Validation loss decreased (0.080721 --> 0.080583).  Saving model ...
Validation loss decreased (0.080583 --> 0.080444).  Saving model ...
Validation loss decreased (0.080444 --> 0.080307).  Saving model ...
Validation loss decreased (0.080307 --> 0.080171).  Saving model ...
Validation loss decreased (0.080171 --> 0.080037).  Saving model ...
Validation loss decreased (0.080037 --> 0.079904).  Saving model ...
Validation loss decreased (0.079904 --> 0.079772).  Saving model ...
Validation loss decreased (0.079772 --> 0.079640).  Saving model ...
Validation loss decreased (0.079640 --> 0.079508).  Saving model ...
Validation loss decreased (0.079508 --> 0.079375).  Saving model ...
Validation loss decreased (0.079375 --> 0.079243).  Saving model ...
Validation loss decreased (0.079243 --> 0.079110).  Saving model ...
Validation loss decreased (0.079110 --> 0.078980).  Saving model ...
Validation loss decreased (0.078980 --> 0.078848).  Saving model ...
Validation loss decreased (0.078848 --> 0.078717).  Saving model ...
Validation loss decreased (0.078717 --> 0.078587).  Saving model ...
Validation loss decreased (0.078587 --> 0.078458).  Saving model ...
Validation loss decreased (0.078458 --> 0.078329).  Saving model ...
Validation loss decreased (0.078329 --> 0.078200).  Saving model ...
Validation loss decreased (0.078200 --> 0.078071).  Saving model ...
Validation loss decreased (0.078071 --> 0.077945).  Saving model ...
Validation loss decreased (0.077945 --> 0.077820).  Saving model ...
Validation loss decreased (0.077820 --> 0.077696).  Saving model ...
Validation loss decreased (0.077696 --> 0.077574).  Saving model ...
Validation loss decreased (0.077574 --> 0.077453).  Saving model ...
Validation loss decreased (0.077453 --> 0.077336).  Saving model ...
Validation loss decreased (0.077336 --> 0.077220).  Saving model ...
Validation loss decreased (0.077220 --> 0.077105).  Saving model ...
Validation loss decreased (0.077105 --> 0.076991).  Saving model ...
Validation loss decreased (0.076991 --> 0.076875).  Saving model ...
Validation loss decreased (0.076875 --> 0.076760).  Saving model ...
Validation loss decreased (0.076760 --> 0.076648).  Saving model ...
Validation loss decreased (0.076648 --> 0.076536).  Saving model ...
Validation loss decreased (0.076536 --> 0.076425).  Saving model ...
Validation loss decreased (0.076425 --> 0.076315).  Saving model ...
Validation loss decreased (0.076315 --> 0.076204).  Saving model ...
Validation loss decreased (0.076204 --> 0.076094).  Saving model ...
Validation loss decreased (0.076094 --> 0.075983).  Saving model ...
Validation loss decreased (0.075983 --> 0.075872).  Saving model ...
Validation loss decreased (0.075872 --> 0.075762).  Saving model ...
Validation loss decreased (0.075762 --> 0.075655).  Saving model ...
Validation loss decreased (0.075655 --> 0.075547).  Saving model ...
Validation loss decreased (0.075547 --> 0.075441).  Saving model ...
Validation loss decreased (0.075441 --> 0.075333).  Saving model ...
Validation loss decreased (0.075333 --> 0.075228).  Saving model ...
Validation loss decreased (0.075228 --> 0.075124).  Saving model ...
Validation loss decreased (0.075124 --> 0.075020).  Saving model ...
Validation loss decreased (0.075020 --> 0.074918).  Saving model ...
epoch 601, loss 0.2337, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.074918 --> 0.074817).  Saving model ...
Validation loss decreased (0.074817 --> 0.074718).  Saving model ...
Validation loss decreased (0.074718 --> 0.074620).  Saving model ...
Validation loss decreased (0.074620 --> 0.074523).  Saving model ...
Validation loss decreased (0.074523 --> 0.074427).  Saving model ...
Validation loss decreased (0.074427 --> 0.074333).  Saving model ...
Validation loss decreased (0.074333 --> 0.074239).  Saving model ...
Validation loss decreased (0.074239 --> 0.074145).  Saving model ...
Validation loss decreased (0.074145 --> 0.074052).  Saving model ...
Validation loss decreased (0.074052 --> 0.073959).  Saving model ...
Validation loss decreased (0.073959 --> 0.073867).  Saving model ...
Validation loss decreased (0.073867 --> 0.073773).  Saving model ...
Validation loss decreased (0.073773 --> 0.073681).  Saving model ...
Validation loss decreased (0.073681 --> 0.073591).  Saving model ...
Validation loss decreased (0.073591 --> 0.073501).  Saving model ...
Validation loss decreased (0.073501 --> 0.073413).  Saving model ...
Validation loss decreased (0.073413 --> 0.073325).  Saving model ...
Validation loss decreased (0.073325 --> 0.073238).  Saving model ...
Validation loss decreased (0.073238 --> 0.073153).  Saving model ...
Validation loss decreased (0.073153 --> 0.073068).  Saving model ...
Validation loss decreased (0.073068 --> 0.072981).  Saving model ...
Validation loss decreased (0.072981 --> 0.072896).  Saving model ...
Validation loss decreased (0.072896 --> 0.072809).  Saving model ...
Validation loss decreased (0.072809 --> 0.072724).  Saving model ...
Validation loss decreased (0.072724 --> 0.072639).  Saving model ...
Validation loss decreased (0.072639 --> 0.072553).  Saving model ...
Validation loss decreased (0.072553 --> 0.072468).  Saving model ...
Validation loss decreased (0.072468 --> 0.072382).  Saving model ...
Validation loss decreased (0.072382 --> 0.072294).  Saving model ...
Validation loss decreased (0.072294 --> 0.072206).  Saving model ...
Validation loss decreased (0.072206 --> 0.072121).  Saving model ...
Validation loss decreased (0.072121 --> 0.072037).  Saving model ...
Validation loss decreased (0.072037 --> 0.071957).  Saving model ...
Validation loss decreased (0.071957 --> 0.071878).  Saving model ...
Validation loss decreased (0.071878 --> 0.071800).  Saving model ...
Validation loss decreased (0.071800 --> 0.071723).  Saving model ...
Validation loss decreased (0.071723 --> 0.071649).  Saving model ...
Validation loss decreased (0.071649 --> 0.071575).  Saving model ...
Validation loss decreased (0.071575 --> 0.071502).  Saving model ...
Validation loss decreased (0.071502 --> 0.071428).  Saving model ...
Validation loss decreased (0.071428 --> 0.071352).  Saving model ...
Validation loss decreased (0.071352 --> 0.071276).  Saving model ...
Validation loss decreased (0.071276 --> 0.071201).  Saving model ...
Validation loss decreased (0.071201 --> 0.071128).  Saving model ...
Validation loss decreased (0.071128 --> 0.071054).  Saving model ...
Validation loss decreased (0.071054 --> 0.070979).  Saving model ...
Validation loss decreased (0.070979 --> 0.070904).  Saving model ...
Validation loss decreased (0.070904 --> 0.070831).  Saving model ...
Validation loss decreased (0.070831 --> 0.070759).  Saving model ...
Validation loss decreased (0.070759 --> 0.070687).  Saving model ...
Validation loss decreased (0.070687 --> 0.070612).  Saving model ...
Validation loss decreased (0.070612 --> 0.070539).  Saving model ...
Validation loss decreased (0.070539 --> 0.070468).  Saving model ...
Validation loss decreased (0.070468 --> 0.070399).  Saving model ...
Validation loss decreased (0.070399 --> 0.070330).  Saving model ...
Validation loss decreased (0.070330 --> 0.070262).  Saving model ...
Validation loss decreased (0.070262 --> 0.070194).  Saving model ...
Validation loss decreased (0.070194 --> 0.070128).  Saving model ...
Validation loss decreased (0.070128 --> 0.070060).  Saving model ...
Validation loss decreased (0.070060 --> 0.069992).  Saving model ...
Validation loss decreased (0.069992 --> 0.069925).  Saving model ...
Validation loss decreased (0.069925 --> 0.069859).  Saving model ...
Validation loss decreased (0.069859 --> 0.069793).  Saving model ...
Validation loss decreased (0.069793 --> 0.069729).  Saving model ...
Validation loss decreased (0.069729 --> 0.069665).  Saving model ...
Validation loss decreased (0.069665 --> 0.069601).  Saving model ...
Validation loss decreased (0.069601 --> 0.069538).  Saving model ...
Validation loss decreased (0.069538 --> 0.069476).  Saving model ...
Validation loss decreased (0.069476 --> 0.069414).  Saving model ...
Validation loss decreased (0.069414 --> 0.069355).  Saving model ...
Validation loss decreased (0.069355 --> 0.069296).  Saving model ...
Validation loss decreased (0.069296 --> 0.069238).  Saving model ...
Validation loss decreased (0.069238 --> 0.069179).  Saving model ...
Validation loss decreased (0.069179 --> 0.069119).  Saving model ...
Validation loss decreased (0.069119 --> 0.069060).  Saving model ...
Validation loss decreased (0.069060 --> 0.069001).  Saving model ...
Validation loss decreased (0.069001 --> 0.068943).  Saving model ...
Validation loss decreased (0.068943 --> 0.068887).  Saving model ...
Validation loss decreased (0.068887 --> 0.068831).  Saving model ...
Validation loss decreased (0.068831 --> 0.068776).  Saving model ...
Validation loss decreased (0.068776 --> 0.068716).  Saving model ...
Validation loss decreased (0.068716 --> 0.068657).  Saving model ...
Validation loss decreased (0.068657 --> 0.068597).  Saving model ...
Validation loss decreased (0.068597 --> 0.068535).  Saving model ...
Validation loss decreased (0.068535 --> 0.068475).  Saving model ...
Validation loss decreased (0.068475 --> 0.068415).  Saving model ...
Validation loss decreased (0.068415 --> 0.068357).  Saving model ...
Validation loss decreased (0.068357 --> 0.068299).  Saving model ...
Validation loss decreased (0.068299 --> 0.068240).  Saving model ...
Validation loss decreased (0.068240 --> 0.068181).  Saving model ...
Validation loss decreased (0.068181 --> 0.068124).  Saving model ...
Validation loss decreased (0.068124 --> 0.068069).  Saving model ...
Validation loss decreased (0.068069 --> 0.068015).  Saving model ...
Validation loss decreased (0.068015 --> 0.067962).  Saving model ...
Validation loss decreased (0.067962 --> 0.067911).  Saving model ...
Validation loss decreased (0.067911 --> 0.067860).  Saving model ...
Validation loss decreased (0.067860 --> 0.067809).  Saving model ...
Validation loss decreased (0.067809 --> 0.067760).  Saving model ...
Validation loss decreased (0.067760 --> 0.067711).  Saving model ...
Validation loss decreased (0.067711 --> 0.067663).  Saving model ...
epoch 701, loss 0.2226, train acc 99.39%, f1 0.9939, precision 0.9939, recall 0.9939, auc 0.9939
Validation loss decreased (0.067663 --> 0.067617).  Saving model ...
Validation loss decreased (0.067617 --> 0.067570).  Saving model ...
Validation loss decreased (0.067570 --> 0.067524).  Saving model ...
Validation loss decreased (0.067524 --> 0.067478).  Saving model ...
Validation loss decreased (0.067478 --> 0.067434).  Saving model ...
Validation loss decreased (0.067434 --> 0.067389).  Saving model ...
Validation loss decreased (0.067389 --> 0.067345).  Saving model ...
Validation loss decreased (0.067345 --> 0.067304).  Saving model ...
Validation loss decreased (0.067304 --> 0.067261).  Saving model ...
Validation loss decreased (0.067261 --> 0.067218).  Saving model ...
Validation loss decreased (0.067218 --> 0.067176).  Saving model ...
Validation loss decreased (0.067176 --> 0.067134).  Saving model ...
Validation loss decreased (0.067134 --> 0.067092).  Saving model ...
Validation loss decreased (0.067092 --> 0.067051).  Saving model ...
Validation loss decreased (0.067051 --> 0.067008).  Saving model ...
Validation loss decreased (0.067008 --> 0.066965).  Saving model ...
Validation loss decreased (0.066965 --> 0.066921).  Saving model ...
Validation loss decreased (0.066921 --> 0.066878).  Saving model ...
Validation loss decreased (0.066878 --> 0.066834).  Saving model ...
Validation loss decreased (0.066834 --> 0.066790).  Saving model ...
Validation loss decreased (0.066790 --> 0.066744).  Saving model ...
Validation loss decreased (0.066744 --> 0.066697).  Saving model ...
Validation loss decreased (0.066697 --> 0.066651).  Saving model ...
Validation loss decreased (0.066651 --> 0.066604).  Saving model ...
Validation loss decreased (0.066604 --> 0.066557).  Saving model ...
Validation loss decreased (0.066557 --> 0.066509).  Saving model ...
Validation loss decreased (0.066509 --> 0.066461).  Saving model ...
Validation loss decreased (0.066461 --> 0.066414).  Saving model ...
Validation loss decreased (0.066414 --> 0.066366).  Saving model ...
Validation loss decreased (0.066366 --> 0.066318).  Saving model ...
Validation loss decreased (0.066318 --> 0.066271).  Saving model ...
Validation loss decreased (0.066271 --> 0.066226).  Saving model ...
Validation loss decreased (0.066226 --> 0.066182).  Saving model ...
Validation loss decreased (0.066182 --> 0.066140).  Saving model ...
Validation loss decreased (0.066140 --> 0.066098).  Saving model ...
Validation loss decreased (0.066098 --> 0.066056).  Saving model ...
Validation loss decreased (0.066056 --> 0.066014).  Saving model ...
Validation loss decreased (0.066014 --> 0.065972).  Saving model ...
Validation loss decreased (0.065972 --> 0.065932).  Saving model ...
Validation loss decreased (0.065932 --> 0.065894).  Saving model ...
Validation loss decreased (0.065894 --> 0.065856).  Saving model ...
Validation loss decreased (0.065856 --> 0.065821).  Saving model ...
Validation loss decreased (0.065821 --> 0.065786).  Saving model ...
Validation loss decreased (0.065786 --> 0.065752).  Saving model ...
Validation loss decreased (0.065752 --> 0.065720).  Saving model ...
Validation loss decreased (0.065720 --> 0.065687).  Saving model ...
Validation loss decreased (0.065687 --> 0.065656).  Saving model ...
Validation loss decreased (0.065656 --> 0.065626).  Saving model ...
Validation loss decreased (0.065626 --> 0.065596).  Saving model ...
Validation loss decreased (0.065596 --> 0.065567).  Saving model ...
Validation loss decreased (0.065567 --> 0.065537).  Saving model ...
Validation loss decreased (0.065537 --> 0.065507).  Saving model ...
Validation loss decreased (0.065507 --> 0.065477).  Saving model ...
Validation loss decreased (0.065477 --> 0.065448).  Saving model ...
Validation loss decreased (0.065448 --> 0.065420).  Saving model ...
Validation loss decreased (0.065420 --> 0.065390).  Saving model ...
Validation loss decreased (0.065390 --> 0.065362).  Saving model ...
Validation loss decreased (0.065362 --> 0.065334).  Saving model ...
Validation loss decreased (0.065334 --> 0.065303).  Saving model ...
Validation loss decreased (0.065303 --> 0.065271).  Saving model ...
Validation loss decreased (0.065271 --> 0.065238).  Saving model ...
Validation loss decreased (0.065238 --> 0.065204).  Saving model ...
Validation loss decreased (0.065204 --> 0.065167).  Saving model ...
Validation loss decreased (0.065167 --> 0.065128).  Saving model ...
Validation loss decreased (0.065128 --> 0.065090).  Saving model ...
Validation loss decreased (0.065090 --> 0.065054).  Saving model ...
Validation loss decreased (0.065054 --> 0.065018).  Saving model ...
Validation loss decreased (0.065018 --> 0.064984).  Saving model ...
Validation loss decreased (0.064984 --> 0.064950).  Saving model ...
Validation loss decreased (0.064950 --> 0.064918).  Saving model ...
Validation loss decreased (0.064918 --> 0.064885).  Saving model ...
Validation loss decreased (0.064885 --> 0.064852).  Saving model ...
Validation loss decreased (0.064852 --> 0.064823).  Saving model ...
Validation loss decreased (0.064823 --> 0.064794).  Saving model ...
Validation loss decreased (0.064794 --> 0.064766).  Saving model ...
Validation loss decreased (0.064766 --> 0.064740).  Saving model ...
Validation loss decreased (0.064740 --> 0.064714).  Saving model ...
Validation loss decreased (0.064714 --> 0.064689).  Saving model ...
Validation loss decreased (0.064689 --> 0.064661).  Saving model ...
Validation loss decreased (0.064661 --> 0.064633).  Saving model ...
Validation loss decreased (0.064633 --> 0.064604).  Saving model ...
Validation loss decreased (0.064604 --> 0.064573).  Saving model ...
Validation loss decreased (0.064573 --> 0.064544).  Saving model ...
Validation loss decreased (0.064544 --> 0.064516).  Saving model ...
Validation loss decreased (0.064516 --> 0.064489).  Saving model ...
Validation loss decreased (0.064489 --> 0.064462).  Saving model ...
Validation loss decreased (0.064462 --> 0.064439).  Saving model ...
Validation loss decreased (0.064439 --> 0.064416).  Saving model ...
Validation loss decreased (0.064416 --> 0.064394).  Saving model ...
Validation loss decreased (0.064394 --> 0.064371).  Saving model ...
Validation loss decreased (0.064371 --> 0.064349).  Saving model ...
Validation loss decreased (0.064349 --> 0.064326).  Saving model ...
Validation loss decreased (0.064326 --> 0.064302).  Saving model ...
Validation loss decreased (0.064302 --> 0.064279).  Saving model ...
Validation loss decreased (0.064279 --> 0.064257).  Saving model ...
Validation loss decreased (0.064257 --> 0.064237).  Saving model ...
Validation loss decreased (0.064237 --> 0.064216).  Saving model ...
Validation loss decreased (0.064216 --> 0.064194).  Saving model ...
Validation loss decreased (0.064194 --> 0.064175).  Saving model ...
Validation loss decreased (0.064175 --> 0.064156).  Saving model ...
epoch 801, loss 0.2151, train acc 99.39%, f1 0.9939, precision 0.9939, recall 0.9939, auc 0.9939
Validation loss decreased (0.064156 --> 0.064135).  Saving model ...
Validation loss decreased (0.064135 --> 0.064116).  Saving model ...
Validation loss decreased (0.064116 --> 0.064098).  Saving model ...
Validation loss decreased (0.064098 --> 0.064081).  Saving model ...
Validation loss decreased (0.064081 --> 0.064064).  Saving model ...
Validation loss decreased (0.064064 --> 0.064051).  Saving model ...
Validation loss decreased (0.064051 --> 0.064038).  Saving model ...
Validation loss decreased (0.064038 --> 0.064025).  Saving model ...
Validation loss decreased (0.064025 --> 0.064014).  Saving model ...
Validation loss decreased (0.064014 --> 0.063998).  Saving model ...
Validation loss decreased (0.063998 --> 0.063983).  Saving model ...
Validation loss decreased (0.063983 --> 0.063967).  Saving model ...
Validation loss decreased (0.063967 --> 0.063952).  Saving model ...
Validation loss decreased (0.063952 --> 0.063938).  Saving model ...
Validation loss decreased (0.063938 --> 0.063919).  Saving model ...
Validation loss decreased (0.063919 --> 0.063898).  Saving model ...
Validation loss decreased (0.063898 --> 0.063879).  Saving model ...
Validation loss decreased (0.063879 --> 0.063858).  Saving model ...
Validation loss decreased (0.063858 --> 0.063837).  Saving model ...
Validation loss decreased (0.063837 --> 0.063815).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.063815 --> 0.063795).  Saving model ...
Validation loss decreased (0.063795 --> 0.063776).  Saving model ...
Validation loss decreased (0.063776 --> 0.063759).  Saving model ...
Validation loss decreased (0.063759 --> 0.063744).  Saving model ...
Validation loss decreased (0.063744 --> 0.063728).  Saving model ...
Validation loss decreased (0.063728 --> 0.063716).  Saving model ...
Validation loss decreased (0.063716 --> 0.063704).  Saving model ...
Validation loss decreased (0.063704 --> 0.063693).  Saving model ...
Validation loss decreased (0.063693 --> 0.063686).  Saving model ...
Validation loss decreased (0.063686 --> 0.063677).  Saving model ...
Validation loss decreased (0.063677 --> 0.063670).  Saving model ...
Validation loss decreased (0.063670 --> 0.063659).  Saving model ...
Validation loss decreased (0.063659 --> 0.063650).  Saving model ...
Validation loss decreased (0.063650 --> 0.063641).  Saving model ...
Validation loss decreased (0.063641 --> 0.063632).  Saving model ...
Validation loss decreased (0.063632 --> 0.063624).  Saving model ...
Validation loss decreased (0.063624 --> 0.063617).  Saving model ...
Validation loss decreased (0.063617 --> 0.063612).  Saving model ...
Validation loss decreased (0.063612 --> 0.063606).  Saving model ...
Validation loss decreased (0.063606 --> 0.063601).  Saving model ...
Validation loss decreased (0.063601 --> 0.063596).  Saving model ...
Validation loss decreased (0.063596 --> 0.063592).  Saving model ...
Validation loss decreased (0.063592 --> 0.063591).  Saving model ...
Validation loss decreased (0.063591 --> 0.063590).  Saving model ...
Validation loss decreased (0.063590 --> 0.063587).  Saving model ...
Validation loss decreased (0.063587 --> 0.063586).  Saving model ...
Validation loss decreased (0.063586 --> 0.063584).  Saving model ...
Validation loss decreased (0.063584 --> 0.063580).  Saving model ...
Validation loss decreased (0.063580 --> 0.063578).  Saving model ...
Validation loss decreased (0.063578 --> 0.063574).  Saving model ...
Validation loss decreased (0.063574 --> 0.063567).  Saving model ...
Validation loss decreased (0.063567 --> 0.063561).  Saving model ...
Validation loss decreased (0.063561 --> 0.063558).  Saving model ...
Validation loss decreased (0.063558 --> 0.063555).  Saving model ...
Validation loss decreased (0.063555 --> 0.063551).  Saving model ...
Validation loss decreased (0.063551 --> 0.063547).  Saving model ...
Validation loss decreased (0.063547 --> 0.063544).  Saving model ...
Validation loss decreased (0.063544 --> 0.063540).  Saving model ...
Validation loss decreased (0.063540 --> 0.063539).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 879, loss 0.2097, train acc 99.39%, f1 0.9939, precision 0.9939, recall 0.9939, auc 0.9939



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_abalone19/standlization_data/abalone19_std_train_3.csv
./test_abalone19/standlization_data/abalone19_std_test_3.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_abalone19/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_3
./test_abalone19/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.8993975903614457

the Fscore is 0.05649717514124294

the precision is 0.029069767441860465

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_abalone19/standlization_data/abalone19_std_train_3.csv
./test_abalone19/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_3
----------------------



epoch 1, loss 0.6934, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5329, train acc 73.82%, f1 0.7342, precision 0.7455, recall 0.7233, auc 0.7382
epoch 201, loss 0.4494, train acc 78.45%, f1 0.7858, precision 0.7813, recall 0.7902, auc 0.7845
epoch 301, loss 0.3566, train acc 86.44%, f1 0.8645, precision 0.8638, recall 0.8652, auc 0.8644
epoch 401, loss 0.2844, train acc 90.56%, f1 0.9057, precision 0.9050, recall 0.9064, auc 0.9056
epoch 501, loss 0.2468, train acc 91.77%, f1 0.9178, precision 0.9163, recall 0.9192, auc 0.9177
epoch 601, loss 0.2272, train acc 92.32%, f1 0.9233, precision 0.9215, recall 0.9251, auc 0.9232
epoch 701, loss 0.2159, train acc 92.67%, f1 0.9269, precision 0.9246, recall 0.9293, auc 0.9267
epoch 801, loss 0.2088, train acc 92.88%, f1 0.9290, precision 0.9269, recall 0.9311, auc 0.9288
epoch 901, loss 0.2036, train acc 93.00%, f1 0.9302, precision 0.9281, recall 0.9323, auc 0.9300
epoch 1001, loss 0.1977, train acc 93.09%, f1 0.9310, precision 0.9289, recall 0.9331, auc 0.9309
epoch 1101, loss 0.1908, train acc 93.22%, f1 0.9323, precision 0.9302, recall 0.9345, auc 0.9322
epoch 1201, loss 0.1839, train acc 93.38%, f1 0.9340, precision 0.9320, recall 0.9360, auc 0.9338
epoch 1301, loss 0.1776, train acc 93.56%, f1 0.9358, precision 0.9338, recall 0.9378, auc 0.9356
epoch 1401, loss 0.1720, train acc 93.78%, f1 0.9379, precision 0.9358, recall 0.9400, auc 0.9378
epoch 1501, loss 0.1668, train acc 93.94%, f1 0.9395, precision 0.9375, recall 0.9415, auc 0.9394
epoch 1601, loss 0.1621, train acc 94.05%, f1 0.9406, precision 0.9387, recall 0.9426, auc 0.9405
epoch 1701, loss 0.1576, train acc 94.15%, f1 0.9416, precision 0.9397, recall 0.9435, auc 0.9415
epoch 1801, loss 0.1533, train acc 94.25%, f1 0.9426, precision 0.9407, recall 0.9445, auc 0.9425
epoch 1901, loss 0.1491, train acc 94.33%, f1 0.9434, precision 0.9416, recall 0.9453, auc 0.9433
epoch 2001, loss 0.1450, train acc 94.43%, f1 0.9445, precision 0.9426, recall 0.9463, auc 0.9443
epoch 2101, loss 0.1410, train acc 94.52%, f1 0.9453, precision 0.9436, recall 0.9471, auc 0.9452
epoch 2201, loss 0.1371, train acc 94.64%, f1 0.9465, precision 0.9449, recall 0.9481, auc 0.9464
epoch 2301, loss 0.1333, train acc 94.78%, f1 0.9479, precision 0.9463, recall 0.9495, auc 0.9478
epoch 2401, loss 0.1297, train acc 94.89%, f1 0.9490, precision 0.9473, recall 0.9507, auc 0.9489
epoch 2501, loss 0.1262, train acc 95.01%, f1 0.9502, precision 0.9487, recall 0.9517, auc 0.9501
epoch 2601, loss 0.1228, train acc 95.11%, f1 0.9512, precision 0.9496, recall 0.9528, auc 0.9511
epoch 2701, loss 0.1196, train acc 95.22%, f1 0.9523, precision 0.9508, recall 0.9537, auc 0.9522
epoch 2801, loss 0.1164, train acc 95.34%, f1 0.9535, precision 0.9520, recall 0.9550, auc 0.9534
epoch 2901, loss 0.1134, train acc 95.45%, f1 0.9546, precision 0.9530, recall 0.9562, auc 0.9545
epoch 3001, loss 0.1105, train acc 95.57%, f1 0.9557, precision 0.9542, recall 0.9573, auc 0.9557
epoch 3101, loss 0.1077, train acc 95.67%, f1 0.9568, precision 0.9551, recall 0.9585, auc 0.9567
epoch 3201, loss 0.1050, train acc 95.77%, f1 0.9578, precision 0.9562, recall 0.9594, auc 0.9577
epoch 3301, loss 0.1025, train acc 95.86%, f1 0.9586, precision 0.9570, recall 0.9603, auc 0.9586
epoch 3401, loss 0.1000, train acc 95.95%, f1 0.9595, precision 0.9581, recall 0.9610, auc 0.9595
epoch 3501, loss 0.0975, train acc 96.03%, f1 0.9604, precision 0.9589, recall 0.9618, auc 0.9603
epoch 3601, loss 0.0951, train acc 96.10%, f1 0.9611, precision 0.9599, recall 0.9623, auc 0.9610
epoch 3701, loss 0.0928, train acc 96.20%, f1 0.9621, precision 0.9609, recall 0.9633, auc 0.9620
epoch 3801, loss 0.0906, train acc 96.30%, f1 0.9631, precision 0.9618, recall 0.9644, auc 0.9630
epoch 3901, loss 0.0885, train acc 96.38%, f1 0.9639, precision 0.9627, recall 0.9650, auc 0.9638
epoch 4001, loss 0.0864, train acc 96.46%, f1 0.9646, precision 0.9635, recall 0.9657, auc 0.9646
epoch 4101, loss 0.0844, train acc 96.53%, f1 0.9653, precision 0.9643, recall 0.9664, auc 0.9653
epoch 4201, loss 0.0824, train acc 96.61%, f1 0.9662, precision 0.9652, recall 0.9672, auc 0.9661
epoch 4301, loss 0.0805, train acc 96.67%, f1 0.9668, precision 0.9660, recall 0.9676, auc 0.9667
epoch 4401, loss 0.0787, train acc 96.73%, f1 0.9674, precision 0.9667, recall 0.9681, auc 0.9673
epoch 4501, loss 0.0768, train acc 96.80%, f1 0.9681, precision 0.9673, recall 0.9688, auc 0.9680
epoch 4601, loss 0.0750, train acc 96.87%, f1 0.9687, precision 0.9680, recall 0.9694, auc 0.9687
epoch 4701, loss 0.0732, train acc 96.94%, f1 0.9694, precision 0.9688, recall 0.9700, auc 0.9694
epoch 4801, loss 0.0714, train acc 97.01%, f1 0.9701, precision 0.9696, recall 0.9707, auc 0.9701
epoch 4901, loss 0.0697, train acc 97.09%, f1 0.9709, precision 0.9703, recall 0.9715, auc 0.9709
epoch 5001, loss 0.0679, train acc 97.15%, f1 0.9715, precision 0.9709, recall 0.9721, auc 0.9715
epoch 5101, loss 0.0661, train acc 97.22%, f1 0.9722, precision 0.9715, recall 0.9729, auc 0.9722
epoch 5201, loss 0.0644, train acc 97.27%, f1 0.9728, precision 0.9721, recall 0.9735, auc 0.9727
epoch 5301, loss 0.0627, train acc 97.35%, f1 0.9736, precision 0.9729, recall 0.9742, auc 0.9735
epoch 5401, loss 0.0610, train acc 97.43%, f1 0.9743, precision 0.9738, recall 0.9748, auc 0.9743
epoch 5501, loss 0.0594, train acc 97.51%, f1 0.9751, precision 0.9747, recall 0.9755, auc 0.9751
epoch 5601, loss 0.0578, train acc 97.57%, f1 0.9757, precision 0.9752, recall 0.9762, auc 0.9757
epoch 5701, loss 0.0562, train acc 97.65%, f1 0.9766, precision 0.9761, recall 0.9770, auc 0.9765
epoch 5801, loss 0.0546, train acc 97.73%, f1 0.9773, precision 0.9768, recall 0.9777, auc 0.9773
epoch 5901, loss 0.0530, train acc 97.79%, f1 0.9779, precision 0.9776, recall 0.9783, auc 0.9779
epoch 6001, loss 0.0515, train acc 97.88%, f1 0.9788, precision 0.9786, recall 0.9791, auc 0.9788
epoch 6101, loss 0.0499, train acc 97.97%, f1 0.9797, precision 0.9795, recall 0.9800, auc 0.9797
epoch 6201, loss 0.0483, train acc 98.05%, f1 0.9806, precision 0.9802, recall 0.9810, auc 0.9805
epoch 6301, loss 0.0467, train acc 98.14%, f1 0.9814, precision 0.9811, recall 0.9816, auc 0.9814
epoch 6401, loss 0.0452, train acc 98.23%, f1 0.9824, precision 0.9819, recall 0.9828, auc 0.9823
epoch 6501, loss 0.0436, train acc 98.30%, f1 0.9830, precision 0.9827, recall 0.9833, auc 0.9830
epoch 6601, loss 0.0420, train acc 98.38%, f1 0.9838, precision 0.9835, recall 0.9840, auc 0.9838
epoch 6701, loss 0.0404, train acc 98.46%, f1 0.9846, precision 0.9846, recall 0.9847, auc 0.9846
epoch 6801, loss 0.0389, train acc 98.55%, f1 0.9855, precision 0.9855, recall 0.9856, auc 0.9855
epoch 6901, loss 0.0374, train acc 98.62%, f1 0.9862, precision 0.9862, recall 0.9863, auc 0.9862
epoch 7001, loss 0.0360, train acc 98.69%, f1 0.9869, precision 0.9869, recall 0.9868, auc 0.9869
epoch 7101, loss 0.0346, train acc 98.76%, f1 0.9876, precision 0.9877, recall 0.9875, auc 0.9876
epoch 7201, loss 0.0331, train acc 98.83%, f1 0.9883, precision 0.9883, recall 0.9883, auc 0.9883
epoch 7301, loss 0.0317, train acc 98.90%, f1 0.9890, precision 0.9890, recall 0.9890, auc 0.9890
epoch 7401, loss 0.0304, train acc 98.97%, f1 0.9897, precision 0.9896, recall 0.9898, auc 0.9897
epoch 7501, loss 0.0291, train acc 99.02%, f1 0.9902, precision 0.9901, recall 0.9904, auc 0.9902
epoch 7601, loss 0.0279, train acc 99.08%, f1 0.9908, precision 0.9906, recall 0.9909, auc 0.9908
epoch 7701, loss 0.0267, train acc 99.13%, f1 0.9913, precision 0.9911, recall 0.9914, auc 0.9913
epoch 7801, loss 0.0256, train acc 99.18%, f1 0.9918, precision 0.9916, recall 0.9921, auc 0.9918
epoch 7901, loss 0.0245, train acc 99.23%, f1 0.9923, precision 0.9921, recall 0.9925, auc 0.9923
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_abalone19/standlization_data/abalone19_std_train_3.csv
./test_abalone19/standlization_data/abalone19_std_test_3.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_abalone19/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_3
./test_abalone19/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6849397590361445

the Fscore is 0.125

the precision is 0.07407407407407407

the recall is 0.4

Done
train_mlp_4_1.sh: line 20: 19929 Terminated              python3 ./classifier_MLP/train_MLP.py dataset_name=abalone19 dataset_index=3 record_index=1 device_id=4 train_method=MLP_concat_Mirror_5000
