nohup: ignoring input
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_4
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693154).  Saving model ...
Validation loss decreased (0.693154 --> 0.693007).  Saving model ...
Validation loss decreased (0.693007 --> 0.692832).  Saving model ...
Validation loss decreased (0.692832 --> 0.692640).  Saving model ...
Validation loss decreased (0.692640 --> 0.692440).  Saving model ...
Validation loss decreased (0.692440 --> 0.692220).  Saving model ...
Validation loss decreased (0.692220 --> 0.691996).  Saving model ...
Validation loss decreased (0.691996 --> 0.691755).  Saving model ...
Validation loss decreased (0.691755 --> 0.691473).  Saving model ...
Validation loss decreased (0.691473 --> 0.691149).  Saving model ...
Validation loss decreased (0.691149 --> 0.690798).  Saving model ...
Validation loss decreased (0.690798 --> 0.690409).  Saving model ...
Validation loss decreased (0.690409 --> 0.689973).  Saving model ...
Validation loss decreased (0.689973 --> 0.689483).  Saving model ...
Validation loss decreased (0.689483 --> 0.688963).  Saving model ...
Validation loss decreased (0.688963 --> 0.688404).  Saving model ...
Validation loss decreased (0.688404 --> 0.687796).  Saving model ...
Validation loss decreased (0.687796 --> 0.687130).  Saving model ...
Validation loss decreased (0.687130 --> 0.686417).  Saving model ...
Validation loss decreased (0.686417 --> 0.685667).  Saving model ...
Validation loss decreased (0.685667 --> 0.684895).  Saving model ...
Validation loss decreased (0.684895 --> 0.684071).  Saving model ...
Validation loss decreased (0.684071 --> 0.683193).  Saving model ...
Validation loss decreased (0.683193 --> 0.682239).  Saving model ...
Validation loss decreased (0.682239 --> 0.681213).  Saving model ...
Validation loss decreased (0.681213 --> 0.680173).  Saving model ...
Validation loss decreased (0.680173 --> 0.679091).  Saving model ...
Validation loss decreased (0.679091 --> 0.677949).  Saving model ...
Validation loss decreased (0.677949 --> 0.676783).  Saving model ...
Validation loss decreased (0.676783 --> 0.675547).  Saving model ...
Validation loss decreased (0.675547 --> 0.674267).  Saving model ...
Validation loss decreased (0.674267 --> 0.672926).  Saving model ...
Validation loss decreased (0.672926 --> 0.671496).  Saving model ...
Validation loss decreased (0.671496 --> 0.670041).  Saving model ...
Validation loss decreased (0.670041 --> 0.668508).  Saving model ...
Validation loss decreased (0.668508 --> 0.666898).  Saving model ...
Validation loss decreased (0.666898 --> 0.665249).  Saving model ...
Validation loss decreased (0.665249 --> 0.663546).  Saving model ...
Validation loss decreased (0.663546 --> 0.661795).  Saving model ...
Validation loss decreased (0.661795 --> 0.660020).  Saving model ...
Validation loss decreased (0.660020 --> 0.658174).  Saving model ...
Validation loss decreased (0.658174 --> 0.656249).  Saving model ...
Validation loss decreased (0.656249 --> 0.654271).  Saving model ...
Validation loss decreased (0.654271 --> 0.652263).  Saving model ...
Validation loss decreased (0.652263 --> 0.650252).  Saving model ...
Validation loss decreased (0.650252 --> 0.648160).  Saving model ...
Validation loss decreased (0.648160 --> 0.645998).  Saving model ...
Validation loss decreased (0.645998 --> 0.643854).  Saving model ...
Validation loss decreased (0.643854 --> 0.641779).  Saving model ...
Validation loss decreased (0.641779 --> 0.639659).  Saving model ...
Validation loss decreased (0.639659 --> 0.637530).  Saving model ...
Validation loss decreased (0.637530 --> 0.635335).  Saving model ...
Validation loss decreased (0.635335 --> 0.633094).  Saving model ...
Validation loss decreased (0.633094 --> 0.630807).  Saving model ...
Validation loss decreased (0.630807 --> 0.628427).  Saving model ...
Validation loss decreased (0.628427 --> 0.625997).  Saving model ...
Validation loss decreased (0.625997 --> 0.623483).  Saving model ...
Validation loss decreased (0.623483 --> 0.621092).  Saving model ...
Validation loss decreased (0.621092 --> 0.618645).  Saving model ...
Validation loss decreased (0.618645 --> 0.616134).  Saving model ...
Validation loss decreased (0.616134 --> 0.613718).  Saving model ...
Validation loss decreased (0.613718 --> 0.611382).  Saving model ...
Validation loss decreased (0.611382 --> 0.608986).  Saving model ...
Validation loss decreased (0.608986 --> 0.606602).  Saving model ...
Validation loss decreased (0.606602 --> 0.604262).  Saving model ...
Validation loss decreased (0.604262 --> 0.601873).  Saving model ...
Validation loss decreased (0.601873 --> 0.599349).  Saving model ...
Validation loss decreased (0.599349 --> 0.596805).  Saving model ...
Validation loss decreased (0.596805 --> 0.594234).  Saving model ...
Validation loss decreased (0.594234 --> 0.591593).  Saving model ...
Validation loss decreased (0.591593 --> 0.588910).  Saving model ...
Validation loss decreased (0.588910 --> 0.586165).  Saving model ...
Validation loss decreased (0.586165 --> 0.583320).  Saving model ...
Validation loss decreased (0.583320 --> 0.580451).  Saving model ...
Validation loss decreased (0.580451 --> 0.577511).  Saving model ...
Validation loss decreased (0.577511 --> 0.574539).  Saving model ...
Validation loss decreased (0.574539 --> 0.571636).  Saving model ...
Validation loss decreased (0.571636 --> 0.568959).  Saving model ...
Validation loss decreased (0.568959 --> 0.566342).  Saving model ...
Validation loss decreased (0.566342 --> 0.563679).  Saving model ...
Validation loss decreased (0.563679 --> 0.561000).  Saving model ...
Validation loss decreased (0.561000 --> 0.558288).  Saving model ...
Validation loss decreased (0.558288 --> 0.555498).  Saving model ...
Validation loss decreased (0.555498 --> 0.552735).  Saving model ...
Validation loss decreased (0.552735 --> 0.550011).  Saving model ...
Validation loss decreased (0.550011 --> 0.547439).  Saving model ...
Validation loss decreased (0.547439 --> 0.544858).  Saving model ...
Validation loss decreased (0.544858 --> 0.542215).  Saving model ...
Validation loss decreased (0.542215 --> 0.539635).  Saving model ...
Validation loss decreased (0.539635 --> 0.537126).  Saving model ...
Validation loss decreased (0.537126 --> 0.534678).  Saving model ...
Validation loss decreased (0.534678 --> 0.532364).  Saving model ...
Validation loss decreased (0.532364 --> 0.529909).  Saving model ...
Validation loss decreased (0.529909 --> 0.527489).  Saving model ...
Validation loss decreased (0.527489 --> 0.525145).  Saving model ...
Validation loss decreased (0.525145 --> 0.522795).  Saving model ...
Validation loss decreased (0.522795 --> 0.520599).  Saving model ...
Validation loss decreased (0.520599 --> 0.518348).  Saving model ...
Validation loss decreased (0.518348 --> 0.516087).  Saving model ...
Validation loss decreased (0.516087 --> 0.513788).  Saving model ...
epoch 101, loss 0.5418, train acc 78.25%, f1 0.7830, precision 0.7811, recall 0.7850, auc 0.7825
Validation loss decreased (0.513788 --> 0.511506).  Saving model ...
Validation loss decreased (0.511506 --> 0.509260).  Saving model ...
Validation loss decreased (0.509260 --> 0.507146).  Saving model ...
Validation loss decreased (0.507146 --> 0.505047).  Saving model ...
Validation loss decreased (0.505047 --> 0.502963).  Saving model ...
Validation loss decreased (0.502963 --> 0.500909).  Saving model ...
Validation loss decreased (0.500909 --> 0.498912).  Saving model ...
Validation loss decreased (0.498912 --> 0.496955).  Saving model ...
Validation loss decreased (0.496955 --> 0.495081).  Saving model ...
Validation loss decreased (0.495081 --> 0.493298).  Saving model ...
Validation loss decreased (0.493298 --> 0.491515).  Saving model ...
Validation loss decreased (0.491515 --> 0.489758).  Saving model ...
Validation loss decreased (0.489758 --> 0.487984).  Saving model ...
Validation loss decreased (0.487984 --> 0.486245).  Saving model ...
Validation loss decreased (0.486245 --> 0.484508).  Saving model ...
Validation loss decreased (0.484508 --> 0.482932).  Saving model ...
Validation loss decreased (0.482932 --> 0.481452).  Saving model ...
Validation loss decreased (0.481452 --> 0.479966).  Saving model ...
Validation loss decreased (0.479966 --> 0.478461).  Saving model ...
Validation loss decreased (0.478461 --> 0.477052).  Saving model ...
Validation loss decreased (0.477052 --> 0.475753).  Saving model ...
Validation loss decreased (0.475753 --> 0.474403).  Saving model ...
Validation loss decreased (0.474403 --> 0.473035).  Saving model ...
Validation loss decreased (0.473035 --> 0.471738).  Saving model ...
Validation loss decreased (0.471738 --> 0.470451).  Saving model ...
Validation loss decreased (0.470451 --> 0.469260).  Saving model ...
Validation loss decreased (0.469260 --> 0.468064).  Saving model ...
Validation loss decreased (0.468064 --> 0.466920).  Saving model ...
Validation loss decreased (0.466920 --> 0.465787).  Saving model ...
Validation loss decreased (0.465787 --> 0.464587).  Saving model ...
Validation loss decreased (0.464587 --> 0.463333).  Saving model ...
Validation loss decreased (0.463333 --> 0.462181).  Saving model ...
Validation loss decreased (0.462181 --> 0.461051).  Saving model ...
Validation loss decreased (0.461051 --> 0.460029).  Saving model ...
Validation loss decreased (0.460029 --> 0.458891).  Saving model ...
Validation loss decreased (0.458891 --> 0.457824).  Saving model ...
Validation loss decreased (0.457824 --> 0.456842).  Saving model ...
Validation loss decreased (0.456842 --> 0.455939).  Saving model ...
Validation loss decreased (0.455939 --> 0.455082).  Saving model ...
Validation loss decreased (0.455082 --> 0.454286).  Saving model ...
Validation loss decreased (0.454286 --> 0.453426).  Saving model ...
Validation loss decreased (0.453426 --> 0.452648).  Saving model ...
Validation loss decreased (0.452648 --> 0.451828).  Saving model ...
Validation loss decreased (0.451828 --> 0.451068).  Saving model ...
Validation loss decreased (0.451068 --> 0.450309).  Saving model ...
Validation loss decreased (0.450309 --> 0.449660).  Saving model ...
Validation loss decreased (0.449660 --> 0.448978).  Saving model ...
Validation loss decreased (0.448978 --> 0.448204).  Saving model ...
Validation loss decreased (0.448204 --> 0.447398).  Saving model ...
Validation loss decreased (0.447398 --> 0.446570).  Saving model ...
Validation loss decreased (0.446570 --> 0.445740).  Saving model ...
Validation loss decreased (0.445740 --> 0.444825).  Saving model ...
Validation loss decreased (0.444825 --> 0.443906).  Saving model ...
Validation loss decreased (0.443906 --> 0.442914).  Saving model ...
Validation loss decreased (0.442914 --> 0.441989).  Saving model ...
Validation loss decreased (0.441989 --> 0.441114).  Saving model ...
Validation loss decreased (0.441114 --> 0.440163).  Saving model ...
Validation loss decreased (0.440163 --> 0.439260).  Saving model ...
Validation loss decreased (0.439260 --> 0.438322).  Saving model ...
Validation loss decreased (0.438322 --> 0.437445).  Saving model ...
Validation loss decreased (0.437445 --> 0.436462).  Saving model ...
Validation loss decreased (0.436462 --> 0.435592).  Saving model ...
Validation loss decreased (0.435592 --> 0.434831).  Saving model ...
Validation loss decreased (0.434831 --> 0.434113).  Saving model ...
Validation loss decreased (0.434113 --> 0.433397).  Saving model ...
Validation loss decreased (0.433397 --> 0.432738).  Saving model ...
Validation loss decreased (0.432738 --> 0.432119).  Saving model ...
Validation loss decreased (0.432119 --> 0.431536).  Saving model ...
Validation loss decreased (0.431536 --> 0.430986).  Saving model ...
Validation loss decreased (0.430986 --> 0.430407).  Saving model ...
Validation loss decreased (0.430407 --> 0.429753).  Saving model ...
Validation loss decreased (0.429753 --> 0.429204).  Saving model ...
Validation loss decreased (0.429204 --> 0.428674).  Saving model ...
Validation loss decreased (0.428674 --> 0.428183).  Saving model ...
Validation loss decreased (0.428183 --> 0.427704).  Saving model ...
Validation loss decreased (0.427704 --> 0.427297).  Saving model ...
Validation loss decreased (0.427297 --> 0.426913).  Saving model ...
Validation loss decreased (0.426913 --> 0.426473).  Saving model ...
Validation loss decreased (0.426473 --> 0.426005).  Saving model ...
Validation loss decreased (0.426005 --> 0.425642).  Saving model ...
Validation loss decreased (0.425642 --> 0.425289).  Saving model ...
Validation loss decreased (0.425289 --> 0.425046).  Saving model ...
Validation loss decreased (0.425046 --> 0.424888).  Saving model ...
Validation loss decreased (0.424888 --> 0.424781).  Saving model ...
Validation loss decreased (0.424781 --> 0.424711).  Saving model ...
Validation loss decreased (0.424711 --> 0.424649).  Saving model ...
Validation loss decreased (0.424649 --> 0.424563).  Saving model ...
Validation loss decreased (0.424563 --> 0.424484).  Saving model ...
Validation loss decreased (0.424484 --> 0.424423).  Saving model ...
Validation loss decreased (0.424423 --> 0.424359).  Saving model ...
Validation loss decreased (0.424359 --> 0.424264).  Saving model ...
Validation loss decreased (0.424264 --> 0.424155).  Saving model ...
Validation loss decreased (0.424155 --> 0.424051).  Saving model ...
Validation loss decreased (0.424051 --> 0.423997).  Saving model ...
Validation loss decreased (0.423997 --> 0.423955).  Saving model ...
Validation loss decreased (0.423955 --> 0.423840).  Saving model ...
Validation loss decreased (0.423840 --> 0.423701).  Saving model ...
Validation loss decreased (0.423701 --> 0.423556).  Saving model ...
Validation loss decreased (0.423556 --> 0.423450).  Saving model ...
Validation loss decreased (0.423450 --> 0.423295).  Saving model ...
epoch 201, loss 0.3821, train acc 79.75%, f1 0.7980, precision 0.7960, recall 0.8000, auc 0.7975
Validation loss decreased (0.423295 --> 0.423170).  Saving model ...
Validation loss decreased (0.423170 --> 0.423101).  Saving model ...
Validation loss decreased (0.423101 --> 0.423055).  Saving model ...
Validation loss decreased (0.423055 --> 0.422943).  Saving model ...
Validation loss decreased (0.422943 --> 0.422847).  Saving model ...
Validation loss decreased (0.422847 --> 0.422784).  Saving model ...
Validation loss decreased (0.422784 --> 0.422758).  Saving model ...
Validation loss decreased (0.422758 --> 0.422658).  Saving model ...
Validation loss decreased (0.422658 --> 0.422534).  Saving model ...
Validation loss decreased (0.422534 --> 0.422371).  Saving model ...
Validation loss decreased (0.422371 --> 0.422225).  Saving model ...
Validation loss decreased (0.422225 --> 0.422148).  Saving model ...
Validation loss decreased (0.422148 --> 0.422022).  Saving model ...
Validation loss decreased (0.422022 --> 0.421812).  Saving model ...
Validation loss decreased (0.421812 --> 0.421661).  Saving model ...
Validation loss decreased (0.421661 --> 0.421565).  Saving model ...
Validation loss decreased (0.421565 --> 0.421559).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
Validation loss decreased (0.421559 --> 0.421479).  Saving model ...
Validation loss decreased (0.421479 --> 0.421342).  Saving model ...
Validation loss decreased (0.421342 --> 0.421237).  Saving model ...
Validation loss decreased (0.421237 --> 0.421187).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 248, loss 0.2983, train acc 79.00%, f1 0.7900, precision 0.7900, recall 0.7900, auc 0.7900



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_4
./test_pima/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6378301886792452

the Fscore is 0.5853658536585367

the precision is 0.43243243243243246

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_4
----------------------



epoch 1, loss 0.6931, train acc 51.64%, f1 0.6723, precision 0.5084, recall 0.9921, auc 0.5164
epoch 101, loss 0.5474, train acc 78.97%, f1 0.7919, precision 0.7838, recall 0.8002, auc 0.7897
epoch 201, loss 0.3988, train acc 82.98%, f1 0.8296, precision 0.8306, recall 0.8287, auc 0.8298
epoch 301, loss 0.3389, train acc 84.47%, f1 0.8445, precision 0.8457, recall 0.8434, auc 0.8447
epoch 401, loss 0.3214, train acc 84.90%, f1 0.8486, precision 0.8508, recall 0.8464, auc 0.8490
epoch 501, loss 0.3833, train acc 85.03%, f1 0.8497, precision 0.8533, recall 0.8461, auc 0.8503
epoch 601, loss 0.3383, train acc 85.03%, f1 0.8499, precision 0.8521, recall 0.8477, auc 0.8503
epoch 701, loss 0.2877, train acc 85.09%, f1 0.8507, precision 0.8520, recall 0.8494, auc 0.8509
epoch 801, loss 0.1660, train acc 85.08%, f1 0.8504, precision 0.8525, recall 0.8484, auc 0.8508
epoch 901, loss 0.2493, train acc 85.04%, f1 0.8500, precision 0.8522, recall 0.8479, auc 0.8504
epoch 1001, loss 0.4962, train acc 85.07%, f1 0.8505, precision 0.8518, recall 0.8492, auc 0.8507
epoch 1101, loss 0.3166, train acc 85.10%, f1 0.8508, precision 0.8519, recall 0.8496, auc 0.8510
epoch 1201, loss 0.2797, train acc 85.08%, f1 0.8506, precision 0.8517, recall 0.8495, auc 0.8508
epoch 1301, loss 0.3453, train acc 85.08%, f1 0.8506, precision 0.8517, recall 0.8496, auc 0.8508
epoch 1401, loss 0.2396, train acc 85.08%, f1 0.8506, precision 0.8516, recall 0.8496, auc 0.8508
epoch 1501, loss 0.2711, train acc 85.03%, f1 0.8502, precision 0.8509, recall 0.8494, auc 0.8503
epoch 1601, loss 0.3125, train acc 85.06%, f1 0.8504, precision 0.8513, recall 0.8496, auc 0.8506
epoch 1701, loss 0.2894, train acc 85.07%, f1 0.8507, precision 0.8511, recall 0.8503, auc 0.8507
epoch 1801, loss 0.4150, train acc 85.08%, f1 0.8507, precision 0.8513, recall 0.8501, auc 0.8508
epoch 1901, loss 0.4031, train acc 85.13%, f1 0.8512, precision 0.8517, recall 0.8507, auc 0.8513
epoch 2001, loss 0.3104, train acc 85.04%, f1 0.8503, precision 0.8507, recall 0.8499, auc 0.8504
epoch 2101, loss 0.3810, train acc 85.09%, f1 0.8508, precision 0.8515, recall 0.8501, auc 0.8509
epoch 2201, loss 0.3972, train acc 85.08%, f1 0.8508, precision 0.8511, recall 0.8504, auc 0.8508
epoch 2301, loss 0.2585, train acc 85.11%, f1 0.8510, precision 0.8517, recall 0.8504, auc 0.8511
epoch 2401, loss 0.4255, train acc 85.11%, f1 0.8510, precision 0.8515, recall 0.8505, auc 0.8511
epoch 2501, loss 0.3563, train acc 85.14%, f1 0.8512, precision 0.8521, recall 0.8504, auc 0.8514
epoch 2601, loss 0.3860, train acc 85.22%, f1 0.8522, precision 0.8524, recall 0.8520, auc 0.8522
epoch 2701, loss 0.2388, train acc 85.25%, f1 0.8524, precision 0.8530, recall 0.8519, auc 0.8525
epoch 2801, loss 0.2700, train acc 85.28%, f1 0.8527, precision 0.8528, recall 0.8527, auc 0.8528
epoch 2901, loss 0.2963, train acc 85.32%, f1 0.8532, precision 0.8534, recall 0.8529, auc 0.8532
epoch 3001, loss 0.3255, train acc 85.47%, f1 0.8547, precision 0.8548, recall 0.8547, auc 0.8547
epoch 3101, loss 0.2331, train acc 85.50%, f1 0.8550, precision 0.8550, recall 0.8550, auc 0.8550
epoch 3201, loss 0.3702, train acc 85.63%, f1 0.8562, precision 0.8567, recall 0.8558, auc 0.8563
epoch 3301, loss 0.2549, train acc 85.70%, f1 0.8569, precision 0.8573, recall 0.8566, auc 0.8570
epoch 3401, loss 0.2605, train acc 85.86%, f1 0.8585, precision 0.8589, recall 0.8582, auc 0.8586
epoch 3501, loss 0.3240, train acc 85.97%, f1 0.8597, precision 0.8596, recall 0.8598, auc 0.8597
epoch 3601, loss 0.3293, train acc 86.09%, f1 0.8609, precision 0.8613, recall 0.8604, auc 0.8609
epoch 3701, loss 0.3248, train acc 86.28%, f1 0.8628, precision 0.8627, recall 0.8628, auc 0.8628
epoch 3801, loss 0.2727, train acc 86.35%, f1 0.8634, precision 0.8636, recall 0.8633, auc 0.8635
epoch 3901, loss 0.2660, train acc 86.50%, f1 0.8649, precision 0.8655, recall 0.8643, auc 0.8650
epoch 4001, loss 0.2544, train acc 86.51%, f1 0.8651, precision 0.8652, recall 0.8649, auc 0.8651
epoch 4101, loss 0.2625, train acc 86.58%, f1 0.8658, precision 0.8662, recall 0.8653, auc 0.8658
epoch 4201, loss 0.2514, train acc 86.65%, f1 0.8664, precision 0.8667, recall 0.8661, auc 0.8665
epoch 4301, loss 0.2861, train acc 86.74%, f1 0.8673, precision 0.8678, recall 0.8668, auc 0.8674
epoch 4401, loss 0.2347, train acc 86.74%, f1 0.8673, precision 0.8678, recall 0.8668, auc 0.8674
epoch 4501, loss 0.2676, train acc 86.81%, f1 0.8681, precision 0.8682, recall 0.8679, auc 0.8681
epoch 4601, loss 0.3657, train acc 86.83%, f1 0.8684, precision 0.8681, recall 0.8687, auc 0.8683
epoch 4701, loss 0.4362, train acc 86.94%, f1 0.8693, precision 0.8696, recall 0.8690, auc 0.8694
epoch 4801, loss 0.2978, train acc 86.84%, f1 0.8683, precision 0.8696, recall 0.8670, auc 0.8684
epoch 4901, loss 0.2975, train acc 86.97%, f1 0.8697, precision 0.8696, recall 0.8698, auc 0.8697
epoch 5001, loss 0.2747, train acc 86.99%, f1 0.8699, precision 0.8697, recall 0.8700, auc 0.8699
epoch 5101, loss 0.3746, train acc 86.99%, f1 0.8698, precision 0.8702, recall 0.8694, auc 0.8699
epoch 5201, loss 0.2251, train acc 87.09%, f1 0.8709, precision 0.8710, recall 0.8708, auc 0.8709
epoch 5301, loss 0.3304, train acc 87.15%, f1 0.8715, precision 0.8715, recall 0.8715, auc 0.8715
epoch 5401, loss 0.2555, train acc 87.18%, f1 0.8719, precision 0.8718, recall 0.8719, auc 0.8718
epoch 5501, loss 0.2396, train acc 87.18%, f1 0.8717, precision 0.8721, recall 0.8713, auc 0.8718
epoch 5601, loss 0.2474, train acc 87.23%, f1 0.8722, precision 0.8727, recall 0.8718, auc 0.8723
epoch 5701, loss 0.2428, train acc 87.29%, f1 0.8729, precision 0.8729, recall 0.8728, auc 0.8729
epoch 5801, loss 0.2341, train acc 87.31%, f1 0.8731, precision 0.8731, recall 0.8730, auc 0.8731
epoch 5901, loss 0.3846, train acc 87.36%, f1 0.8736, precision 0.8736, recall 0.8736, auc 0.8736
epoch 6001, loss 0.1559, train acc 87.43%, f1 0.8742, precision 0.8746, recall 0.8738, auc 0.8743
epoch 6101, loss 0.2484, train acc 87.45%, f1 0.8744, precision 0.8753, recall 0.8735, auc 0.8745
epoch 6201, loss 0.2376, train acc 87.48%, f1 0.8748, precision 0.8748, recall 0.8748, auc 0.8748
epoch 6301, loss 0.3165, train acc 87.58%, f1 0.8757, precision 0.8763, recall 0.8751, auc 0.8758
epoch 6401, loss 0.4482, train acc 87.58%, f1 0.8757, precision 0.8761, recall 0.8753, auc 0.8758
epoch 6501, loss 0.2907, train acc 87.62%, f1 0.8762, precision 0.8761, recall 0.8764, auc 0.8762
epoch 6601, loss 0.2107, train acc 87.67%, f1 0.8767, precision 0.8768, recall 0.8766, auc 0.8767
epoch 6701, loss 0.2578, train acc 87.70%, f1 0.8769, precision 0.8772, recall 0.8767, auc 0.8770
epoch 6801, loss 0.2491, train acc 87.79%, f1 0.8778, precision 0.8784, recall 0.8772, auc 0.8779
epoch 6901, loss 0.3104, train acc 87.79%, f1 0.8779, precision 0.8781, recall 0.8777, auc 0.8779
epoch 7001, loss 0.2329, train acc 87.82%, f1 0.8782, precision 0.8784, recall 0.8780, auc 0.8782
epoch 7101, loss 0.2692, train acc 87.87%, f1 0.8787, precision 0.8784, recall 0.8791, auc 0.8787
epoch 7201, loss 0.3101, train acc 87.91%, f1 0.8791, precision 0.8791, recall 0.8792, auc 0.8791
epoch 7301, loss 0.3475, train acc 87.95%, f1 0.8796, precision 0.8791, recall 0.8800, auc 0.8795
epoch 7401, loss 0.2407, train acc 88.01%, f1 0.8802, precision 0.8798, recall 0.8805, auc 0.8801
epoch 7501, loss 0.2688, train acc 88.05%, f1 0.8805, precision 0.8806, recall 0.8805, auc 0.8805
epoch 7601, loss 0.2868, train acc 88.02%, f1 0.8803, precision 0.8799, recall 0.8807, auc 0.8802
epoch 7701, loss 0.2396, train acc 88.09%, f1 0.8810, precision 0.8798, recall 0.8823, auc 0.8809
epoch 7801, loss 0.2105, train acc 88.10%, f1 0.8811, precision 0.8807, recall 0.8814, auc 0.8810
epoch 7901, loss 0.3237, train acc 88.19%, f1 0.8819, precision 0.8819, recall 0.8819, auc 0.8819
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_4
./test_pima/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6578301886792453

the Fscore is 0.6

the precision is 0.4485981308411215

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_4
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.5163, train acc 79.33%, f1 0.7932, precision 0.7935, recall 0.7930, auc 0.7933
epoch 201, loss 0.3772, train acc 82.82%, f1 0.8282, precision 0.8283, recall 0.8281, auc 0.8282
epoch 301, loss 0.3316, train acc 84.31%, f1 0.8431, precision 0.8431, recall 0.8430, auc 0.8431
epoch 401, loss 0.3708, train acc 84.86%, f1 0.8486, precision 0.8486, recall 0.8486, auc 0.8486
epoch 501, loss 0.4124, train acc 84.94%, f1 0.8494, precision 0.8494, recall 0.8494, auc 0.8494
epoch 601, loss 0.3146, train acc 85.05%, f1 0.8505, precision 0.8505, recall 0.8504, auc 0.8505
epoch 701, loss 0.3621, train acc 85.07%, f1 0.8507, precision 0.8508, recall 0.8507, auc 0.8507
epoch 801, loss 0.3126, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8508, auc 0.8508
epoch 901, loss 0.3067, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 1001, loss 0.2727, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 1101, loss 0.4978, train acc 85.06%, f1 0.8505, precision 0.8506, recall 0.8505, auc 0.8506
epoch 1201, loss 0.4138, train acc 85.03%, f1 0.8503, precision 0.8503, recall 0.8503, auc 0.8503
epoch 1301, loss 0.2873, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8504, auc 0.8504
epoch 1401, loss 0.2332, train acc 85.07%, f1 0.8507, precision 0.8506, recall 0.8507, auc 0.8507
epoch 1501, loss 0.3326, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8504, auc 0.8504
epoch 1601, loss 0.3188, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8508, auc 0.8508
epoch 1701, loss 0.3432, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 1801, loss 0.3174, train acc 85.05%, f1 0.8505, precision 0.8505, recall 0.8504, auc 0.8505
epoch 1901, loss 0.2194, train acc 85.09%, f1 0.8509, precision 0.8510, recall 0.8509, auc 0.8509
epoch 2001, loss 0.2850, train acc 85.02%, f1 0.8502, precision 0.8503, recall 0.8502, auc 0.8502
epoch 2101, loss 0.3090, train acc 85.08%, f1 0.8508, precision 0.8509, recall 0.8508, auc 0.8508
epoch 2201, loss 0.2304, train acc 85.13%, f1 0.8513, precision 0.8514, recall 0.8513, auc 0.8513
epoch 2301, loss 0.2747, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8507, auc 0.8508
epoch 2401, loss 0.4018, train acc 85.15%, f1 0.8515, precision 0.8516, recall 0.8515, auc 0.8515
epoch 2501, loss 0.3564, train acc 85.20%, f1 0.8519, precision 0.8520, recall 0.8519, auc 0.8520
epoch 2601, loss 0.4019, train acc 85.17%, f1 0.8517, precision 0.8518, recall 0.8517, auc 0.8518
epoch 2701, loss 0.3775, train acc 85.25%, f1 0.8525, precision 0.8526, recall 0.8524, auc 0.8525
epoch 2801, loss 0.3170, train acc 85.32%, f1 0.8532, precision 0.8532, recall 0.8532, auc 0.8532
epoch 2901, loss 0.3442, train acc 85.40%, f1 0.8540, precision 0.8541, recall 0.8540, auc 0.8540
epoch 3001, loss 0.3033, train acc 85.54%, f1 0.8554, precision 0.8555, recall 0.8553, auc 0.8554
epoch 3101, loss 0.2592, train acc 85.55%, f1 0.8555, precision 0.8555, recall 0.8555, auc 0.8555
epoch 3201, loss 0.3651, train acc 85.70%, f1 0.8570, precision 0.8570, recall 0.8570, auc 0.8570
epoch 3301, loss 0.2062, train acc 85.87%, f1 0.8588, precision 0.8587, recall 0.8588, auc 0.8587
epoch 3401, loss 0.2402, train acc 85.96%, f1 0.8596, precision 0.8596, recall 0.8597, auc 0.8596
epoch 3501, loss 0.4444, train acc 86.08%, f1 0.8609, precision 0.8608, recall 0.8610, auc 0.8608
epoch 3601, loss 0.3384, train acc 86.20%, f1 0.8620, precision 0.8622, recall 0.8619, auc 0.8620
epoch 3701, loss 0.1783, train acc 86.38%, f1 0.8639, precision 0.8638, recall 0.8639, auc 0.8638
epoch 3801, loss 0.2993, train acc 86.34%, f1 0.8634, precision 0.8634, recall 0.8634, auc 0.8634
epoch 3901, loss 0.2566, train acc 86.47%, f1 0.8647, precision 0.8647, recall 0.8647, auc 0.8647
epoch 4001, loss 0.4274, train acc 86.65%, f1 0.8665, precision 0.8665, recall 0.8665, auc 0.8665
epoch 4101, loss 0.3508, train acc 86.65%, f1 0.8664, precision 0.8665, recall 0.8664, auc 0.8665
epoch 4201, loss 0.2975, train acc 86.75%, f1 0.8675, precision 0.8675, recall 0.8676, auc 0.8675
epoch 4301, loss 0.2965, train acc 86.76%, f1 0.8676, precision 0.8675, recall 0.8677, auc 0.8676
epoch 4401, loss 0.2804, train acc 86.85%, f1 0.8685, precision 0.8684, recall 0.8685, auc 0.8685
epoch 4501, loss 0.2613, train acc 86.87%, f1 0.8687, precision 0.8687, recall 0.8686, auc 0.8687
epoch 4601, loss 0.2489, train acc 86.93%, f1 0.8693, precision 0.8694, recall 0.8693, auc 0.8693
epoch 4701, loss 0.2408, train acc 86.96%, f1 0.8696, precision 0.8695, recall 0.8697, auc 0.8696
epoch 4801, loss 0.2814, train acc 86.96%, f1 0.8696, precision 0.8697, recall 0.8696, auc 0.8696
epoch 4901, loss 0.3643, train acc 87.01%, f1 0.8701, precision 0.8702, recall 0.8701, auc 0.8701
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_Mirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_4
./test_pima/result_MLP_concat_Mirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6578301886792453

the Fscore is 0.6

the precision is 0.4485981308411215

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_4
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.1429, recall 0.0000, auc 0.5000
epoch 101, loss 0.5461, train acc 79.72%, f1 0.8006, precision 0.7875, recall 0.8142, auc 0.7972
epoch 201, loss 0.4218, train acc 82.69%, f1 0.8269, precision 0.8271, recall 0.8268, auc 0.8269
epoch 301, loss 0.3091, train acc 84.32%, f1 0.8430, precision 0.8445, recall 0.8415, auc 0.8432
epoch 401, loss 0.3389, train acc 84.91%, f1 0.8487, precision 0.8510, recall 0.8465, auc 0.8491
epoch 501, loss 0.2904, train acc 84.95%, f1 0.8491, precision 0.8515, recall 0.8467, auc 0.8495
epoch 601, loss 0.4689, train acc 85.06%, f1 0.8502, precision 0.8524, recall 0.8481, auc 0.8506
epoch 701, loss 0.2622, train acc 85.06%, f1 0.8502, precision 0.8526, recall 0.8478, auc 0.8506
epoch 801, loss 0.4524, train acc 85.05%, f1 0.8502, precision 0.8520, recall 0.8483, auc 0.8505
epoch 901, loss 0.2295, train acc 85.05%, f1 0.8500, precision 0.8527, recall 0.8473, auc 0.8505
epoch 1001, loss 0.2636, train acc 85.05%, f1 0.8503, precision 0.8518, recall 0.8488, auc 0.8505
epoch 1101, loss 0.3583, train acc 85.02%, f1 0.8500, precision 0.8510, recall 0.8490, auc 0.8502
epoch 1201, loss 0.3713, train acc 85.07%, f1 0.8505, precision 0.8517, recall 0.8492, auc 0.8507
epoch 1301, loss 0.2795, train acc 85.06%, f1 0.8504, precision 0.8517, recall 0.8490, auc 0.8506
epoch 1401, loss 0.3092, train acc 85.02%, f1 0.8501, precision 0.8508, recall 0.8495, auc 0.8502
epoch 1501, loss 0.3437, train acc 85.09%, f1 0.8507, precision 0.8522, recall 0.8492, auc 0.8509
epoch 1601, loss 0.2511, train acc 85.07%, f1 0.8505, precision 0.8518, recall 0.8492, auc 0.8507
epoch 1701, loss 0.3373, train acc 85.11%, f1 0.8509, precision 0.8518, recall 0.8501, auc 0.8511
epoch 1801, loss 0.3940, train acc 85.05%, f1 0.8504, precision 0.8511, recall 0.8496, auc 0.8505
epoch 1901, loss 0.3539, train acc 85.09%, f1 0.8508, precision 0.8513, recall 0.8503, auc 0.8509
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_Mirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_4
./test_pima/result_MLP_concat_Mirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6478301886792452

the Fscore is 0.5925925925925927

the precision is 0.44036697247706424

the recall is 0.9056603773584906

Done
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_4
----------------------



epoch 1, loss 0.6931, train acc 46.00%, f1 0.6301, precision 0.4600, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.694255).  Saving model ...
Validation loss decreased (0.694255 --> 0.693556).  Saving model ...
Validation loss decreased (0.693556 --> 0.693020).  Saving model ...
Validation loss decreased (0.693020 --> 0.692507).  Saving model ...
Validation loss decreased (0.692507 --> 0.691992).  Saving model ...
Validation loss decreased (0.691992 --> 0.691555).  Saving model ...
Validation loss decreased (0.691555 --> 0.691278).  Saving model ...
Validation loss decreased (0.691278 --> 0.691142).  Saving model ...
Validation loss decreased (0.691142 --> 0.691024).  Saving model ...
Validation loss decreased (0.691024 --> 0.690924).  Saving model ...
Validation loss decreased (0.690924 --> 0.690757).  Saving model ...
Validation loss decreased (0.690757 --> 0.690552).  Saving model ...
Validation loss decreased (0.690552 --> 0.690293).  Saving model ...
Validation loss decreased (0.690293 --> 0.690063).  Saving model ...
Validation loss decreased (0.690063 --> 0.689859).  Saving model ...
Validation loss decreased (0.689859 --> 0.689699).  Saving model ...
Validation loss decreased (0.689699 --> 0.689538).  Saving model ...
Validation loss decreased (0.689538 --> 0.689337).  Saving model ...
Validation loss decreased (0.689337 --> 0.689038).  Saving model ...
Validation loss decreased (0.689038 --> 0.688684).  Saving model ...
Validation loss decreased (0.688684 --> 0.688282).  Saving model ...
Validation loss decreased (0.688282 --> 0.687812).  Saving model ...
Validation loss decreased (0.687812 --> 0.687404).  Saving model ...
Validation loss decreased (0.687404 --> 0.686951).  Saving model ...
Validation loss decreased (0.686951 --> 0.686441).  Saving model ...
Validation loss decreased (0.686441 --> 0.685879).  Saving model ...
Validation loss decreased (0.685879 --> 0.685248).  Saving model ...
Validation loss decreased (0.685248 --> 0.684533).  Saving model ...
Validation loss decreased (0.684533 --> 0.683738).  Saving model ...
Validation loss decreased (0.683738 --> 0.682907).  Saving model ...
Validation loss decreased (0.682907 --> 0.682004).  Saving model ...
Validation loss decreased (0.682004 --> 0.681120).  Saving model ...
Validation loss decreased (0.681120 --> 0.680156).  Saving model ...
Validation loss decreased (0.680156 --> 0.679115).  Saving model ...
Validation loss decreased (0.679115 --> 0.678040).  Saving model ...
Validation loss decreased (0.678040 --> 0.676894).  Saving model ...
Validation loss decreased (0.676894 --> 0.675676).  Saving model ...
Validation loss decreased (0.675676 --> 0.674383).  Saving model ...
Validation loss decreased (0.674383 --> 0.673065).  Saving model ...
Validation loss decreased (0.673065 --> 0.671712).  Saving model ...
Validation loss decreased (0.671712 --> 0.670314).  Saving model ...
Validation loss decreased (0.670314 --> 0.668868).  Saving model ...
Validation loss decreased (0.668868 --> 0.667323).  Saving model ...
Validation loss decreased (0.667323 --> 0.665723).  Saving model ...
Validation loss decreased (0.665723 --> 0.664067).  Saving model ...
Validation loss decreased (0.664067 --> 0.662354).  Saving model ...
Validation loss decreased (0.662354 --> 0.660599).  Saving model ...
Validation loss decreased (0.660599 --> 0.658805).  Saving model ...
Validation loss decreased (0.658805 --> 0.656980).  Saving model ...
Validation loss decreased (0.656980 --> 0.655121).  Saving model ...
Validation loss decreased (0.655121 --> 0.653238).  Saving model ...
Validation loss decreased (0.653238 --> 0.651448).  Saving model ...
Validation loss decreased (0.651448 --> 0.649707).  Saving model ...
Validation loss decreased (0.649707 --> 0.648002).  Saving model ...
Validation loss decreased (0.648002 --> 0.646251).  Saving model ...
Validation loss decreased (0.646251 --> 0.644425).  Saving model ...
Validation loss decreased (0.644425 --> 0.642519).  Saving model ...
Validation loss decreased (0.642519 --> 0.640574).  Saving model ...
Validation loss decreased (0.640574 --> 0.638570).  Saving model ...
Validation loss decreased (0.638570 --> 0.636585).  Saving model ...
Validation loss decreased (0.636585 --> 0.634585).  Saving model ...
Validation loss decreased (0.634585 --> 0.632606).  Saving model ...
Validation loss decreased (0.632606 --> 0.630621).  Saving model ...
Validation loss decreased (0.630621 --> 0.628681).  Saving model ...
Validation loss decreased (0.628681 --> 0.626670).  Saving model ...
Validation loss decreased (0.626670 --> 0.624636).  Saving model ...
Validation loss decreased (0.624636 --> 0.622580).  Saving model ...
Validation loss decreased (0.622580 --> 0.620462).  Saving model ...
Validation loss decreased (0.620462 --> 0.618313).  Saving model ...
Validation loss decreased (0.618313 --> 0.616168).  Saving model ...
Validation loss decreased (0.616168 --> 0.614007).  Saving model ...
Validation loss decreased (0.614007 --> 0.611779).  Saving model ...
Validation loss decreased (0.611779 --> 0.609480).  Saving model ...
Validation loss decreased (0.609480 --> 0.607163).  Saving model ...
Validation loss decreased (0.607163 --> 0.604795).  Saving model ...
Validation loss decreased (0.604795 --> 0.602397).  Saving model ...
Validation loss decreased (0.602397 --> 0.599963).  Saving model ...
Validation loss decreased (0.599963 --> 0.597476).  Saving model ...
Validation loss decreased (0.597476 --> 0.594981).  Saving model ...
Validation loss decreased (0.594981 --> 0.592491).  Saving model ...
Validation loss decreased (0.592491 --> 0.589930).  Saving model ...
Validation loss decreased (0.589930 --> 0.587413).  Saving model ...
Validation loss decreased (0.587413 --> 0.584885).  Saving model ...
Validation loss decreased (0.584885 --> 0.582396).  Saving model ...
Validation loss decreased (0.582396 --> 0.579967).  Saving model ...
Validation loss decreased (0.579967 --> 0.577584).  Saving model ...
Validation loss decreased (0.577584 --> 0.575137).  Saving model ...
Validation loss decreased (0.575137 --> 0.572678).  Saving model ...
Validation loss decreased (0.572678 --> 0.570197).  Saving model ...
Validation loss decreased (0.570197 --> 0.567753).  Saving model ...
Validation loss decreased (0.567753 --> 0.565379).  Saving model ...
Validation loss decreased (0.565379 --> 0.563060).  Saving model ...
Validation loss decreased (0.563060 --> 0.560783).  Saving model ...
Validation loss decreased (0.560783 --> 0.558528).  Saving model ...
Validation loss decreased (0.558528 --> 0.556301).  Saving model ...
Validation loss decreased (0.556301 --> 0.554097).  Saving model ...
Validation loss decreased (0.554097 --> 0.551874).  Saving model ...
Validation loss decreased (0.551874 --> 0.549576).  Saving model ...
Validation loss decreased (0.549576 --> 0.547275).  Saving model ...
Validation loss decreased (0.547275 --> 0.544976).  Saving model ...
epoch 101, loss 0.5541, train acc 80.50%, f1 0.8000, precision 0.7573, recall 0.8478, auc 0.8082
Validation loss decreased (0.544976 --> 0.542647).  Saving model ...
Validation loss decreased (0.542647 --> 0.540371).  Saving model ...
Validation loss decreased (0.540371 --> 0.538058).  Saving model ...
Validation loss decreased (0.538058 --> 0.535814).  Saving model ...
Validation loss decreased (0.535814 --> 0.533626).  Saving model ...
Validation loss decreased (0.533626 --> 0.531497).  Saving model ...
Validation loss decreased (0.531497 --> 0.529409).  Saving model ...
Validation loss decreased (0.529409 --> 0.527349).  Saving model ...
Validation loss decreased (0.527349 --> 0.525305).  Saving model ...
Validation loss decreased (0.525305 --> 0.523297).  Saving model ...
Validation loss decreased (0.523297 --> 0.521259).  Saving model ...
Validation loss decreased (0.521259 --> 0.519271).  Saving model ...
Validation loss decreased (0.519271 --> 0.517350).  Saving model ...
Validation loss decreased (0.517350 --> 0.515435).  Saving model ...
Validation loss decreased (0.515435 --> 0.513513).  Saving model ...
Validation loss decreased (0.513513 --> 0.511617).  Saving model ...
Validation loss decreased (0.511617 --> 0.509771).  Saving model ...
Validation loss decreased (0.509771 --> 0.507971).  Saving model ...
Validation loss decreased (0.507971 --> 0.506104).  Saving model ...
Validation loss decreased (0.506104 --> 0.504181).  Saving model ...
Validation loss decreased (0.504181 --> 0.502278).  Saving model ...
Validation loss decreased (0.502278 --> 0.500407).  Saving model ...
Validation loss decreased (0.500407 --> 0.498638).  Saving model ...
Validation loss decreased (0.498638 --> 0.496888).  Saving model ...
Validation loss decreased (0.496888 --> 0.495143).  Saving model ...
Validation loss decreased (0.495143 --> 0.493466).  Saving model ...
Validation loss decreased (0.493466 --> 0.491830).  Saving model ...
Validation loss decreased (0.491830 --> 0.490201).  Saving model ...
Validation loss decreased (0.490201 --> 0.488577).  Saving model ...
Validation loss decreased (0.488577 --> 0.487046).  Saving model ...
Validation loss decreased (0.487046 --> 0.485478).  Saving model ...
Validation loss decreased (0.485478 --> 0.483935).  Saving model ...
Validation loss decreased (0.483935 --> 0.482514).  Saving model ...
Validation loss decreased (0.482514 --> 0.481173).  Saving model ...
Validation loss decreased (0.481173 --> 0.479833).  Saving model ...
Validation loss decreased (0.479833 --> 0.478516).  Saving model ...
Validation loss decreased (0.478516 --> 0.477259).  Saving model ...
Validation loss decreased (0.477259 --> 0.476022).  Saving model ...
Validation loss decreased (0.476022 --> 0.474792).  Saving model ...
Validation loss decreased (0.474792 --> 0.473557).  Saving model ...
Validation loss decreased (0.473557 --> 0.472315).  Saving model ...
Validation loss decreased (0.472315 --> 0.471102).  Saving model ...
Validation loss decreased (0.471102 --> 0.469940).  Saving model ...
Validation loss decreased (0.469940 --> 0.468792).  Saving model ...
Validation loss decreased (0.468792 --> 0.467611).  Saving model ...
Validation loss decreased (0.467611 --> 0.466364).  Saving model ...
Validation loss decreased (0.466364 --> 0.465134).  Saving model ...
Validation loss decreased (0.465134 --> 0.463828).  Saving model ...
Validation loss decreased (0.463828 --> 0.462511).  Saving model ...
Validation loss decreased (0.462511 --> 0.461244).  Saving model ...
Validation loss decreased (0.461244 --> 0.459995).  Saving model ...
Validation loss decreased (0.459995 --> 0.458803).  Saving model ...
Validation loss decreased (0.458803 --> 0.457615).  Saving model ...
Validation loss decreased (0.457615 --> 0.456532).  Saving model ...
Validation loss decreased (0.456532 --> 0.455488).  Saving model ...
Validation loss decreased (0.455488 --> 0.454444).  Saving model ...
Validation loss decreased (0.454444 --> 0.453444).  Saving model ...
Validation loss decreased (0.453444 --> 0.452405).  Saving model ...
Validation loss decreased (0.452405 --> 0.451411).  Saving model ...
Validation loss decreased (0.451411 --> 0.450395).  Saving model ...
Validation loss decreased (0.450395 --> 0.449432).  Saving model ...
Validation loss decreased (0.449432 --> 0.448427).  Saving model ...
Validation loss decreased (0.448427 --> 0.447418).  Saving model ...
Validation loss decreased (0.447418 --> 0.446469).  Saving model ...
Validation loss decreased (0.446469 --> 0.445553).  Saving model ...
Validation loss decreased (0.445553 --> 0.444680).  Saving model ...
Validation loss decreased (0.444680 --> 0.443784).  Saving model ...
Validation loss decreased (0.443784 --> 0.442943).  Saving model ...
Validation loss decreased (0.442943 --> 0.442103).  Saving model ...
Validation loss decreased (0.442103 --> 0.441346).  Saving model ...
Validation loss decreased (0.441346 --> 0.440528).  Saving model ...
Validation loss decreased (0.440528 --> 0.439688).  Saving model ...
Validation loss decreased (0.439688 --> 0.438862).  Saving model ...
Validation loss decreased (0.438862 --> 0.438045).  Saving model ...
Validation loss decreased (0.438045 --> 0.437239).  Saving model ...
Validation loss decreased (0.437239 --> 0.436435).  Saving model ...
Validation loss decreased (0.436435 --> 0.435641).  Saving model ...
Validation loss decreased (0.435641 --> 0.434875).  Saving model ...
Validation loss decreased (0.434875 --> 0.434141).  Saving model ...
Validation loss decreased (0.434141 --> 0.433399).  Saving model ...
Validation loss decreased (0.433399 --> 0.432587).  Saving model ...
Validation loss decreased (0.432587 --> 0.431816).  Saving model ...
Validation loss decreased (0.431816 --> 0.431034).  Saving model ...
Validation loss decreased (0.431034 --> 0.430261).  Saving model ...
Validation loss decreased (0.430261 --> 0.429533).  Saving model ...
Validation loss decreased (0.429533 --> 0.428858).  Saving model ...
Validation loss decreased (0.428858 --> 0.428209).  Saving model ...
Validation loss decreased (0.428209 --> 0.427605).  Saving model ...
Validation loss decreased (0.427605 --> 0.426982).  Saving model ...
Validation loss decreased (0.426982 --> 0.426322).  Saving model ...
Validation loss decreased (0.426322 --> 0.425674).  Saving model ...
Validation loss decreased (0.425674 --> 0.425158).  Saving model ...
Validation loss decreased (0.425158 --> 0.424611).  Saving model ...
Validation loss decreased (0.424611 --> 0.424143).  Saving model ...
Validation loss decreased (0.424143 --> 0.423688).  Saving model ...
Validation loss decreased (0.423688 --> 0.423278).  Saving model ...
Validation loss decreased (0.423278 --> 0.422843).  Saving model ...
Validation loss decreased (0.422843 --> 0.422420).  Saving model ...
Validation loss decreased (0.422420 --> 0.421939).  Saving model ...
Validation loss decreased (0.421939 --> 0.421392).  Saving model ...
epoch 201, loss 0.3752, train acc 82.50%, f1 0.8128, precision 0.8000, recall 0.8261, auc 0.8251
Validation loss decreased (0.421392 --> 0.420838).  Saving model ...
Validation loss decreased (0.420838 --> 0.420300).  Saving model ...
Validation loss decreased (0.420300 --> 0.419823).  Saving model ...
Validation loss decreased (0.419823 --> 0.419364).  Saving model ...
Validation loss decreased (0.419364 --> 0.418889).  Saving model ...
Validation loss decreased (0.418889 --> 0.418415).  Saving model ...
Validation loss decreased (0.418415 --> 0.417960).  Saving model ...
Validation loss decreased (0.417960 --> 0.417535).  Saving model ...
Validation loss decreased (0.417535 --> 0.417096).  Saving model ...
Validation loss decreased (0.417096 --> 0.416647).  Saving model ...
Validation loss decreased (0.416647 --> 0.416216).  Saving model ...
Validation loss decreased (0.416216 --> 0.415773).  Saving model ...
Validation loss decreased (0.415773 --> 0.415319).  Saving model ...
Validation loss decreased (0.415319 --> 0.414819).  Saving model ...
Validation loss decreased (0.414819 --> 0.414285).  Saving model ...
Validation loss decreased (0.414285 --> 0.413696).  Saving model ...
Validation loss decreased (0.413696 --> 0.413119).  Saving model ...
Validation loss decreased (0.413119 --> 0.412608).  Saving model ...
Validation loss decreased (0.412608 --> 0.412111).  Saving model ...
Validation loss decreased (0.412111 --> 0.411581).  Saving model ...
Validation loss decreased (0.411581 --> 0.411101).  Saving model ...
Validation loss decreased (0.411101 --> 0.410581).  Saving model ...
Validation loss decreased (0.410581 --> 0.410132).  Saving model ...
Validation loss decreased (0.410132 --> 0.409642).  Saving model ...
Validation loss decreased (0.409642 --> 0.409158).  Saving model ...
Validation loss decreased (0.409158 --> 0.408646).  Saving model ...
Validation loss decreased (0.408646 --> 0.408088).  Saving model ...
Validation loss decreased (0.408088 --> 0.407594).  Saving model ...
Validation loss decreased (0.407594 --> 0.407174).  Saving model ...
Validation loss decreased (0.407174 --> 0.406718).  Saving model ...
Validation loss decreased (0.406718 --> 0.406272).  Saving model ...
Validation loss decreased (0.406272 --> 0.405824).  Saving model ...
Validation loss decreased (0.405824 --> 0.405403).  Saving model ...
Validation loss decreased (0.405403 --> 0.404989).  Saving model ...
Validation loss decreased (0.404989 --> 0.404598).  Saving model ...
Validation loss decreased (0.404598 --> 0.404160).  Saving model ...
Validation loss decreased (0.404160 --> 0.403697).  Saving model ...
Validation loss decreased (0.403697 --> 0.403277).  Saving model ...
Validation loss decreased (0.403277 --> 0.402941).  Saving model ...
Validation loss decreased (0.402941 --> 0.402574).  Saving model ...
Validation loss decreased (0.402574 --> 0.402143).  Saving model ...
Validation loss decreased (0.402143 --> 0.401710).  Saving model ...
Validation loss decreased (0.401710 --> 0.401268).  Saving model ...
Validation loss decreased (0.401268 --> 0.400876).  Saving model ...
Validation loss decreased (0.400876 --> 0.400474).  Saving model ...
Validation loss decreased (0.400474 --> 0.400157).  Saving model ...
Validation loss decreased (0.400157 --> 0.399839).  Saving model ...
Validation loss decreased (0.399839 --> 0.399577).  Saving model ...
Validation loss decreased (0.399577 --> 0.399297).  Saving model ...
Validation loss decreased (0.399297 --> 0.399111).  Saving model ...
Validation loss decreased (0.399111 --> 0.398911).  Saving model ...
Validation loss decreased (0.398911 --> 0.398709).  Saving model ...
Validation loss decreased (0.398709 --> 0.398449).  Saving model ...
Validation loss decreased (0.398449 --> 0.398140).  Saving model ...
Validation loss decreased (0.398140 --> 0.397820).  Saving model ...
Validation loss decreased (0.397820 --> 0.397600).  Saving model ...
Validation loss decreased (0.397600 --> 0.397377).  Saving model ...
Validation loss decreased (0.397377 --> 0.397182).  Saving model ...
Validation loss decreased (0.397182 --> 0.397061).  Saving model ...
Validation loss decreased (0.397061 --> 0.397025).  Saving model ...
Validation loss decreased (0.397025 --> 0.396882).  Saving model ...
Validation loss decreased (0.396882 --> 0.396626).  Saving model ...
Validation loss decreased (0.396626 --> 0.396444).  Saving model ...
Validation loss decreased (0.396444 --> 0.396256).  Saving model ...
Validation loss decreased (0.396256 --> 0.396086).  Saving model ...
Validation loss decreased (0.396086 --> 0.395928).  Saving model ...
Validation loss decreased (0.395928 --> 0.395708).  Saving model ...
Validation loss decreased (0.395708 --> 0.395503).  Saving model ...
Validation loss decreased (0.395503 --> 0.395308).  Saving model ...
Validation loss decreased (0.395308 --> 0.395175).  Saving model ...
Validation loss decreased (0.395175 --> 0.395044).  Saving model ...
Validation loss decreased (0.395044 --> 0.394881).  Saving model ...
Validation loss decreased (0.394881 --> 0.394748).  Saving model ...
Validation loss decreased (0.394748 --> 0.394606).  Saving model ...
Validation loss decreased (0.394606 --> 0.394421).  Saving model ...
Validation loss decreased (0.394421 --> 0.394219).  Saving model ...
Validation loss decreased (0.394219 --> 0.394013).  Saving model ...
Validation loss decreased (0.394013 --> 0.393828).  Saving model ...
Validation loss decreased (0.393828 --> 0.393592).  Saving model ...
Validation loss decreased (0.393592 --> 0.393413).  Saving model ...
Validation loss decreased (0.393413 --> 0.393289).  Saving model ...
Validation loss decreased (0.393289 --> 0.393112).  Saving model ...
Validation loss decreased (0.393112 --> 0.393003).  Saving model ...
Validation loss decreased (0.393003 --> 0.392926).  Saving model ...
Validation loss decreased (0.392926 --> 0.392858).  Saving model ...
Validation loss decreased (0.392858 --> 0.392791).  Saving model ...
Validation loss decreased (0.392791 --> 0.392730).  Saving model ...
Validation loss decreased (0.392730 --> 0.392565).  Saving model ...
Validation loss decreased (0.392565 --> 0.392446).  Saving model ...
Validation loss decreased (0.392446 --> 0.392364).  Saving model ...
Validation loss decreased (0.392364 --> 0.392263).  Saving model ...
Validation loss decreased (0.392263 --> 0.392139).  Saving model ...
Validation loss decreased (0.392139 --> 0.392036).  Saving model ...
Validation loss decreased (0.392036 --> 0.391900).  Saving model ...
Validation loss decreased (0.391900 --> 0.391772).  Saving model ...
Validation loss decreased (0.391772 --> 0.391546).  Saving model ...
Validation loss decreased (0.391546 --> 0.391361).  Saving model ...
Validation loss decreased (0.391361 --> 0.391207).  Saving model ...
Validation loss decreased (0.391207 --> 0.391036).  Saving model ...
Validation loss decreased (0.391036 --> 0.390839).  Saving model ...
epoch 301, loss 0.2985, train acc 84.00%, f1 0.8333, precision 0.8000, recall 0.8696, auc 0.8422
Validation loss decreased (0.390839 --> 0.390603).  Saving model ...
Validation loss decreased (0.390603 --> 0.390401).  Saving model ...
Validation loss decreased (0.390401 --> 0.390185).  Saving model ...
Validation loss decreased (0.390185 --> 0.390000).  Saving model ...
Validation loss decreased (0.390000 --> 0.389834).  Saving model ...
Validation loss decreased (0.389834 --> 0.389680).  Saving model ...
Validation loss decreased (0.389680 --> 0.389518).  Saving model ...
Validation loss decreased (0.389518 --> 0.389381).  Saving model ...
Validation loss decreased (0.389381 --> 0.389191).  Saving model ...
Validation loss decreased (0.389191 --> 0.389001).  Saving model ...
Validation loss decreased (0.389001 --> 0.388797).  Saving model ...
Validation loss decreased (0.388797 --> 0.388580).  Saving model ...
Validation loss decreased (0.388580 --> 0.388287).  Saving model ...
Validation loss decreased (0.388287 --> 0.387945).  Saving model ...
Validation loss decreased (0.387945 --> 0.387655).  Saving model ...
Validation loss decreased (0.387655 --> 0.387247).  Saving model ...
Validation loss decreased (0.387247 --> 0.386810).  Saving model ...
Validation loss decreased (0.386810 --> 0.386405).  Saving model ...
Validation loss decreased (0.386405 --> 0.386009).  Saving model ...
Validation loss decreased (0.386009 --> 0.385675).  Saving model ...
Validation loss decreased (0.385675 --> 0.385368).  Saving model ...
Validation loss decreased (0.385368 --> 0.385087).  Saving model ...
Validation loss decreased (0.385087 --> 0.384874).  Saving model ...
Validation loss decreased (0.384874 --> 0.384690).  Saving model ...
Validation loss decreased (0.384690 --> 0.384535).  Saving model ...
Validation loss decreased (0.384535 --> 0.384432).  Saving model ...
Validation loss decreased (0.384432 --> 0.384241).  Saving model ...
Validation loss decreased (0.384241 --> 0.384067).  Saving model ...
Validation loss decreased (0.384067 --> 0.383900).  Saving model ...
Validation loss decreased (0.383900 --> 0.383752).  Saving model ...
Validation loss decreased (0.383752 --> 0.383609).  Saving model ...
Validation loss decreased (0.383609 --> 0.383530).  Saving model ...
Validation loss decreased (0.383530 --> 0.383408).  Saving model ...
Validation loss decreased (0.383408 --> 0.383307).  Saving model ...
Validation loss decreased (0.383307 --> 0.383224).  Saving model ...
Validation loss decreased (0.383224 --> 0.383085).  Saving model ...
Validation loss decreased (0.383085 --> 0.382942).  Saving model ...
Validation loss decreased (0.382942 --> 0.382754).  Saving model ...
Validation loss decreased (0.382754 --> 0.382500).  Saving model ...
Validation loss decreased (0.382500 --> 0.382211).  Saving model ...
Validation loss decreased (0.382211 --> 0.381943).  Saving model ...
Validation loss decreased (0.381943 --> 0.381677).  Saving model ...
Validation loss decreased (0.381677 --> 0.381477).  Saving model ...
Validation loss decreased (0.381477 --> 0.381194).  Saving model ...
Validation loss decreased (0.381194 --> 0.380980).  Saving model ...
Validation loss decreased (0.380980 --> 0.380810).  Saving model ...
Validation loss decreased (0.380810 --> 0.380693).  Saving model ...
Validation loss decreased (0.380693 --> 0.380586).  Saving model ...
Validation loss decreased (0.380586 --> 0.380498).  Saving model ...
Validation loss decreased (0.380498 --> 0.380498).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.380498 --> 0.380460).  Saving model ...
Validation loss decreased (0.380460 --> 0.380358).  Saving model ...
Validation loss decreased (0.380358 --> 0.380297).  Saving model ...
Validation loss decreased (0.380297 --> 0.380209).  Saving model ...
Validation loss decreased (0.380209 --> 0.380058).  Saving model ...
Validation loss decreased (0.380058 --> 0.379982).  Saving model ...
Validation loss decreased (0.379982 --> 0.379924).  Saving model ...
Validation loss decreased (0.379924 --> 0.379885).  Saving model ...
Validation loss decreased (0.379885 --> 0.379876).  Saving model ...
Validation loss decreased (0.379876 --> 0.379812).  Saving model ...
Validation loss decreased (0.379812 --> 0.379762).  Saving model ...
Validation loss decreased (0.379762 --> 0.379595).  Saving model ...
Validation loss decreased (0.379595 --> 0.379431).  Saving model ...
Validation loss decreased (0.379431 --> 0.379307).  Saving model ...
Validation loss decreased (0.379307 --> 0.379241).  Saving model ...
Validation loss decreased (0.379241 --> 0.379169).  Saving model ...
Validation loss decreased (0.379169 --> 0.379077).  Saving model ...
Validation loss decreased (0.379077 --> 0.379007).  Saving model ...
Validation loss decreased (0.379007 --> 0.378958).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.378958 --> 0.378938).  Saving model ...
Validation loss decreased (0.378938 --> 0.378890).  Saving model ...
Validation loss decreased (0.378890 --> 0.378866).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.378866 --> 0.378847).  Saving model ...
Validation loss decreased (0.378847 --> 0.378829).  Saving model ...
Validation loss decreased (0.378829 --> 0.378775).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 398, loss 0.3208, train acc 84.00%, f1 0.8333, precision 0.8000, recall 0.8696, auc 0.8422



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_notMirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_4
./test_pima/result_MLP_concat_notMirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6372641509433963

the Fscore is 0.5868263473053892

the precision is 0.4298245614035088

the recall is 0.9245283018867925

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_4
----------------------



epoch 1, loss 0.6932, train acc 50.14%, f1 0.6679, precision 0.5014, recall 1.0000, auc 0.5000
epoch 101, loss 0.5825, train acc 79.21%, f1 0.7937, precision 0.7898, recall 0.7977, auc 0.7921
epoch 201, loss 0.4240, train acc 82.69%, f1 0.8262, precision 0.8319, recall 0.8206, auc 0.8269
epoch 301, loss 0.3670, train acc 84.32%, f1 0.8436, precision 0.8441, recall 0.8431, auc 0.8432
epoch 401, loss 0.4151, train acc 84.83%, f1 0.8487, precision 0.8490, recall 0.8484, auc 0.8483
epoch 501, loss 0.3451, train acc 84.95%, f1 0.8496, precision 0.8517, recall 0.8475, auc 0.8495
epoch 601, loss 0.3797, train acc 85.00%, f1 0.8499, precision 0.8526, recall 0.8472, auc 0.8500
epoch 701, loss 0.3305, train acc 85.08%, f1 0.8507, precision 0.8534, recall 0.8481, auc 0.8508
epoch 801, loss 0.2657, train acc 85.07%, f1 0.8513, precision 0.8502, recall 0.8523, auc 0.8507
epoch 901, loss 0.3888, train acc 85.05%, f1 0.8507, precision 0.8515, recall 0.8500, auc 0.8505
epoch 1001, loss 0.3721, train acc 85.04%, f1 0.8506, precision 0.8518, recall 0.8494, auc 0.8504
epoch 1101, loss 0.3575, train acc 85.10%, f1 0.8510, precision 0.8532, recall 0.8488, auc 0.8510
epoch 1201, loss 0.4585, train acc 85.08%, f1 0.8507, precision 0.8541, recall 0.8473, auc 0.8508
epoch 1301, loss 0.3749, train acc 85.08%, f1 0.8514, precision 0.8501, recall 0.8527, auc 0.8508
epoch 1401, loss 0.3390, train acc 85.05%, f1 0.8503, precision 0.8535, recall 0.8472, auc 0.8505
epoch 1501, loss 0.3940, train acc 85.05%, f1 0.8509, precision 0.8510, recall 0.8508, auc 0.8505
epoch 1601, loss 0.2686, train acc 85.08%, f1 0.8512, precision 0.8513, recall 0.8511, auc 0.8508
epoch 1701, loss 0.3174, train acc 85.07%, f1 0.8507, precision 0.8534, recall 0.8480, auc 0.8508
epoch 1801, loss 0.2658, train acc 84.98%, f1 0.8499, precision 0.8515, recall 0.8483, auc 0.8498
epoch 1901, loss 0.3493, train acc 85.08%, f1 0.8514, precision 0.8500, recall 0.8529, auc 0.8507
epoch 2001, loss 0.3121, train acc 85.03%, f1 0.8505, precision 0.8519, recall 0.8491, auc 0.8503
epoch 2101, loss 0.2483, train acc 85.06%, f1 0.8512, precision 0.8505, recall 0.8518, auc 0.8506
epoch 2201, loss 0.3378, train acc 85.08%, f1 0.8507, precision 0.8536, recall 0.8478, auc 0.8508
epoch 2301, loss 0.4525, train acc 85.08%, f1 0.8505, precision 0.8544, recall 0.8466, auc 0.8508
epoch 2401, loss 0.3138, train acc 85.05%, f1 0.8510, precision 0.8508, recall 0.8512, auc 0.8505
epoch 2501, loss 0.2816, train acc 85.09%, f1 0.8510, precision 0.8525, recall 0.8496, auc 0.8509
epoch 2601, loss 0.3470, train acc 85.11%, f1 0.8517, precision 0.8506, recall 0.8528, auc 0.8511
epoch 2701, loss 0.3775, train acc 85.06%, f1 0.8512, precision 0.8506, recall 0.8517, auc 0.8506
epoch 2801, loss 0.3164, train acc 85.08%, f1 0.8508, precision 0.8530, recall 0.8485, auc 0.8508
epoch 2901, loss 0.2898, train acc 85.13%, f1 0.8512, precision 0.8539, recall 0.8486, auc 0.8513
epoch 3001, loss 0.3897, train acc 85.12%, f1 0.8515, precision 0.8523, recall 0.8507, auc 0.8512
epoch 3101, loss 0.2419, train acc 85.07%, f1 0.8510, precision 0.8515, recall 0.8506, auc 0.8507
epoch 3201, loss 0.3306, train acc 85.10%, f1 0.8512, precision 0.8524, recall 0.8500, auc 0.8510
epoch 3301, loss 0.4007, train acc 85.10%, f1 0.8515, precision 0.8507, recall 0.8523, auc 0.8509
epoch 3401, loss 0.3422, train acc 85.10%, f1 0.8512, precision 0.8526, recall 0.8497, auc 0.8510
epoch 3501, loss 0.2789, train acc 85.15%, f1 0.8523, precision 0.8503, recall 0.8542, auc 0.8515
epoch 3601, loss 0.2900, train acc 85.17%, f1 0.8522, precision 0.8517, recall 0.8527, auc 0.8517
epoch 3701, loss 0.2537, train acc 85.22%, f1 0.8523, precision 0.8539, recall 0.8507, auc 0.8522
epoch 3801, loss 0.2847, train acc 85.28%, f1 0.8534, precision 0.8525, recall 0.8543, auc 0.8528
epoch 3901, loss 0.2597, train acc 85.30%, f1 0.8531, precision 0.8549, recall 0.8512, auc 0.8530
epoch 4001, loss 0.1824, train acc 85.34%, f1 0.8536, precision 0.8545, recall 0.8528, auc 0.8534
epoch 4101, loss 0.2701, train acc 85.46%, f1 0.8551, precision 0.8547, recall 0.8554, auc 0.8546
epoch 4201, loss 0.4209, train acc 85.50%, f1 0.8547, precision 0.8590, recall 0.8505, auc 0.8551
epoch 4301, loss 0.3434, train acc 85.63%, f1 0.8564, precision 0.8580, recall 0.8549, auc 0.8563
epoch 4401, loss 0.2703, train acc 85.70%, f1 0.8573, precision 0.8580, recall 0.8566, auc 0.8570
epoch 4501, loss 0.3343, train acc 85.82%, f1 0.8586, precision 0.8584, recall 0.8589, auc 0.8582
epoch 4601, loss 0.3024, train acc 85.92%, f1 0.8591, precision 0.8617, recall 0.8567, auc 0.8592
epoch 4701, loss 0.3327, train acc 86.02%, f1 0.8605, precision 0.8615, recall 0.8594, auc 0.8602
epoch 4801, loss 0.2765, train acc 86.06%, f1 0.8609, precision 0.8615, recall 0.8603, auc 0.8606
epoch 4901, loss 0.2951, train acc 86.19%, f1 0.8616, precision 0.8656, recall 0.8577, auc 0.8619
epoch 5001, loss 0.3246, train acc 86.25%, f1 0.8629, precision 0.8628, recall 0.8630, auc 0.8625
epoch 5101, loss 0.2509, train acc 86.39%, f1 0.8644, precision 0.8636, recall 0.8653, auc 0.8639
epoch 5201, loss 0.2998, train acc 86.41%, f1 0.8644, precision 0.8646, recall 0.8643, auc 0.8641
epoch 5301, loss 0.2773, train acc 86.51%, f1 0.8654, precision 0.8660, recall 0.8648, auc 0.8651
epoch 5401, loss 0.3537, train acc 86.51%, f1 0.8654, precision 0.8659, recall 0.8650, auc 0.8651
epoch 5501, loss 0.3190, train acc 86.61%, f1 0.8669, precision 0.8646, recall 0.8691, auc 0.8661
epoch 5601, loss 0.3552, train acc 86.65%, f1 0.8674, precision 0.8642, recall 0.8707, auc 0.8665
epoch 5701, loss 0.2932, train acc 86.68%, f1 0.8667, precision 0.8699, recall 0.8635, auc 0.8668
epoch 5801, loss 0.2240, train acc 86.67%, f1 0.8675, precision 0.8649, recall 0.8702, auc 0.8667
epoch 5901, loss 0.2918, train acc 86.73%, f1 0.8671, precision 0.8708, recall 0.8633, auc 0.8673
epoch 6001, loss 0.2400, train acc 86.78%, f1 0.8679, precision 0.8695, recall 0.8663, auc 0.8678
epoch 6101, loss 0.3318, train acc 86.82%, f1 0.8682, precision 0.8704, recall 0.8661, auc 0.8682
epoch 6201, loss 0.3645, train acc 86.80%, f1 0.8680, precision 0.8707, recall 0.8654, auc 0.8681
epoch 6301, loss 0.2808, train acc 86.84%, f1 0.8687, precision 0.8689, recall 0.8685, auc 0.8684
epoch 6401, loss 0.3995, train acc 86.91%, f1 0.8696, precision 0.8686, recall 0.8706, auc 0.8691
epoch 6501, loss 0.2286, train acc 86.95%, f1 0.8702, precision 0.8679, recall 0.8725, auc 0.8695
epoch 6601, loss 0.3430, train acc 86.92%, f1 0.8694, precision 0.8704, recall 0.8685, auc 0.8692
epoch 6701, loss 0.3109, train acc 86.97%, f1 0.8701, precision 0.8697, recall 0.8704, auc 0.8697
epoch 6801, loss 0.2990, train acc 86.97%, f1 0.8701, precision 0.8698, recall 0.8704, auc 0.8697
epoch 6901, loss 0.2635, train acc 87.08%, f1 0.8710, precision 0.8717, recall 0.8704, auc 0.8708
epoch 7001, loss 0.2309, train acc 87.09%, f1 0.8713, precision 0.8711, recall 0.8715, auc 0.8709
epoch 7101, loss 0.3825, train acc 87.10%, f1 0.8713, precision 0.8719, recall 0.8706, auc 0.8710
epoch 7201, loss 0.2364, train acc 87.17%, f1 0.8722, precision 0.8710, recall 0.8734, auc 0.8717
epoch 7301, loss 0.3853, train acc 87.18%, f1 0.8721, precision 0.8726, recall 0.8717, auc 0.8718
epoch 7401, loss 0.2186, train acc 87.23%, f1 0.8728, precision 0.8713, recall 0.8744, auc 0.8722
epoch 7501, loss 0.3021, train acc 87.30%, f1 0.8736, precision 0.8720, recall 0.8751, auc 0.8730
epoch 7601, loss 0.2542, train acc 87.31%, f1 0.8733, precision 0.8743, recall 0.8723, auc 0.8731
epoch 7701, loss 0.3099, train acc 87.35%, f1 0.8733, precision 0.8770, recall 0.8697, auc 0.8735
epoch 7801, loss 0.3378, train acc 87.41%, f1 0.8749, precision 0.8720, recall 0.8779, auc 0.8741
epoch 7901, loss 0.2998, train acc 87.47%, f1 0.8753, precision 0.8734, recall 0.8771, auc 0.8747
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_notMirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_4
./test_pima/result_MLP_concat_notMirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6628301886792454

the Fscore is 0.6037735849056604

the precision is 0.4528301886792453

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_4
----------------------



epoch 1, loss 0.6931, train acc 50.13%, f1 0.6678, precision 0.5013, recall 1.0000, auc 0.5000
epoch 101, loss 0.5433, train acc 79.02%, f1 0.7909, precision 0.7903, recall 0.7915, auc 0.7902
epoch 201, loss 0.4732, train acc 82.94%, f1 0.8295, precision 0.8312, recall 0.8278, auc 0.8294
epoch 301, loss 0.2665, train acc 84.35%, f1 0.8435, precision 0.8454, recall 0.8417, auc 0.8435
epoch 401, loss 0.3023, train acc 84.84%, f1 0.8487, precision 0.8492, recall 0.8482, auc 0.8484
epoch 501, loss 0.2497, train acc 84.98%, f1 0.8498, precision 0.8519, recall 0.8477, auc 0.8498
epoch 601, loss 0.3692, train acc 85.00%, f1 0.8502, precision 0.8515, recall 0.8489, auc 0.8500
epoch 701, loss 0.3455, train acc 85.07%, f1 0.8508, precision 0.8526, recall 0.8490, auc 0.8507
epoch 801, loss 0.3203, train acc 85.06%, f1 0.8510, precision 0.8513, recall 0.8507, auc 0.8506
epoch 901, loss 0.3220, train acc 85.05%, f1 0.8509, precision 0.8511, recall 0.8506, auc 0.8505
epoch 1001, loss 0.3805, train acc 85.07%, f1 0.8511, precision 0.8512, recall 0.8509, auc 0.8507
epoch 1101, loss 0.4650, train acc 85.08%, f1 0.8507, precision 0.8536, recall 0.8478, auc 0.8508
epoch 1201, loss 0.4043, train acc 85.12%, f1 0.8516, precision 0.8514, recall 0.8517, auc 0.8512
epoch 1301, loss 0.3316, train acc 85.08%, f1 0.8513, precision 0.8508, recall 0.8518, auc 0.8508
epoch 1401, loss 0.2916, train acc 85.08%, f1 0.8509, precision 0.8525, recall 0.8493, auc 0.8508
epoch 1501, loss 0.3334, train acc 85.03%, f1 0.8506, precision 0.8512, recall 0.8499, auc 0.8503
epoch 1601, loss 0.3851, train acc 85.08%, f1 0.8513, precision 0.8506, recall 0.8519, auc 0.8508
epoch 1701, loss 0.3459, train acc 85.09%, f1 0.8510, precision 0.8526, recall 0.8495, auc 0.8509
epoch 1801, loss 0.3559, train acc 85.09%, f1 0.8514, precision 0.8511, recall 0.8516, auc 0.8509
epoch 1901, loss 0.1918, train acc 85.08%, f1 0.8508, precision 0.8530, recall 0.8485, auc 0.8508
epoch 2001, loss 0.4344, train acc 85.05%, f1 0.8507, precision 0.8513, recall 0.8502, auc 0.8505
epoch 2101, loss 0.2857, train acc 85.07%, f1 0.8511, precision 0.8507, recall 0.8516, auc 0.8507
epoch 2201, loss 0.3268, train acc 85.05%, f1 0.8503, precision 0.8537, recall 0.8469, auc 0.8505
epoch 2301, loss 0.3474, train acc 85.04%, f1 0.8506, precision 0.8515, recall 0.8497, auc 0.8504
epoch 2401, loss 0.2823, train acc 85.07%, f1 0.8511, precision 0.8506, recall 0.8516, auc 0.8507
epoch 2501, loss 0.3727, train acc 85.07%, f1 0.8506, precision 0.8531, recall 0.8482, auc 0.8507
epoch 2601, loss 0.2793, train acc 85.07%, f1 0.8511, precision 0.8508, recall 0.8515, auc 0.8507
epoch 2701, loss 0.3604, train acc 85.05%, f1 0.8510, precision 0.8502, recall 0.8517, auc 0.8505
epoch 2801, loss 0.3137, train acc 85.03%, f1 0.8511, precision 0.8487, recall 0.8534, auc 0.8503
epoch 2901, loss 0.2716, train acc 85.03%, f1 0.8504, precision 0.8525, recall 0.8483, auc 0.8504
epoch 3001, loss 0.2313, train acc 85.05%, f1 0.8508, precision 0.8512, recall 0.8505, auc 0.8505
epoch 3101, loss 0.2432, train acc 85.02%, f1 0.8503, precision 0.8519, recall 0.8488, auc 0.8502
epoch 3201, loss 0.3240, train acc 85.11%, f1 0.8508, precision 0.8547, recall 0.8470, auc 0.8511
epoch 3301, loss 0.3320, train acc 85.07%, f1 0.8508, precision 0.8525, recall 0.8492, auc 0.8507
epoch 3401, loss 0.2997, train acc 85.08%, f1 0.8505, precision 0.8544, recall 0.8467, auc 0.8508
epoch 3501, loss 0.3726, train acc 85.14%, f1 0.8515, precision 0.8531, recall 0.8499, auc 0.8514
epoch 3601, loss 0.2269, train acc 85.20%, f1 0.8523, precision 0.8528, recall 0.8519, auc 0.8520
epoch 3701, loss 0.2665, train acc 85.19%, f1 0.8524, precision 0.8517, recall 0.8530, auc 0.8519
epoch 3801, loss 0.3600, train acc 85.23%, f1 0.8523, precision 0.8545, recall 0.8501, auc 0.8523
epoch 3901, loss 0.2953, train acc 85.23%, f1 0.8517, precision 0.8572, recall 0.8462, auc 0.8523
epoch 4001, loss 0.3176, train acc 85.30%, f1 0.8525, precision 0.8575, recall 0.8476, auc 0.8530
epoch 4101, loss 0.4283, train acc 85.39%, f1 0.8546, precision 0.8530, recall 0.8562, auc 0.8539
epoch 4201, loss 0.3922, train acc 85.41%, f1 0.8541, precision 0.8564, recall 0.8518, auc 0.8541
epoch 4301, loss 0.2875, train acc 85.54%, f1 0.8558, precision 0.8561, recall 0.8554, auc 0.8554
epoch 4401, loss 0.4292, train acc 85.59%, f1 0.8558, precision 0.8586, recall 0.8531, auc 0.8559
epoch 4501, loss 0.3145, train acc 85.76%, f1 0.8581, precision 0.8577, recall 0.8584, auc 0.8576
epoch 4601, loss 0.3283, train acc 85.86%, f1 0.8584, precision 0.8616, recall 0.8553, auc 0.8586
epoch 4701, loss 0.2254, train acc 85.91%, f1 0.8590, precision 0.8619, recall 0.8561, auc 0.8591
epoch 4801, loss 0.3147, train acc 86.02%, f1 0.8605, precision 0.8610, recall 0.8599, auc 0.8602
epoch 4901, loss 0.4664, train acc 86.11%, f1 0.8614, precision 0.8616, recall 0.8613, auc 0.8611
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_notMirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_4
./test_pima/result_MLP_concat_notMirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6478301886792452

the Fscore is 0.5925925925925927

the precision is 0.44036697247706424

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_4
----------------------



epoch 1, loss 0.6931, train acc 50.21%, f1 0.6685, precision 0.5021, recall 1.0000, auc 0.5000
epoch 101, loss 0.5772, train acc 78.67%, f1 0.7960, precision 0.7657, recall 0.8288, auc 0.7865
epoch 201, loss 0.4180, train acc 82.60%, f1 0.8272, precision 0.8247, recall 0.8298, auc 0.8260
epoch 301, loss 0.3718, train acc 84.27%, f1 0.8423, precision 0.8479, recall 0.8368, auc 0.8427
epoch 401, loss 0.3973, train acc 84.90%, f1 0.8489, precision 0.8527, recall 0.8452, auc 0.8490
epoch 501, loss 0.3261, train acc 84.98%, f1 0.8491, precision 0.8567, recall 0.8417, auc 0.8499
epoch 601, loss 0.3252, train acc 85.00%, f1 0.8495, precision 0.8559, recall 0.8432, auc 0.8501
epoch 701, loss 0.4398, train acc 85.03%, f1 0.8497, precision 0.8565, recall 0.8430, auc 0.8503
epoch 801, loss 0.4064, train acc 85.10%, f1 0.8507, precision 0.8560, recall 0.8456, auc 0.8511
epoch 901, loss 0.2745, train acc 85.06%, f1 0.8506, precision 0.8538, recall 0.8474, auc 0.8506
epoch 1001, loss 0.5353, train acc 85.08%, f1 0.8508, precision 0.8544, recall 0.8472, auc 0.8508
epoch 1101, loss 0.2942, train acc 85.08%, f1 0.8501, precision 0.8579, recall 0.8424, auc 0.8509
epoch 1201, loss 0.3434, train acc 85.10%, f1 0.8503, precision 0.8576, recall 0.8432, auc 0.8510
epoch 1301, loss 0.2928, train acc 85.08%, f1 0.8504, precision 0.8565, recall 0.8443, auc 0.8508
epoch 1401, loss 0.4613, train acc 85.08%, f1 0.8505, precision 0.8561, recall 0.8449, auc 0.8508
epoch 1501, loss 0.4281, train acc 85.00%, f1 0.8495, precision 0.8559, recall 0.8432, auc 0.8500
epoch 1601, loss 0.3267, train acc 85.05%, f1 0.8504, precision 0.8542, recall 0.8467, auc 0.8505
epoch 1701, loss 0.3940, train acc 85.11%, f1 0.8504, precision 0.8581, recall 0.8428, auc 0.8511
epoch 1801, loss 0.3656, train acc 85.10%, f1 0.8512, precision 0.8535, recall 0.8488, auc 0.8510
epoch 1901, loss 0.3213, train acc 85.03%, f1 0.8503, precision 0.8540, recall 0.8465, auc 0.8503
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_concat_notMirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_4
./test_pima/result_MLP_concat_notMirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6472641509433963

the Fscore is 0.593939393939394

the precision is 0.4375

the recall is 0.9245283018867925

Done
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_4
----------------------



epoch 1, loss 0.6933, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693275).  Saving model ...
Validation loss decreased (0.693275 --> 0.693203).  Saving model ...
Validation loss decreased (0.693203 --> 0.693143).  Saving model ...
Validation loss decreased (0.693143 --> 0.693091).  Saving model ...
Validation loss decreased (0.693091 --> 0.693037).  Saving model ...
Validation loss decreased (0.693037 --> 0.692979).  Saving model ...
Validation loss decreased (0.692979 --> 0.692915).  Saving model ...
Validation loss decreased (0.692915 --> 0.692843).  Saving model ...
Validation loss decreased (0.692843 --> 0.692761).  Saving model ...
Validation loss decreased (0.692761 --> 0.692668).  Saving model ...
Validation loss decreased (0.692668 --> 0.692564).  Saving model ...
Validation loss decreased (0.692564 --> 0.692446).  Saving model ...
Validation loss decreased (0.692446 --> 0.692316).  Saving model ...
Validation loss decreased (0.692316 --> 0.692172).  Saving model ...
Validation loss decreased (0.692172 --> 0.692018).  Saving model ...
Validation loss decreased (0.692018 --> 0.691852).  Saving model ...
Validation loss decreased (0.691852 --> 0.691678).  Saving model ...
Validation loss decreased (0.691678 --> 0.691491).  Saving model ...
Validation loss decreased (0.691491 --> 0.691288).  Saving model ...
Validation loss decreased (0.691288 --> 0.691065).  Saving model ...
Validation loss decreased (0.691065 --> 0.690820).  Saving model ...
Validation loss decreased (0.690820 --> 0.690558).  Saving model ...
Validation loss decreased (0.690558 --> 0.690279).  Saving model ...
Validation loss decreased (0.690279 --> 0.689985).  Saving model ...
Validation loss decreased (0.689985 --> 0.689671).  Saving model ...
Validation loss decreased (0.689671 --> 0.689334).  Saving model ...
Validation loss decreased (0.689334 --> 0.688978).  Saving model ...
Validation loss decreased (0.688978 --> 0.688605).  Saving model ...
Validation loss decreased (0.688605 --> 0.688221).  Saving model ...
Validation loss decreased (0.688221 --> 0.687825).  Saving model ...
Validation loss decreased (0.687825 --> 0.687402).  Saving model ...
Validation loss decreased (0.687402 --> 0.686962).  Saving model ...
Validation loss decreased (0.686962 --> 0.686508).  Saving model ...
Validation loss decreased (0.686508 --> 0.686033).  Saving model ...
Validation loss decreased (0.686033 --> 0.685550).  Saving model ...
Validation loss decreased (0.685550 --> 0.685038).  Saving model ...
Validation loss decreased (0.685038 --> 0.684500).  Saving model ...
Validation loss decreased (0.684500 --> 0.683939).  Saving model ...
Validation loss decreased (0.683939 --> 0.683345).  Saving model ...
Validation loss decreased (0.683345 --> 0.682730).  Saving model ...
Validation loss decreased (0.682730 --> 0.682087).  Saving model ...
Validation loss decreased (0.682087 --> 0.681422).  Saving model ...
Validation loss decreased (0.681422 --> 0.680722).  Saving model ...
Validation loss decreased (0.680722 --> 0.680022).  Saving model ...
Validation loss decreased (0.680022 --> 0.679298).  Saving model ...
Validation loss decreased (0.679298 --> 0.678540).  Saving model ...
Validation loss decreased (0.678540 --> 0.677753).  Saving model ...
Validation loss decreased (0.677753 --> 0.676944).  Saving model ...
Validation loss decreased (0.676944 --> 0.676111).  Saving model ...
Validation loss decreased (0.676111 --> 0.675259).  Saving model ...
Validation loss decreased (0.675259 --> 0.674352).  Saving model ...
Validation loss decreased (0.674352 --> 0.673418).  Saving model ...
Validation loss decreased (0.673418 --> 0.672444).  Saving model ...
Validation loss decreased (0.672444 --> 0.671432).  Saving model ...
Validation loss decreased (0.671432 --> 0.670396).  Saving model ...
Validation loss decreased (0.670396 --> 0.669316).  Saving model ...
Validation loss decreased (0.669316 --> 0.668216).  Saving model ...
Validation loss decreased (0.668216 --> 0.667123).  Saving model ...
Validation loss decreased (0.667123 --> 0.666001).  Saving model ...
Validation loss decreased (0.666001 --> 0.664890).  Saving model ...
Validation loss decreased (0.664890 --> 0.663780).  Saving model ...
Validation loss decreased (0.663780 --> 0.662633).  Saving model ...
Validation loss decreased (0.662633 --> 0.661451).  Saving model ...
Validation loss decreased (0.661451 --> 0.660242).  Saving model ...
Validation loss decreased (0.660242 --> 0.659019).  Saving model ...
Validation loss decreased (0.659019 --> 0.657801).  Saving model ...
Validation loss decreased (0.657801 --> 0.656548).  Saving model ...
Validation loss decreased (0.656548 --> 0.655267).  Saving model ...
Validation loss decreased (0.655267 --> 0.653972).  Saving model ...
Validation loss decreased (0.653972 --> 0.652642).  Saving model ...
Validation loss decreased (0.652642 --> 0.651327).  Saving model ...
Validation loss decreased (0.651327 --> 0.649996).  Saving model ...
Validation loss decreased (0.649996 --> 0.648630).  Saving model ...
Validation loss decreased (0.648630 --> 0.647315).  Saving model ...
Validation loss decreased (0.647315 --> 0.646014).  Saving model ...
Validation loss decreased (0.646014 --> 0.644687).  Saving model ...
Validation loss decreased (0.644687 --> 0.643315).  Saving model ...
Validation loss decreased (0.643315 --> 0.641917).  Saving model ...
Validation loss decreased (0.641917 --> 0.640511).  Saving model ...
Validation loss decreased (0.640511 --> 0.639090).  Saving model ...
Validation loss decreased (0.639090 --> 0.637708).  Saving model ...
Validation loss decreased (0.637708 --> 0.636320).  Saving model ...
Validation loss decreased (0.636320 --> 0.634892).  Saving model ...
Validation loss decreased (0.634892 --> 0.633447).  Saving model ...
Validation loss decreased (0.633447 --> 0.631984).  Saving model ...
Validation loss decreased (0.631984 --> 0.630497).  Saving model ...
Validation loss decreased (0.630497 --> 0.629009).  Saving model ...
Validation loss decreased (0.629009 --> 0.627471).  Saving model ...
Validation loss decreased (0.627471 --> 0.625916).  Saving model ...
Validation loss decreased (0.625916 --> 0.624335).  Saving model ...
Validation loss decreased (0.624335 --> 0.622769).  Saving model ...
Validation loss decreased (0.622769 --> 0.621185).  Saving model ...
Validation loss decreased (0.621185 --> 0.619579).  Saving model ...
Validation loss decreased (0.619579 --> 0.617921).  Saving model ...
Validation loss decreased (0.617921 --> 0.616266).  Saving model ...
Validation loss decreased (0.616266 --> 0.614603).  Saving model ...
Validation loss decreased (0.614603 --> 0.612916).  Saving model ...
Validation loss decreased (0.612916 --> 0.611254).  Saving model ...
Validation loss decreased (0.611254 --> 0.609633).  Saving model ...
Validation loss decreased (0.609633 --> 0.608034).  Saving model ...
epoch 101, loss 0.5932, train acc 80.00%, f1 0.8283, precision 0.7256, recall 0.9650, auc 0.8000
Validation loss decreased (0.608034 --> 0.606406).  Saving model ...
Validation loss decreased (0.606406 --> 0.604780).  Saving model ...
Validation loss decreased (0.604780 --> 0.603145).  Saving model ...
Validation loss decreased (0.603145 --> 0.601520).  Saving model ...
Validation loss decreased (0.601520 --> 0.599820).  Saving model ...
Validation loss decreased (0.599820 --> 0.598151).  Saving model ...
Validation loss decreased (0.598151 --> 0.596453).  Saving model ...
Validation loss decreased (0.596453 --> 0.594771).  Saving model ...
Validation loss decreased (0.594771 --> 0.593101).  Saving model ...
Validation loss decreased (0.593101 --> 0.591420).  Saving model ...
Validation loss decreased (0.591420 --> 0.589740).  Saving model ...
Validation loss decreased (0.589740 --> 0.588160).  Saving model ...
Validation loss decreased (0.588160 --> 0.586590).  Saving model ...
Validation loss decreased (0.586590 --> 0.585005).  Saving model ...
Validation loss decreased (0.585005 --> 0.583407).  Saving model ...
Validation loss decreased (0.583407 --> 0.581796).  Saving model ...
Validation loss decreased (0.581796 --> 0.580165).  Saving model ...
Validation loss decreased (0.580165 --> 0.578521).  Saving model ...
Validation loss decreased (0.578521 --> 0.576883).  Saving model ...
Validation loss decreased (0.576883 --> 0.575222).  Saving model ...
Validation loss decreased (0.575222 --> 0.573590).  Saving model ...
Validation loss decreased (0.573590 --> 0.571965).  Saving model ...
Validation loss decreased (0.571965 --> 0.570350).  Saving model ...
Validation loss decreased (0.570350 --> 0.568748).  Saving model ...
Validation loss decreased (0.568748 --> 0.567199).  Saving model ...
Validation loss decreased (0.567199 --> 0.565708).  Saving model ...
Validation loss decreased (0.565708 --> 0.564216).  Saving model ...
Validation loss decreased (0.564216 --> 0.562703).  Saving model ...
Validation loss decreased (0.562703 --> 0.561193).  Saving model ...
Validation loss decreased (0.561193 --> 0.559677).  Saving model ...
Validation loss decreased (0.559677 --> 0.558137).  Saving model ...
Validation loss decreased (0.558137 --> 0.556533).  Saving model ...
Validation loss decreased (0.556533 --> 0.554937).  Saving model ...
Validation loss decreased (0.554937 --> 0.553269).  Saving model ...
Validation loss decreased (0.553269 --> 0.551673).  Saving model ...
Validation loss decreased (0.551673 --> 0.550081).  Saving model ...
Validation loss decreased (0.550081 --> 0.548544).  Saving model ...
Validation loss decreased (0.548544 --> 0.546952).  Saving model ...
Validation loss decreased (0.546952 --> 0.545347).  Saving model ...
Validation loss decreased (0.545347 --> 0.543721).  Saving model ...
Validation loss decreased (0.543721 --> 0.542059).  Saving model ...
Validation loss decreased (0.542059 --> 0.540488).  Saving model ...
Validation loss decreased (0.540488 --> 0.538924).  Saving model ...
Validation loss decreased (0.538924 --> 0.537427).  Saving model ...
Validation loss decreased (0.537427 --> 0.535902).  Saving model ...
Validation loss decreased (0.535902 --> 0.534386).  Saving model ...
Validation loss decreased (0.534386 --> 0.532855).  Saving model ...
Validation loss decreased (0.532855 --> 0.531328).  Saving model ...
Validation loss decreased (0.531328 --> 0.529797).  Saving model ...
Validation loss decreased (0.529797 --> 0.528301).  Saving model ...
Validation loss decreased (0.528301 --> 0.526762).  Saving model ...
Validation loss decreased (0.526762 --> 0.525198).  Saving model ...
Validation loss decreased (0.525198 --> 0.523633).  Saving model ...
Validation loss decreased (0.523633 --> 0.522090).  Saving model ...
Validation loss decreased (0.522090 --> 0.520544).  Saving model ...
Validation loss decreased (0.520544 --> 0.518972).  Saving model ...
Validation loss decreased (0.518972 --> 0.517380).  Saving model ...
Validation loss decreased (0.517380 --> 0.515786).  Saving model ...
Validation loss decreased (0.515786 --> 0.514221).  Saving model ...
Validation loss decreased (0.514221 --> 0.512656).  Saving model ...
Validation loss decreased (0.512656 --> 0.511104).  Saving model ...
Validation loss decreased (0.511104 --> 0.509569).  Saving model ...
Validation loss decreased (0.509569 --> 0.508072).  Saving model ...
Validation loss decreased (0.508072 --> 0.506555).  Saving model ...
Validation loss decreased (0.506555 --> 0.505097).  Saving model ...
Validation loss decreased (0.505097 --> 0.503629).  Saving model ...
Validation loss decreased (0.503629 --> 0.502171).  Saving model ...
Validation loss decreased (0.502171 --> 0.500749).  Saving model ...
Validation loss decreased (0.500749 --> 0.499322).  Saving model ...
Validation loss decreased (0.499322 --> 0.497841).  Saving model ...
Validation loss decreased (0.497841 --> 0.496348).  Saving model ...
Validation loss decreased (0.496348 --> 0.494861).  Saving model ...
Validation loss decreased (0.494861 --> 0.493422).  Saving model ...
Validation loss decreased (0.493422 --> 0.491936).  Saving model ...
Validation loss decreased (0.491936 --> 0.490446).  Saving model ...
Validation loss decreased (0.490446 --> 0.488961).  Saving model ...
Validation loss decreased (0.488961 --> 0.487452).  Saving model ...
Validation loss decreased (0.487452 --> 0.485963).  Saving model ...
Validation loss decreased (0.485963 --> 0.484501).  Saving model ...
Validation loss decreased (0.484501 --> 0.483012).  Saving model ...
Validation loss decreased (0.483012 --> 0.481532).  Saving model ...
Validation loss decreased (0.481532 --> 0.480123).  Saving model ...
Validation loss decreased (0.480123 --> 0.478726).  Saving model ...
Validation loss decreased (0.478726 --> 0.477359).  Saving model ...
Validation loss decreased (0.477359 --> 0.475942).  Saving model ...
Validation loss decreased (0.475942 --> 0.474534).  Saving model ...
Validation loss decreased (0.474534 --> 0.473126).  Saving model ...
Validation loss decreased (0.473126 --> 0.471753).  Saving model ...
Validation loss decreased (0.471753 --> 0.470332).  Saving model ...
Validation loss decreased (0.470332 --> 0.468951).  Saving model ...
Validation loss decreased (0.468951 --> 0.467547).  Saving model ...
Validation loss decreased (0.467547 --> 0.466216).  Saving model ...
Validation loss decreased (0.466216 --> 0.464851).  Saving model ...
Validation loss decreased (0.464851 --> 0.463469).  Saving model ...
Validation loss decreased (0.463469 --> 0.462073).  Saving model ...
Validation loss decreased (0.462073 --> 0.460729).  Saving model ...
Validation loss decreased (0.460729 --> 0.459397).  Saving model ...
Validation loss decreased (0.459397 --> 0.458013).  Saving model ...
Validation loss decreased (0.458013 --> 0.456589).  Saving model ...
Validation loss decreased (0.456589 --> 0.455204).  Saving model ...
epoch 201, loss 0.4721, train acc 90.00%, f1 0.9029, precision 0.8774, recall 0.9300, auc 0.9000
Validation loss decreased (0.455204 --> 0.453808).  Saving model ...
Validation loss decreased (0.453808 --> 0.452448).  Saving model ...
Validation loss decreased (0.452448 --> 0.451133).  Saving model ...
Validation loss decreased (0.451133 --> 0.449825).  Saving model ...
Validation loss decreased (0.449825 --> 0.448504).  Saving model ...
Validation loss decreased (0.448504 --> 0.447195).  Saving model ...
Validation loss decreased (0.447195 --> 0.445935).  Saving model ...
Validation loss decreased (0.445935 --> 0.444737).  Saving model ...
Validation loss decreased (0.444737 --> 0.443557).  Saving model ...
Validation loss decreased (0.443557 --> 0.442397).  Saving model ...
Validation loss decreased (0.442397 --> 0.441265).  Saving model ...
Validation loss decreased (0.441265 --> 0.440098).  Saving model ...
Validation loss decreased (0.440098 --> 0.438948).  Saving model ...
Validation loss decreased (0.438948 --> 0.437822).  Saving model ...
Validation loss decreased (0.437822 --> 0.436641).  Saving model ...
Validation loss decreased (0.436641 --> 0.435485).  Saving model ...
Validation loss decreased (0.435485 --> 0.434325).  Saving model ...
Validation loss decreased (0.434325 --> 0.433163).  Saving model ...
Validation loss decreased (0.433163 --> 0.431995).  Saving model ...
Validation loss decreased (0.431995 --> 0.430817).  Saving model ...
Validation loss decreased (0.430817 --> 0.429644).  Saving model ...
Validation loss decreased (0.429644 --> 0.428488).  Saving model ...
Validation loss decreased (0.428488 --> 0.427348).  Saving model ...
Validation loss decreased (0.427348 --> 0.426167).  Saving model ...
Validation loss decreased (0.426167 --> 0.424957).  Saving model ...
Validation loss decreased (0.424957 --> 0.423751).  Saving model ...
Validation loss decreased (0.423751 --> 0.422522).  Saving model ...
Validation loss decreased (0.422522 --> 0.421291).  Saving model ...
Validation loss decreased (0.421291 --> 0.420130).  Saving model ...
Validation loss decreased (0.420130 --> 0.419019).  Saving model ...
Validation loss decreased (0.419019 --> 0.417879).  Saving model ...
Validation loss decreased (0.417879 --> 0.416720).  Saving model ...
Validation loss decreased (0.416720 --> 0.415539).  Saving model ...
Validation loss decreased (0.415539 --> 0.414328).  Saving model ...
Validation loss decreased (0.414328 --> 0.413146).  Saving model ...
Validation loss decreased (0.413146 --> 0.411959).  Saving model ...
Validation loss decreased (0.411959 --> 0.410751).  Saving model ...
Validation loss decreased (0.410751 --> 0.409560).  Saving model ...
Validation loss decreased (0.409560 --> 0.408338).  Saving model ...
Validation loss decreased (0.408338 --> 0.407298).  Saving model ...
Validation loss decreased (0.407298 --> 0.406293).  Saving model ...
Validation loss decreased (0.406293 --> 0.405275).  Saving model ...
Validation loss decreased (0.405275 --> 0.404274).  Saving model ...
Validation loss decreased (0.404274 --> 0.403264).  Saving model ...
Validation loss decreased (0.403264 --> 0.402198).  Saving model ...
Validation loss decreased (0.402198 --> 0.401124).  Saving model ...
Validation loss decreased (0.401124 --> 0.400072).  Saving model ...
Validation loss decreased (0.400072 --> 0.399030).  Saving model ...
Validation loss decreased (0.399030 --> 0.397993).  Saving model ...
Validation loss decreased (0.397993 --> 0.396939).  Saving model ...
Validation loss decreased (0.396939 --> 0.395892).  Saving model ...
Validation loss decreased (0.395892 --> 0.394837).  Saving model ...
Validation loss decreased (0.394837 --> 0.393768).  Saving model ...
Validation loss decreased (0.393768 --> 0.392677).  Saving model ...
Validation loss decreased (0.392677 --> 0.391531).  Saving model ...
Validation loss decreased (0.391531 --> 0.390394).  Saving model ...
Validation loss decreased (0.390394 --> 0.389250).  Saving model ...
Validation loss decreased (0.389250 --> 0.388133).  Saving model ...
Validation loss decreased (0.388133 --> 0.387027).  Saving model ...
Validation loss decreased (0.387027 --> 0.385893).  Saving model ...
Validation loss decreased (0.385893 --> 0.384817).  Saving model ...
Validation loss decreased (0.384817 --> 0.383747).  Saving model ...
Validation loss decreased (0.383747 --> 0.382714).  Saving model ...
Validation loss decreased (0.382714 --> 0.381668).  Saving model ...
Validation loss decreased (0.381668 --> 0.380678).  Saving model ...
Validation loss decreased (0.380678 --> 0.379705).  Saving model ...
Validation loss decreased (0.379705 --> 0.378745).  Saving model ...
Validation loss decreased (0.378745 --> 0.377876).  Saving model ...
Validation loss decreased (0.377876 --> 0.377023).  Saving model ...
Validation loss decreased (0.377023 --> 0.376162).  Saving model ...
Validation loss decreased (0.376162 --> 0.375315).  Saving model ...
Validation loss decreased (0.375315 --> 0.374440).  Saving model ...
Validation loss decreased (0.374440 --> 0.373557).  Saving model ...
Validation loss decreased (0.373557 --> 0.372660).  Saving model ...
Validation loss decreased (0.372660 --> 0.371754).  Saving model ...
Validation loss decreased (0.371754 --> 0.370821).  Saving model ...
Validation loss decreased (0.370821 --> 0.369876).  Saving model ...
Validation loss decreased (0.369876 --> 0.368880).  Saving model ...
Validation loss decreased (0.368880 --> 0.367907).  Saving model ...
Validation loss decreased (0.367907 --> 0.366853).  Saving model ...
Validation loss decreased (0.366853 --> 0.365798).  Saving model ...
Validation loss decreased (0.365798 --> 0.364718).  Saving model ...
Validation loss decreased (0.364718 --> 0.363654).  Saving model ...
Validation loss decreased (0.363654 --> 0.362609).  Saving model ...
Validation loss decreased (0.362609 --> 0.361670).  Saving model ...
Validation loss decreased (0.361670 --> 0.360781).  Saving model ...
Validation loss decreased (0.360781 --> 0.359911).  Saving model ...
Validation loss decreased (0.359911 --> 0.359034).  Saving model ...
Validation loss decreased (0.359034 --> 0.358189).  Saving model ...
Validation loss decreased (0.358189 --> 0.357338).  Saving model ...
Validation loss decreased (0.357338 --> 0.356427).  Saving model ...
Validation loss decreased (0.356427 --> 0.355539).  Saving model ...
Validation loss decreased (0.355539 --> 0.354644).  Saving model ...
Validation loss decreased (0.354644 --> 0.353705).  Saving model ...
Validation loss decreased (0.353705 --> 0.352799).  Saving model ...
Validation loss decreased (0.352799 --> 0.351856).  Saving model ...
Validation loss decreased (0.351856 --> 0.350943).  Saving model ...
Validation loss decreased (0.350943 --> 0.349978).  Saving model ...
Validation loss decreased (0.349978 --> 0.349020).  Saving model ...
Validation loss decreased (0.349020 --> 0.348061).  Saving model ...
epoch 301, loss 0.3560, train acc 93.75%, f1 0.9380, precision 0.9310, recall 0.9450, auc 0.9375
Validation loss decreased (0.348061 --> 0.347053).  Saving model ...
Validation loss decreased (0.347053 --> 0.346116).  Saving model ...
Validation loss decreased (0.346116 --> 0.345215).  Saving model ...
Validation loss decreased (0.345215 --> 0.344301).  Saving model ...
Validation loss decreased (0.344301 --> 0.343399).  Saving model ...
Validation loss decreased (0.343399 --> 0.342512).  Saving model ...
Validation loss decreased (0.342512 --> 0.341648).  Saving model ...
Validation loss decreased (0.341648 --> 0.340806).  Saving model ...
Validation loss decreased (0.340806 --> 0.339937).  Saving model ...
Validation loss decreased (0.339937 --> 0.339052).  Saving model ...
Validation loss decreased (0.339052 --> 0.338165).  Saving model ...
Validation loss decreased (0.338165 --> 0.337248).  Saving model ...
Validation loss decreased (0.337248 --> 0.336364).  Saving model ...
Validation loss decreased (0.336364 --> 0.335479).  Saving model ...
Validation loss decreased (0.335479 --> 0.334719).  Saving model ...
Validation loss decreased (0.334719 --> 0.333949).  Saving model ...
Validation loss decreased (0.333949 --> 0.333175).  Saving model ...
Validation loss decreased (0.333175 --> 0.332452).  Saving model ...
Validation loss decreased (0.332452 --> 0.331726).  Saving model ...
Validation loss decreased (0.331726 --> 0.330998).  Saving model ...
Validation loss decreased (0.330998 --> 0.330269).  Saving model ...
Validation loss decreased (0.330269 --> 0.329546).  Saving model ...
Validation loss decreased (0.329546 --> 0.328817).  Saving model ...
Validation loss decreased (0.328817 --> 0.328082).  Saving model ...
Validation loss decreased (0.328082 --> 0.327333).  Saving model ...
Validation loss decreased (0.327333 --> 0.326575).  Saving model ...
Validation loss decreased (0.326575 --> 0.325791).  Saving model ...
Validation loss decreased (0.325791 --> 0.324998).  Saving model ...
Validation loss decreased (0.324998 --> 0.324238).  Saving model ...
Validation loss decreased (0.324238 --> 0.323438).  Saving model ...
Validation loss decreased (0.323438 --> 0.322686).  Saving model ...
Validation loss decreased (0.322686 --> 0.321892).  Saving model ...
Validation loss decreased (0.321892 --> 0.321124).  Saving model ...
Validation loss decreased (0.321124 --> 0.320348).  Saving model ...
Validation loss decreased (0.320348 --> 0.319600).  Saving model ...
Validation loss decreased (0.319600 --> 0.318868).  Saving model ...
Validation loss decreased (0.318868 --> 0.318152).  Saving model ...
Validation loss decreased (0.318152 --> 0.317433).  Saving model ...
Validation loss decreased (0.317433 --> 0.316720).  Saving model ...
Validation loss decreased (0.316720 --> 0.315965).  Saving model ...
Validation loss decreased (0.315965 --> 0.315237).  Saving model ...
Validation loss decreased (0.315237 --> 0.314522).  Saving model ...
Validation loss decreased (0.314522 --> 0.313845).  Saving model ...
Validation loss decreased (0.313845 --> 0.313167).  Saving model ...
Validation loss decreased (0.313167 --> 0.312498).  Saving model ...
Validation loss decreased (0.312498 --> 0.311752).  Saving model ...
Validation loss decreased (0.311752 --> 0.311061).  Saving model ...
Validation loss decreased (0.311061 --> 0.310371).  Saving model ...
Validation loss decreased (0.310371 --> 0.309687).  Saving model ...
Validation loss decreased (0.309687 --> 0.309011).  Saving model ...
Validation loss decreased (0.309011 --> 0.308316).  Saving model ...
Validation loss decreased (0.308316 --> 0.307733).  Saving model ...
Validation loss decreased (0.307733 --> 0.307094).  Saving model ...
Validation loss decreased (0.307094 --> 0.306445).  Saving model ...
Validation loss decreased (0.306445 --> 0.305887).  Saving model ...
Validation loss decreased (0.305887 --> 0.305332).  Saving model ...
Validation loss decreased (0.305332 --> 0.304780).  Saving model ...
Validation loss decreased (0.304780 --> 0.304158).  Saving model ...
Validation loss decreased (0.304158 --> 0.303551).  Saving model ...
Validation loss decreased (0.303551 --> 0.302878).  Saving model ...
Validation loss decreased (0.302878 --> 0.302182).  Saving model ...
Validation loss decreased (0.302182 --> 0.301444).  Saving model ...
Validation loss decreased (0.301444 --> 0.300746).  Saving model ...
Validation loss decreased (0.300746 --> 0.300074).  Saving model ...
Validation loss decreased (0.300074 --> 0.299407).  Saving model ...
Validation loss decreased (0.299407 --> 0.298753).  Saving model ...
Validation loss decreased (0.298753 --> 0.298034).  Saving model ...
Validation loss decreased (0.298034 --> 0.297321).  Saving model ...
Validation loss decreased (0.297321 --> 0.296650).  Saving model ...
Validation loss decreased (0.296650 --> 0.295984).  Saving model ...
Validation loss decreased (0.295984 --> 0.295315).  Saving model ...
Validation loss decreased (0.295315 --> 0.294723).  Saving model ...
Validation loss decreased (0.294723 --> 0.294152).  Saving model ...
Validation loss decreased (0.294152 --> 0.293645).  Saving model ...
Validation loss decreased (0.293645 --> 0.293173).  Saving model ...
Validation loss decreased (0.293173 --> 0.292696).  Saving model ...
Validation loss decreased (0.292696 --> 0.292216).  Saving model ...
Validation loss decreased (0.292216 --> 0.291770).  Saving model ...
Validation loss decreased (0.291770 --> 0.291339).  Saving model ...
Validation loss decreased (0.291339 --> 0.290864).  Saving model ...
Validation loss decreased (0.290864 --> 0.290351).  Saving model ...
Validation loss decreased (0.290351 --> 0.289845).  Saving model ...
Validation loss decreased (0.289845 --> 0.289291).  Saving model ...
Validation loss decreased (0.289291 --> 0.288744).  Saving model ...
Validation loss decreased (0.288744 --> 0.288195).  Saving model ...
Validation loss decreased (0.288195 --> 0.287647).  Saving model ...
Validation loss decreased (0.287647 --> 0.287089).  Saving model ...
Validation loss decreased (0.287089 --> 0.286546).  Saving model ...
Validation loss decreased (0.286546 --> 0.286008).  Saving model ...
Validation loss decreased (0.286008 --> 0.285518).  Saving model ...
Validation loss decreased (0.285518 --> 0.285071).  Saving model ...
Validation loss decreased (0.285071 --> 0.284685).  Saving model ...
Validation loss decreased (0.284685 --> 0.284285).  Saving model ...
Validation loss decreased (0.284285 --> 0.283864).  Saving model ...
Validation loss decreased (0.283864 --> 0.283378).  Saving model ...
Validation loss decreased (0.283378 --> 0.282887).  Saving model ...
Validation loss decreased (0.282887 --> 0.282441).  Saving model ...
Validation loss decreased (0.282441 --> 0.282010).  Saving model ...
Validation loss decreased (0.282010 --> 0.281545).  Saving model ...
Validation loss decreased (0.281545 --> 0.281021).  Saving model ...
epoch 401, loss 0.3451, train acc 95.75%, f1 0.9572, precision 0.9645, recall 0.9500, auc 0.9575
Validation loss decreased (0.281021 --> 0.280477).  Saving model ...
Validation loss decreased (0.280477 --> 0.279902).  Saving model ...
Validation loss decreased (0.279902 --> 0.279304).  Saving model ...
Validation loss decreased (0.279304 --> 0.278720).  Saving model ...
Validation loss decreased (0.278720 --> 0.278180).  Saving model ...
Validation loss decreased (0.278180 --> 0.277609).  Saving model ...
Validation loss decreased (0.277609 --> 0.277058).  Saving model ...
Validation loss decreased (0.277058 --> 0.276520).  Saving model ...
Validation loss decreased (0.276520 --> 0.275956).  Saving model ...
Validation loss decreased (0.275956 --> 0.275382).  Saving model ...
Validation loss decreased (0.275382 --> 0.274848).  Saving model ...
Validation loss decreased (0.274848 --> 0.274365).  Saving model ...
Validation loss decreased (0.274365 --> 0.273863).  Saving model ...
Validation loss decreased (0.273863 --> 0.273375).  Saving model ...
Validation loss decreased (0.273375 --> 0.272832).  Saving model ...
Validation loss decreased (0.272832 --> 0.272304).  Saving model ...
Validation loss decreased (0.272304 --> 0.271840).  Saving model ...
Validation loss decreased (0.271840 --> 0.271461).  Saving model ...
Validation loss decreased (0.271461 --> 0.271059).  Saving model ...
Validation loss decreased (0.271059 --> 0.270649).  Saving model ...
Validation loss decreased (0.270649 --> 0.270182).  Saving model ...
Validation loss decreased (0.270182 --> 0.269690).  Saving model ...
Validation loss decreased (0.269690 --> 0.269147).  Saving model ...
Validation loss decreased (0.269147 --> 0.268639).  Saving model ...
Validation loss decreased (0.268639 --> 0.268138).  Saving model ...
Validation loss decreased (0.268138 --> 0.267642).  Saving model ...
Validation loss decreased (0.267642 --> 0.267090).  Saving model ...
Validation loss decreased (0.267090 --> 0.266581).  Saving model ...
Validation loss decreased (0.266581 --> 0.266084).  Saving model ...
Validation loss decreased (0.266084 --> 0.265609).  Saving model ...
Validation loss decreased (0.265609 --> 0.265113).  Saving model ...
Validation loss decreased (0.265113 --> 0.264609).  Saving model ...
Validation loss decreased (0.264609 --> 0.264079).  Saving model ...
Validation loss decreased (0.264079 --> 0.263656).  Saving model ...
Validation loss decreased (0.263656 --> 0.263260).  Saving model ...
Validation loss decreased (0.263260 --> 0.262871).  Saving model ...
Validation loss decreased (0.262871 --> 0.262439).  Saving model ...
Validation loss decreased (0.262439 --> 0.262000).  Saving model ...
Validation loss decreased (0.262000 --> 0.261561).  Saving model ...
Validation loss decreased (0.261561 --> 0.261180).  Saving model ...
Validation loss decreased (0.261180 --> 0.260797).  Saving model ...
Validation loss decreased (0.260797 --> 0.260402).  Saving model ...
Validation loss decreased (0.260402 --> 0.260022).  Saving model ...
Validation loss decreased (0.260022 --> 0.259673).  Saving model ...
Validation loss decreased (0.259673 --> 0.259401).  Saving model ...
Validation loss decreased (0.259401 --> 0.259067).  Saving model ...
Validation loss decreased (0.259067 --> 0.258791).  Saving model ...
Validation loss decreased (0.258791 --> 0.258491).  Saving model ...
Validation loss decreased (0.258491 --> 0.258179).  Saving model ...
Validation loss decreased (0.258179 --> 0.257870).  Saving model ...
Validation loss decreased (0.257870 --> 0.257601).  Saving model ...
Validation loss decreased (0.257601 --> 0.257325).  Saving model ...
Validation loss decreased (0.257325 --> 0.257058).  Saving model ...
Validation loss decreased (0.257058 --> 0.256763).  Saving model ...
Validation loss decreased (0.256763 --> 0.256454).  Saving model ...
Validation loss decreased (0.256454 --> 0.256062).  Saving model ...
Validation loss decreased (0.256062 --> 0.255646).  Saving model ...
Validation loss decreased (0.255646 --> 0.255302).  Saving model ...
Validation loss decreased (0.255302 --> 0.254892).  Saving model ...
Validation loss decreased (0.254892 --> 0.254476).  Saving model ...
Validation loss decreased (0.254476 --> 0.254049).  Saving model ...
Validation loss decreased (0.254049 --> 0.253572).  Saving model ...
Validation loss decreased (0.253572 --> 0.253022).  Saving model ...
Validation loss decreased (0.253022 --> 0.252432).  Saving model ...
Validation loss decreased (0.252432 --> 0.251832).  Saving model ...
Validation loss decreased (0.251832 --> 0.251275).  Saving model ...
Validation loss decreased (0.251275 --> 0.250707).  Saving model ...
Validation loss decreased (0.250707 --> 0.250217).  Saving model ...
Validation loss decreased (0.250217 --> 0.249706).  Saving model ...
Validation loss decreased (0.249706 --> 0.249248).  Saving model ...
Validation loss decreased (0.249248 --> 0.248816).  Saving model ...
Validation loss decreased (0.248816 --> 0.248361).  Saving model ...
Validation loss decreased (0.248361 --> 0.247978).  Saving model ...
Validation loss decreased (0.247978 --> 0.247595).  Saving model ...
Validation loss decreased (0.247595 --> 0.247252).  Saving model ...
Validation loss decreased (0.247252 --> 0.247008).  Saving model ...
Validation loss decreased (0.247008 --> 0.246753).  Saving model ...
Validation loss decreased (0.246753 --> 0.246476).  Saving model ...
Validation loss decreased (0.246476 --> 0.246252).  Saving model ...
Validation loss decreased (0.246252 --> 0.246009).  Saving model ...
Validation loss decreased (0.246009 --> 0.245720).  Saving model ...
Validation loss decreased (0.245720 --> 0.245411).  Saving model ...
Validation loss decreased (0.245411 --> 0.245120).  Saving model ...
Validation loss decreased (0.245120 --> 0.244818).  Saving model ...
Validation loss decreased (0.244818 --> 0.244557).  Saving model ...
Validation loss decreased (0.244557 --> 0.244331).  Saving model ...
Validation loss decreased (0.244331 --> 0.244074).  Saving model ...
Validation loss decreased (0.244074 --> 0.243735).  Saving model ...
Validation loss decreased (0.243735 --> 0.243353).  Saving model ...
Validation loss decreased (0.243353 --> 0.243033).  Saving model ...
Validation loss decreased (0.243033 --> 0.242670).  Saving model ...
Validation loss decreased (0.242670 --> 0.242276).  Saving model ...
Validation loss decreased (0.242276 --> 0.241920).  Saving model ...
Validation loss decreased (0.241920 --> 0.241573).  Saving model ...
Validation loss decreased (0.241573 --> 0.241258).  Saving model ...
Validation loss decreased (0.241258 --> 0.240961).  Saving model ...
Validation loss decreased (0.240961 --> 0.240656).  Saving model ...
Validation loss decreased (0.240656 --> 0.240352).  Saving model ...
Validation loss decreased (0.240352 --> 0.240073).  Saving model ...
Validation loss decreased (0.240073 --> 0.239852).  Saving model ...
epoch 501, loss 0.4011, train acc 95.50%, f1 0.9548, precision 0.9596, recall 0.9500, auc 0.9550
Validation loss decreased (0.239852 --> 0.239606).  Saving model ...
Validation loss decreased (0.239606 --> 0.239312).  Saving model ...
Validation loss decreased (0.239312 --> 0.238983).  Saving model ...
Validation loss decreased (0.238983 --> 0.238689).  Saving model ...
Validation loss decreased (0.238689 --> 0.238401).  Saving model ...
Validation loss decreased (0.238401 --> 0.238123).  Saving model ...
Validation loss decreased (0.238123 --> 0.237842).  Saving model ...
Validation loss decreased (0.237842 --> 0.237566).  Saving model ...
Validation loss decreased (0.237566 --> 0.237341).  Saving model ...
Validation loss decreased (0.237341 --> 0.237121).  Saving model ...
Validation loss decreased (0.237121 --> 0.237007).  Saving model ...
Validation loss decreased (0.237007 --> 0.236929).  Saving model ...
Validation loss decreased (0.236929 --> 0.236863).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.236863 --> 0.236846).  Saving model ...
Validation loss decreased (0.236846 --> 0.236842).  Saving model ...
Validation loss decreased (0.236842 --> 0.236839).  Saving model ...
Validation loss decreased (0.236839 --> 0.236770).  Saving model ...
Validation loss decreased (0.236770 --> 0.236684).  Saving model ...
Validation loss decreased (0.236684 --> 0.236577).  Saving model ...
Validation loss decreased (0.236577 --> 0.236467).  Saving model ...
Validation loss decreased (0.236467 --> 0.236457).  Saving model ...
Validation loss decreased (0.236457 --> 0.236428).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.236428 --> 0.236419).  Saving model ...
Validation loss decreased (0.236419 --> 0.236390).  Saving model ...
Validation loss decreased (0.236390 --> 0.236335).  Saving model ...
Validation loss decreased (0.236335 --> 0.236216).  Saving model ...
Validation loss decreased (0.236216 --> 0.236061).  Saving model ...
Validation loss decreased (0.236061 --> 0.235891).  Saving model ...
Validation loss decreased (0.235891 --> 0.235716).  Saving model ...
Validation loss decreased (0.235716 --> 0.235554).  Saving model ...
Validation loss decreased (0.235554 --> 0.235341).  Saving model ...
Validation loss decreased (0.235341 --> 0.235111).  Saving model ...
Validation loss decreased (0.235111 --> 0.234911).  Saving model ...
Validation loss decreased (0.234911 --> 0.234732).  Saving model ...
Validation loss decreased (0.234732 --> 0.234497).  Saving model ...
Validation loss decreased (0.234497 --> 0.234196).  Saving model ...
Validation loss decreased (0.234196 --> 0.233890).  Saving model ...
Validation loss decreased (0.233890 --> 0.233557).  Saving model ...
Validation loss decreased (0.233557 --> 0.233201).  Saving model ...
Validation loss decreased (0.233201 --> 0.232837).  Saving model ...
Validation loss decreased (0.232837 --> 0.232559).  Saving model ...
Validation loss decreased (0.232559 --> 0.232195).  Saving model ...
Validation loss decreased (0.232195 --> 0.231831).  Saving model ...
Validation loss decreased (0.231831 --> 0.231466).  Saving model ...
Validation loss decreased (0.231466 --> 0.231074).  Saving model ...
Validation loss decreased (0.231074 --> 0.230694).  Saving model ...
Validation loss decreased (0.230694 --> 0.230258).  Saving model ...
Validation loss decreased (0.230258 --> 0.229883).  Saving model ...
Validation loss decreased (0.229883 --> 0.229535).  Saving model ...
Validation loss decreased (0.229535 --> 0.229304).  Saving model ...
Validation loss decreased (0.229304 --> 0.229041).  Saving model ...
Validation loss decreased (0.229041 --> 0.228739).  Saving model ...
Validation loss decreased (0.228739 --> 0.228422).  Saving model ...
Validation loss decreased (0.228422 --> 0.228125).  Saving model ...
Validation loss decreased (0.228125 --> 0.227842).  Saving model ...
Validation loss decreased (0.227842 --> 0.227598).  Saving model ...
Validation loss decreased (0.227598 --> 0.227423).  Saving model ...
Validation loss decreased (0.227423 --> 0.227260).  Saving model ...
Validation loss decreased (0.227260 --> 0.227050).  Saving model ...
Validation loss decreased (0.227050 --> 0.226794).  Saving model ...
Validation loss decreased (0.226794 --> 0.226514).  Saving model ...
Validation loss decreased (0.226514 --> 0.226240).  Saving model ...
Validation loss decreased (0.226240 --> 0.226010).  Saving model ...
Validation loss decreased (0.226010 --> 0.225721).  Saving model ...
Validation loss decreased (0.225721 --> 0.225467).  Saving model ...
Validation loss decreased (0.225467 --> 0.225261).  Saving model ...
Validation loss decreased (0.225261 --> 0.225056).  Saving model ...
Validation loss decreased (0.225056 --> 0.224863).  Saving model ...
Validation loss decreased (0.224863 --> 0.224651).  Saving model ...
Validation loss decreased (0.224651 --> 0.224410).  Saving model ...
Validation loss decreased (0.224410 --> 0.224216).  Saving model ...
Validation loss decreased (0.224216 --> 0.224050).  Saving model ...
Validation loss decreased (0.224050 --> 0.223887).  Saving model ...
Validation loss decreased (0.223887 --> 0.223794).  Saving model ...
Validation loss decreased (0.223794 --> 0.223708).  Saving model ...
Validation loss decreased (0.223708 --> 0.223603).  Saving model ...
Validation loss decreased (0.223603 --> 0.223455).  Saving model ...
Validation loss decreased (0.223455 --> 0.223302).  Saving model ...
Validation loss decreased (0.223302 --> 0.223090).  Saving model ...
Validation loss decreased (0.223090 --> 0.222838).  Saving model ...
Validation loss decreased (0.222838 --> 0.222564).  Saving model ...
Validation loss decreased (0.222564 --> 0.222353).  Saving model ...
Validation loss decreased (0.222353 --> 0.222099).  Saving model ...
Validation loss decreased (0.222099 --> 0.221881).  Saving model ...
Validation loss decreased (0.221881 --> 0.221653).  Saving model ...
Validation loss decreased (0.221653 --> 0.221422).  Saving model ...
Validation loss decreased (0.221422 --> 0.221197).  Saving model ...
Validation loss decreased (0.221197 --> 0.220962).  Saving model ...
Validation loss decreased (0.220962 --> 0.220756).  Saving model ...
Validation loss decreased (0.220756 --> 0.220609).  Saving model ...
Validation loss decreased (0.220609 --> 0.220401).  Saving model ...
Validation loss decreased (0.220401 --> 0.220206).  Saving model ...
Validation loss decreased (0.220206 --> 0.220044).  Saving model ...
Validation loss decreased (0.220044 --> 0.219925).  Saving model ...
Validation loss decreased (0.219925 --> 0.219805).  Saving model ...
Validation loss decreased (0.219805 --> 0.219656).  Saving model ...
Validation loss decreased (0.219656 --> 0.219494).  Saving model ...
Validation loss decreased (0.219494 --> 0.219351).  Saving model ...
epoch 601, loss 0.3960, train acc 95.50%, f1 0.9548, precision 0.9596, recall 0.9500, auc 0.9550
Validation loss decreased (0.219351 --> 0.219211).  Saving model ...
Validation loss decreased (0.219211 --> 0.219067).  Saving model ...
Validation loss decreased (0.219067 --> 0.218979).  Saving model ...
Validation loss decreased (0.218979 --> 0.218845).  Saving model ...
Validation loss decreased (0.218845 --> 0.218728).  Saving model ...
Validation loss decreased (0.218728 --> 0.218596).  Saving model ...
Validation loss decreased (0.218596 --> 0.218400).  Saving model ...
Validation loss decreased (0.218400 --> 0.218211).  Saving model ...
Validation loss decreased (0.218211 --> 0.218030).  Saving model ...
Validation loss decreased (0.218030 --> 0.217849).  Saving model ...
Validation loss decreased (0.217849 --> 0.217668).  Saving model ...
Validation loss decreased (0.217668 --> 0.217458).  Saving model ...
Validation loss decreased (0.217458 --> 0.217300).  Saving model ...
Validation loss decreased (0.217300 --> 0.217166).  Saving model ...
Validation loss decreased (0.217166 --> 0.216986).  Saving model ...
Validation loss decreased (0.216986 --> 0.216774).  Saving model ...
Validation loss decreased (0.216774 --> 0.216552).  Saving model ...
Validation loss decreased (0.216552 --> 0.216301).  Saving model ...
Validation loss decreased (0.216301 --> 0.216064).  Saving model ...
Validation loss decreased (0.216064 --> 0.215855).  Saving model ...
Validation loss decreased (0.215855 --> 0.215702).  Saving model ...
Validation loss decreased (0.215702 --> 0.215563).  Saving model ...
Validation loss decreased (0.215563 --> 0.215374).  Saving model ...
Validation loss decreased (0.215374 --> 0.215215).  Saving model ...
Validation loss decreased (0.215215 --> 0.215065).  Saving model ...
Validation loss decreased (0.215065 --> 0.214981).  Saving model ...
Validation loss decreased (0.214981 --> 0.214864).  Saving model ...
Validation loss decreased (0.214864 --> 0.214779).  Saving model ...
Validation loss decreased (0.214779 --> 0.214673).  Saving model ...
Validation loss decreased (0.214673 --> 0.214528).  Saving model ...
Validation loss decreased (0.214528 --> 0.214397).  Saving model ...
Validation loss decreased (0.214397 --> 0.214224).  Saving model ...
Validation loss decreased (0.214224 --> 0.213984).  Saving model ...
Validation loss decreased (0.213984 --> 0.213744).  Saving model ...
Validation loss decreased (0.213744 --> 0.213411).  Saving model ...
Validation loss decreased (0.213411 --> 0.213125).  Saving model ...
Validation loss decreased (0.213125 --> 0.212818).  Saving model ...
Validation loss decreased (0.212818 --> 0.212479).  Saving model ...
Validation loss decreased (0.212479 --> 0.212168).  Saving model ...
Validation loss decreased (0.212168 --> 0.211962).  Saving model ...
Validation loss decreased (0.211962 --> 0.211801).  Saving model ...
Validation loss decreased (0.211801 --> 0.211671).  Saving model ...
Validation loss decreased (0.211671 --> 0.211546).  Saving model ...
Validation loss decreased (0.211546 --> 0.211369).  Saving model ...
Validation loss decreased (0.211369 --> 0.211146).  Saving model ...
Validation loss decreased (0.211146 --> 0.210980).  Saving model ...
Validation loss decreased (0.210980 --> 0.210928).  Saving model ...
Validation loss decreased (0.210928 --> 0.210843).  Saving model ...
Validation loss decreased (0.210843 --> 0.210745).  Saving model ...
Validation loss decreased (0.210745 --> 0.210600).  Saving model ...
Validation loss decreased (0.210600 --> 0.210530).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.210530 --> 0.210502).  Saving model ...
Validation loss decreased (0.210502 --> 0.210438).  Saving model ...
Validation loss decreased (0.210438 --> 0.210317).  Saving model ...
Validation loss decreased (0.210317 --> 0.210161).  Saving model ...
Validation loss decreased (0.210161 --> 0.210041).  Saving model ...
Validation loss decreased (0.210041 --> 0.209922).  Saving model ...
Validation loss decreased (0.209922 --> 0.209762).  Saving model ...
Validation loss decreased (0.209762 --> 0.209655).  Saving model ...
Validation loss decreased (0.209655 --> 0.209535).  Saving model ...
Validation loss decreased (0.209535 --> 0.209364).  Saving model ...
Validation loss decreased (0.209364 --> 0.209193).  Saving model ...
Validation loss decreased (0.209193 --> 0.208987).  Saving model ...
Validation loss decreased (0.208987 --> 0.208789).  Saving model ...
Validation loss decreased (0.208789 --> 0.208587).  Saving model ...
Validation loss decreased (0.208587 --> 0.208384).  Saving model ...
Validation loss decreased (0.208384 --> 0.208209).  Saving model ...
Validation loss decreased (0.208209 --> 0.208073).  Saving model ...
Validation loss decreased (0.208073 --> 0.207975).  Saving model ...
Validation loss decreased (0.207975 --> 0.207841).  Saving model ...
Validation loss decreased (0.207841 --> 0.207701).  Saving model ...
Validation loss decreased (0.207701 --> 0.207599).  Saving model ...
Validation loss decreased (0.207599 --> 0.207447).  Saving model ...
Validation loss decreased (0.207447 --> 0.207232).  Saving model ...
Validation loss decreased (0.207232 --> 0.206993).  Saving model ...
Validation loss decreased (0.206993 --> 0.206776).  Saving model ...
Validation loss decreased (0.206776 --> 0.206607).  Saving model ...
Validation loss decreased (0.206607 --> 0.206409).  Saving model ...
Validation loss decreased (0.206409 --> 0.206216).  Saving model ...
Validation loss decreased (0.206216 --> 0.206004).  Saving model ...
Validation loss decreased (0.206004 --> 0.205830).  Saving model ...
Validation loss decreased (0.205830 --> 0.205687).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.205687 --> 0.205676).  Saving model ...
Validation loss decreased (0.205676 --> 0.205617).  Saving model ...
Validation loss decreased (0.205617 --> 0.205571).  Saving model ...
Validation loss decreased (0.205571 --> 0.205467).  Saving model ...
Validation loss decreased (0.205467 --> 0.205346).  Saving model ...
Validation loss decreased (0.205346 --> 0.205155).  Saving model ...
Validation loss decreased (0.205155 --> 0.204976).  Saving model ...
Validation loss decreased (0.204976 --> 0.204865).  Saving model ...
Validation loss decreased (0.204865 --> 0.204768).  Saving model ...
Validation loss decreased (0.204768 --> 0.204713).  Saving model ...
Validation loss decreased (0.204713 --> 0.204671).  Saving model ...
Validation loss decreased (0.204671 --> 0.204603).  Saving model ...
Validation loss decreased (0.204603 --> 0.204488).  Saving model ...
Validation loss decreased (0.204488 --> 0.204377).  Saving model ...
Validation loss decreased (0.204377 --> 0.204224).  Saving model ...
epoch 701, loss 0.3499, train acc 95.75%, f1 0.9574, precision 0.9598, recall 0.9550, auc 0.9575
Validation loss decreased (0.204224 --> 0.204065).  Saving model ...
Validation loss decreased (0.204065 --> 0.203903).  Saving model ...
Validation loss decreased (0.203903 --> 0.203701).  Saving model ...
Validation loss decreased (0.203701 --> 0.203533).  Saving model ...
Validation loss decreased (0.203533 --> 0.203337).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.203337 --> 0.203118).  Saving model ...
Validation loss decreased (0.203118 --> 0.202921).  Saving model ...
Validation loss decreased (0.202921 --> 0.202717).  Saving model ...
Validation loss decreased (0.202717 --> 0.202541).  Saving model ...
Validation loss decreased (0.202541 --> 0.202324).  Saving model ...
Validation loss decreased (0.202324 --> 0.202078).  Saving model ...
Validation loss decreased (0.202078 --> 0.201778).  Saving model ...
Validation loss decreased (0.201778 --> 0.201449).  Saving model ...
Validation loss decreased (0.201449 --> 0.201099).  Saving model ...
Validation loss decreased (0.201099 --> 0.200784).  Saving model ...
Validation loss decreased (0.200784 --> 0.200449).  Saving model ...
Validation loss decreased (0.200449 --> 0.200114).  Saving model ...
Validation loss decreased (0.200114 --> 0.199869).  Saving model ...
Validation loss decreased (0.199869 --> 0.199658).  Saving model ...
Validation loss decreased (0.199658 --> 0.199457).  Saving model ...
Validation loss decreased (0.199457 --> 0.199179).  Saving model ...
Validation loss decreased (0.199179 --> 0.198973).  Saving model ...
Validation loss decreased (0.198973 --> 0.198749).  Saving model ...
Validation loss decreased (0.198749 --> 0.198544).  Saving model ...
Validation loss decreased (0.198544 --> 0.198307).  Saving model ...
Validation loss decreased (0.198307 --> 0.198094).  Saving model ...
Validation loss decreased (0.198094 --> 0.197877).  Saving model ...
Validation loss decreased (0.197877 --> 0.197698).  Saving model ...
Validation loss decreased (0.197698 --> 0.197544).  Saving model ...
Validation loss decreased (0.197544 --> 0.197438).  Saving model ...
Validation loss decreased (0.197438 --> 0.197360).  Saving model ...
Validation loss decreased (0.197360 --> 0.197289).  Saving model ...
Validation loss decreased (0.197289 --> 0.197187).  Saving model ...
Validation loss decreased (0.197187 --> 0.197059).  Saving model ...
Validation loss decreased (0.197059 --> 0.196909).  Saving model ...
Validation loss decreased (0.196909 --> 0.196739).  Saving model ...
Validation loss decreased (0.196739 --> 0.196577).  Saving model ...
Validation loss decreased (0.196577 --> 0.196443).  Saving model ...
Validation loss decreased (0.196443 --> 0.196322).  Saving model ...
Validation loss decreased (0.196322 --> 0.196227).  Saving model ...
Validation loss decreased (0.196227 --> 0.196129).  Saving model ...
Validation loss decreased (0.196129 --> 0.196073).  Saving model ...
Validation loss decreased (0.196073 --> 0.195997).  Saving model ...
Validation loss decreased (0.195997 --> 0.195896).  Saving model ...
Validation loss decreased (0.195896 --> 0.195793).  Saving model ...
Validation loss decreased (0.195793 --> 0.195631).  Saving model ...
Validation loss decreased (0.195631 --> 0.195453).  Saving model ...
Validation loss decreased (0.195453 --> 0.195272).  Saving model ...
Validation loss decreased (0.195272 --> 0.195111).  Saving model ...
Validation loss decreased (0.195111 --> 0.194947).  Saving model ...
Validation loss decreased (0.194947 --> 0.194778).  Saving model ...
Validation loss decreased (0.194778 --> 0.194585).  Saving model ...
Validation loss decreased (0.194585 --> 0.194420).  Saving model ...
Validation loss decreased (0.194420 --> 0.194265).  Saving model ...
Validation loss decreased (0.194265 --> 0.194082).  Saving model ...
Validation loss decreased (0.194082 --> 0.193963).  Saving model ...
Validation loss decreased (0.193963 --> 0.193852).  Saving model ...
Validation loss decreased (0.193852 --> 0.193747).  Saving model ...
Validation loss decreased (0.193747 --> 0.193627).  Saving model ...
Validation loss decreased (0.193627 --> 0.193436).  Saving model ...
Validation loss decreased (0.193436 --> 0.193270).  Saving model ...
Validation loss decreased (0.193270 --> 0.193135).  Saving model ...
Validation loss decreased (0.193135 --> 0.192966).  Saving model ...
Validation loss decreased (0.192966 --> 0.192777).  Saving model ...
Validation loss decreased (0.192777 --> 0.192578).  Saving model ...
Validation loss decreased (0.192578 --> 0.192308).  Saving model ...
Validation loss decreased (0.192308 --> 0.192038).  Saving model ...
Validation loss decreased (0.192038 --> 0.191736).  Saving model ...
Validation loss decreased (0.191736 --> 0.191394).  Saving model ...
Validation loss decreased (0.191394 --> 0.191104).  Saving model ...
Validation loss decreased (0.191104 --> 0.190865).  Saving model ...
Validation loss decreased (0.190865 --> 0.190632).  Saving model ...
Validation loss decreased (0.190632 --> 0.190498).  Saving model ...
Validation loss decreased (0.190498 --> 0.190379).  Saving model ...
Validation loss decreased (0.190379 --> 0.190256).  Saving model ...
Validation loss decreased (0.190256 --> 0.190165).  Saving model ...
Validation loss decreased (0.190165 --> 0.190013).  Saving model ...
Validation loss decreased (0.190013 --> 0.189851).  Saving model ...
Validation loss decreased (0.189851 --> 0.189678).  Saving model ...
Validation loss decreased (0.189678 --> 0.189496).  Saving model ...
Validation loss decreased (0.189496 --> 0.189286).  Saving model ...
Validation loss decreased (0.189286 --> 0.189147).  Saving model ...
Validation loss decreased (0.189147 --> 0.189086).  Saving model ...
Validation loss decreased (0.189086 --> 0.189004).  Saving model ...
Validation loss decreased (0.189004 --> 0.188929).  Saving model ...
Validation loss decreased (0.188929 --> 0.188842).  Saving model ...
Validation loss decreased (0.188842 --> 0.188720).  Saving model ...
Validation loss decreased (0.188720 --> 0.188643).  Saving model ...
Validation loss decreased (0.188643 --> 0.188596).  Saving model ...
Validation loss decreased (0.188596 --> 0.188561).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
epoch 801, loss 0.4057, train acc 96.00%, f1 0.9598, precision 0.9646, recall 0.9550, auc 0.9600
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 810, loss 0.4531, train acc 96.25%, f1 0.9622, precision 0.9695, recall 0.9550, auc 0.9625



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_Mirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_4
./test_pima/result_MLP_minus_Mirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6678301886792453

the Fscore is 0.6075949367088608

the precision is 0.45714285714285713

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_4
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5932, train acc 78.84%, f1 0.7875, precision 0.7912, recall 0.7838, auc 0.7884
epoch 201, loss 0.4748, train acc 81.51%, f1 0.8150, precision 0.8154, recall 0.8147, auc 0.8151
epoch 301, loss 0.4260, train acc 83.43%, f1 0.8343, precision 0.8342, recall 0.8344, auc 0.8343
epoch 401, loss 0.4348, train acc 84.40%, f1 0.8441, precision 0.8436, recall 0.8446, auc 0.8440
epoch 501, loss 0.3827, train acc 84.82%, f1 0.8483, precision 0.8480, recall 0.8486, auc 0.8482
epoch 601, loss 0.3450, train acc 84.93%, f1 0.8493, precision 0.8492, recall 0.8494, auc 0.8493
epoch 701, loss 0.4068, train acc 84.99%, f1 0.8500, precision 0.8498, recall 0.8501, auc 0.8499
epoch 801, loss 0.2549, train acc 85.01%, f1 0.8501, precision 0.8500, recall 0.8502, auc 0.8501
epoch 901, loss 0.3224, train acc 85.06%, f1 0.8506, precision 0.8505, recall 0.8508, auc 0.8506
epoch 1001, loss 0.4142, train acc 85.02%, f1 0.8502, precision 0.8501, recall 0.8504, auc 0.8502
epoch 1101, loss 0.3825, train acc 85.07%, f1 0.8507, precision 0.8506, recall 0.8508, auc 0.8507
epoch 1201, loss 0.2547, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8511, auc 0.8510
epoch 1301, loss 0.3096, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8509, auc 0.8508
epoch 1401, loss 0.2681, train acc 85.05%, f1 0.8505, precision 0.8505, recall 0.8506, auc 0.8505
epoch 1501, loss 0.2354, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8510, auc 0.8510
epoch 1601, loss 0.4055, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8509, auc 0.8509
epoch 1701, loss 0.4896, train acc 85.07%, f1 0.8507, precision 0.8506, recall 0.8509, auc 0.8507
epoch 1801, loss 0.3478, train acc 85.03%, f1 0.8503, precision 0.8503, recall 0.8502, auc 0.8503
epoch 1901, loss 0.3112, train acc 85.03%, f1 0.8503, precision 0.8503, recall 0.8503, auc 0.8503
epoch 2001, loss 0.2647, train acc 85.11%, f1 0.8511, precision 0.8512, recall 0.8510, auc 0.8511
epoch 2101, loss 0.3673, train acc 85.11%, f1 0.8511, precision 0.8510, recall 0.8512, auc 0.8511
epoch 2201, loss 0.3533, train acc 85.05%, f1 0.8505, precision 0.8504, recall 0.8506, auc 0.8505
epoch 2301, loss 0.3217, train acc 85.07%, f1 0.8507, precision 0.8506, recall 0.8507, auc 0.8507
epoch 2401, loss 0.3122, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8511, auc 0.8511
epoch 2501, loss 0.3610, train acc 85.09%, f1 0.8509, precision 0.8508, recall 0.8509, auc 0.8509
epoch 2601, loss 0.2599, train acc 85.07%, f1 0.8507, precision 0.8506, recall 0.8508, auc 0.8507
epoch 2701, loss 0.3362, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8511, auc 0.8511
epoch 2801, loss 0.3150, train acc 85.09%, f1 0.8510, precision 0.8508, recall 0.8511, auc 0.8509
epoch 2901, loss 0.3725, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8506, auc 0.8507
epoch 3001, loss 0.2118, train acc 85.07%, f1 0.8507, precision 0.8508, recall 0.8507, auc 0.8507
epoch 3101, loss 0.3684, train acc 85.06%, f1 0.8506, precision 0.8507, recall 0.8505, auc 0.8506
epoch 3201, loss 0.4315, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8504, auc 0.8504
epoch 3301, loss 0.4131, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8511, auc 0.8511
epoch 3401, loss 0.4042, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 3501, loss 0.3837, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8510, auc 0.8510
epoch 3601, loss 0.2055, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8507, auc 0.8508
epoch 3701, loss 0.3516, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8510, auc 0.8510
epoch 3801, loss 0.4031, train acc 85.06%, f1 0.8506, precision 0.8506, recall 0.8506, auc 0.8506
epoch 3901, loss 0.3906, train acc 85.04%, f1 0.8505, precision 0.8504, recall 0.8505, auc 0.8504
epoch 4001, loss 0.3866, train acc 85.06%, f1 0.8506, precision 0.8506, recall 0.8505, auc 0.8506
epoch 4101, loss 0.3432, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8503, auc 0.8504
epoch 4201, loss 0.3791, train acc 85.04%, f1 0.8503, precision 0.8505, recall 0.8502, auc 0.8504
epoch 4301, loss 0.2447, train acc 85.07%, f1 0.8507, precision 0.8508, recall 0.8506, auc 0.8507
epoch 4401, loss 0.3253, train acc 85.05%, f1 0.8505, precision 0.8506, recall 0.8505, auc 0.8505
epoch 4501, loss 0.3128, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8509, auc 0.8509
epoch 4601, loss 0.2879, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8508, auc 0.8509
epoch 4701, loss 0.3297, train acc 85.06%, f1 0.8506, precision 0.8506, recall 0.8506, auc 0.8506
epoch 4801, loss 0.2997, train acc 85.05%, f1 0.8505, precision 0.8506, recall 0.8505, auc 0.8505
epoch 4901, loss 0.2989, train acc 85.07%, f1 0.8507, precision 0.8508, recall 0.8506, auc 0.8507
epoch 5001, loss 0.3953, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8510, auc 0.8508
epoch 5101, loss 0.4218, train acc 85.05%, f1 0.8505, precision 0.8504, recall 0.8506, auc 0.8505
epoch 5201, loss 0.3503, train acc 85.03%, f1 0.8502, precision 0.8503, recall 0.8502, auc 0.8503
epoch 5301, loss 0.3171, train acc 85.10%, f1 0.8510, precision 0.8511, recall 0.8509, auc 0.8510
epoch 5401, loss 0.3657, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8511, auc 0.8511
epoch 5501, loss 0.3298, train acc 85.10%, f1 0.8510, precision 0.8511, recall 0.8509, auc 0.8510
epoch 5601, loss 0.3612, train acc 85.06%, f1 0.8506, precision 0.8506, recall 0.8505, auc 0.8506
epoch 5701, loss 0.2444, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8509, auc 0.8508
epoch 5801, loss 0.3815, train acc 85.07%, f1 0.8507, precision 0.8508, recall 0.8505, auc 0.8507
epoch 5901, loss 0.3037, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8508, auc 0.8508
epoch 6001, loss 0.1890, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8508, auc 0.8509
epoch 6101, loss 0.4281, train acc 85.09%, f1 0.8509, precision 0.8510, recall 0.8509, auc 0.8509
epoch 6201, loss 0.3493, train acc 85.03%, f1 0.8503, precision 0.8502, recall 0.8505, auc 0.8503
epoch 6301, loss 0.2531, train acc 85.10%, f1 0.8510, precision 0.8511, recall 0.8509, auc 0.8510
epoch 6401, loss 0.3455, train acc 85.15%, f1 0.8515, precision 0.8515, recall 0.8515, auc 0.8515
epoch 6501, loss 0.4073, train acc 85.07%, f1 0.8507, precision 0.8505, recall 0.8510, auc 0.8507
epoch 6601, loss 0.4020, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8510, auc 0.8510
epoch 6701, loss 0.4063, train acc 85.12%, f1 0.8513, precision 0.8512, recall 0.8513, auc 0.8512
epoch 6801, loss 0.4382, train acc 85.09%, f1 0.8509, precision 0.8510, recall 0.8508, auc 0.8509
epoch 6901, loss 0.3694, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8508, auc 0.8509
epoch 7001, loss 0.3738, train acc 85.09%, f1 0.8509, precision 0.8511, recall 0.8507, auc 0.8509
epoch 7101, loss 0.2559, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8509, auc 0.8508
epoch 7201, loss 0.3523, train acc 85.08%, f1 0.8508, precision 0.8509, recall 0.8507, auc 0.8508
epoch 7301, loss 0.3257, train acc 85.12%, f1 0.8512, precision 0.8512, recall 0.8512, auc 0.8512
epoch 7401, loss 0.3173, train acc 85.14%, f1 0.8514, precision 0.8513, recall 0.8516, auc 0.8514
epoch 7501, loss 0.3450, train acc 85.15%, f1 0.8515, precision 0.8514, recall 0.8515, auc 0.8515
epoch 7601, loss 0.2817, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8509, auc 0.8510
epoch 7701, loss 0.2781, train acc 85.05%, f1 0.8505, precision 0.8506, recall 0.8504, auc 0.8505
epoch 7801, loss 0.2894, train acc 85.17%, f1 0.8517, precision 0.8516, recall 0.8518, auc 0.8517
epoch 7901, loss 0.3834, train acc 85.14%, f1 0.8514, precision 0.8514, recall 0.8514, auc 0.8514
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_Mirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_4
./test_pima/result_MLP_minus_Mirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6278301886792452

the Fscore is 0.5783132530120482

the precision is 0.4247787610619469

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_4
----------------------



epoch 1, loss 0.6933, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6026, train acc 78.45%, f1 0.7710, precision 0.8225, recall 0.7257, auc 0.7845
epoch 201, loss 0.5113, train acc 81.70%, f1 0.8155, precision 0.8223, recall 0.8088, auc 0.8170
epoch 301, loss 0.4411, train acc 83.47%, f1 0.8345, precision 0.8352, recall 0.8338, auc 0.8347
epoch 401, loss 0.3536, train acc 84.29%, f1 0.8433, precision 0.8412, recall 0.8453, auc 0.8429
epoch 501, loss 0.3436, train acc 84.79%, f1 0.8483, precision 0.8456, recall 0.8511, auc 0.8479
epoch 601, loss 0.2639, train acc 84.97%, f1 0.8503, precision 0.8468, recall 0.8538, auc 0.8497
epoch 701, loss 0.2555, train acc 85.03%, f1 0.8510, precision 0.8472, recall 0.8547, auc 0.8503
epoch 801, loss 0.2411, train acc 85.05%, f1 0.8512, precision 0.8471, recall 0.8554, auc 0.8505
epoch 901, loss 0.3020, train acc 85.07%, f1 0.8514, precision 0.8475, recall 0.8553, auc 0.8507
epoch 1001, loss 0.4222, train acc 85.09%, f1 0.8514, precision 0.8485, recall 0.8544, auc 0.8509
epoch 1101, loss 0.4001, train acc 85.06%, f1 0.8511, precision 0.8482, recall 0.8540, auc 0.8506
epoch 1201, loss 0.3941, train acc 85.05%, f1 0.8510, precision 0.8482, recall 0.8539, auc 0.8505
epoch 1301, loss 0.2549, train acc 85.08%, f1 0.8512, precision 0.8488, recall 0.8536, auc 0.8508
epoch 1401, loss 0.3329, train acc 85.08%, f1 0.8511, precision 0.8491, recall 0.8531, auc 0.8508
epoch 1501, loss 0.2459, train acc 85.09%, f1 0.8512, precision 0.8491, recall 0.8534, auc 0.8509
epoch 1601, loss 0.5412, train acc 85.12%, f1 0.8514, precision 0.8502, recall 0.8526, auc 0.8512
epoch 1701, loss 0.3368, train acc 85.10%, f1 0.8514, precision 0.8494, recall 0.8534, auc 0.8510
epoch 1801, loss 0.4201, train acc 85.06%, f1 0.8509, precision 0.8490, recall 0.8529, auc 0.8506
epoch 1901, loss 0.4277, train acc 85.07%, f1 0.8509, precision 0.8499, recall 0.8518, auc 0.8507
epoch 2001, loss 0.2780, train acc 85.08%, f1 0.8509, precision 0.8502, recall 0.8516, auc 0.8508
epoch 2101, loss 0.2930, train acc 85.08%, f1 0.8510, precision 0.8498, recall 0.8523, auc 0.8508
epoch 2201, loss 0.3193, train acc 85.10%, f1 0.8511, precision 0.8503, recall 0.8519, auc 0.8510
epoch 2301, loss 0.3312, train acc 85.12%, f1 0.8514, precision 0.8505, recall 0.8523, auc 0.8512
epoch 2401, loss 0.3284, train acc 85.08%, f1 0.8509, precision 0.8505, recall 0.8513, auc 0.8508
epoch 2501, loss 0.4414, train acc 85.04%, f1 0.8505, precision 0.8502, recall 0.8508, auc 0.8504
epoch 2601, loss 0.3286, train acc 85.08%, f1 0.8509, precision 0.8506, recall 0.8512, auc 0.8508
epoch 2701, loss 0.3393, train acc 85.08%, f1 0.8509, precision 0.8508, recall 0.8510, auc 0.8508
epoch 2801, loss 0.2158, train acc 85.08%, f1 0.8509, precision 0.8506, recall 0.8512, auc 0.8508
epoch 2901, loss 0.2366, train acc 85.06%, f1 0.8507, precision 0.8502, recall 0.8512, auc 0.8506
epoch 3001, loss 0.3027, train acc 85.07%, f1 0.8507, precision 0.8505, recall 0.8508, auc 0.8507
epoch 3101, loss 0.4171, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8504, auc 0.8504
epoch 3201, loss 0.2872, train acc 85.07%, f1 0.8508, precision 0.8506, recall 0.8509, auc 0.8507
epoch 3301, loss 0.4073, train acc 85.06%, f1 0.8506, precision 0.8504, recall 0.8508, auc 0.8506
epoch 3401, loss 0.4614, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8510, auc 0.8509
epoch 3501, loss 0.4011, train acc 85.08%, f1 0.8509, precision 0.8506, recall 0.8511, auc 0.8508
epoch 3601, loss 0.3022, train acc 85.07%, f1 0.8507, precision 0.8509, recall 0.8504, auc 0.8507
epoch 3701, loss 0.2265, train acc 85.07%, f1 0.8507, precision 0.8505, recall 0.8508, auc 0.8507
epoch 3801, loss 0.3799, train acc 85.09%, f1 0.8509, precision 0.8507, recall 0.8512, auc 0.8509
epoch 3901, loss 0.3925, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 4001, loss 0.3755, train acc 85.09%, f1 0.8509, precision 0.8507, recall 0.8510, auc 0.8509
epoch 4101, loss 0.2213, train acc 85.06%, f1 0.8507, precision 0.8505, recall 0.8508, auc 0.8506
epoch 4201, loss 0.3728, train acc 85.05%, f1 0.8506, precision 0.8504, recall 0.8507, auc 0.8505
epoch 4301, loss 0.2494, train acc 85.07%, f1 0.8508, precision 0.8504, recall 0.8511, auc 0.8507
epoch 4401, loss 0.4325, train acc 85.10%, f1 0.8509, precision 0.8510, recall 0.8508, auc 0.8510
epoch 4501, loss 0.3383, train acc 85.09%, f1 0.8509, precision 0.8508, recall 0.8509, auc 0.8509
epoch 4601, loss 0.3360, train acc 85.06%, f1 0.8507, precision 0.8505, recall 0.8509, auc 0.8506
epoch 4701, loss 0.3233, train acc 85.05%, f1 0.8505, precision 0.8502, recall 0.8509, auc 0.8505
epoch 4801, loss 0.3950, train acc 85.07%, f1 0.8508, precision 0.8504, recall 0.8512, auc 0.8507
epoch 4901, loss 0.2440, train acc 85.05%, f1 0.8505, precision 0.8508, recall 0.8501, auc 0.8505
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_Mirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_4
./test_pima/result_MLP_minus_Mirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6478301886792452

the Fscore is 0.5925925925925927

the precision is 0.44036697247706424

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_4
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.5947, train acc 78.97%, f1 0.7897, precision 0.7896, recall 0.7898, auc 0.7897
epoch 201, loss 0.5145, train acc 81.73%, f1 0.8172, precision 0.8173, recall 0.8172, auc 0.8172
epoch 301, loss 0.3709, train acc 83.49%, f1 0.8349, precision 0.8349, recall 0.8348, auc 0.8349
epoch 401, loss 0.3110, train acc 84.39%, f1 0.8439, precision 0.8439, recall 0.8439, auc 0.8439
epoch 501, loss 0.4001, train acc 84.83%, f1 0.8483, precision 0.8483, recall 0.8483, auc 0.8483
epoch 601, loss 0.4459, train acc 84.97%, f1 0.8497, precision 0.8497, recall 0.8497, auc 0.8497
epoch 701, loss 0.2939, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8508, auc 0.8508
epoch 801, loss 0.4091, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 901, loss 0.4020, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8511, auc 0.8511
epoch 1001, loss 0.4365, train acc 85.12%, f1 0.8512, precision 0.8512, recall 0.8512, auc 0.8512
epoch 1101, loss 0.3971, train acc 85.08%, f1 0.8508, precision 0.8508, recall 0.8508, auc 0.8508
epoch 1201, loss 0.3394, train acc 85.11%, f1 0.8511, precision 0.8511, recall 0.8510, auc 0.8511
epoch 1301, loss 0.2864, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8508, auc 0.8507
epoch 1401, loss 0.3019, train acc 85.09%, f1 0.8509, precision 0.8509, recall 0.8509, auc 0.8509
epoch 1501, loss 0.3611, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8511, auc 0.8510
epoch 1601, loss 0.2866, train acc 85.07%, f1 0.8507, precision 0.8507, recall 0.8507, auc 0.8507
epoch 1701, loss 0.3475, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8509, auc 0.8508
epoch 1801, loss 0.3560, train acc 85.06%, f1 0.8506, precision 0.8506, recall 0.8507, auc 0.8506
epoch 1901, loss 0.2880, train acc 85.01%, f1 0.8501, precision 0.8501, recall 0.8502, auc 0.8501
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_Mirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_4
./test_pima/result_MLP_minus_Mirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6228301886792453

the Fscore is 0.5748502994011976

the precision is 0.42105263157894735

the recall is 0.9056603773584906

Done
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_4
----------------------



epoch 1, loss 0.6929, train acc 52.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.692426).  Saving model ...
Validation loss decreased (0.692426 --> 0.692241).  Saving model ...
Validation loss decreased (0.692241 --> 0.692183).  Saving model ...
Validation loss decreased (0.692183 --> 0.692142).  Saving model ...
Validation loss decreased (0.692142 --> 0.692075).  Saving model ...
Validation loss decreased (0.692075 --> 0.691954).  Saving model ...
Validation loss decreased (0.691954 --> 0.691812).  Saving model ...
Validation loss decreased (0.691812 --> 0.691722).  Saving model ...
Validation loss decreased (0.691722 --> 0.691595).  Saving model ...
Validation loss decreased (0.691595 --> 0.691497).  Saving model ...
Validation loss decreased (0.691497 --> 0.691406).  Saving model ...
Validation loss decreased (0.691406 --> 0.691323).  Saving model ...
Validation loss decreased (0.691323 --> 0.691207).  Saving model ...
Validation loss decreased (0.691207 --> 0.691102).  Saving model ...
Validation loss decreased (0.691102 --> 0.691006).  Saving model ...
Validation loss decreased (0.691006 --> 0.690880).  Saving model ...
Validation loss decreased (0.690880 --> 0.690759).  Saving model ...
Validation loss decreased (0.690759 --> 0.690625).  Saving model ...
Validation loss decreased (0.690625 --> 0.690472).  Saving model ...
Validation loss decreased (0.690472 --> 0.690259).  Saving model ...
Validation loss decreased (0.690259 --> 0.689999).  Saving model ...
Validation loss decreased (0.689999 --> 0.689697).  Saving model ...
Validation loss decreased (0.689697 --> 0.689367).  Saving model ...
Validation loss decreased (0.689367 --> 0.688990).  Saving model ...
Validation loss decreased (0.688990 --> 0.688619).  Saving model ...
Validation loss decreased (0.688619 --> 0.688223).  Saving model ...
Validation loss decreased (0.688223 --> 0.687775).  Saving model ...
Validation loss decreased (0.687775 --> 0.687324).  Saving model ...
Validation loss decreased (0.687324 --> 0.686839).  Saving model ...
Validation loss decreased (0.686839 --> 0.686324).  Saving model ...
Validation loss decreased (0.686324 --> 0.685765).  Saving model ...
Validation loss decreased (0.685765 --> 0.685173).  Saving model ...
Validation loss decreased (0.685173 --> 0.684541).  Saving model ...
Validation loss decreased (0.684541 --> 0.683861).  Saving model ...
Validation loss decreased (0.683861 --> 0.683112).  Saving model ...
Validation loss decreased (0.683112 --> 0.682342).  Saving model ...
Validation loss decreased (0.682342 --> 0.681548).  Saving model ...
Validation loss decreased (0.681548 --> 0.680707).  Saving model ...
Validation loss decreased (0.680707 --> 0.679832).  Saving model ...
Validation loss decreased (0.679832 --> 0.678878).  Saving model ...
Validation loss decreased (0.678878 --> 0.677924).  Saving model ...
Validation loss decreased (0.677924 --> 0.676943).  Saving model ...
Validation loss decreased (0.676943 --> 0.675884).  Saving model ...
Validation loss decreased (0.675884 --> 0.674754).  Saving model ...
Validation loss decreased (0.674754 --> 0.673582).  Saving model ...
Validation loss decreased (0.673582 --> 0.672366).  Saving model ...
Validation loss decreased (0.672366 --> 0.671117).  Saving model ...
Validation loss decreased (0.671117 --> 0.669838).  Saving model ...
Validation loss decreased (0.669838 --> 0.668493).  Saving model ...
Validation loss decreased (0.668493 --> 0.667147).  Saving model ...
Validation loss decreased (0.667147 --> 0.665734).  Saving model ...
Validation loss decreased (0.665734 --> 0.664251).  Saving model ...
Validation loss decreased (0.664251 --> 0.662807).  Saving model ...
Validation loss decreased (0.662807 --> 0.661324).  Saving model ...
Validation loss decreased (0.661324 --> 0.659793).  Saving model ...
Validation loss decreased (0.659793 --> 0.658259).  Saving model ...
Validation loss decreased (0.658259 --> 0.656663).  Saving model ...
Validation loss decreased (0.656663 --> 0.655060).  Saving model ...
Validation loss decreased (0.655060 --> 0.653370).  Saving model ...
Validation loss decreased (0.653370 --> 0.651679).  Saving model ...
Validation loss decreased (0.651679 --> 0.649961).  Saving model ...
Validation loss decreased (0.649961 --> 0.648154).  Saving model ...
Validation loss decreased (0.648154 --> 0.646283).  Saving model ...
Validation loss decreased (0.646283 --> 0.644369).  Saving model ...
Validation loss decreased (0.644369 --> 0.642398).  Saving model ...
Validation loss decreased (0.642398 --> 0.640415).  Saving model ...
Validation loss decreased (0.640415 --> 0.638312).  Saving model ...
Validation loss decreased (0.638312 --> 0.636207).  Saving model ...
Validation loss decreased (0.636207 --> 0.634015).  Saving model ...
Validation loss decreased (0.634015 --> 0.631760).  Saving model ...
Validation loss decreased (0.631760 --> 0.629465).  Saving model ...
Validation loss decreased (0.629465 --> 0.627167).  Saving model ...
Validation loss decreased (0.627167 --> 0.624797).  Saving model ...
Validation loss decreased (0.624797 --> 0.622470).  Saving model ...
Validation loss decreased (0.622470 --> 0.620106).  Saving model ...
Validation loss decreased (0.620106 --> 0.617676).  Saving model ...
Validation loss decreased (0.617676 --> 0.615234).  Saving model ...
Validation loss decreased (0.615234 --> 0.612801).  Saving model ...
Validation loss decreased (0.612801 --> 0.610344).  Saving model ...
Validation loss decreased (0.610344 --> 0.607928).  Saving model ...
Validation loss decreased (0.607928 --> 0.605455).  Saving model ...
Validation loss decreased (0.605455 --> 0.602992).  Saving model ...
Validation loss decreased (0.602992 --> 0.600503).  Saving model ...
Validation loss decreased (0.600503 --> 0.597983).  Saving model ...
Validation loss decreased (0.597983 --> 0.595403).  Saving model ...
Validation loss decreased (0.595403 --> 0.592748).  Saving model ...
Validation loss decreased (0.592748 --> 0.589983).  Saving model ...
Validation loss decreased (0.589983 --> 0.587221).  Saving model ...
Validation loss decreased (0.587221 --> 0.584518).  Saving model ...
Validation loss decreased (0.584518 --> 0.581939).  Saving model ...
Validation loss decreased (0.581939 --> 0.579295).  Saving model ...
Validation loss decreased (0.579295 --> 0.576642).  Saving model ...
Validation loss decreased (0.576642 --> 0.573941).  Saving model ...
Validation loss decreased (0.573941 --> 0.571226).  Saving model ...
Validation loss decreased (0.571226 --> 0.568465).  Saving model ...
Validation loss decreased (0.568465 --> 0.565751).  Saving model ...
Validation loss decreased (0.565751 --> 0.563107).  Saving model ...
Validation loss decreased (0.563107 --> 0.560451).  Saving model ...
Validation loss decreased (0.560451 --> 0.557849).  Saving model ...
Validation loss decreased (0.557849 --> 0.555339).  Saving model ...
epoch 101, loss 0.6180, train acc 97.00%, f1 0.9684, precision 0.9684, recall 0.9684, auc 0.9699
Validation loss decreased (0.555339 --> 0.552812).  Saving model ...
Validation loss decreased (0.552812 --> 0.550226).  Saving model ...
Validation loss decreased (0.550226 --> 0.547554).  Saving model ...
Validation loss decreased (0.547554 --> 0.544906).  Saving model ...
Validation loss decreased (0.544906 --> 0.542143).  Saving model ...
Validation loss decreased (0.542143 --> 0.539421).  Saving model ...
Validation loss decreased (0.539421 --> 0.536684).  Saving model ...
Validation loss decreased (0.536684 --> 0.533970).  Saving model ...
Validation loss decreased (0.533970 --> 0.531287).  Saving model ...
Validation loss decreased (0.531287 --> 0.528622).  Saving model ...
Validation loss decreased (0.528622 --> 0.525971).  Saving model ...
Validation loss decreased (0.525971 --> 0.523210).  Saving model ...
Validation loss decreased (0.523210 --> 0.520409).  Saving model ...
Validation loss decreased (0.520409 --> 0.517601).  Saving model ...
Validation loss decreased (0.517601 --> 0.514834).  Saving model ...
Validation loss decreased (0.514834 --> 0.512179).  Saving model ...
Validation loss decreased (0.512179 --> 0.509518).  Saving model ...
Validation loss decreased (0.509518 --> 0.506915).  Saving model ...
Validation loss decreased (0.506915 --> 0.504329).  Saving model ...
Validation loss decreased (0.504329 --> 0.501749).  Saving model ...
Validation loss decreased (0.501749 --> 0.499156).  Saving model ...
Validation loss decreased (0.499156 --> 0.496513).  Saving model ...
Validation loss decreased (0.496513 --> 0.493900).  Saving model ...
Validation loss decreased (0.493900 --> 0.491274).  Saving model ...
Validation loss decreased (0.491274 --> 0.488678).  Saving model ...
Validation loss decreased (0.488678 --> 0.486061).  Saving model ...
Validation loss decreased (0.486061 --> 0.483501).  Saving model ...
Validation loss decreased (0.483501 --> 0.480910).  Saving model ...
Validation loss decreased (0.480910 --> 0.478367).  Saving model ...
Validation loss decreased (0.478367 --> 0.475861).  Saving model ...
Validation loss decreased (0.475861 --> 0.473336).  Saving model ...
Validation loss decreased (0.473336 --> 0.470818).  Saving model ...
Validation loss decreased (0.470818 --> 0.468372).  Saving model ...
Validation loss decreased (0.468372 --> 0.465846).  Saving model ...
Validation loss decreased (0.465846 --> 0.463313).  Saving model ...
Validation loss decreased (0.463313 --> 0.460848).  Saving model ...
Validation loss decreased (0.460848 --> 0.458439).  Saving model ...
Validation loss decreased (0.458439 --> 0.456006).  Saving model ...
Validation loss decreased (0.456006 --> 0.453507).  Saving model ...
Validation loss decreased (0.453507 --> 0.450927).  Saving model ...
Validation loss decreased (0.450927 --> 0.448323).  Saving model ...
Validation loss decreased (0.448323 --> 0.445800).  Saving model ...
Validation loss decreased (0.445800 --> 0.443373).  Saving model ...
Validation loss decreased (0.443373 --> 0.441008).  Saving model ...
Validation loss decreased (0.441008 --> 0.438571).  Saving model ...
Validation loss decreased (0.438571 --> 0.436172).  Saving model ...
Validation loss decreased (0.436172 --> 0.433832).  Saving model ...
Validation loss decreased (0.433832 --> 0.431466).  Saving model ...
Validation loss decreased (0.431466 --> 0.429185).  Saving model ...
Validation loss decreased (0.429185 --> 0.426971).  Saving model ...
Validation loss decreased (0.426971 --> 0.424738).  Saving model ...
Validation loss decreased (0.424738 --> 0.422417).  Saving model ...
Validation loss decreased (0.422417 --> 0.420164).  Saving model ...
Validation loss decreased (0.420164 --> 0.417904).  Saving model ...
Validation loss decreased (0.417904 --> 0.415662).  Saving model ...
Validation loss decreased (0.415662 --> 0.413429).  Saving model ...
Validation loss decreased (0.413429 --> 0.411324).  Saving model ...
Validation loss decreased (0.411324 --> 0.409210).  Saving model ...
Validation loss decreased (0.409210 --> 0.407050).  Saving model ...
Validation loss decreased (0.407050 --> 0.404962).  Saving model ...
Validation loss decreased (0.404962 --> 0.402870).  Saving model ...
Validation loss decreased (0.402870 --> 0.400731).  Saving model ...
Validation loss decreased (0.400731 --> 0.398656).  Saving model ...
Validation loss decreased (0.398656 --> 0.396527).  Saving model ...
Validation loss decreased (0.396527 --> 0.394304).  Saving model ...
Validation loss decreased (0.394304 --> 0.392153).  Saving model ...
Validation loss decreased (0.392153 --> 0.389990).  Saving model ...
Validation loss decreased (0.389990 --> 0.387963).  Saving model ...
Validation loss decreased (0.387963 --> 0.385941).  Saving model ...
Validation loss decreased (0.385941 --> 0.384024).  Saving model ...
Validation loss decreased (0.384024 --> 0.382152).  Saving model ...
Validation loss decreased (0.382152 --> 0.380402).  Saving model ...
Validation loss decreased (0.380402 --> 0.378812).  Saving model ...
Validation loss decreased (0.378812 --> 0.377245).  Saving model ...
Validation loss decreased (0.377245 --> 0.375575).  Saving model ...
Validation loss decreased (0.375575 --> 0.373825).  Saving model ...
Validation loss decreased (0.373825 --> 0.372012).  Saving model ...
Validation loss decreased (0.372012 --> 0.370300).  Saving model ...
Validation loss decreased (0.370300 --> 0.368641).  Saving model ...
Validation loss decreased (0.368641 --> 0.366908).  Saving model ...
Validation loss decreased (0.366908 --> 0.365163).  Saving model ...
Validation loss decreased (0.365163 --> 0.363462).  Saving model ...
Validation loss decreased (0.363462 --> 0.361811).  Saving model ...
Validation loss decreased (0.361811 --> 0.360205).  Saving model ...
Validation loss decreased (0.360205 --> 0.358584).  Saving model ...
Validation loss decreased (0.358584 --> 0.357024).  Saving model ...
Validation loss decreased (0.357024 --> 0.355413).  Saving model ...
Validation loss decreased (0.355413 --> 0.353877).  Saving model ...
Validation loss decreased (0.353877 --> 0.352251).  Saving model ...
Validation loss decreased (0.352251 --> 0.350650).  Saving model ...
Validation loss decreased (0.350650 --> 0.349220).  Saving model ...
Validation loss decreased (0.349220 --> 0.347751).  Saving model ...
Validation loss decreased (0.347751 --> 0.346325).  Saving model ...
Validation loss decreased (0.346325 --> 0.344863).  Saving model ...
Validation loss decreased (0.344863 --> 0.343445).  Saving model ...
Validation loss decreased (0.343445 --> 0.342123).  Saving model ...
Validation loss decreased (0.342123 --> 0.340841).  Saving model ...
Validation loss decreased (0.340841 --> 0.339611).  Saving model ...
Validation loss decreased (0.339611 --> 0.338377).  Saving model ...
Validation loss decreased (0.338377 --> 0.337131).  Saving model ...
epoch 201, loss 0.5375, train acc 97.00%, f1 0.9688, precision 0.9588, recall 0.9789, auc 0.9704
Validation loss decreased (0.337131 --> 0.335958).  Saving model ...
Validation loss decreased (0.335958 --> 0.334747).  Saving model ...
Validation loss decreased (0.334747 --> 0.333521).  Saving model ...
Validation loss decreased (0.333521 --> 0.332412).  Saving model ...
Validation loss decreased (0.332412 --> 0.331361).  Saving model ...
Validation loss decreased (0.331361 --> 0.330325).  Saving model ...
Validation loss decreased (0.330325 --> 0.329174).  Saving model ...
Validation loss decreased (0.329174 --> 0.327950).  Saving model ...
Validation loss decreased (0.327950 --> 0.326648).  Saving model ...
Validation loss decreased (0.326648 --> 0.325321).  Saving model ...
Validation loss decreased (0.325321 --> 0.323951).  Saving model ...
Validation loss decreased (0.323951 --> 0.322597).  Saving model ...
Validation loss decreased (0.322597 --> 0.321251).  Saving model ...
Validation loss decreased (0.321251 --> 0.319960).  Saving model ...
Validation loss decreased (0.319960 --> 0.318658).  Saving model ...
Validation loss decreased (0.318658 --> 0.317319).  Saving model ...
Validation loss decreased (0.317319 --> 0.315975).  Saving model ...
Validation loss decreased (0.315975 --> 0.314657).  Saving model ...
Validation loss decreased (0.314657 --> 0.313311).  Saving model ...
Validation loss decreased (0.313311 --> 0.311958).  Saving model ...
Validation loss decreased (0.311958 --> 0.310608).  Saving model ...
Validation loss decreased (0.310608 --> 0.309305).  Saving model ...
Validation loss decreased (0.309305 --> 0.308109).  Saving model ...
Validation loss decreased (0.308109 --> 0.307018).  Saving model ...
Validation loss decreased (0.307018 --> 0.305955).  Saving model ...
Validation loss decreased (0.305955 --> 0.304929).  Saving model ...
Validation loss decreased (0.304929 --> 0.303936).  Saving model ...
Validation loss decreased (0.303936 --> 0.302863).  Saving model ...
Validation loss decreased (0.302863 --> 0.301845).  Saving model ...
Validation loss decreased (0.301845 --> 0.300710).  Saving model ...
Validation loss decreased (0.300710 --> 0.299552).  Saving model ...
Validation loss decreased (0.299552 --> 0.298442).  Saving model ...
Validation loss decreased (0.298442 --> 0.297347).  Saving model ...
Validation loss decreased (0.297347 --> 0.296249).  Saving model ...
Validation loss decreased (0.296249 --> 0.295137).  Saving model ...
Validation loss decreased (0.295137 --> 0.294042).  Saving model ...
Validation loss decreased (0.294042 --> 0.292953).  Saving model ...
Validation loss decreased (0.292953 --> 0.291834).  Saving model ...
Validation loss decreased (0.291834 --> 0.290704).  Saving model ...
Validation loss decreased (0.290704 --> 0.289680).  Saving model ...
Validation loss decreased (0.289680 --> 0.288586).  Saving model ...
Validation loss decreased (0.288586 --> 0.287493).  Saving model ...
Validation loss decreased (0.287493 --> 0.286425).  Saving model ...
Validation loss decreased (0.286425 --> 0.285333).  Saving model ...
Validation loss decreased (0.285333 --> 0.284231).  Saving model ...
Validation loss decreased (0.284231 --> 0.283099).  Saving model ...
Validation loss decreased (0.283099 --> 0.282105).  Saving model ...
Validation loss decreased (0.282105 --> 0.281122).  Saving model ...
Validation loss decreased (0.281122 --> 0.280161).  Saving model ...
Validation loss decreased (0.280161 --> 0.279134).  Saving model ...
Validation loss decreased (0.279134 --> 0.278114).  Saving model ...
Validation loss decreased (0.278114 --> 0.277038).  Saving model ...
Validation loss decreased (0.277038 --> 0.276058).  Saving model ...
Validation loss decreased (0.276058 --> 0.275084).  Saving model ...
Validation loss decreased (0.275084 --> 0.274131).  Saving model ...
Validation loss decreased (0.274131 --> 0.273217).  Saving model ...
Validation loss decreased (0.273217 --> 0.272244).  Saving model ...
Validation loss decreased (0.272244 --> 0.271399).  Saving model ...
Validation loss decreased (0.271399 --> 0.270570).  Saving model ...
Validation loss decreased (0.270570 --> 0.269774).  Saving model ...
Validation loss decreased (0.269774 --> 0.269054).  Saving model ...
Validation loss decreased (0.269054 --> 0.268448).  Saving model ...
Validation loss decreased (0.268448 --> 0.267905).  Saving model ...
Validation loss decreased (0.267905 --> 0.267387).  Saving model ...
Validation loss decreased (0.267387 --> 0.266905).  Saving model ...
Validation loss decreased (0.266905 --> 0.266368).  Saving model ...
Validation loss decreased (0.266368 --> 0.265823).  Saving model ...
Validation loss decreased (0.265823 --> 0.265264).  Saving model ...
Validation loss decreased (0.265264 --> 0.264725).  Saving model ...
Validation loss decreased (0.264725 --> 0.264213).  Saving model ...
Validation loss decreased (0.264213 --> 0.263671).  Saving model ...
Validation loss decreased (0.263671 --> 0.262985).  Saving model ...
Validation loss decreased (0.262985 --> 0.262446).  Saving model ...
Validation loss decreased (0.262446 --> 0.261882).  Saving model ...
Validation loss decreased (0.261882 --> 0.261243).  Saving model ...
Validation loss decreased (0.261243 --> 0.260567).  Saving model ...
Validation loss decreased (0.260567 --> 0.259949).  Saving model ...
Validation loss decreased (0.259949 --> 0.259335).  Saving model ...
Validation loss decreased (0.259335 --> 0.258724).  Saving model ...
Validation loss decreased (0.258724 --> 0.258109).  Saving model ...
Validation loss decreased (0.258109 --> 0.257530).  Saving model ...
Validation loss decreased (0.257530 --> 0.256892).  Saving model ...
Validation loss decreased (0.256892 --> 0.256314).  Saving model ...
Validation loss decreased (0.256314 --> 0.255864).  Saving model ...
Validation loss decreased (0.255864 --> 0.255400).  Saving model ...
Validation loss decreased (0.255400 --> 0.254979).  Saving model ...
Validation loss decreased (0.254979 --> 0.254542).  Saving model ...
Validation loss decreased (0.254542 --> 0.254109).  Saving model ...
Validation loss decreased (0.254109 --> 0.253614).  Saving model ...
Validation loss decreased (0.253614 --> 0.253030).  Saving model ...
Validation loss decreased (0.253030 --> 0.252424).  Saving model ...
Validation loss decreased (0.252424 --> 0.251791).  Saving model ...
Validation loss decreased (0.251791 --> 0.251196).  Saving model ...
Validation loss decreased (0.251196 --> 0.250643).  Saving model ...
Validation loss decreased (0.250643 --> 0.250051).  Saving model ...
Validation loss decreased (0.250051 --> 0.249399).  Saving model ...
Validation loss decreased (0.249399 --> 0.248762).  Saving model ...
Validation loss decreased (0.248762 --> 0.248129).  Saving model ...
Validation loss decreased (0.248129 --> 0.247389).  Saving model ...
Validation loss decreased (0.247389 --> 0.246675).  Saving model ...
epoch 301, loss 0.4975, train acc 96.00%, f1 0.9583, precision 0.9485, recall 0.9684, auc 0.9604
Validation loss decreased (0.246675 --> 0.246008).  Saving model ...
Validation loss decreased (0.246008 --> 0.245390).  Saving model ...
Validation loss decreased (0.245390 --> 0.244694).  Saving model ...
Validation loss decreased (0.244694 --> 0.243997).  Saving model ...
Validation loss decreased (0.243997 --> 0.243509).  Saving model ...
Validation loss decreased (0.243509 --> 0.243048).  Saving model ...
Validation loss decreased (0.243048 --> 0.242558).  Saving model ...
Validation loss decreased (0.242558 --> 0.242149).  Saving model ...
Validation loss decreased (0.242149 --> 0.241673).  Saving model ...
Validation loss decreased (0.241673 --> 0.241271).  Saving model ...
Validation loss decreased (0.241271 --> 0.240915).  Saving model ...
Validation loss decreased (0.240915 --> 0.240602).  Saving model ...
Validation loss decreased (0.240602 --> 0.240193).  Saving model ...
Validation loss decreased (0.240193 --> 0.239857).  Saving model ...
Validation loss decreased (0.239857 --> 0.239536).  Saving model ...
Validation loss decreased (0.239536 --> 0.239209).  Saving model ...
Validation loss decreased (0.239209 --> 0.238903).  Saving model ...
Validation loss decreased (0.238903 --> 0.238563).  Saving model ...
Validation loss decreased (0.238563 --> 0.238134).  Saving model ...
Validation loss decreased (0.238134 --> 0.237744).  Saving model ...
Validation loss decreased (0.237744 --> 0.237354).  Saving model ...
Validation loss decreased (0.237354 --> 0.236978).  Saving model ...
Validation loss decreased (0.236978 --> 0.236628).  Saving model ...
Validation loss decreased (0.236628 --> 0.236222).  Saving model ...
Validation loss decreased (0.236222 --> 0.235802).  Saving model ...
Validation loss decreased (0.235802 --> 0.235385).  Saving model ...
Validation loss decreased (0.235385 --> 0.234978).  Saving model ...
Validation loss decreased (0.234978 --> 0.234636).  Saving model ...
Validation loss decreased (0.234636 --> 0.234321).  Saving model ...
Validation loss decreased (0.234321 --> 0.234081).  Saving model ...
Validation loss decreased (0.234081 --> 0.233857).  Saving model ...
Validation loss decreased (0.233857 --> 0.233599).  Saving model ...
Validation loss decreased (0.233599 --> 0.233350).  Saving model ...
Validation loss decreased (0.233350 --> 0.233127).  Saving model ...
Validation loss decreased (0.233127 --> 0.232761).  Saving model ...
Validation loss decreased (0.232761 --> 0.232409).  Saving model ...
Validation loss decreased (0.232409 --> 0.232026).  Saving model ...
Validation loss decreased (0.232026 --> 0.231624).  Saving model ...
Validation loss decreased (0.231624 --> 0.231227).  Saving model ...
Validation loss decreased (0.231227 --> 0.230758).  Saving model ...
Validation loss decreased (0.230758 --> 0.230260).  Saving model ...
Validation loss decreased (0.230260 --> 0.229794).  Saving model ...
Validation loss decreased (0.229794 --> 0.229282).  Saving model ...
Validation loss decreased (0.229282 --> 0.228890).  Saving model ...
Validation loss decreased (0.228890 --> 0.228497).  Saving model ...
Validation loss decreased (0.228497 --> 0.228071).  Saving model ...
Validation loss decreased (0.228071 --> 0.227617).  Saving model ...
Validation loss decreased (0.227617 --> 0.227327).  Saving model ...
Validation loss decreased (0.227327 --> 0.227046).  Saving model ...
Validation loss decreased (0.227046 --> 0.226762).  Saving model ...
Validation loss decreased (0.226762 --> 0.226427).  Saving model ...
Validation loss decreased (0.226427 --> 0.226043).  Saving model ...
Validation loss decreased (0.226043 --> 0.225595).  Saving model ...
Validation loss decreased (0.225595 --> 0.225290).  Saving model ...
Validation loss decreased (0.225290 --> 0.225079).  Saving model ...
Validation loss decreased (0.225079 --> 0.224987).  Saving model ...
Validation loss decreased (0.224987 --> 0.224852).  Saving model ...
Validation loss decreased (0.224852 --> 0.224609).  Saving model ...
Validation loss decreased (0.224609 --> 0.224390).  Saving model ...
Validation loss decreased (0.224390 --> 0.224140).  Saving model ...
Validation loss decreased (0.224140 --> 0.223915).  Saving model ...
Validation loss decreased (0.223915 --> 0.223636).  Saving model ...
Validation loss decreased (0.223636 --> 0.223379).  Saving model ...
Validation loss decreased (0.223379 --> 0.223076).  Saving model ...
Validation loss decreased (0.223076 --> 0.222799).  Saving model ...
Validation loss decreased (0.222799 --> 0.222481).  Saving model ...
Validation loss decreased (0.222481 --> 0.222092).  Saving model ...
Validation loss decreased (0.222092 --> 0.221653).  Saving model ...
Validation loss decreased (0.221653 --> 0.221134).  Saving model ...
Validation loss decreased (0.221134 --> 0.220566).  Saving model ...
Validation loss decreased (0.220566 --> 0.219858).  Saving model ...
Validation loss decreased (0.219858 --> 0.219266).  Saving model ...
Validation loss decreased (0.219266 --> 0.218657).  Saving model ...
Validation loss decreased (0.218657 --> 0.218076).  Saving model ...
Validation loss decreased (0.218076 --> 0.217484).  Saving model ...
Validation loss decreased (0.217484 --> 0.216838).  Saving model ...
Validation loss decreased (0.216838 --> 0.216187).  Saving model ...
Validation loss decreased (0.216187 --> 0.215573).  Saving model ...
Validation loss decreased (0.215573 --> 0.214972).  Saving model ...
Validation loss decreased (0.214972 --> 0.214363).  Saving model ...
Validation loss decreased (0.214363 --> 0.213742).  Saving model ...
Validation loss decreased (0.213742 --> 0.213082).  Saving model ...
Validation loss decreased (0.213082 --> 0.212375).  Saving model ...
Validation loss decreased (0.212375 --> 0.211668).  Saving model ...
Validation loss decreased (0.211668 --> 0.211003).  Saving model ...
Validation loss decreased (0.211003 --> 0.210358).  Saving model ...
Validation loss decreased (0.210358 --> 0.209740).  Saving model ...
Validation loss decreased (0.209740 --> 0.209062).  Saving model ...
Validation loss decreased (0.209062 --> 0.208414).  Saving model ...
Validation loss decreased (0.208414 --> 0.207734).  Saving model ...
Validation loss decreased (0.207734 --> 0.207138).  Saving model ...
Validation loss decreased (0.207138 --> 0.206489).  Saving model ...
Validation loss decreased (0.206489 --> 0.205819).  Saving model ...
Validation loss decreased (0.205819 --> 0.205187).  Saving model ...
Validation loss decreased (0.205187 --> 0.204512).  Saving model ...
Validation loss decreased (0.204512 --> 0.204045).  Saving model ...
Validation loss decreased (0.204045 --> 0.203574).  Saving model ...
Validation loss decreased (0.203574 --> 0.203092).  Saving model ...
Validation loss decreased (0.203092 --> 0.202559).  Saving model ...
Validation loss decreased (0.202559 --> 0.201986).  Saving model ...
epoch 401, loss 0.3723, train acc 95.50%, f1 0.9534, precision 0.9388, recall 0.9684, auc 0.9556
Validation loss decreased (0.201986 --> 0.201576).  Saving model ...
Validation loss decreased (0.201576 --> 0.201163).  Saving model ...
Validation loss decreased (0.201163 --> 0.200797).  Saving model ...
Validation loss decreased (0.200797 --> 0.200567).  Saving model ...
Validation loss decreased (0.200567 --> 0.200343).  Saving model ...
Validation loss decreased (0.200343 --> 0.200013).  Saving model ...
Validation loss decreased (0.200013 --> 0.199631).  Saving model ...
Validation loss decreased (0.199631 --> 0.199307).  Saving model ...
Validation loss decreased (0.199307 --> 0.199060).  Saving model ...
Validation loss decreased (0.199060 --> 0.198930).  Saving model ...
Validation loss decreased (0.198930 --> 0.198816).  Saving model ...
Validation loss decreased (0.198816 --> 0.198659).  Saving model ...
Validation loss decreased (0.198659 --> 0.198451).  Saving model ...
Validation loss decreased (0.198451 --> 0.198176).  Saving model ...
Validation loss decreased (0.198176 --> 0.197854).  Saving model ...
Validation loss decreased (0.197854 --> 0.197605).  Saving model ...
Validation loss decreased (0.197605 --> 0.197294).  Saving model ...
Validation loss decreased (0.197294 --> 0.196974).  Saving model ...
Validation loss decreased (0.196974 --> 0.196616).  Saving model ...
Validation loss decreased (0.196616 --> 0.196292).  Saving model ...
Validation loss decreased (0.196292 --> 0.195957).  Saving model ...
Validation loss decreased (0.195957 --> 0.195745).  Saving model ...
Validation loss decreased (0.195745 --> 0.195422).  Saving model ...
Validation loss decreased (0.195422 --> 0.195084).  Saving model ...
Validation loss decreased (0.195084 --> 0.194726).  Saving model ...
Validation loss decreased (0.194726 --> 0.194344).  Saving model ...
Validation loss decreased (0.194344 --> 0.194006).  Saving model ...
Validation loss decreased (0.194006 --> 0.193628).  Saving model ...
Validation loss decreased (0.193628 --> 0.193321).  Saving model ...
Validation loss decreased (0.193321 --> 0.192993).  Saving model ...
Validation loss decreased (0.192993 --> 0.192787).  Saving model ...
Validation loss decreased (0.192787 --> 0.192624).  Saving model ...
Validation loss decreased (0.192624 --> 0.192408).  Saving model ...
Validation loss decreased (0.192408 --> 0.192216).  Saving model ...
Validation loss decreased (0.192216 --> 0.192057).  Saving model ...
Validation loss decreased (0.192057 --> 0.191834).  Saving model ...
Validation loss decreased (0.191834 --> 0.191630).  Saving model ...
Validation loss decreased (0.191630 --> 0.191570).  Saving model ...
Validation loss decreased (0.191570 --> 0.191420).  Saving model ...
Validation loss decreased (0.191420 --> 0.191196).  Saving model ...
Validation loss decreased (0.191196 --> 0.191038).  Saving model ...
Validation loss decreased (0.191038 --> 0.190828).  Saving model ...
Validation loss decreased (0.190828 --> 0.190556).  Saving model ...
Validation loss decreased (0.190556 --> 0.190331).  Saving model ...
Validation loss decreased (0.190331 --> 0.190107).  Saving model ...
Validation loss decreased (0.190107 --> 0.189770).  Saving model ...
Validation loss decreased (0.189770 --> 0.189515).  Saving model ...
Validation loss decreased (0.189515 --> 0.189187).  Saving model ...
Validation loss decreased (0.189187 --> 0.188905).  Saving model ...
Validation loss decreased (0.188905 --> 0.188602).  Saving model ...
Validation loss decreased (0.188602 --> 0.188286).  Saving model ...
Validation loss decreased (0.188286 --> 0.187975).  Saving model ...
Validation loss decreased (0.187975 --> 0.187683).  Saving model ...
Validation loss decreased (0.187683 --> 0.187460).  Saving model ...
Validation loss decreased (0.187460 --> 0.187207).  Saving model ...
Validation loss decreased (0.187207 --> 0.186894).  Saving model ...
Validation loss decreased (0.186894 --> 0.186589).  Saving model ...
Validation loss decreased (0.186589 --> 0.186355).  Saving model ...
Validation loss decreased (0.186355 --> 0.186167).  Saving model ...
Validation loss decreased (0.186167 --> 0.185900).  Saving model ...
Validation loss decreased (0.185900 --> 0.185732).  Saving model ...
Validation loss decreased (0.185732 --> 0.185515).  Saving model ...
Validation loss decreased (0.185515 --> 0.185295).  Saving model ...
Validation loss decreased (0.185295 --> 0.185140).  Saving model ...
Validation loss decreased (0.185140 --> 0.184912).  Saving model ...
Validation loss decreased (0.184912 --> 0.184668).  Saving model ...
Validation loss decreased (0.184668 --> 0.184394).  Saving model ...
Validation loss decreased (0.184394 --> 0.184077).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.184077 --> 0.183749).  Saving model ...
Validation loss decreased (0.183749 --> 0.183425).  Saving model ...
Validation loss decreased (0.183425 --> 0.183146).  Saving model ...
Validation loss decreased (0.183146 --> 0.182907).  Saving model ...
Validation loss decreased (0.182907 --> 0.182766).  Saving model ...
Validation loss decreased (0.182766 --> 0.182560).  Saving model ...
Validation loss decreased (0.182560 --> 0.182346).  Saving model ...
Validation loss decreased (0.182346 --> 0.181996).  Saving model ...
Validation loss decreased (0.181996 --> 0.181593).  Saving model ...
Validation loss decreased (0.181593 --> 0.181221).  Saving model ...
Validation loss decreased (0.181221 --> 0.180841).  Saving model ...
Validation loss decreased (0.180841 --> 0.180467).  Saving model ...
Validation loss decreased (0.180467 --> 0.180156).  Saving model ...
Validation loss decreased (0.180156 --> 0.179813).  Saving model ...
Validation loss decreased (0.179813 --> 0.179513).  Saving model ...
Validation loss decreased (0.179513 --> 0.179267).  Saving model ...
Validation loss decreased (0.179267 --> 0.178981).  Saving model ...
Validation loss decreased (0.178981 --> 0.178730).  Saving model ...
Validation loss decreased (0.178730 --> 0.178432).  Saving model ...
Validation loss decreased (0.178432 --> 0.178099).  Saving model ...
Validation loss decreased (0.178099 --> 0.177868).  Saving model ...
Validation loss decreased (0.177868 --> 0.177672).  Saving model ...
Validation loss decreased (0.177672 --> 0.177434).  Saving model ...
Validation loss decreased (0.177434 --> 0.177155).  Saving model ...
Validation loss decreased (0.177155 --> 0.176842).  Saving model ...
Validation loss decreased (0.176842 --> 0.176645).  Saving model ...
Validation loss decreased (0.176645 --> 0.176401).  Saving model ...
Validation loss decreased (0.176401 --> 0.176259).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.176259 --> 0.176237).  Saving model ...
Validation loss decreased (0.176237 --> 0.176106).  Saving model ...
Validation loss decreased (0.176106 --> 0.176012).  Saving model ...
epoch 501, loss 0.3832, train acc 95.00%, f1 0.9490, precision 0.9208, recall 0.9789, auc 0.9514
Validation loss decreased (0.176012 --> 0.175899).  Saving model ...
Validation loss decreased (0.175899 --> 0.175786).  Saving model ...
Validation loss decreased (0.175786 --> 0.175701).  Saving model ...
Validation loss decreased (0.175701 --> 0.175640).  Saving model ...
Validation loss decreased (0.175640 --> 0.175506).  Saving model ...
Validation loss decreased (0.175506 --> 0.175295).  Saving model ...
Validation loss decreased (0.175295 --> 0.175015).  Saving model ...
Validation loss decreased (0.175015 --> 0.174758).  Saving model ...
Validation loss decreased (0.174758 --> 0.174493).  Saving model ...
Validation loss decreased (0.174493 --> 0.174334).  Saving model ...
Validation loss decreased (0.174334 --> 0.174269).  Saving model ...
Validation loss decreased (0.174269 --> 0.174241).  Saving model ...
Validation loss decreased (0.174241 --> 0.174174).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 533, loss 0.3054, train acc 95.00%, f1 0.9490, precision 0.9208, recall 0.9789, auc 0.9514



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_notMirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_4
./test_pima/result_MLP_minus_notMirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6183962264150944

the Fscore is 0.5696969696969697

the precision is 0.41964285714285715

the recall is 0.8867924528301887

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_4
----------------------



epoch 1, loss 0.6936, train acc 49.90%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6136, train acc 78.64%, f1 0.7954, precision 0.7647, recall 0.8287, auc 0.7863
epoch 201, loss 0.5106, train acc 81.63%, f1 0.8176, precision 0.8134, recall 0.8218, auc 0.8163
epoch 301, loss 0.4055, train acc 83.43%, f1 0.8342, precision 0.8364, recall 0.8320, auc 0.8343
epoch 401, loss 0.2708, train acc 84.34%, f1 0.8437, precision 0.8440, recall 0.8433, auc 0.8434
epoch 501, loss 0.3892, train acc 84.77%, f1 0.8476, precision 0.8497, recall 0.8455, auc 0.8477
epoch 601, loss 0.3079, train acc 84.89%, f1 0.8487, precision 0.8512, recall 0.8462, auc 0.8489
epoch 701, loss 0.2943, train acc 84.99%, f1 0.8498, precision 0.8522, recall 0.8474, auc 0.8499
epoch 801, loss 0.4605, train acc 84.99%, f1 0.8494, precision 0.8540, recall 0.8450, auc 0.8499
epoch 901, loss 0.3358, train acc 85.08%, f1 0.8503, precision 0.8547, recall 0.8460, auc 0.8508
epoch 1001, loss 0.4448, train acc 85.11%, f1 0.8510, precision 0.8530, recall 0.8490, auc 0.8511
epoch 1101, loss 0.3532, train acc 85.04%, f1 0.8500, precision 0.8541, recall 0.8459, auc 0.8504
epoch 1201, loss 0.3698, train acc 85.09%, f1 0.8506, precision 0.8539, recall 0.8473, auc 0.8509
epoch 1301, loss 0.3485, train acc 85.09%, f1 0.8511, precision 0.8515, recall 0.8508, auc 0.8509
epoch 1401, loss 0.3557, train acc 85.07%, f1 0.8508, precision 0.8517, recall 0.8498, auc 0.8507
epoch 1501, loss 0.2665, train acc 85.05%, f1 0.8504, precision 0.8526, recall 0.8482, auc 0.8505
epoch 1601, loss 0.2835, train acc 85.10%, f1 0.8511, precision 0.8526, recall 0.8495, auc 0.8510
epoch 1701, loss 0.2701, train acc 85.09%, f1 0.8507, precision 0.8534, recall 0.8480, auc 0.8509
epoch 1801, loss 0.2239, train acc 85.09%, f1 0.8511, precision 0.8517, recall 0.8505, auc 0.8509
epoch 1901, loss 0.2733, train acc 85.10%, f1 0.8511, precision 0.8520, recall 0.8502, auc 0.8510
epoch 2001, loss 0.3266, train acc 85.09%, f1 0.8510, precision 0.8522, recall 0.8499, auc 0.8509
epoch 2101, loss 0.3424, train acc 85.09%, f1 0.8510, precision 0.8523, recall 0.8497, auc 0.8509
epoch 2201, loss 0.4013, train acc 85.12%, f1 0.8513, precision 0.8523, recall 0.8503, auc 0.8512
epoch 2301, loss 0.3358, train acc 85.08%, f1 0.8507, precision 0.8530, recall 0.8484, auc 0.8508
epoch 2401, loss 0.2630, train acc 85.07%, f1 0.8509, precision 0.8514, recall 0.8505, auc 0.8507
epoch 2501, loss 0.2992, train acc 85.10%, f1 0.8513, precision 0.8513, recall 0.8513, auc 0.8510
epoch 2601, loss 0.4174, train acc 85.11%, f1 0.8511, precision 0.8528, recall 0.8493, auc 0.8511
epoch 2701, loss 0.3285, train acc 85.09%, f1 0.8509, precision 0.8522, recall 0.8496, auc 0.8509
epoch 2801, loss 0.3804, train acc 85.06%, f1 0.8507, precision 0.8518, recall 0.8497, auc 0.8506
epoch 2901, loss 0.2730, train acc 85.07%, f1 0.8505, precision 0.8530, recall 0.8481, auc 0.8507
epoch 3001, loss 0.3689, train acc 85.08%, f1 0.8508, precision 0.8527, recall 0.8489, auc 0.8509
epoch 3101, loss 0.4019, train acc 85.07%, f1 0.8505, precision 0.8534, recall 0.8477, auc 0.8507
epoch 3201, loss 0.3155, train acc 85.09%, f1 0.8510, precision 0.8520, recall 0.8500, auc 0.8509
epoch 3301, loss 0.2514, train acc 85.06%, f1 0.8505, precision 0.8530, recall 0.8479, auc 0.8506
epoch 3401, loss 0.2560, train acc 85.05%, f1 0.8505, precision 0.8520, recall 0.8491, auc 0.8505
epoch 3501, loss 0.2361, train acc 85.04%, f1 0.8508, precision 0.8504, recall 0.8512, auc 0.8504
epoch 3601, loss 0.3497, train acc 85.06%, f1 0.8509, precision 0.8512, recall 0.8505, auc 0.8506
epoch 3701, loss 0.3582, train acc 84.98%, f1 0.8499, precision 0.8514, recall 0.8483, auc 0.8499
epoch 3801, loss 0.6000, train acc 85.06%, f1 0.8505, precision 0.8524, recall 0.8487, auc 0.8506
epoch 3901, loss 0.3842, train acc 85.06%, f1 0.8506, precision 0.8521, recall 0.8492, auc 0.8506
epoch 4001, loss 0.3405, train acc 85.08%, f1 0.8510, precision 0.8515, recall 0.8504, auc 0.8508
epoch 4101, loss 0.3225, train acc 85.07%, f1 0.8507, precision 0.8521, recall 0.8494, auc 0.8507
epoch 4201, loss 0.2773, train acc 85.07%, f1 0.8509, precision 0.8512, recall 0.8506, auc 0.8507
epoch 4301, loss 0.3801, train acc 85.06%, f1 0.8505, precision 0.8525, recall 0.8486, auc 0.8506
epoch 4401, loss 0.2536, train acc 85.08%, f1 0.8507, precision 0.8528, recall 0.8487, auc 0.8508
epoch 4501, loss 0.3531, train acc 85.05%, f1 0.8507, precision 0.8514, recall 0.8500, auc 0.8505
epoch 4601, loss 0.3697, train acc 85.06%, f1 0.8507, precision 0.8518, recall 0.8495, auc 0.8506
epoch 4701, loss 0.3160, train acc 85.06%, f1 0.8508, precision 0.8515, recall 0.8501, auc 0.8506
epoch 4801, loss 0.3956, train acc 85.09%, f1 0.8507, precision 0.8532, recall 0.8483, auc 0.8509
epoch 4901, loss 0.3782, train acc 85.06%, f1 0.8504, precision 0.8531, recall 0.8477, auc 0.8506
epoch 5001, loss 0.4403, train acc 85.05%, f1 0.8507, precision 0.8509, recall 0.8505, auc 0.8505
epoch 5101, loss 0.3666, train acc 85.11%, f1 0.8513, precision 0.8515, recall 0.8511, auc 0.8511
epoch 5201, loss 0.4809, train acc 85.09%, f1 0.8510, precision 0.8524, recall 0.8495, auc 0.8509
epoch 5301, loss 0.3172, train acc 85.06%, f1 0.8506, precision 0.8522, recall 0.8491, auc 0.8506
epoch 5401, loss 0.2541, train acc 85.08%, f1 0.8508, precision 0.8521, recall 0.8495, auc 0.8508
epoch 5501, loss 0.3654, train acc 85.07%, f1 0.8512, precision 0.8501, recall 0.8523, auc 0.8507
epoch 5601, loss 0.2287, train acc 85.10%, f1 0.8516, precision 0.8498, recall 0.8535, auc 0.8510
epoch 5701, loss 0.3444, train acc 85.09%, f1 0.8511, precision 0.8517, recall 0.8505, auc 0.8509
epoch 5801, loss 0.2907, train acc 85.12%, f1 0.8510, precision 0.8539, recall 0.8481, auc 0.8512
epoch 5901, loss 0.3424, train acc 85.09%, f1 0.8510, precision 0.8522, recall 0.8498, auc 0.8509
epoch 6001, loss 0.3416, train acc 85.12%, f1 0.8513, precision 0.8524, recall 0.8502, auc 0.8512
epoch 6101, loss 0.3776, train acc 85.13%, f1 0.8516, precision 0.8515, recall 0.8517, auc 0.8513
epoch 6201, loss 0.3414, train acc 85.11%, f1 0.8516, precision 0.8502, recall 0.8531, auc 0.8511
epoch 6301, loss 0.2457, train acc 85.07%, f1 0.8505, precision 0.8534, recall 0.8476, auc 0.8507
epoch 6401, loss 0.2915, train acc 85.11%, f1 0.8510, precision 0.8537, recall 0.8482, auc 0.8511
epoch 6501, loss 0.2756, train acc 85.12%, f1 0.8515, precision 0.8510, recall 0.8521, auc 0.8511
epoch 6601, loss 0.3740, train acc 85.07%, f1 0.8508, precision 0.8518, recall 0.8499, auc 0.8507
epoch 6701, loss 0.4462, train acc 85.12%, f1 0.8511, precision 0.8532, recall 0.8489, auc 0.8512
epoch 6801, loss 0.3581, train acc 85.10%, f1 0.8513, precision 0.8511, recall 0.8515, auc 0.8510
epoch 6901, loss 0.2853, train acc 85.15%, f1 0.8516, precision 0.8522, recall 0.8510, auc 0.8515
epoch 7001, loss 0.3311, train acc 85.12%, f1 0.8515, precision 0.8511, recall 0.8520, auc 0.8511
epoch 7101, loss 0.2460, train acc 85.16%, f1 0.8519, precision 0.8516, recall 0.8523, auc 0.8516
epoch 7201, loss 0.4116, train acc 85.19%, f1 0.8521, precision 0.8524, recall 0.8518, auc 0.8519
epoch 7301, loss 0.3810, train acc 85.15%, f1 0.8515, precision 0.8533, recall 0.8497, auc 0.8516
epoch 7401, loss 0.3067, train acc 85.19%, f1 0.8522, precision 0.8521, recall 0.8524, auc 0.8519
epoch 7501, loss 0.2535, train acc 85.14%, f1 0.8511, precision 0.8545, recall 0.8477, auc 0.8514
epoch 7601, loss 0.4754, train acc 85.17%, f1 0.8521, precision 0.8517, recall 0.8525, auc 0.8517
epoch 7701, loss 0.3190, train acc 85.17%, f1 0.8521, precision 0.8514, recall 0.8528, auc 0.8517
epoch 7801, loss 0.5159, train acc 85.21%, f1 0.8519, precision 0.8550, recall 0.8488, auc 0.8521
epoch 7901, loss 0.4805, train acc 85.21%, f1 0.8521, precision 0.8541, recall 0.8501, auc 0.8521
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_notMirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_4
./test_pima/result_MLP_minus_notMirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6328301886792453

the Fscore is 0.5818181818181818

the precision is 0.42857142857142855

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_4
----------------------



epoch 1, loss 0.6932, train acc 49.92%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5983, train acc 78.47%, f1 0.7863, precision 0.7819, recall 0.7907, auc 0.7847
epoch 201, loss 0.4883, train acc 81.34%, f1 0.8129, precision 0.8165, recall 0.8093, auc 0.8134
epoch 301, loss 0.4407, train acc 83.44%, f1 0.8340, precision 0.8375, recall 0.8305, auc 0.8344
epoch 401, loss 0.4092, train acc 84.29%, f1 0.8432, precision 0.8427, recall 0.8437, auc 0.8429
epoch 501, loss 0.2944, train acc 84.75%, f1 0.8474, precision 0.8493, recall 0.8456, auc 0.8475
epoch 601, loss 0.3556, train acc 84.86%, f1 0.8482, precision 0.8517, recall 0.8447, auc 0.8486
epoch 701, loss 0.2529, train acc 84.90%, f1 0.8490, precision 0.8503, recall 0.8477, auc 0.8490
epoch 801, loss 0.3668, train acc 85.00%, f1 0.8496, precision 0.8529, recall 0.8464, auc 0.8500
epoch 901, loss 0.3525, train acc 85.06%, f1 0.8502, precision 0.8541, recall 0.8463, auc 0.8506
epoch 1001, loss 0.2705, train acc 85.07%, f1 0.8506, precision 0.8525, recall 0.8486, auc 0.8507
epoch 1101, loss 0.3303, train acc 85.06%, f1 0.8505, precision 0.8525, recall 0.8485, auc 0.8506
epoch 1201, loss 0.3215, train acc 85.10%, f1 0.8508, precision 0.8530, recall 0.8487, auc 0.8510
epoch 1301, loss 0.2969, train acc 85.11%, f1 0.8509, precision 0.8533, recall 0.8485, auc 0.8511
epoch 1401, loss 0.3721, train acc 85.06%, f1 0.8507, precision 0.8517, recall 0.8497, auc 0.8506
epoch 1501, loss 0.3454, train acc 85.05%, f1 0.8502, precision 0.8532, recall 0.8472, auc 0.8505
epoch 1601, loss 0.4104, train acc 85.07%, f1 0.8506, precision 0.8527, recall 0.8485, auc 0.8507
epoch 1701, loss 0.2811, train acc 85.06%, f1 0.8502, precision 0.8539, recall 0.8464, auc 0.8506
epoch 1801, loss 0.4305, train acc 85.05%, f1 0.8506, precision 0.8516, recall 0.8495, auc 0.8505
epoch 1901, loss 0.2986, train acc 85.07%, f1 0.8510, precision 0.8511, recall 0.8509, auc 0.8507
epoch 2001, loss 0.2678, train acc 85.07%, f1 0.8506, precision 0.8525, recall 0.8487, auc 0.8507
epoch 2101, loss 0.2725, train acc 85.06%, f1 0.8507, precision 0.8515, recall 0.8499, auc 0.8506
epoch 2201, loss 0.2577, train acc 85.10%, f1 0.8510, precision 0.8524, recall 0.8497, auc 0.8510
epoch 2301, loss 0.3149, train acc 85.07%, f1 0.8507, precision 0.8521, recall 0.8492, auc 0.8507
epoch 2401, loss 0.3623, train acc 85.08%, f1 0.8504, precision 0.8542, recall 0.8466, auc 0.8508
epoch 2501, loss 0.3093, train acc 85.13%, f1 0.8512, precision 0.8532, recall 0.8492, auc 0.8513
epoch 2601, loss 0.3530, train acc 85.09%, f1 0.8508, precision 0.8527, recall 0.8490, auc 0.8509
epoch 2701, loss 0.4021, train acc 85.08%, f1 0.8504, precision 0.8541, recall 0.8468, auc 0.8508
epoch 2801, loss 0.4133, train acc 85.11%, f1 0.8509, precision 0.8538, recall 0.8479, auc 0.8511
epoch 2901, loss 0.2355, train acc 85.08%, f1 0.8505, precision 0.8539, recall 0.8471, auc 0.8508
epoch 3001, loss 0.3399, train acc 85.10%, f1 0.8511, precision 0.8518, recall 0.8505, auc 0.8510
epoch 3101, loss 0.2878, train acc 85.11%, f1 0.8509, precision 0.8535, recall 0.8484, auc 0.8511
epoch 3201, loss 0.2894, train acc 85.07%, f1 0.8504, precision 0.8537, recall 0.8471, auc 0.8507
epoch 3301, loss 0.2827, train acc 85.08%, f1 0.8506, precision 0.8528, recall 0.8485, auc 0.8508
epoch 3401, loss 0.3150, train acc 85.08%, f1 0.8507, precision 0.8527, recall 0.8486, auc 0.8508
epoch 3501, loss 0.4441, train acc 85.11%, f1 0.8508, precision 0.8542, recall 0.8473, auc 0.8511
epoch 3601, loss 0.3399, train acc 85.09%, f1 0.8508, precision 0.8529, recall 0.8487, auc 0.8509
epoch 3701, loss 0.4024, train acc 85.04%, f1 0.8509, precision 0.8495, recall 0.8523, auc 0.8504
epoch 3801, loss 0.3751, train acc 85.02%, f1 0.8501, precision 0.8523, recall 0.8478, auc 0.8502
epoch 3901, loss 0.2504, train acc 85.08%, f1 0.8508, precision 0.8527, recall 0.8489, auc 0.8509
epoch 4001, loss 0.3489, train acc 85.08%, f1 0.8508, precision 0.8519, recall 0.8497, auc 0.8508
epoch 4101, loss 0.3904, train acc 85.08%, f1 0.8510, precision 0.8514, recall 0.8506, auc 0.8508
epoch 4201, loss 0.4110, train acc 85.06%, f1 0.8501, precision 0.8543, recall 0.8460, auc 0.8506
epoch 4301, loss 0.3468, train acc 84.99%, f1 0.8493, precision 0.8542, recall 0.8445, auc 0.8499
epoch 4401, loss 0.3712, train acc 85.03%, f1 0.8502, precision 0.8523, recall 0.8482, auc 0.8504
epoch 4501, loss 0.4320, train acc 85.04%, f1 0.8499, precision 0.8544, recall 0.8455, auc 0.8504
epoch 4601, loss 0.4041, train acc 85.07%, f1 0.8502, precision 0.8546, recall 0.8459, auc 0.8507
epoch 4701, loss 0.2096, train acc 85.09%, f1 0.8508, precision 0.8530, recall 0.8485, auc 0.8509
epoch 4801, loss 0.4461, train acc 85.05%, f1 0.8499, precision 0.8552, recall 0.8446, auc 0.8506
epoch 4901, loss 0.3055, train acc 85.06%, f1 0.8505, precision 0.8529, recall 0.8481, auc 0.8506
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_notMirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_4
./test_pima/result_MLP_minus_notMirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6328301886792453

the Fscore is 0.5818181818181818

the precision is 0.42857142857142855

the recall is 0.9056603773584906

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_4
----------------------



epoch 1, loss 0.6928, train acc 50.24%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6109, train acc 78.16%, f1 0.7900, precision 0.7572, recall 0.8258, auc 0.7818
epoch 201, loss 0.5467, train acc 81.13%, f1 0.8103, precision 0.8106, recall 0.8100, auc 0.8113
epoch 301, loss 0.3954, train acc 83.46%, f1 0.8335, precision 0.8349, recall 0.8321, auc 0.8346
epoch 401, loss 0.2796, train acc 84.44%, f1 0.8432, precision 0.8456, recall 0.8408, auc 0.8444
epoch 501, loss 0.3266, train acc 84.84%, f1 0.8468, precision 0.8518, recall 0.8418, auc 0.8484
epoch 601, loss 0.2904, train acc 84.93%, f1 0.8483, precision 0.8497, recall 0.8470, auc 0.8493
epoch 701, loss 0.3116, train acc 85.03%, f1 0.8490, precision 0.8521, recall 0.8460, auc 0.8503
epoch 801, loss 0.2675, train acc 85.05%, f1 0.8495, precision 0.8512, recall 0.8478, auc 0.8505
epoch 901, loss 0.4080, train acc 85.08%, f1 0.8500, precision 0.8504, recall 0.8495, auc 0.8508
epoch 1001, loss 0.3706, train acc 85.11%, f1 0.8496, precision 0.8538, recall 0.8456, auc 0.8511
epoch 1101, loss 0.3192, train acc 85.10%, f1 0.8497, precision 0.8530, recall 0.8463, auc 0.8510
epoch 1201, loss 0.3894, train acc 85.12%, f1 0.8500, precision 0.8524, recall 0.8476, auc 0.8511
epoch 1301, loss 0.2215, train acc 85.07%, f1 0.8495, precision 0.8524, recall 0.8465, auc 0.8507
epoch 1401, loss 0.3513, train acc 85.06%, f1 0.8497, precision 0.8504, recall 0.8490, auc 0.8506
epoch 1501, loss 0.2594, train acc 85.08%, f1 0.8494, precision 0.8537, recall 0.8451, auc 0.8508
epoch 1601, loss 0.3611, train acc 85.08%, f1 0.8500, precision 0.8503, recall 0.8498, auc 0.8508
epoch 1701, loss 0.3624, train acc 85.05%, f1 0.8499, precision 0.8492, recall 0.8506, auc 0.8505
epoch 1801, loss 0.3481, train acc 85.11%, f1 0.8503, precision 0.8504, recall 0.8503, auc 0.8511
epoch 1901, loss 0.4254, train acc 85.07%, f1 0.8498, precision 0.8506, recall 0.8490, auc 0.8507
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_minus_notMirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_4
./test_pima/result_MLP_minus_notMirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6528301886792454

the Fscore is 0.5962732919254657

the precision is 0.4444444444444444

the recall is 0.9056603773584906

Done
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_4
----------------------



epoch 1, loss 0.6905, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.689134).  Saving model ...
Validation loss decreased (0.689134 --> 0.687818).  Saving model ...
Validation loss decreased (0.687818 --> 0.686521).  Saving model ...
Validation loss decreased (0.686521 --> 0.685242).  Saving model ...
Validation loss decreased (0.685242 --> 0.683982).  Saving model ...
Validation loss decreased (0.683982 --> 0.682741).  Saving model ...
Validation loss decreased (0.682741 --> 0.681520).  Saving model ...
Validation loss decreased (0.681520 --> 0.680317).  Saving model ...
Validation loss decreased (0.680317 --> 0.679133).  Saving model ...
Validation loss decreased (0.679133 --> 0.677968).  Saving model ...
Validation loss decreased (0.677968 --> 0.676822).  Saving model ...
Validation loss decreased (0.676822 --> 0.675694).  Saving model ...
Validation loss decreased (0.675694 --> 0.674584).  Saving model ...
Validation loss decreased (0.674584 --> 0.673493).  Saving model ...
Validation loss decreased (0.673493 --> 0.672419).  Saving model ...
Validation loss decreased (0.672419 --> 0.671363).  Saving model ...
Validation loss decreased (0.671363 --> 0.670325).  Saving model ...
Validation loss decreased (0.670325 --> 0.669304).  Saving model ...
Validation loss decreased (0.669304 --> 0.668300).  Saving model ...
Validation loss decreased (0.668300 --> 0.667313).  Saving model ...
Validation loss decreased (0.667313 --> 0.666343).  Saving model ...
Validation loss decreased (0.666343 --> 0.665389).  Saving model ...
Validation loss decreased (0.665389 --> 0.664450).  Saving model ...
Validation loss decreased (0.664450 --> 0.663528).  Saving model ...
Validation loss decreased (0.663528 --> 0.662620).  Saving model ...
Validation loss decreased (0.662620 --> 0.661728).  Saving model ...
Validation loss decreased (0.661728 --> 0.660851).  Saving model ...
Validation loss decreased (0.660851 --> 0.659989).  Saving model ...
Validation loss decreased (0.659989 --> 0.659141).  Saving model ...
Validation loss decreased (0.659141 --> 0.658307).  Saving model ...
Validation loss decreased (0.658307 --> 0.657487).  Saving model ...
Validation loss decreased (0.657487 --> 0.656681).  Saving model ...
Validation loss decreased (0.656681 --> 0.655888).  Saving model ...
Validation loss decreased (0.655888 --> 0.655108).  Saving model ...
Validation loss decreased (0.655108 --> 0.654342).  Saving model ...
Validation loss decreased (0.654342 --> 0.653588).  Saving model ...
Validation loss decreased (0.653588 --> 0.652846).  Saving model ...
Validation loss decreased (0.652846 --> 0.652117).  Saving model ...
Validation loss decreased (0.652117 --> 0.651400).  Saving model ...
Validation loss decreased (0.651400 --> 0.650695).  Saving model ...
Validation loss decreased (0.650695 --> 0.650001).  Saving model ...
Validation loss decreased (0.650001 --> 0.649319).  Saving model ...
Validation loss decreased (0.649319 --> 0.648647).  Saving model ...
Validation loss decreased (0.648647 --> 0.647987).  Saving model ...
Validation loss decreased (0.647987 --> 0.647337).  Saving model ...
Validation loss decreased (0.647337 --> 0.646698).  Saving model ...
Validation loss decreased (0.646698 --> 0.646070).  Saving model ...
Validation loss decreased (0.646070 --> 0.645451).  Saving model ...
Validation loss decreased (0.645451 --> 0.644842).  Saving model ...
Validation loss decreased (0.644842 --> 0.644243).  Saving model ...
Validation loss decreased (0.644243 --> 0.643654).  Saving model ...
Validation loss decreased (0.643654 --> 0.643073).  Saving model ...
Validation loss decreased (0.643073 --> 0.642502).  Saving model ...
Validation loss decreased (0.642502 --> 0.641940).  Saving model ...
Validation loss decreased (0.641940 --> 0.641386).  Saving model ...
Validation loss decreased (0.641386 --> 0.640841).  Saving model ...
Validation loss decreased (0.640841 --> 0.640304).  Saving model ...
Validation loss decreased (0.640304 --> 0.639776).  Saving model ...
Validation loss decreased (0.639776 --> 0.639255).  Saving model ...
Validation loss decreased (0.639255 --> 0.638742).  Saving model ...
Validation loss decreased (0.638742 --> 0.638237).  Saving model ...
Validation loss decreased (0.638237 --> 0.637739).  Saving model ...
Validation loss decreased (0.637739 --> 0.637248).  Saving model ...
Validation loss decreased (0.637248 --> 0.636765).  Saving model ...
Validation loss decreased (0.636765 --> 0.636288).  Saving model ...
Validation loss decreased (0.636288 --> 0.635818).  Saving model ...
Validation loss decreased (0.635818 --> 0.635355).  Saving model ...
Validation loss decreased (0.635355 --> 0.634898).  Saving model ...
Validation loss decreased (0.634898 --> 0.634447).  Saving model ...
Validation loss decreased (0.634447 --> 0.634003).  Saving model ...
Validation loss decreased (0.634003 --> 0.633564).  Saving model ...
Validation loss decreased (0.633564 --> 0.633131).  Saving model ...
Validation loss decreased (0.633131 --> 0.632704).  Saving model ...
Validation loss decreased (0.632704 --> 0.632282).  Saving model ...
Validation loss decreased (0.632282 --> 0.631865).  Saving model ...
Validation loss decreased (0.631865 --> 0.631454).  Saving model ...
Validation loss decreased (0.631454 --> 0.631047).  Saving model ...
Validation loss decreased (0.631047 --> 0.630646).  Saving model ...
Validation loss decreased (0.630646 --> 0.630249).  Saving model ...
Validation loss decreased (0.630249 --> 0.629856).  Saving model ...
Validation loss decreased (0.629856 --> 0.629468).  Saving model ...
Validation loss decreased (0.629468 --> 0.629085).  Saving model ...
Validation loss decreased (0.629085 --> 0.628705).  Saving model ...
Validation loss decreased (0.628705 --> 0.628330).  Saving model ...
Validation loss decreased (0.628330 --> 0.627959).  Saving model ...
Validation loss decreased (0.627959 --> 0.627591).  Saving model ...
Validation loss decreased (0.627591 --> 0.627227).  Saving model ...
Validation loss decreased (0.627227 --> 0.626867).  Saving model ...
Validation loss decreased (0.626867 --> 0.626509).  Saving model ...
Validation loss decreased (0.626509 --> 0.626156).  Saving model ...
Validation loss decreased (0.626156 --> 0.625805).  Saving model ...
Validation loss decreased (0.625805 --> 0.625458).  Saving model ...
Validation loss decreased (0.625458 --> 0.625113).  Saving model ...
Validation loss decreased (0.625113 --> 0.624772).  Saving model ...
Validation loss decreased (0.624772 --> 0.624433).  Saving model ...
Validation loss decreased (0.624433 --> 0.624097).  Saving model ...
Validation loss decreased (0.624097 --> 0.623764).  Saving model ...
Validation loss decreased (0.623764 --> 0.623433).  Saving model ...
Validation loss decreased (0.623433 --> 0.623104).  Saving model ...
Validation loss decreased (0.623104 --> 0.622778).  Saving model ...
epoch 101, loss 0.6228, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.622778 --> 0.622454).  Saving model ...
Validation loss decreased (0.622454 --> 0.622132).  Saving model ...
Validation loss decreased (0.622132 --> 0.621812).  Saving model ...
Validation loss decreased (0.621812 --> 0.621494).  Saving model ...
Validation loss decreased (0.621494 --> 0.621179).  Saving model ...
Validation loss decreased (0.621179 --> 0.620865).  Saving model ...
Validation loss decreased (0.620865 --> 0.620552).  Saving model ...
Validation loss decreased (0.620552 --> 0.620242).  Saving model ...
Validation loss decreased (0.620242 --> 0.619933).  Saving model ...
Validation loss decreased (0.619933 --> 0.619625).  Saving model ...
Validation loss decreased (0.619625 --> 0.619319).  Saving model ...
Validation loss decreased (0.619319 --> 0.619015).  Saving model ...
Validation loss decreased (0.619015 --> 0.618712).  Saving model ...
Validation loss decreased (0.618712 --> 0.618410).  Saving model ...
Validation loss decreased (0.618410 --> 0.618110).  Saving model ...
Validation loss decreased (0.618110 --> 0.617811).  Saving model ...
Validation loss decreased (0.617811 --> 0.617513).  Saving model ...
Validation loss decreased (0.617513 --> 0.617216).  Saving model ...
Validation loss decreased (0.617216 --> 0.616920).  Saving model ...
Validation loss decreased (0.616920 --> 0.616626).  Saving model ...
Validation loss decreased (0.616626 --> 0.616332).  Saving model ...
Validation loss decreased (0.616332 --> 0.616039).  Saving model ...
Validation loss decreased (0.616039 --> 0.615748).  Saving model ...
Validation loss decreased (0.615748 --> 0.615457).  Saving model ...
Validation loss decreased (0.615457 --> 0.615167).  Saving model ...
Validation loss decreased (0.615167 --> 0.614878).  Saving model ...
Validation loss decreased (0.614878 --> 0.614589).  Saving model ...
Validation loss decreased (0.614589 --> 0.614301).  Saving model ...
Validation loss decreased (0.614301 --> 0.614014).  Saving model ...
Validation loss decreased (0.614014 --> 0.613728).  Saving model ...
Validation loss decreased (0.613728 --> 0.613443).  Saving model ...
Validation loss decreased (0.613443 --> 0.613158).  Saving model ...
Validation loss decreased (0.613158 --> 0.612873).  Saving model ...
Validation loss decreased (0.612873 --> 0.612590).  Saving model ...
Validation loss decreased (0.612590 --> 0.612306).  Saving model ...
Validation loss decreased (0.612306 --> 0.612024).  Saving model ...
Validation loss decreased (0.612024 --> 0.611742).  Saving model ...
Validation loss decreased (0.611742 --> 0.611460).  Saving model ...
Validation loss decreased (0.611460 --> 0.611179).  Saving model ...
Validation loss decreased (0.611179 --> 0.610898).  Saving model ...
Validation loss decreased (0.610898 --> 0.610618).  Saving model ...
Validation loss decreased (0.610618 --> 0.610338).  Saving model ...
Validation loss decreased (0.610338 --> 0.610059).  Saving model ...
Validation loss decreased (0.610059 --> 0.609779).  Saving model ...
Validation loss decreased (0.609779 --> 0.609501).  Saving model ...
Validation loss decreased (0.609501 --> 0.609222).  Saving model ...
Validation loss decreased (0.609222 --> 0.608944).  Saving model ...
Validation loss decreased (0.608944 --> 0.608667).  Saving model ...
Validation loss decreased (0.608667 --> 0.608389).  Saving model ...
Validation loss decreased (0.608389 --> 0.608112).  Saving model ...
Validation loss decreased (0.608112 --> 0.607835).  Saving model ...
Validation loss decreased (0.607835 --> 0.607559).  Saving model ...
Validation loss decreased (0.607559 --> 0.607282).  Saving model ...
Validation loss decreased (0.607282 --> 0.607006).  Saving model ...
Validation loss decreased (0.607006 --> 0.606730).  Saving model ...
Validation loss decreased (0.606730 --> 0.606455).  Saving model ...
Validation loss decreased (0.606455 --> 0.606179).  Saving model ...
Validation loss decreased (0.606179 --> 0.605904).  Saving model ...
Validation loss decreased (0.605904 --> 0.605629).  Saving model ...
Validation loss decreased (0.605629 --> 0.605354).  Saving model ...
Validation loss decreased (0.605354 --> 0.605079).  Saving model ...
Validation loss decreased (0.605079 --> 0.604805).  Saving model ...
Validation loss decreased (0.604805 --> 0.604531).  Saving model ...
Validation loss decreased (0.604531 --> 0.604256).  Saving model ...
Validation loss decreased (0.604256 --> 0.603982).  Saving model ...
Validation loss decreased (0.603982 --> 0.603709).  Saving model ...
Validation loss decreased (0.603709 --> 0.603435).  Saving model ...
Validation loss decreased (0.603435 --> 0.603161).  Saving model ...
Validation loss decreased (0.603161 --> 0.602888).  Saving model ...
Validation loss decreased (0.602888 --> 0.602614).  Saving model ...
Validation loss decreased (0.602614 --> 0.602341).  Saving model ...
Validation loss decreased (0.602341 --> 0.602068).  Saving model ...
Validation loss decreased (0.602068 --> 0.601795).  Saving model ...
Validation loss decreased (0.601795 --> 0.601522).  Saving model ...
Validation loss decreased (0.601522 --> 0.601249).  Saving model ...
Validation loss decreased (0.601249 --> 0.600976).  Saving model ...
Validation loss decreased (0.600976 --> 0.600703).  Saving model ...
Validation loss decreased (0.600703 --> 0.600430).  Saving model ...
Validation loss decreased (0.600430 --> 0.600158).  Saving model ...
Validation loss decreased (0.600158 --> 0.599885).  Saving model ...
Validation loss decreased (0.599885 --> 0.599613).  Saving model ...
Validation loss decreased (0.599613 --> 0.599340).  Saving model ...
Validation loss decreased (0.599340 --> 0.599068).  Saving model ...
Validation loss decreased (0.599068 --> 0.598796).  Saving model ...
Validation loss decreased (0.598796 --> 0.598524).  Saving model ...
Validation loss decreased (0.598524 --> 0.598251).  Saving model ...
Validation loss decreased (0.598251 --> 0.597979).  Saving model ...
Validation loss decreased (0.597979 --> 0.597707).  Saving model ...
Validation loss decreased (0.597707 --> 0.597435).  Saving model ...
Validation loss decreased (0.597435 --> 0.597163).  Saving model ...
Validation loss decreased (0.597163 --> 0.596891).  Saving model ...
Validation loss decreased (0.596891 --> 0.596619).  Saving model ...
Validation loss decreased (0.596619 --> 0.596347).  Saving model ...
Validation loss decreased (0.596347 --> 0.596075).  Saving model ...
Validation loss decreased (0.596075 --> 0.595803).  Saving model ...
Validation loss decreased (0.595803 --> 0.595532).  Saving model ...
Validation loss decreased (0.595532 --> 0.595260).  Saving model ...
Validation loss decreased (0.595260 --> 0.594988).  Saving model ...
Validation loss decreased (0.594988 --> 0.594716).  Saving model ...
Validation loss decreased (0.594716 --> 0.594444).  Saving model ...
epoch 201, loss 0.5944, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.594444 --> 0.594173).  Saving model ...
Validation loss decreased (0.594173 --> 0.593901).  Saving model ...
Validation loss decreased (0.593901 --> 0.593629).  Saving model ...
Validation loss decreased (0.593629 --> 0.593357).  Saving model ...
Validation loss decreased (0.593357 --> 0.593086).  Saving model ...
Validation loss decreased (0.593086 --> 0.592814).  Saving model ...
Validation loss decreased (0.592814 --> 0.592542).  Saving model ...
Validation loss decreased (0.592542 --> 0.592270).  Saving model ...
Validation loss decreased (0.592270 --> 0.591999).  Saving model ...
Validation loss decreased (0.591999 --> 0.591727).  Saving model ...
Validation loss decreased (0.591727 --> 0.591455).  Saving model ...
Validation loss decreased (0.591455 --> 0.591183).  Saving model ...
Validation loss decreased (0.591183 --> 0.590911).  Saving model ...
Validation loss decreased (0.590911 --> 0.590640).  Saving model ...
Validation loss decreased (0.590640 --> 0.590368).  Saving model ...
Validation loss decreased (0.590368 --> 0.590096).  Saving model ...
Validation loss decreased (0.590096 --> 0.589824).  Saving model ...
Validation loss decreased (0.589824 --> 0.589552).  Saving model ...
Validation loss decreased (0.589552 --> 0.589280).  Saving model ...
Validation loss decreased (0.589280 --> 0.589008).  Saving model ...
Validation loss decreased (0.589008 --> 0.588736).  Saving model ...
Validation loss decreased (0.588736 --> 0.588464).  Saving model ...
Validation loss decreased (0.588464 --> 0.588193).  Saving model ...
Validation loss decreased (0.588193 --> 0.587921).  Saving model ...
Validation loss decreased (0.587921 --> 0.587649).  Saving model ...
Validation loss decreased (0.587649 --> 0.587377).  Saving model ...
Validation loss decreased (0.587377 --> 0.587104).  Saving model ...
Validation loss decreased (0.587104 --> 0.586832).  Saving model ...
Validation loss decreased (0.586832 --> 0.586560).  Saving model ...
Validation loss decreased (0.586560 --> 0.586288).  Saving model ...
Validation loss decreased (0.586288 --> 0.586016).  Saving model ...
Validation loss decreased (0.586016 --> 0.585744).  Saving model ...
Validation loss decreased (0.585744 --> 0.585472).  Saving model ...
Validation loss decreased (0.585472 --> 0.585200).  Saving model ...
Validation loss decreased (0.585200 --> 0.584927).  Saving model ...
Validation loss decreased (0.584927 --> 0.584655).  Saving model ...
Validation loss decreased (0.584655 --> 0.584383).  Saving model ...
Validation loss decreased (0.584383 --> 0.584111).  Saving model ...
Validation loss decreased (0.584111 --> 0.583838).  Saving model ...
Validation loss decreased (0.583838 --> 0.583566).  Saving model ...
Validation loss decreased (0.583566 --> 0.583294).  Saving model ...
Validation loss decreased (0.583294 --> 0.583022).  Saving model ...
Validation loss decreased (0.583022 --> 0.582749).  Saving model ...
Validation loss decreased (0.582749 --> 0.582477).  Saving model ...
Validation loss decreased (0.582477 --> 0.582205).  Saving model ...
Validation loss decreased (0.582205 --> 0.581932).  Saving model ...
Validation loss decreased (0.581932 --> 0.581660).  Saving model ...
Validation loss decreased (0.581660 --> 0.581388).  Saving model ...
Validation loss decreased (0.581388 --> 0.581115).  Saving model ...
Validation loss decreased (0.581115 --> 0.580843).  Saving model ...
Validation loss decreased (0.580843 --> 0.580571).  Saving model ...
Validation loss decreased (0.580571 --> 0.580299).  Saving model ...
Validation loss decreased (0.580299 --> 0.580027).  Saving model ...
Validation loss decreased (0.580027 --> 0.579754).  Saving model ...
Validation loss decreased (0.579754 --> 0.579482).  Saving model ...
Validation loss decreased (0.579482 --> 0.579210).  Saving model ...
Validation loss decreased (0.579210 --> 0.578938).  Saving model ...
Validation loss decreased (0.578938 --> 0.578666).  Saving model ...
Validation loss decreased (0.578666 --> 0.578394).  Saving model ...
Validation loss decreased (0.578394 --> 0.578122).  Saving model ...
Validation loss decreased (0.578122 --> 0.577850).  Saving model ...
Validation loss decreased (0.577850 --> 0.577578).  Saving model ...
Validation loss decreased (0.577578 --> 0.577307).  Saving model ...
Validation loss decreased (0.577307 --> 0.577035).  Saving model ...
Validation loss decreased (0.577035 --> 0.576763).  Saving model ...
Validation loss decreased (0.576763 --> 0.576492).  Saving model ...
Validation loss decreased (0.576492 --> 0.576220).  Saving model ...
Validation loss decreased (0.576220 --> 0.575949).  Saving model ...
Validation loss decreased (0.575949 --> 0.575677).  Saving model ...
Validation loss decreased (0.575677 --> 0.575406).  Saving model ...
Validation loss decreased (0.575406 --> 0.575135).  Saving model ...
Validation loss decreased (0.575135 --> 0.574864).  Saving model ...
Validation loss decreased (0.574864 --> 0.574593).  Saving model ...
Validation loss decreased (0.574593 --> 0.574322).  Saving model ...
Validation loss decreased (0.574322 --> 0.574052).  Saving model ...
Validation loss decreased (0.574052 --> 0.573781).  Saving model ...
Validation loss decreased (0.573781 --> 0.573511).  Saving model ...
Validation loss decreased (0.573511 --> 0.573241).  Saving model ...
Validation loss decreased (0.573241 --> 0.572971).  Saving model ...
Validation loss decreased (0.572971 --> 0.572701).  Saving model ...
Validation loss decreased (0.572701 --> 0.572431).  Saving model ...
Validation loss decreased (0.572431 --> 0.572161).  Saving model ...
Validation loss decreased (0.572161 --> 0.571892).  Saving model ...
Validation loss decreased (0.571892 --> 0.571622).  Saving model ...
Validation loss decreased (0.571622 --> 0.571353).  Saving model ...
Validation loss decreased (0.571353 --> 0.571084).  Saving model ...
Validation loss decreased (0.571084 --> 0.570816).  Saving model ...
Validation loss decreased (0.570816 --> 0.570547).  Saving model ...
Validation loss decreased (0.570547 --> 0.570278).  Saving model ...
Validation loss decreased (0.570278 --> 0.570010).  Saving model ...
Validation loss decreased (0.570010 --> 0.569742).  Saving model ...
Validation loss decreased (0.569742 --> 0.569475).  Saving model ...
Validation loss decreased (0.569475 --> 0.569207).  Saving model ...
Validation loss decreased (0.569207 --> 0.568940).  Saving model ...
Validation loss decreased (0.568940 --> 0.568673).  Saving model ...
Validation loss decreased (0.568673 --> 0.568406).  Saving model ...
Validation loss decreased (0.568406 --> 0.568139).  Saving model ...
Validation loss decreased (0.568139 --> 0.567873).  Saving model ...
Validation loss decreased (0.567873 --> 0.567607).  Saving model ...
Validation loss decreased (0.567607 --> 0.567341).  Saving model ...
epoch 301, loss 0.5673, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.567341 --> 0.567076).  Saving model ...
Validation loss decreased (0.567076 --> 0.566810).  Saving model ...
Validation loss decreased (0.566810 --> 0.566545).  Saving model ...
Validation loss decreased (0.566545 --> 0.566281).  Saving model ...
Validation loss decreased (0.566281 --> 0.566016).  Saving model ...
Validation loss decreased (0.566016 --> 0.565752).  Saving model ...
Validation loss decreased (0.565752 --> 0.565488).  Saving model ...
Validation loss decreased (0.565488 --> 0.565225).  Saving model ...
Validation loss decreased (0.565225 --> 0.564961).  Saving model ...
Validation loss decreased (0.564961 --> 0.564698).  Saving model ...
Validation loss decreased (0.564698 --> 0.564436).  Saving model ...
Validation loss decreased (0.564436 --> 0.564174).  Saving model ...
Validation loss decreased (0.564174 --> 0.563912).  Saving model ...
Validation loss decreased (0.563912 --> 0.563650).  Saving model ...
Validation loss decreased (0.563650 --> 0.563389).  Saving model ...
Validation loss decreased (0.563389 --> 0.563128).  Saving model ...
Validation loss decreased (0.563128 --> 0.562867).  Saving model ...
Validation loss decreased (0.562867 --> 0.562607).  Saving model ...
Validation loss decreased (0.562607 --> 0.562347).  Saving model ...
Validation loss decreased (0.562347 --> 0.562087).  Saving model ...
Validation loss decreased (0.562087 --> 0.561828).  Saving model ...
Validation loss decreased (0.561828 --> 0.561569).  Saving model ...
Validation loss decreased (0.561569 --> 0.561311).  Saving model ...
Validation loss decreased (0.561311 --> 0.561053).  Saving model ...
Validation loss decreased (0.561053 --> 0.560795).  Saving model ...
Validation loss decreased (0.560795 --> 0.560538).  Saving model ...
Validation loss decreased (0.560538 --> 0.560281).  Saving model ...
Validation loss decreased (0.560281 --> 0.560024).  Saving model ...
Validation loss decreased (0.560024 --> 0.559768).  Saving model ...
Validation loss decreased (0.559768 --> 0.559513).  Saving model ...
Validation loss decreased (0.559513 --> 0.559257).  Saving model ...
Validation loss decreased (0.559257 --> 0.559002).  Saving model ...
Validation loss decreased (0.559002 --> 0.558748).  Saving model ...
Validation loss decreased (0.558748 --> 0.558494).  Saving model ...
Validation loss decreased (0.558494 --> 0.558240).  Saving model ...
Validation loss decreased (0.558240 --> 0.557987).  Saving model ...
Validation loss decreased (0.557987 --> 0.557734).  Saving model ...
Validation loss decreased (0.557734 --> 0.557481).  Saving model ...
Validation loss decreased (0.557481 --> 0.557229).  Saving model ...
Validation loss decreased (0.557229 --> 0.556978).  Saving model ...
Validation loss decreased (0.556978 --> 0.556727).  Saving model ...
Validation loss decreased (0.556727 --> 0.556476).  Saving model ...
Validation loss decreased (0.556476 --> 0.556226).  Saving model ...
Validation loss decreased (0.556226 --> 0.555976).  Saving model ...
Validation loss decreased (0.555976 --> 0.555727).  Saving model ...
Validation loss decreased (0.555727 --> 0.555478).  Saving model ...
Validation loss decreased (0.555478 --> 0.555229).  Saving model ...
Validation loss decreased (0.555229 --> 0.554981).  Saving model ...
Validation loss decreased (0.554981 --> 0.554733).  Saving model ...
Validation loss decreased (0.554733 --> 0.554486).  Saving model ...
Validation loss decreased (0.554486 --> 0.554240).  Saving model ...
Validation loss decreased (0.554240 --> 0.553993).  Saving model ...
Validation loss decreased (0.553993 --> 0.553748).  Saving model ...
Validation loss decreased (0.553748 --> 0.553502).  Saving model ...
Validation loss decreased (0.553502 --> 0.553258).  Saving model ...
Validation loss decreased (0.553258 --> 0.553013).  Saving model ...
Validation loss decreased (0.553013 --> 0.552769).  Saving model ...
Validation loss decreased (0.552769 --> 0.552526).  Saving model ...
Validation loss decreased (0.552526 --> 0.552283).  Saving model ...
Validation loss decreased (0.552283 --> 0.552040).  Saving model ...
Validation loss decreased (0.552040 --> 0.551798).  Saving model ...
Validation loss decreased (0.551798 --> 0.551557).  Saving model ...
Validation loss decreased (0.551557 --> 0.551316).  Saving model ...
Validation loss decreased (0.551316 --> 0.551075).  Saving model ...
Validation loss decreased (0.551075 --> 0.550835).  Saving model ...
Validation loss decreased (0.550835 --> 0.550595).  Saving model ...
Validation loss decreased (0.550595 --> 0.550356).  Saving model ...
Validation loss decreased (0.550356 --> 0.550118).  Saving model ...
Validation loss decreased (0.550118 --> 0.549880).  Saving model ...
Validation loss decreased (0.549880 --> 0.549642).  Saving model ...
Validation loss decreased (0.549642 --> 0.549405).  Saving model ...
Validation loss decreased (0.549405 --> 0.549168).  Saving model ...
Validation loss decreased (0.549168 --> 0.548932).  Saving model ...
Validation loss decreased (0.548932 --> 0.548696).  Saving model ...
Validation loss decreased (0.548696 --> 0.548461).  Saving model ...
Validation loss decreased (0.548461 --> 0.548226).  Saving model ...
Validation loss decreased (0.548226 --> 0.547992).  Saving model ...
Validation loss decreased (0.547992 --> 0.547758).  Saving model ...
Validation loss decreased (0.547758 --> 0.547525).  Saving model ...
Validation loss decreased (0.547525 --> 0.547292).  Saving model ...
Validation loss decreased (0.547292 --> 0.547060).  Saving model ...
Validation loss decreased (0.547060 --> 0.546828).  Saving model ...
Validation loss decreased (0.546828 --> 0.546596).  Saving model ...
Validation loss decreased (0.546596 --> 0.546366).  Saving model ...
Validation loss decreased (0.546366 --> 0.546135).  Saving model ...
Validation loss decreased (0.546135 --> 0.545905).  Saving model ...
Validation loss decreased (0.545905 --> 0.545676).  Saving model ...
Validation loss decreased (0.545676 --> 0.545447).  Saving model ...
Validation loss decreased (0.545447 --> 0.545219).  Saving model ...
Validation loss decreased (0.545219 --> 0.544991).  Saving model ...
Validation loss decreased (0.544991 --> 0.544764).  Saving model ...
Validation loss decreased (0.544764 --> 0.544537).  Saving model ...
Validation loss decreased (0.544537 --> 0.544311).  Saving model ...
Validation loss decreased (0.544311 --> 0.544085).  Saving model ...
Validation loss decreased (0.544085 --> 0.543859).  Saving model ...
Validation loss decreased (0.543859 --> 0.543635).  Saving model ...
Validation loss decreased (0.543635 --> 0.543410).  Saving model ...
Validation loss decreased (0.543410 --> 0.543186).  Saving model ...
Validation loss decreased (0.543186 --> 0.542963).  Saving model ...
Validation loss decreased (0.542963 --> 0.542740).  Saving model ...
epoch 401, loss 0.5427, train acc 67.35%, f1 0.1732, precision 0.7692, recall 0.0976, auc 0.5409
Validation loss decreased (0.542740 --> 0.542518).  Saving model ...
Validation loss decreased (0.542518 --> 0.542296).  Saving model ...
Validation loss decreased (0.542296 --> 0.542075).  Saving model ...
Validation loss decreased (0.542075 --> 0.541854).  Saving model ...
Validation loss decreased (0.541854 --> 0.541633).  Saving model ...
Validation loss decreased (0.541633 --> 0.541413).  Saving model ...
Validation loss decreased (0.541413 --> 0.541194).  Saving model ...
Validation loss decreased (0.541194 --> 0.540975).  Saving model ...
Validation loss decreased (0.540975 --> 0.540757).  Saving model ...
Validation loss decreased (0.540757 --> 0.540539).  Saving model ...
Validation loss decreased (0.540539 --> 0.540321).  Saving model ...
Validation loss decreased (0.540321 --> 0.540105).  Saving model ...
Validation loss decreased (0.540105 --> 0.539888).  Saving model ...
Validation loss decreased (0.539888 --> 0.539672).  Saving model ...
Validation loss decreased (0.539672 --> 0.539457).  Saving model ...
Validation loss decreased (0.539457 --> 0.539242).  Saving model ...
Validation loss decreased (0.539242 --> 0.539027).  Saving model ...
Validation loss decreased (0.539027 --> 0.538813).  Saving model ...
Validation loss decreased (0.538813 --> 0.538600).  Saving model ...
Validation loss decreased (0.538600 --> 0.538387).  Saving model ...
Validation loss decreased (0.538387 --> 0.538175).  Saving model ...
Validation loss decreased (0.538175 --> 0.537963).  Saving model ...
Validation loss decreased (0.537963 --> 0.537751).  Saving model ...
Validation loss decreased (0.537751 --> 0.537540).  Saving model ...
Validation loss decreased (0.537540 --> 0.537330).  Saving model ...
Validation loss decreased (0.537330 --> 0.537120).  Saving model ...
Validation loss decreased (0.537120 --> 0.536910).  Saving model ...
Validation loss decreased (0.536910 --> 0.536701).  Saving model ...
Validation loss decreased (0.536701 --> 0.536492).  Saving model ...
Validation loss decreased (0.536492 --> 0.536284).  Saving model ...
Validation loss decreased (0.536284 --> 0.536077).  Saving model ...
Validation loss decreased (0.536077 --> 0.535870).  Saving model ...
Validation loss decreased (0.535870 --> 0.535663).  Saving model ...
Validation loss decreased (0.535663 --> 0.535457).  Saving model ...
Validation loss decreased (0.535457 --> 0.535251).  Saving model ...
Validation loss decreased (0.535251 --> 0.535046).  Saving model ...
Validation loss decreased (0.535046 --> 0.534841).  Saving model ...
Validation loss decreased (0.534841 --> 0.534637).  Saving model ...
Validation loss decreased (0.534637 --> 0.534433).  Saving model ...
Validation loss decreased (0.534433 --> 0.534230).  Saving model ...
Validation loss decreased (0.534230 --> 0.534027).  Saving model ...
Validation loss decreased (0.534027 --> 0.533825).  Saving model ...
Validation loss decreased (0.533825 --> 0.533623).  Saving model ...
Validation loss decreased (0.533623 --> 0.533422).  Saving model ...
Validation loss decreased (0.533422 --> 0.533221).  Saving model ...
Validation loss decreased (0.533221 --> 0.533021).  Saving model ...
Validation loss decreased (0.533021 --> 0.532821).  Saving model ...
Validation loss decreased (0.532821 --> 0.532621).  Saving model ...
Validation loss decreased (0.532621 --> 0.532422).  Saving model ...
Validation loss decreased (0.532422 --> 0.532224).  Saving model ...
Validation loss decreased (0.532224 --> 0.532026).  Saving model ...
Validation loss decreased (0.532026 --> 0.531828).  Saving model ...
Validation loss decreased (0.531828 --> 0.531631).  Saving model ...
Validation loss decreased (0.531631 --> 0.531435).  Saving model ...
Validation loss decreased (0.531435 --> 0.531239).  Saving model ...
Validation loss decreased (0.531239 --> 0.531043).  Saving model ...
Validation loss decreased (0.531043 --> 0.530848).  Saving model ...
Validation loss decreased (0.530848 --> 0.530653).  Saving model ...
Validation loss decreased (0.530653 --> 0.530459).  Saving model ...
Validation loss decreased (0.530459 --> 0.530265).  Saving model ...
Validation loss decreased (0.530265 --> 0.530072).  Saving model ...
Validation loss decreased (0.530072 --> 0.529879).  Saving model ...
Validation loss decreased (0.529879 --> 0.529686).  Saving model ...
Validation loss decreased (0.529686 --> 0.529495).  Saving model ...
Validation loss decreased (0.529495 --> 0.529303).  Saving model ...
Validation loss decreased (0.529303 --> 0.529112).  Saving model ...
Validation loss decreased (0.529112 --> 0.528921).  Saving model ...
Validation loss decreased (0.528921 --> 0.528731).  Saving model ...
Validation loss decreased (0.528731 --> 0.528542).  Saving model ...
Validation loss decreased (0.528542 --> 0.528353).  Saving model ...
Validation loss decreased (0.528353 --> 0.528164).  Saving model ...
Validation loss decreased (0.528164 --> 0.527976).  Saving model ...
Validation loss decreased (0.527976 --> 0.527788).  Saving model ...
Validation loss decreased (0.527788 --> 0.527600).  Saving model ...
Validation loss decreased (0.527600 --> 0.527413).  Saving model ...
Validation loss decreased (0.527413 --> 0.527227).  Saving model ...
Validation loss decreased (0.527227 --> 0.527041).  Saving model ...
Validation loss decreased (0.527041 --> 0.526855).  Saving model ...
Validation loss decreased (0.526855 --> 0.526670).  Saving model ...
Validation loss decreased (0.526670 --> 0.526486).  Saving model ...
Validation loss decreased (0.526486 --> 0.526302).  Saving model ...
Validation loss decreased (0.526302 --> 0.526118).  Saving model ...
Validation loss decreased (0.526118 --> 0.525934).  Saving model ...
Validation loss decreased (0.525934 --> 0.525752).  Saving model ...
Validation loss decreased (0.525752 --> 0.525569).  Saving model ...
Validation loss decreased (0.525569 --> 0.525387).  Saving model ...
Validation loss decreased (0.525387 --> 0.525206).  Saving model ...
Validation loss decreased (0.525206 --> 0.525024).  Saving model ...
Validation loss decreased (0.525024 --> 0.524844).  Saving model ...
Validation loss decreased (0.524844 --> 0.524664).  Saving model ...
Validation loss decreased (0.524664 --> 0.524484).  Saving model ...
Validation loss decreased (0.524484 --> 0.524305).  Saving model ...
Validation loss decreased (0.524305 --> 0.524126).  Saving model ...
Validation loss decreased (0.524126 --> 0.523947).  Saving model ...
Validation loss decreased (0.523947 --> 0.523769).  Saving model ...
Validation loss decreased (0.523769 --> 0.523592).  Saving model ...
Validation loss decreased (0.523592 --> 0.523414).  Saving model ...
Validation loss decreased (0.523414 --> 0.523238).  Saving model ...
Validation loss decreased (0.523238 --> 0.523061).  Saving model ...
Validation loss decreased (0.523061 --> 0.522885).  Saving model ...
epoch 501, loss 0.5229, train acc 71.45%, f1 0.3650, precision 0.8276, recall 0.2341, auc 0.6039
Validation loss decreased (0.522885 --> 0.522710).  Saving model ...
Validation loss decreased (0.522710 --> 0.522535).  Saving model ...
Validation loss decreased (0.522535 --> 0.522360).  Saving model ...
Validation loss decreased (0.522360 --> 0.522186).  Saving model ...
Validation loss decreased (0.522186 --> 0.522013).  Saving model ...
Validation loss decreased (0.522013 --> 0.521839).  Saving model ...
Validation loss decreased (0.521839 --> 0.521666).  Saving model ...
Validation loss decreased (0.521666 --> 0.521494).  Saving model ...
Validation loss decreased (0.521494 --> 0.521322).  Saving model ...
Validation loss decreased (0.521322 --> 0.521150).  Saving model ...
Validation loss decreased (0.521150 --> 0.520979).  Saving model ...
Validation loss decreased (0.520979 --> 0.520808).  Saving model ...
Validation loss decreased (0.520808 --> 0.520638).  Saving model ...
Validation loss decreased (0.520638 --> 0.520468).  Saving model ...
Validation loss decreased (0.520468 --> 0.520299).  Saving model ...
Validation loss decreased (0.520299 --> 0.520130).  Saving model ...
Validation loss decreased (0.520130 --> 0.519961).  Saving model ...
Validation loss decreased (0.519961 --> 0.519793).  Saving model ...
Validation loss decreased (0.519793 --> 0.519625).  Saving model ...
Validation loss decreased (0.519625 --> 0.519457).  Saving model ...
Validation loss decreased (0.519457 --> 0.519290).  Saving model ...
Validation loss decreased (0.519290 --> 0.519124).  Saving model ...
Validation loss decreased (0.519124 --> 0.518958).  Saving model ...
Validation loss decreased (0.518958 --> 0.518792).  Saving model ...
Validation loss decreased (0.518792 --> 0.518626).  Saving model ...
Validation loss decreased (0.518626 --> 0.518461).  Saving model ...
Validation loss decreased (0.518461 --> 0.518297).  Saving model ...
Validation loss decreased (0.518297 --> 0.518133).  Saving model ...
Validation loss decreased (0.518133 --> 0.517969).  Saving model ...
Validation loss decreased (0.517969 --> 0.517806).  Saving model ...
Validation loss decreased (0.517806 --> 0.517643).  Saving model ...
Validation loss decreased (0.517643 --> 0.517480).  Saving model ...
Validation loss decreased (0.517480 --> 0.517318).  Saving model ...
Validation loss decreased (0.517318 --> 0.517156).  Saving model ...
Validation loss decreased (0.517156 --> 0.516995).  Saving model ...
Validation loss decreased (0.516995 --> 0.516834).  Saving model ...
Validation loss decreased (0.516834 --> 0.516674).  Saving model ...
Validation loss decreased (0.516674 --> 0.516514).  Saving model ...
Validation loss decreased (0.516514 --> 0.516354).  Saving model ...
Validation loss decreased (0.516354 --> 0.516194).  Saving model ...
Validation loss decreased (0.516194 --> 0.516036).  Saving model ...
Validation loss decreased (0.516036 --> 0.515877).  Saving model ...
Validation loss decreased (0.515877 --> 0.515719).  Saving model ...
Validation loss decreased (0.515719 --> 0.515561).  Saving model ...
Validation loss decreased (0.515561 --> 0.515404).  Saving model ...
Validation loss decreased (0.515404 --> 0.515247).  Saving model ...
Validation loss decreased (0.515247 --> 0.515090).  Saving model ...
Validation loss decreased (0.515090 --> 0.514934).  Saving model ...
Validation loss decreased (0.514934 --> 0.514778).  Saving model ...
Validation loss decreased (0.514778 --> 0.514623).  Saving model ...
Validation loss decreased (0.514623 --> 0.514468).  Saving model ...
Validation loss decreased (0.514468 --> 0.514313).  Saving model ...
Validation loss decreased (0.514313 --> 0.514159).  Saving model ...
Validation loss decreased (0.514159 --> 0.514005).  Saving model ...
Validation loss decreased (0.514005 --> 0.513852).  Saving model ...
Validation loss decreased (0.513852 --> 0.513698).  Saving model ...
Validation loss decreased (0.513698 --> 0.513546).  Saving model ...
Validation loss decreased (0.513546 --> 0.513393).  Saving model ...
Validation loss decreased (0.513393 --> 0.513241).  Saving model ...
Validation loss decreased (0.513241 --> 0.513090).  Saving model ...
Validation loss decreased (0.513090 --> 0.512939).  Saving model ...
Validation loss decreased (0.512939 --> 0.512788).  Saving model ...
Validation loss decreased (0.512788 --> 0.512637).  Saving model ...
Validation loss decreased (0.512637 --> 0.512487).  Saving model ...
Validation loss decreased (0.512487 --> 0.512338).  Saving model ...
Validation loss decreased (0.512338 --> 0.512188).  Saving model ...
Validation loss decreased (0.512188 --> 0.512039).  Saving model ...
Validation loss decreased (0.512039 --> 0.511891).  Saving model ...
Validation loss decreased (0.511891 --> 0.511743).  Saving model ...
Validation loss decreased (0.511743 --> 0.511595).  Saving model ...
Validation loss decreased (0.511595 --> 0.511447).  Saving model ...
Validation loss decreased (0.511447 --> 0.511300).  Saving model ...
Validation loss decreased (0.511300 --> 0.511154).  Saving model ...
Validation loss decreased (0.511154 --> 0.511007).  Saving model ...
Validation loss decreased (0.511007 --> 0.510861).  Saving model ...
Validation loss decreased (0.510861 --> 0.510716).  Saving model ...
Validation loss decreased (0.510716 --> 0.510571).  Saving model ...
Validation loss decreased (0.510571 --> 0.510426).  Saving model ...
Validation loss decreased (0.510426 --> 0.510281).  Saving model ...
Validation loss decreased (0.510281 --> 0.510137).  Saving model ...
Validation loss decreased (0.510137 --> 0.509993).  Saving model ...
Validation loss decreased (0.509993 --> 0.509850).  Saving model ...
Validation loss decreased (0.509850 --> 0.509707).  Saving model ...
Validation loss decreased (0.509707 --> 0.509564).  Saving model ...
Validation loss decreased (0.509564 --> 0.509422).  Saving model ...
Validation loss decreased (0.509422 --> 0.509280).  Saving model ...
Validation loss decreased (0.509280 --> 0.509138).  Saving model ...
Validation loss decreased (0.509138 --> 0.508997).  Saving model ...
Validation loss decreased (0.508997 --> 0.508856).  Saving model ...
Validation loss decreased (0.508856 --> 0.508715).  Saving model ...
Validation loss decreased (0.508715 --> 0.508575).  Saving model ...
Validation loss decreased (0.508575 --> 0.508435).  Saving model ...
Validation loss decreased (0.508435 --> 0.508296).  Saving model ...
Validation loss decreased (0.508296 --> 0.508157).  Saving model ...
Validation loss decreased (0.508157 --> 0.508018).  Saving model ...
Validation loss decreased (0.508018 --> 0.507880).  Saving model ...
Validation loss decreased (0.507880 --> 0.507742).  Saving model ...
Validation loss decreased (0.507742 --> 0.507604).  Saving model ...
Validation loss decreased (0.507604 --> 0.507466).  Saving model ...
Validation loss decreased (0.507466 --> 0.507329).  Saving model ...
epoch 601, loss 0.5073, train acc 75.21%, f1 0.5246, precision 0.8000, recall 0.3902, auc 0.6688
Validation loss decreased (0.507329 --> 0.507193).  Saving model ...
Validation loss decreased (0.507193 --> 0.507056).  Saving model ...
Validation loss decreased (0.507056 --> 0.506920).  Saving model ...
Validation loss decreased (0.506920 --> 0.506785).  Saving model ...
Validation loss decreased (0.506785 --> 0.506649).  Saving model ...
Validation loss decreased (0.506649 --> 0.506515).  Saving model ...
Validation loss decreased (0.506515 --> 0.506380).  Saving model ...
Validation loss decreased (0.506380 --> 0.506246).  Saving model ...
Validation loss decreased (0.506246 --> 0.506112).  Saving model ...
Validation loss decreased (0.506112 --> 0.505978).  Saving model ...
Validation loss decreased (0.505978 --> 0.505845).  Saving model ...
Validation loss decreased (0.505845 --> 0.505712).  Saving model ...
Validation loss decreased (0.505712 --> 0.505579).  Saving model ...
Validation loss decreased (0.505579 --> 0.505447).  Saving model ...
Validation loss decreased (0.505447 --> 0.505315).  Saving model ...
Validation loss decreased (0.505315 --> 0.505184).  Saving model ...
Validation loss decreased (0.505184 --> 0.505053).  Saving model ...
Validation loss decreased (0.505053 --> 0.504922).  Saving model ...
Validation loss decreased (0.504922 --> 0.504791).  Saving model ...
Validation loss decreased (0.504791 --> 0.504661).  Saving model ...
Validation loss decreased (0.504661 --> 0.504531).  Saving model ...
Validation loss decreased (0.504531 --> 0.504402).  Saving model ...
Validation loss decreased (0.504402 --> 0.504272).  Saving model ...
Validation loss decreased (0.504272 --> 0.504144).  Saving model ...
Validation loss decreased (0.504144 --> 0.504015).  Saving model ...
Validation loss decreased (0.504015 --> 0.503887).  Saving model ...
Validation loss decreased (0.503887 --> 0.503759).  Saving model ...
Validation loss decreased (0.503759 --> 0.503631).  Saving model ...
Validation loss decreased (0.503631 --> 0.503504).  Saving model ...
Validation loss decreased (0.503504 --> 0.503377).  Saving model ...
Validation loss decreased (0.503377 --> 0.503251).  Saving model ...
Validation loss decreased (0.503251 --> 0.503124).  Saving model ...
Validation loss decreased (0.503124 --> 0.502998).  Saving model ...
Validation loss decreased (0.502998 --> 0.502873).  Saving model ...
Validation loss decreased (0.502873 --> 0.502748).  Saving model ...
Validation loss decreased (0.502748 --> 0.502623).  Saving model ...
Validation loss decreased (0.502623 --> 0.502498).  Saving model ...
Validation loss decreased (0.502498 --> 0.502374).  Saving model ...
Validation loss decreased (0.502374 --> 0.502250).  Saving model ...
Validation loss decreased (0.502250 --> 0.502126).  Saving model ...
Validation loss decreased (0.502126 --> 0.502003).  Saving model ...
Validation loss decreased (0.502003 --> 0.501880).  Saving model ...
Validation loss decreased (0.501880 --> 0.501757).  Saving model ...
Validation loss decreased (0.501757 --> 0.501634).  Saving model ...
Validation loss decreased (0.501634 --> 0.501512).  Saving model ...
Validation loss decreased (0.501512 --> 0.501391).  Saving model ...
Validation loss decreased (0.501391 --> 0.501269).  Saving model ...
Validation loss decreased (0.501269 --> 0.501148).  Saving model ...
Validation loss decreased (0.501148 --> 0.501027).  Saving model ...
Validation loss decreased (0.501027 --> 0.500907).  Saving model ...
Validation loss decreased (0.500907 --> 0.500786).  Saving model ...
Validation loss decreased (0.500786 --> 0.500666).  Saving model ...
Validation loss decreased (0.500666 --> 0.500547).  Saving model ...
Validation loss decreased (0.500547 --> 0.500428).  Saving model ...
Validation loss decreased (0.500428 --> 0.500309).  Saving model ...
Validation loss decreased (0.500309 --> 0.500190).  Saving model ...
Validation loss decreased (0.500190 --> 0.500072).  Saving model ...
Validation loss decreased (0.500072 --> 0.499954).  Saving model ...
Validation loss decreased (0.499954 --> 0.499836).  Saving model ...
Validation loss decreased (0.499836 --> 0.499718).  Saving model ...
Validation loss decreased (0.499718 --> 0.499601).  Saving model ...
Validation loss decreased (0.499601 --> 0.499484).  Saving model ...
Validation loss decreased (0.499484 --> 0.499368).  Saving model ...
Validation loss decreased (0.499368 --> 0.499252).  Saving model ...
Validation loss decreased (0.499252 --> 0.499136).  Saving model ...
Validation loss decreased (0.499136 --> 0.499020).  Saving model ...
Validation loss decreased (0.499020 --> 0.498905).  Saving model ...
Validation loss decreased (0.498905 --> 0.498790).  Saving model ...
Validation loss decreased (0.498790 --> 0.498675).  Saving model ...
Validation loss decreased (0.498675 --> 0.498561).  Saving model ...
Validation loss decreased (0.498561 --> 0.498447).  Saving model ...
Validation loss decreased (0.498447 --> 0.498333).  Saving model ...
Validation loss decreased (0.498333 --> 0.498219).  Saving model ...
Validation loss decreased (0.498219 --> 0.498106).  Saving model ...
Validation loss decreased (0.498106 --> 0.497993).  Saving model ...
Validation loss decreased (0.497993 --> 0.497881).  Saving model ...
Validation loss decreased (0.497881 --> 0.497768).  Saving model ...
Validation loss decreased (0.497768 --> 0.497656).  Saving model ...
Validation loss decreased (0.497656 --> 0.497544).  Saving model ...
Validation loss decreased (0.497544 --> 0.497433).  Saving model ...
Validation loss decreased (0.497433 --> 0.497322).  Saving model ...
Validation loss decreased (0.497322 --> 0.497211).  Saving model ...
Validation loss decreased (0.497211 --> 0.497100).  Saving model ...
Validation loss decreased (0.497100 --> 0.496990).  Saving model ...
Validation loss decreased (0.496990 --> 0.496880).  Saving model ...
Validation loss decreased (0.496880 --> 0.496771).  Saving model ...
Validation loss decreased (0.496771 --> 0.496661).  Saving model ...
Validation loss decreased (0.496661 --> 0.496552).  Saving model ...
Validation loss decreased (0.496552 --> 0.496443).  Saving model ...
Validation loss decreased (0.496443 --> 0.496335).  Saving model ...
Validation loss decreased (0.496335 --> 0.496226).  Saving model ...
Validation loss decreased (0.496226 --> 0.496118).  Saving model ...
Validation loss decreased (0.496118 --> 0.496011).  Saving model ...
Validation loss decreased (0.496011 --> 0.495903).  Saving model ...
Validation loss decreased (0.495903 --> 0.495796).  Saving model ...
Validation loss decreased (0.495796 --> 0.495689).  Saving model ...
Validation loss decreased (0.495689 --> 0.495583).  Saving model ...
Validation loss decreased (0.495583 --> 0.495476).  Saving model ...
Validation loss decreased (0.495476 --> 0.495370).  Saving model ...
Validation loss decreased (0.495370 --> 0.495265).  Saving model ...
epoch 701, loss 0.4953, train acc 76.07%, f1 0.5732, precision 0.7642, recall 0.4585, auc 0.6911
Validation loss decreased (0.495265 --> 0.495159).  Saving model ...
Validation loss decreased (0.495159 --> 0.495054).  Saving model ...
Validation loss decreased (0.495054 --> 0.494949).  Saving model ...
Validation loss decreased (0.494949 --> 0.494845).  Saving model ...
Validation loss decreased (0.494845 --> 0.494740).  Saving model ...
Validation loss decreased (0.494740 --> 0.494636).  Saving model ...
Validation loss decreased (0.494636 --> 0.494532).  Saving model ...
Validation loss decreased (0.494532 --> 0.494429).  Saving model ...
Validation loss decreased (0.494429 --> 0.494326).  Saving model ...
Validation loss decreased (0.494326 --> 0.494223).  Saving model ...
Validation loss decreased (0.494223 --> 0.494120).  Saving model ...
Validation loss decreased (0.494120 --> 0.494018).  Saving model ...
Validation loss decreased (0.494018 --> 0.493916).  Saving model ...
Validation loss decreased (0.493916 --> 0.493814).  Saving model ...
Validation loss decreased (0.493814 --> 0.493712).  Saving model ...
Validation loss decreased (0.493712 --> 0.493611).  Saving model ...
Validation loss decreased (0.493611 --> 0.493510).  Saving model ...
Validation loss decreased (0.493510 --> 0.493409).  Saving model ...
Validation loss decreased (0.493409 --> 0.493308).  Saving model ...
Validation loss decreased (0.493308 --> 0.493208).  Saving model ...
Validation loss decreased (0.493208 --> 0.493108).  Saving model ...
Validation loss decreased (0.493108 --> 0.493009).  Saving model ...
Validation loss decreased (0.493009 --> 0.492909).  Saving model ...
Validation loss decreased (0.492909 --> 0.492810).  Saving model ...
Validation loss decreased (0.492810 --> 0.492711).  Saving model ...
Validation loss decreased (0.492711 --> 0.492612).  Saving model ...
Validation loss decreased (0.492612 --> 0.492514).  Saving model ...
Validation loss decreased (0.492514 --> 0.492416).  Saving model ...
Validation loss decreased (0.492416 --> 0.492318).  Saving model ...
Validation loss decreased (0.492318 --> 0.492220).  Saving model ...
Validation loss decreased (0.492220 --> 0.492123).  Saving model ...
Validation loss decreased (0.492123 --> 0.492026).  Saving model ...
Validation loss decreased (0.492026 --> 0.491929).  Saving model ...
Validation loss decreased (0.491929 --> 0.491833).  Saving model ...
Validation loss decreased (0.491833 --> 0.491736).  Saving model ...
Validation loss decreased (0.491736 --> 0.491640).  Saving model ...
Validation loss decreased (0.491640 --> 0.491545).  Saving model ...
Validation loss decreased (0.491545 --> 0.491449).  Saving model ...
Validation loss decreased (0.491449 --> 0.491354).  Saving model ...
Validation loss decreased (0.491354 --> 0.491259).  Saving model ...
Validation loss decreased (0.491259 --> 0.491164).  Saving model ...
Validation loss decreased (0.491164 --> 0.491070).  Saving model ...
Validation loss decreased (0.491070 --> 0.490975).  Saving model ...
Validation loss decreased (0.490975 --> 0.490881).  Saving model ...
Validation loss decreased (0.490881 --> 0.490788).  Saving model ...
Validation loss decreased (0.490788 --> 0.490694).  Saving model ...
Validation loss decreased (0.490694 --> 0.490601).  Saving model ...
Validation loss decreased (0.490601 --> 0.490508).  Saving model ...
Validation loss decreased (0.490508 --> 0.490415).  Saving model ...
Validation loss decreased (0.490415 --> 0.490323).  Saving model ...
Validation loss decreased (0.490323 --> 0.490230).  Saving model ...
Validation loss decreased (0.490230 --> 0.490138).  Saving model ...
Validation loss decreased (0.490138 --> 0.490047).  Saving model ...
Validation loss decreased (0.490047 --> 0.489955).  Saving model ...
Validation loss decreased (0.489955 --> 0.489864).  Saving model ...
Validation loss decreased (0.489864 --> 0.489773).  Saving model ...
Validation loss decreased (0.489773 --> 0.489682).  Saving model ...
Validation loss decreased (0.489682 --> 0.489592).  Saving model ...
Validation loss decreased (0.489592 --> 0.489501).  Saving model ...
Validation loss decreased (0.489501 --> 0.489412).  Saving model ...
Validation loss decreased (0.489412 --> 0.489322).  Saving model ...
Validation loss decreased (0.489322 --> 0.489232).  Saving model ...
Validation loss decreased (0.489232 --> 0.489143).  Saving model ...
Validation loss decreased (0.489143 --> 0.489054).  Saving model ...
Validation loss decreased (0.489054 --> 0.488965).  Saving model ...
Validation loss decreased (0.488965 --> 0.488877).  Saving model ...
Validation loss decreased (0.488877 --> 0.488788).  Saving model ...
Validation loss decreased (0.488788 --> 0.488700).  Saving model ...
Validation loss decreased (0.488700 --> 0.488612).  Saving model ...
Validation loss decreased (0.488612 --> 0.488525).  Saving model ...
Validation loss decreased (0.488525 --> 0.488437).  Saving model ...
Validation loss decreased (0.488437 --> 0.488350).  Saving model ...
Validation loss decreased (0.488350 --> 0.488263).  Saving model ...
Validation loss decreased (0.488263 --> 0.488177).  Saving model ...
Validation loss decreased (0.488177 --> 0.488090).  Saving model ...
Validation loss decreased (0.488090 --> 0.488004).  Saving model ...
Validation loss decreased (0.488004 --> 0.487918).  Saving model ...
Validation loss decreased (0.487918 --> 0.487833).  Saving model ...
Validation loss decreased (0.487833 --> 0.487747).  Saving model ...
Validation loss decreased (0.487747 --> 0.487662).  Saving model ...
Validation loss decreased (0.487662 --> 0.487577).  Saving model ...
Validation loss decreased (0.487577 --> 0.487492).  Saving model ...
Validation loss decreased (0.487492 --> 0.487408).  Saving model ...
Validation loss decreased (0.487408 --> 0.487323).  Saving model ...
Validation loss decreased (0.487323 --> 0.487239).  Saving model ...
Validation loss decreased (0.487239 --> 0.487155).  Saving model ...
Validation loss decreased (0.487155 --> 0.487072).  Saving model ...
Validation loss decreased (0.487072 --> 0.486988).  Saving model ...
Validation loss decreased (0.486988 --> 0.486905).  Saving model ...
Validation loss decreased (0.486905 --> 0.486822).  Saving model ...
Validation loss decreased (0.486822 --> 0.486740).  Saving model ...
Validation loss decreased (0.486740 --> 0.486657).  Saving model ...
Validation loss decreased (0.486657 --> 0.486575).  Saving model ...
Validation loss decreased (0.486575 --> 0.486493).  Saving model ...
Validation loss decreased (0.486493 --> 0.486411).  Saving model ...
Validation loss decreased (0.486411 --> 0.486330).  Saving model ...
Validation loss decreased (0.486330 --> 0.486248).  Saving model ...
Validation loss decreased (0.486248 --> 0.486167).  Saving model ...
Validation loss decreased (0.486167 --> 0.486086).  Saving model ...
Validation loss decreased (0.486086 --> 0.486006).  Saving model ...
epoch 801, loss 0.4860, train acc 77.44%, f1 0.6229, precision 0.7517, recall 0.5317, auc 0.7185
Validation loss decreased (0.486006 --> 0.485925).  Saving model ...
Validation loss decreased (0.485925 --> 0.485845).  Saving model ...
Validation loss decreased (0.485845 --> 0.485765).  Saving model ...
Validation loss decreased (0.485765 --> 0.485685).  Saving model ...
Validation loss decreased (0.485685 --> 0.485605).  Saving model ...
Validation loss decreased (0.485605 --> 0.485526).  Saving model ...
Validation loss decreased (0.485526 --> 0.485447).  Saving model ...
Validation loss decreased (0.485447 --> 0.485368).  Saving model ...
Validation loss decreased (0.485368 --> 0.485289).  Saving model ...
Validation loss decreased (0.485289 --> 0.485211).  Saving model ...
Validation loss decreased (0.485211 --> 0.485133).  Saving model ...
Validation loss decreased (0.485133 --> 0.485055).  Saving model ...
Validation loss decreased (0.485055 --> 0.484977).  Saving model ...
Validation loss decreased (0.484977 --> 0.484899).  Saving model ...
Validation loss decreased (0.484899 --> 0.484822).  Saving model ...
Validation loss decreased (0.484822 --> 0.484744).  Saving model ...
Validation loss decreased (0.484744 --> 0.484668).  Saving model ...
Validation loss decreased (0.484668 --> 0.484591).  Saving model ...
Validation loss decreased (0.484591 --> 0.484514).  Saving model ...
Validation loss decreased (0.484514 --> 0.484438).  Saving model ...
Validation loss decreased (0.484438 --> 0.484362).  Saving model ...
Validation loss decreased (0.484362 --> 0.484286).  Saving model ...
Validation loss decreased (0.484286 --> 0.484210).  Saving model ...
Validation loss decreased (0.484210 --> 0.484135).  Saving model ...
Validation loss decreased (0.484135 --> 0.484059).  Saving model ...
Validation loss decreased (0.484059 --> 0.483984).  Saving model ...
Validation loss decreased (0.483984 --> 0.483909).  Saving model ...
Validation loss decreased (0.483909 --> 0.483835).  Saving model ...
Validation loss decreased (0.483835 --> 0.483760).  Saving model ...
Validation loss decreased (0.483760 --> 0.483686).  Saving model ...
Validation loss decreased (0.483686 --> 0.483612).  Saving model ...
Validation loss decreased (0.483612 --> 0.483538).  Saving model ...
Validation loss decreased (0.483538 --> 0.483465).  Saving model ...
Validation loss decreased (0.483465 --> 0.483391).  Saving model ...
Validation loss decreased (0.483391 --> 0.483318).  Saving model ...
Validation loss decreased (0.483318 --> 0.483245).  Saving model ...
Validation loss decreased (0.483245 --> 0.483172).  Saving model ...
Validation loss decreased (0.483172 --> 0.483100).  Saving model ...
Validation loss decreased (0.483100 --> 0.483027).  Saving model ...
Validation loss decreased (0.483027 --> 0.482955).  Saving model ...
Validation loss decreased (0.482955 --> 0.482883).  Saving model ...
Validation loss decreased (0.482883 --> 0.482811).  Saving model ...
Validation loss decreased (0.482811 --> 0.482740).  Saving model ...
Validation loss decreased (0.482740 --> 0.482668).  Saving model ...
Validation loss decreased (0.482668 --> 0.482597).  Saving model ...
Validation loss decreased (0.482597 --> 0.482526).  Saving model ...
Validation loss decreased (0.482526 --> 0.482455).  Saving model ...
Validation loss decreased (0.482455 --> 0.482385).  Saving model ...
Validation loss decreased (0.482385 --> 0.482314).  Saving model ...
Validation loss decreased (0.482314 --> 0.482244).  Saving model ...
Validation loss decreased (0.482244 --> 0.482174).  Saving model ...
Validation loss decreased (0.482174 --> 0.482104).  Saving model ...
Validation loss decreased (0.482104 --> 0.482034).  Saving model ...
Validation loss decreased (0.482034 --> 0.481965).  Saving model ...
Validation loss decreased (0.481965 --> 0.481896).  Saving model ...
Validation loss decreased (0.481896 --> 0.481827).  Saving model ...
Validation loss decreased (0.481827 --> 0.481758).  Saving model ...
Validation loss decreased (0.481758 --> 0.481689).  Saving model ...
Validation loss decreased (0.481689 --> 0.481621).  Saving model ...
Validation loss decreased (0.481621 --> 0.481553).  Saving model ...
Validation loss decreased (0.481553 --> 0.481485).  Saving model ...
Validation loss decreased (0.481485 --> 0.481417).  Saving model ...
Validation loss decreased (0.481417 --> 0.481349).  Saving model ...
Validation loss decreased (0.481349 --> 0.481281).  Saving model ...
Validation loss decreased (0.481281 --> 0.481214).  Saving model ...
Validation loss decreased (0.481214 --> 0.481147).  Saving model ...
Validation loss decreased (0.481147 --> 0.481080).  Saving model ...
Validation loss decreased (0.481080 --> 0.481013).  Saving model ...
Validation loss decreased (0.481013 --> 0.480947).  Saving model ...
Validation loss decreased (0.480947 --> 0.480880).  Saving model ...
Validation loss decreased (0.480880 --> 0.480814).  Saving model ...
Validation loss decreased (0.480814 --> 0.480748).  Saving model ...
Validation loss decreased (0.480748 --> 0.480682).  Saving model ...
Validation loss decreased (0.480682 --> 0.480617).  Saving model ...
Validation loss decreased (0.480617 --> 0.480551).  Saving model ...
Validation loss decreased (0.480551 --> 0.480486).  Saving model ...
Validation loss decreased (0.480486 --> 0.480421).  Saving model ...
Validation loss decreased (0.480421 --> 0.480356).  Saving model ...
Validation loss decreased (0.480356 --> 0.480291).  Saving model ...
Validation loss decreased (0.480291 --> 0.480227).  Saving model ...
Validation loss decreased (0.480227 --> 0.480162).  Saving model ...
Validation loss decreased (0.480162 --> 0.480098).  Saving model ...
Validation loss decreased (0.480098 --> 0.480034).  Saving model ...
Validation loss decreased (0.480034 --> 0.479970).  Saving model ...
Validation loss decreased (0.479970 --> 0.479907).  Saving model ...
Validation loss decreased (0.479907 --> 0.479843).  Saving model ...
Validation loss decreased (0.479843 --> 0.479780).  Saving model ...
Validation loss decreased (0.479780 --> 0.479717).  Saving model ...
Validation loss decreased (0.479717 --> 0.479654).  Saving model ...
Validation loss decreased (0.479654 --> 0.479591).  Saving model ...
Validation loss decreased (0.479591 --> 0.479529).  Saving model ...
Validation loss decreased (0.479529 --> 0.479466).  Saving model ...
Validation loss decreased (0.479466 --> 0.479404).  Saving model ...
Validation loss decreased (0.479404 --> 0.479342).  Saving model ...
Validation loss decreased (0.479342 --> 0.479280).  Saving model ...
Validation loss decreased (0.479280 --> 0.479219).  Saving model ...
Validation loss decreased (0.479219 --> 0.479157).  Saving model ...
Validation loss decreased (0.479157 --> 0.479096).  Saving model ...
Validation loss decreased (0.479096 --> 0.479035).  Saving model ...
Validation loss decreased (0.479035 --> 0.478974).  Saving model ...
epoch 901, loss 0.4790, train acc 78.29%, f1 0.6501, precision 0.7468, recall 0.5756, auc 0.7352
Validation loss decreased (0.478974 --> 0.478913).  Saving model ...
Validation loss decreased (0.478913 --> 0.478852).  Saving model ...
Validation loss decreased (0.478852 --> 0.478792).  Saving model ...
Validation loss decreased (0.478792 --> 0.478732).  Saving model ...
Validation loss decreased (0.478732 --> 0.478671).  Saving model ...
Validation loss decreased (0.478671 --> 0.478611).  Saving model ...
Validation loss decreased (0.478611 --> 0.478552).  Saving model ...
Validation loss decreased (0.478552 --> 0.478492).  Saving model ...
Validation loss decreased (0.478492 --> 0.478433).  Saving model ...
Validation loss decreased (0.478433 --> 0.478373).  Saving model ...
Validation loss decreased (0.478373 --> 0.478314).  Saving model ...
Validation loss decreased (0.478314 --> 0.478255).  Saving model ...
Validation loss decreased (0.478255 --> 0.478197).  Saving model ...
Validation loss decreased (0.478197 --> 0.478138).  Saving model ...
Validation loss decreased (0.478138 --> 0.478079).  Saving model ...
Validation loss decreased (0.478079 --> 0.478021).  Saving model ...
Validation loss decreased (0.478021 --> 0.477963).  Saving model ...
Validation loss decreased (0.477963 --> 0.477905).  Saving model ...
Validation loss decreased (0.477905 --> 0.477847).  Saving model ...
Validation loss decreased (0.477847 --> 0.477790).  Saving model ...
Validation loss decreased (0.477790 --> 0.477732).  Saving model ...
Validation loss decreased (0.477732 --> 0.477675).  Saving model ...
Validation loss decreased (0.477675 --> 0.477618).  Saving model ...
Validation loss decreased (0.477618 --> 0.477561).  Saving model ...
Validation loss decreased (0.477561 --> 0.477504).  Saving model ...
Validation loss decreased (0.477504 --> 0.477448).  Saving model ...
Validation loss decreased (0.477448 --> 0.477391).  Saving model ...
Validation loss decreased (0.477391 --> 0.477335).  Saving model ...
Validation loss decreased (0.477335 --> 0.477279).  Saving model ...
Validation loss decreased (0.477279 --> 0.477223).  Saving model ...
Validation loss decreased (0.477223 --> 0.477167).  Saving model ...
Validation loss decreased (0.477167 --> 0.477111).  Saving model ...
Validation loss decreased (0.477111 --> 0.477056).  Saving model ...
Validation loss decreased (0.477056 --> 0.477000).  Saving model ...
Validation loss decreased (0.477000 --> 0.476945).  Saving model ...
Validation loss decreased (0.476945 --> 0.476890).  Saving model ...
Validation loss decreased (0.476890 --> 0.476835).  Saving model ...
Validation loss decreased (0.476835 --> 0.476780).  Saving model ...
Validation loss decreased (0.476780 --> 0.476726).  Saving model ...
Validation loss decreased (0.476726 --> 0.476671).  Saving model ...
Validation loss decreased (0.476671 --> 0.476617).  Saving model ...
Validation loss decreased (0.476617 --> 0.476563).  Saving model ...
Validation loss decreased (0.476563 --> 0.476509).  Saving model ...
Validation loss decreased (0.476509 --> 0.476455).  Saving model ...
Validation loss decreased (0.476455 --> 0.476401).  Saving model ...
Validation loss decreased (0.476401 --> 0.476348).  Saving model ...
Validation loss decreased (0.476348 --> 0.476295).  Saving model ...
Validation loss decreased (0.476295 --> 0.476241).  Saving model ...
Validation loss decreased (0.476241 --> 0.476188).  Saving model ...
Validation loss decreased (0.476188 --> 0.476136).  Saving model ...
Validation loss decreased (0.476136 --> 0.476083).  Saving model ...
Validation loss decreased (0.476083 --> 0.476030).  Saving model ...
Validation loss decreased (0.476030 --> 0.475978).  Saving model ...
Validation loss decreased (0.475978 --> 0.475925).  Saving model ...
Validation loss decreased (0.475925 --> 0.475873).  Saving model ...
Validation loss decreased (0.475873 --> 0.475821).  Saving model ...
Validation loss decreased (0.475821 --> 0.475769).  Saving model ...
Validation loss decreased (0.475769 --> 0.475718).  Saving model ...
Validation loss decreased (0.475718 --> 0.475666).  Saving model ...
Validation loss decreased (0.475666 --> 0.475615).  Saving model ...
Validation loss decreased (0.475615 --> 0.475563).  Saving model ...
Validation loss decreased (0.475563 --> 0.475512).  Saving model ...
Validation loss decreased (0.475512 --> 0.475461).  Saving model ...
Validation loss decreased (0.475461 --> 0.475411).  Saving model ...
Validation loss decreased (0.475411 --> 0.475360).  Saving model ...
Validation loss decreased (0.475360 --> 0.475309).  Saving model ...
Validation loss decreased (0.475309 --> 0.475259).  Saving model ...
Validation loss decreased (0.475259 --> 0.475209).  Saving model ...
Validation loss decreased (0.475209 --> 0.475159).  Saving model ...
Validation loss decreased (0.475159 --> 0.475109).  Saving model ...
Validation loss decreased (0.475109 --> 0.475059).  Saving model ...
Validation loss decreased (0.475059 --> 0.475009).  Saving model ...
Validation loss decreased (0.475009 --> 0.474960).  Saving model ...
Validation loss decreased (0.474960 --> 0.474910).  Saving model ...
Validation loss decreased (0.474910 --> 0.474861).  Saving model ...
Validation loss decreased (0.474861 --> 0.474812).  Saving model ...
Validation loss decreased (0.474812 --> 0.474763).  Saving model ...
Validation loss decreased (0.474763 --> 0.474714).  Saving model ...
Validation loss decreased (0.474714 --> 0.474665).  Saving model ...
Validation loss decreased (0.474665 --> 0.474617).  Saving model ...
Validation loss decreased (0.474617 --> 0.474568).  Saving model ...
Validation loss decreased (0.474568 --> 0.474520).  Saving model ...
Validation loss decreased (0.474520 --> 0.474472).  Saving model ...
Validation loss decreased (0.474472 --> 0.474424).  Saving model ...
Validation loss decreased (0.474424 --> 0.474376).  Saving model ...
Validation loss decreased (0.474376 --> 0.474328).  Saving model ...
Validation loss decreased (0.474328 --> 0.474281).  Saving model ...
Validation loss decreased (0.474281 --> 0.474233).  Saving model ...
Validation loss decreased (0.474233 --> 0.474186).  Saving model ...
Validation loss decreased (0.474186 --> 0.474139).  Saving model ...
Validation loss decreased (0.474139 --> 0.474092).  Saving model ...
Validation loss decreased (0.474092 --> 0.474045).  Saving model ...
Validation loss decreased (0.474045 --> 0.473998).  Saving model ...
Validation loss decreased (0.473998 --> 0.473951).  Saving model ...
Validation loss decreased (0.473951 --> 0.473905).  Saving model ...
Validation loss decreased (0.473905 --> 0.473858).  Saving model ...
Validation loss decreased (0.473858 --> 0.473812).  Saving model ...
Validation loss decreased (0.473812 --> 0.473766).  Saving model ...
Validation loss decreased (0.473766 --> 0.473720).  Saving model ...
Validation loss decreased (0.473720 --> 0.473674).  Saving model ...
epoch 1001, loss 0.4737, train acc 78.12%, f1 0.6522, precision 0.7362, recall 0.5854, auc 0.7361
Validation loss decreased (0.473674 --> 0.473628).  Saving model ...
Validation loss decreased (0.473628 --> 0.473582).  Saving model ...
Validation loss decreased (0.473582 --> 0.473537).  Saving model ...
Validation loss decreased (0.473537 --> 0.473492).  Saving model ...
Validation loss decreased (0.473492 --> 0.473446).  Saving model ...
Validation loss decreased (0.473446 --> 0.473401).  Saving model ...
Validation loss decreased (0.473401 --> 0.473356).  Saving model ...
Validation loss decreased (0.473356 --> 0.473311).  Saving model ...
Validation loss decreased (0.473311 --> 0.473267).  Saving model ...
Validation loss decreased (0.473267 --> 0.473222).  Saving model ...
Validation loss decreased (0.473222 --> 0.473178).  Saving model ...
Validation loss decreased (0.473178 --> 0.473133).  Saving model ...
Validation loss decreased (0.473133 --> 0.473089).  Saving model ...
Validation loss decreased (0.473089 --> 0.473045).  Saving model ...
Validation loss decreased (0.473045 --> 0.473001).  Saving model ...
Validation loss decreased (0.473001 --> 0.472957).  Saving model ...
Validation loss decreased (0.472957 --> 0.472913).  Saving model ...
Validation loss decreased (0.472913 --> 0.472870).  Saving model ...
Validation loss decreased (0.472870 --> 0.472826).  Saving model ...
Validation loss decreased (0.472826 --> 0.472783).  Saving model ...
Validation loss decreased (0.472783 --> 0.472740).  Saving model ...
Validation loss decreased (0.472740 --> 0.472696).  Saving model ...
Validation loss decreased (0.472696 --> 0.472653).  Saving model ...
Validation loss decreased (0.472653 --> 0.472611).  Saving model ...
Validation loss decreased (0.472611 --> 0.472568).  Saving model ...
Validation loss decreased (0.472568 --> 0.472525).  Saving model ...
Validation loss decreased (0.472525 --> 0.472483).  Saving model ...
Validation loss decreased (0.472483 --> 0.472440).  Saving model ...
Validation loss decreased (0.472440 --> 0.472398).  Saving model ...
Validation loss decreased (0.472398 --> 0.472356).  Saving model ...
Validation loss decreased (0.472356 --> 0.472314).  Saving model ...
Validation loss decreased (0.472314 --> 0.472272).  Saving model ...
Validation loss decreased (0.472272 --> 0.472230).  Saving model ...
Validation loss decreased (0.472230 --> 0.472188).  Saving model ...
Validation loss decreased (0.472188 --> 0.472146).  Saving model ...
Validation loss decreased (0.472146 --> 0.472105).  Saving model ...
Validation loss decreased (0.472105 --> 0.472064).  Saving model ...
Validation loss decreased (0.472064 --> 0.472022).  Saving model ...
Validation loss decreased (0.472022 --> 0.471981).  Saving model ...
Validation loss decreased (0.471981 --> 0.471940).  Saving model ...
Validation loss decreased (0.471940 --> 0.471899).  Saving model ...
Validation loss decreased (0.471899 --> 0.471858).  Saving model ...
Validation loss decreased (0.471858 --> 0.471818).  Saving model ...
Validation loss decreased (0.471818 --> 0.471777).  Saving model ...
Validation loss decreased (0.471777 --> 0.471737).  Saving model ...
Validation loss decreased (0.471737 --> 0.471696).  Saving model ...
Validation loss decreased (0.471696 --> 0.471656).  Saving model ...
Validation loss decreased (0.471656 --> 0.471616).  Saving model ...
Validation loss decreased (0.471616 --> 0.471576).  Saving model ...
Validation loss decreased (0.471576 --> 0.471536).  Saving model ...
Validation loss decreased (0.471536 --> 0.471496).  Saving model ...
Validation loss decreased (0.471496 --> 0.471456).  Saving model ...
Validation loss decreased (0.471456 --> 0.471417).  Saving model ...
Validation loss decreased (0.471417 --> 0.471377).  Saving model ...
Validation loss decreased (0.471377 --> 0.471338).  Saving model ...
Validation loss decreased (0.471338 --> 0.471299).  Saving model ...
Validation loss decreased (0.471299 --> 0.471259).  Saving model ...
Validation loss decreased (0.471259 --> 0.471220).  Saving model ...
Validation loss decreased (0.471220 --> 0.471181).  Saving model ...
Validation loss decreased (0.471181 --> 0.471142).  Saving model ...
Validation loss decreased (0.471142 --> 0.471104).  Saving model ...
Validation loss decreased (0.471104 --> 0.471065).  Saving model ...
Validation loss decreased (0.471065 --> 0.471026).  Saving model ...
Validation loss decreased (0.471026 --> 0.470988).  Saving model ...
Validation loss decreased (0.470988 --> 0.470950).  Saving model ...
Validation loss decreased (0.470950 --> 0.470911).  Saving model ...
Validation loss decreased (0.470911 --> 0.470873).  Saving model ...
Validation loss decreased (0.470873 --> 0.470835).  Saving model ...
Validation loss decreased (0.470835 --> 0.470797).  Saving model ...
Validation loss decreased (0.470797 --> 0.470759).  Saving model ...
Validation loss decreased (0.470759 --> 0.470722).  Saving model ...
Validation loss decreased (0.470722 --> 0.470684).  Saving model ...
Validation loss decreased (0.470684 --> 0.470646).  Saving model ...
Validation loss decreased (0.470646 --> 0.470609).  Saving model ...
Validation loss decreased (0.470609 --> 0.470572).  Saving model ...
Validation loss decreased (0.470572 --> 0.470534).  Saving model ...
Validation loss decreased (0.470534 --> 0.470497).  Saving model ...
Validation loss decreased (0.470497 --> 0.470460).  Saving model ...
Validation loss decreased (0.470460 --> 0.470423).  Saving model ...
Validation loss decreased (0.470423 --> 0.470386).  Saving model ...
Validation loss decreased (0.470386 --> 0.470349).  Saving model ...
Validation loss decreased (0.470349 --> 0.470313).  Saving model ...
Validation loss decreased (0.470313 --> 0.470276).  Saving model ...
Validation loss decreased (0.470276 --> 0.470239).  Saving model ...
Validation loss decreased (0.470239 --> 0.470203).  Saving model ...
Validation loss decreased (0.470203 --> 0.470167).  Saving model ...
Validation loss decreased (0.470167 --> 0.470130).  Saving model ...
Validation loss decreased (0.470130 --> 0.470094).  Saving model ...
Validation loss decreased (0.470094 --> 0.470058).  Saving model ...
Validation loss decreased (0.470058 --> 0.470022).  Saving model ...
Validation loss decreased (0.470022 --> 0.469986).  Saving model ...
Validation loss decreased (0.469986 --> 0.469950).  Saving model ...
Validation loss decreased (0.469950 --> 0.469915).  Saving model ...
Validation loss decreased (0.469915 --> 0.469879).  Saving model ...
Validation loss decreased (0.469879 --> 0.469844).  Saving model ...
Validation loss decreased (0.469844 --> 0.469808).  Saving model ...
Validation loss decreased (0.469808 --> 0.469773).  Saving model ...
Validation loss decreased (0.469773 --> 0.469737).  Saving model ...
Validation loss decreased (0.469737 --> 0.469702).  Saving model ...
Validation loss decreased (0.469702 --> 0.469667).  Saving model ...
epoch 1101, loss 0.4697, train acc 78.63%, f1 0.6667, precision 0.7353, recall 0.6098, auc 0.7457
Validation loss decreased (0.469667 --> 0.469632).  Saving model ...
Validation loss decreased (0.469632 --> 0.469597).  Saving model ...
Validation loss decreased (0.469597 --> 0.469562).  Saving model ...
Validation loss decreased (0.469562 --> 0.469527).  Saving model ...
Validation loss decreased (0.469527 --> 0.469493).  Saving model ...
Validation loss decreased (0.469493 --> 0.469458).  Saving model ...
Validation loss decreased (0.469458 --> 0.469424).  Saving model ...
Validation loss decreased (0.469424 --> 0.469389).  Saving model ...
Validation loss decreased (0.469389 --> 0.469355).  Saving model ...
Validation loss decreased (0.469355 --> 0.469320).  Saving model ...
Validation loss decreased (0.469320 --> 0.469286).  Saving model ...
Validation loss decreased (0.469286 --> 0.469252).  Saving model ...
Validation loss decreased (0.469252 --> 0.469218).  Saving model ...
Validation loss decreased (0.469218 --> 0.469184).  Saving model ...
Validation loss decreased (0.469184 --> 0.469150).  Saving model ...
Validation loss decreased (0.469150 --> 0.469116).  Saving model ...
Validation loss decreased (0.469116 --> 0.469082).  Saving model ...
Validation loss decreased (0.469082 --> 0.469049).  Saving model ...
Validation loss decreased (0.469049 --> 0.469015).  Saving model ...
Validation loss decreased (0.469015 --> 0.468981).  Saving model ...
Validation loss decreased (0.468981 --> 0.468948).  Saving model ...
Validation loss decreased (0.468948 --> 0.468914).  Saving model ...
Validation loss decreased (0.468914 --> 0.468881).  Saving model ...
Validation loss decreased (0.468881 --> 0.468848).  Saving model ...
Validation loss decreased (0.468848 --> 0.468814).  Saving model ...
Validation loss decreased (0.468814 --> 0.468781).  Saving model ...
Validation loss decreased (0.468781 --> 0.468748).  Saving model ...
Validation loss decreased (0.468748 --> 0.468715).  Saving model ...
Validation loss decreased (0.468715 --> 0.468682).  Saving model ...
Validation loss decreased (0.468682 --> 0.468649).  Saving model ...
Validation loss decreased (0.468649 --> 0.468616).  Saving model ...
Validation loss decreased (0.468616 --> 0.468584).  Saving model ...
Validation loss decreased (0.468584 --> 0.468551).  Saving model ...
Validation loss decreased (0.468551 --> 0.468518).  Saving model ...
Validation loss decreased (0.468518 --> 0.468486).  Saving model ...
Validation loss decreased (0.468486 --> 0.468453).  Saving model ...
Validation loss decreased (0.468453 --> 0.468421).  Saving model ...
Validation loss decreased (0.468421 --> 0.468388).  Saving model ...
Validation loss decreased (0.468388 --> 0.468356).  Saving model ...
Validation loss decreased (0.468356 --> 0.468324).  Saving model ...
Validation loss decreased (0.468324 --> 0.468291).  Saving model ...
Validation loss decreased (0.468291 --> 0.468259).  Saving model ...
Validation loss decreased (0.468259 --> 0.468227).  Saving model ...
Validation loss decreased (0.468227 --> 0.468195).  Saving model ...
Validation loss decreased (0.468195 --> 0.468163).  Saving model ...
Validation loss decreased (0.468163 --> 0.468131).  Saving model ...
Validation loss decreased (0.468131 --> 0.468099).  Saving model ...
Validation loss decreased (0.468099 --> 0.468067).  Saving model ...
Validation loss decreased (0.468067 --> 0.468036).  Saving model ...
Validation loss decreased (0.468036 --> 0.468004).  Saving model ...
Validation loss decreased (0.468004 --> 0.467972).  Saving model ...
Validation loss decreased (0.467972 --> 0.467941).  Saving model ...
Validation loss decreased (0.467941 --> 0.467909).  Saving model ...
Validation loss decreased (0.467909 --> 0.467877).  Saving model ...
Validation loss decreased (0.467877 --> 0.467846).  Saving model ...
Validation loss decreased (0.467846 --> 0.467815).  Saving model ...
Validation loss decreased (0.467815 --> 0.467783).  Saving model ...
Validation loss decreased (0.467783 --> 0.467752).  Saving model ...
Validation loss decreased (0.467752 --> 0.467720).  Saving model ...
Validation loss decreased (0.467720 --> 0.467689).  Saving model ...
Validation loss decreased (0.467689 --> 0.467658).  Saving model ...
Validation loss decreased (0.467658 --> 0.467627).  Saving model ...
Validation loss decreased (0.467627 --> 0.467596).  Saving model ...
Validation loss decreased (0.467596 --> 0.467565).  Saving model ...
Validation loss decreased (0.467565 --> 0.467533).  Saving model ...
Validation loss decreased (0.467533 --> 0.467502).  Saving model ...
Validation loss decreased (0.467502 --> 0.467471).  Saving model ...
Validation loss decreased (0.467471 --> 0.467440).  Saving model ...
Validation loss decreased (0.467440 --> 0.467409).  Saving model ...
Validation loss decreased (0.467409 --> 0.467379).  Saving model ...
Validation loss decreased (0.467379 --> 0.467348).  Saving model ...
Validation loss decreased (0.467348 --> 0.467317).  Saving model ...
Validation loss decreased (0.467317 --> 0.467286).  Saving model ...
Validation loss decreased (0.467286 --> 0.467255).  Saving model ...
Validation loss decreased (0.467255 --> 0.467225).  Saving model ...
Validation loss decreased (0.467225 --> 0.467194).  Saving model ...
Validation loss decreased (0.467194 --> 0.467163).  Saving model ...
Validation loss decreased (0.467163 --> 0.467133).  Saving model ...
Validation loss decreased (0.467133 --> 0.467102).  Saving model ...
Validation loss decreased (0.467102 --> 0.467071).  Saving model ...
Validation loss decreased (0.467071 --> 0.467041).  Saving model ...
Validation loss decreased (0.467041 --> 0.467010).  Saving model ...
Validation loss decreased (0.467010 --> 0.466980).  Saving model ...
Validation loss decreased (0.466980 --> 0.466949).  Saving model ...
Validation loss decreased (0.466949 --> 0.466919).  Saving model ...
Validation loss decreased (0.466919 --> 0.466888).  Saving model ...
Validation loss decreased (0.466888 --> 0.466858).  Saving model ...
Validation loss decreased (0.466858 --> 0.466828).  Saving model ...
Validation loss decreased (0.466828 --> 0.466797).  Saving model ...
Validation loss decreased (0.466797 --> 0.466767).  Saving model ...
Validation loss decreased (0.466767 --> 0.466736).  Saving model ...
Validation loss decreased (0.466736 --> 0.466706).  Saving model ...
Validation loss decreased (0.466706 --> 0.466676).  Saving model ...
Validation loss decreased (0.466676 --> 0.466645).  Saving model ...
Validation loss decreased (0.466645 --> 0.466615).  Saving model ...
Validation loss decreased (0.466615 --> 0.466585).  Saving model ...
Validation loss decreased (0.466585 --> 0.466555).  Saving model ...
Validation loss decreased (0.466555 --> 0.466524).  Saving model ...
Validation loss decreased (0.466524 --> 0.466494).  Saving model ...
Validation loss decreased (0.466494 --> 0.466464).  Saving model ...
epoch 1201, loss 0.4665, train acc 78.63%, f1 0.6719, precision 0.7273, recall 0.6244, auc 0.7490
Validation loss decreased (0.466464 --> 0.466434).  Saving model ...
Validation loss decreased (0.466434 --> 0.466403).  Saving model ...
Validation loss decreased (0.466403 --> 0.466373).  Saving model ...
Validation loss decreased (0.466373 --> 0.466343).  Saving model ...
Validation loss decreased (0.466343 --> 0.466313).  Saving model ...
Validation loss decreased (0.466313 --> 0.466282).  Saving model ...
Validation loss decreased (0.466282 --> 0.466252).  Saving model ...
Validation loss decreased (0.466252 --> 0.466222).  Saving model ...
Validation loss decreased (0.466222 --> 0.466192).  Saving model ...
Validation loss decreased (0.466192 --> 0.466162).  Saving model ...
Validation loss decreased (0.466162 --> 0.466131).  Saving model ...
Validation loss decreased (0.466131 --> 0.466101).  Saving model ...
Validation loss decreased (0.466101 --> 0.466071).  Saving model ...
Validation loss decreased (0.466071 --> 0.466041).  Saving model ...
Validation loss decreased (0.466041 --> 0.466010).  Saving model ...
Validation loss decreased (0.466010 --> 0.465980).  Saving model ...
Validation loss decreased (0.465980 --> 0.465950).  Saving model ...
Validation loss decreased (0.465950 --> 0.465920).  Saving model ...
Validation loss decreased (0.465920 --> 0.465889).  Saving model ...
Validation loss decreased (0.465889 --> 0.465859).  Saving model ...
Validation loss decreased (0.465859 --> 0.465829).  Saving model ...
Validation loss decreased (0.465829 --> 0.465798).  Saving model ...
Validation loss decreased (0.465798 --> 0.465768).  Saving model ...
Validation loss decreased (0.465768 --> 0.465738).  Saving model ...
Validation loss decreased (0.465738 --> 0.465707).  Saving model ...
Validation loss decreased (0.465707 --> 0.465677).  Saving model ...
Validation loss decreased (0.465677 --> 0.465647).  Saving model ...
Validation loss decreased (0.465647 --> 0.465616).  Saving model ...
Validation loss decreased (0.465616 --> 0.465586).  Saving model ...
Validation loss decreased (0.465586 --> 0.465555).  Saving model ...
Validation loss decreased (0.465555 --> 0.465525).  Saving model ...
Validation loss decreased (0.465525 --> 0.465494).  Saving model ...
Validation loss decreased (0.465494 --> 0.465464).  Saving model ...
Validation loss decreased (0.465464 --> 0.465434).  Saving model ...
Validation loss decreased (0.465434 --> 0.465403).  Saving model ...
Validation loss decreased (0.465403 --> 0.465372).  Saving model ...
Validation loss decreased (0.465372 --> 0.465342).  Saving model ...
Validation loss decreased (0.465342 --> 0.465311).  Saving model ...
Validation loss decreased (0.465311 --> 0.465280).  Saving model ...
Validation loss decreased (0.465280 --> 0.465250).  Saving model ...
Validation loss decreased (0.465250 --> 0.465219).  Saving model ...
Validation loss decreased (0.465219 --> 0.465188).  Saving model ...
Validation loss decreased (0.465188 --> 0.465157).  Saving model ...
Validation loss decreased (0.465157 --> 0.465127).  Saving model ...
Validation loss decreased (0.465127 --> 0.465096).  Saving model ...
Validation loss decreased (0.465096 --> 0.465065).  Saving model ...
Validation loss decreased (0.465065 --> 0.465034).  Saving model ...
Validation loss decreased (0.465034 --> 0.465003).  Saving model ...
Validation loss decreased (0.465003 --> 0.464972).  Saving model ...
Validation loss decreased (0.464972 --> 0.464941).  Saving model ...
Validation loss decreased (0.464941 --> 0.464910).  Saving model ...
Validation loss decreased (0.464910 --> 0.464879).  Saving model ...
Validation loss decreased (0.464879 --> 0.464847).  Saving model ...
Validation loss decreased (0.464847 --> 0.464816).  Saving model ...
Validation loss decreased (0.464816 --> 0.464785).  Saving model ...
Validation loss decreased (0.464785 --> 0.464754).  Saving model ...
Validation loss decreased (0.464754 --> 0.464722).  Saving model ...
Validation loss decreased (0.464722 --> 0.464691).  Saving model ...
Validation loss decreased (0.464691 --> 0.464659).  Saving model ...
Validation loss decreased (0.464659 --> 0.464628).  Saving model ...
Validation loss decreased (0.464628 --> 0.464596).  Saving model ...
Validation loss decreased (0.464596 --> 0.464565).  Saving model ...
Validation loss decreased (0.464565 --> 0.464533).  Saving model ...
Validation loss decreased (0.464533 --> 0.464501).  Saving model ...
Validation loss decreased (0.464501 --> 0.464470).  Saving model ...
Validation loss decreased (0.464470 --> 0.464438).  Saving model ...
Validation loss decreased (0.464438 --> 0.464406).  Saving model ...
Validation loss decreased (0.464406 --> 0.464374).  Saving model ...
Validation loss decreased (0.464374 --> 0.464342).  Saving model ...
Validation loss decreased (0.464342 --> 0.464310).  Saving model ...
Validation loss decreased (0.464310 --> 0.464278).  Saving model ...
Validation loss decreased (0.464278 --> 0.464246).  Saving model ...
Validation loss decreased (0.464246 --> 0.464214).  Saving model ...
Validation loss decreased (0.464214 --> 0.464181).  Saving model ...
Validation loss decreased (0.464181 --> 0.464149).  Saving model ...
Validation loss decreased (0.464149 --> 0.464117).  Saving model ...
Validation loss decreased (0.464117 --> 0.464084).  Saving model ...
Validation loss decreased (0.464084 --> 0.464052).  Saving model ...
Validation loss decreased (0.464052 --> 0.464019).  Saving model ...
Validation loss decreased (0.464019 --> 0.463987).  Saving model ...
Validation loss decreased (0.463987 --> 0.463954).  Saving model ...
Validation loss decreased (0.463954 --> 0.463921).  Saving model ...
Validation loss decreased (0.463921 --> 0.463888).  Saving model ...
Validation loss decreased (0.463888 --> 0.463856).  Saving model ...
Validation loss decreased (0.463856 --> 0.463823).  Saving model ...
Validation loss decreased (0.463823 --> 0.463790).  Saving model ...
Validation loss decreased (0.463790 --> 0.463757).  Saving model ...
Validation loss decreased (0.463757 --> 0.463723).  Saving model ...
Validation loss decreased (0.463723 --> 0.463690).  Saving model ...
Validation loss decreased (0.463690 --> 0.463657).  Saving model ...
Validation loss decreased (0.463657 --> 0.463624).  Saving model ...
Validation loss decreased (0.463624 --> 0.463590).  Saving model ...
Validation loss decreased (0.463590 --> 0.463557).  Saving model ...
Validation loss decreased (0.463557 --> 0.463523).  Saving model ...
Validation loss decreased (0.463523 --> 0.463489).  Saving model ...
Validation loss decreased (0.463489 --> 0.463456).  Saving model ...
Validation loss decreased (0.463456 --> 0.463422).  Saving model ...
Validation loss decreased (0.463422 --> 0.463388).  Saving model ...
Validation loss decreased (0.463388 --> 0.463354).  Saving model ...
Validation loss decreased (0.463354 --> 0.463320).  Saving model ...
epoch 1301, loss 0.4633, train acc 78.80%, f1 0.6804, precision 0.7213, recall 0.6439, auc 0.7548
Validation loss decreased (0.463320 --> 0.463286).  Saving model ...
Validation loss decreased (0.463286 --> 0.463252).  Saving model ...
Validation loss decreased (0.463252 --> 0.463218).  Saving model ...
Validation loss decreased (0.463218 --> 0.463183).  Saving model ...
Validation loss decreased (0.463183 --> 0.463149).  Saving model ...
Validation loss decreased (0.463149 --> 0.463114).  Saving model ...
Validation loss decreased (0.463114 --> 0.463080).  Saving model ...
Validation loss decreased (0.463080 --> 0.463045).  Saving model ...
Validation loss decreased (0.463045 --> 0.463011).  Saving model ...
Validation loss decreased (0.463011 --> 0.462976).  Saving model ...
Validation loss decreased (0.462976 --> 0.462941).  Saving model ...
Validation loss decreased (0.462941 --> 0.462906).  Saving model ...
Validation loss decreased (0.462906 --> 0.462871).  Saving model ...
Validation loss decreased (0.462871 --> 0.462836).  Saving model ...
Validation loss decreased (0.462836 --> 0.462801).  Saving model ...
Validation loss decreased (0.462801 --> 0.462766).  Saving model ...
Validation loss decreased (0.462766 --> 0.462730).  Saving model ...
Validation loss decreased (0.462730 --> 0.462695).  Saving model ...
Validation loss decreased (0.462695 --> 0.462659).  Saving model ...
Validation loss decreased (0.462659 --> 0.462624).  Saving model ...
Validation loss decreased (0.462624 --> 0.462588).  Saving model ...
Validation loss decreased (0.462588 --> 0.462552).  Saving model ...
Validation loss decreased (0.462552 --> 0.462517).  Saving model ...
Validation loss decreased (0.462517 --> 0.462481).  Saving model ...
Validation loss decreased (0.462481 --> 0.462445).  Saving model ...
Validation loss decreased (0.462445 --> 0.462409).  Saving model ...
Validation loss decreased (0.462409 --> 0.462372).  Saving model ...
Validation loss decreased (0.462372 --> 0.462336).  Saving model ...
Validation loss decreased (0.462336 --> 0.462300).  Saving model ...
Validation loss decreased (0.462300 --> 0.462264).  Saving model ...
Validation loss decreased (0.462264 --> 0.462227).  Saving model ...
Validation loss decreased (0.462227 --> 0.462191).  Saving model ...
Validation loss decreased (0.462191 --> 0.462154).  Saving model ...
Validation loss decreased (0.462154 --> 0.462117).  Saving model ...
Validation loss decreased (0.462117 --> 0.462080).  Saving model ...
Validation loss decreased (0.462080 --> 0.462043).  Saving model ...
Validation loss decreased (0.462043 --> 0.462006).  Saving model ...
Validation loss decreased (0.462006 --> 0.461969).  Saving model ...
Validation loss decreased (0.461969 --> 0.461932).  Saving model ...
Validation loss decreased (0.461932 --> 0.461895).  Saving model ...
Validation loss decreased (0.461895 --> 0.461858).  Saving model ...
Validation loss decreased (0.461858 --> 0.461820).  Saving model ...
Validation loss decreased (0.461820 --> 0.461783).  Saving model ...
Validation loss decreased (0.461783 --> 0.461745).  Saving model ...
Validation loss decreased (0.461745 --> 0.461708).  Saving model ...
Validation loss decreased (0.461708 --> 0.461670).  Saving model ...
Validation loss decreased (0.461670 --> 0.461632).  Saving model ...
Validation loss decreased (0.461632 --> 0.461594).  Saving model ...
Validation loss decreased (0.461594 --> 0.461556).  Saving model ...
Validation loss decreased (0.461556 --> 0.461518).  Saving model ...
Validation loss decreased (0.461518 --> 0.461480).  Saving model ...
Validation loss decreased (0.461480 --> 0.461442).  Saving model ...
Validation loss decreased (0.461442 --> 0.461404).  Saving model ...
Validation loss decreased (0.461404 --> 0.461365).  Saving model ...
Validation loss decreased (0.461365 --> 0.461327).  Saving model ...
Validation loss decreased (0.461327 --> 0.461288).  Saving model ...
Validation loss decreased (0.461288 --> 0.461249).  Saving model ...
Validation loss decreased (0.461249 --> 0.461211).  Saving model ...
Validation loss decreased (0.461211 --> 0.461172).  Saving model ...
Validation loss decreased (0.461172 --> 0.461133).  Saving model ...
Validation loss decreased (0.461133 --> 0.461094).  Saving model ...
Validation loss decreased (0.461094 --> 0.461055).  Saving model ...
Validation loss decreased (0.461055 --> 0.461016).  Saving model ...
Validation loss decreased (0.461016 --> 0.460977).  Saving model ...
Validation loss decreased (0.460977 --> 0.460937).  Saving model ...
Validation loss decreased (0.460937 --> 0.460898).  Saving model ...
Validation loss decreased (0.460898 --> 0.460859).  Saving model ...
Validation loss decreased (0.460859 --> 0.460819).  Saving model ...
Validation loss decreased (0.460819 --> 0.460779).  Saving model ...
Validation loss decreased (0.460779 --> 0.460740).  Saving model ...
Validation loss decreased (0.460740 --> 0.460700).  Saving model ...
Validation loss decreased (0.460700 --> 0.460660).  Saving model ...
Validation loss decreased (0.460660 --> 0.460620).  Saving model ...
Validation loss decreased (0.460620 --> 0.460580).  Saving model ...
Validation loss decreased (0.460580 --> 0.460540).  Saving model ...
Validation loss decreased (0.460540 --> 0.460500).  Saving model ...
Validation loss decreased (0.460500 --> 0.460460).  Saving model ...
Validation loss decreased (0.460460 --> 0.460419).  Saving model ...
Validation loss decreased (0.460419 --> 0.460379).  Saving model ...
Validation loss decreased (0.460379 --> 0.460338).  Saving model ...
Validation loss decreased (0.460338 --> 0.460298).  Saving model ...
Validation loss decreased (0.460298 --> 0.460257).  Saving model ...
Validation loss decreased (0.460257 --> 0.460216).  Saving model ...
Validation loss decreased (0.460216 --> 0.460176).  Saving model ...
Validation loss decreased (0.460176 --> 0.460135).  Saving model ...
Validation loss decreased (0.460135 --> 0.460094).  Saving model ...
Validation loss decreased (0.460094 --> 0.460053).  Saving model ...
Validation loss decreased (0.460053 --> 0.460012).  Saving model ...
Validation loss decreased (0.460012 --> 0.459970).  Saving model ...
Validation loss decreased (0.459970 --> 0.459929).  Saving model ...
Validation loss decreased (0.459929 --> 0.459888).  Saving model ...
Validation loss decreased (0.459888 --> 0.459846).  Saving model ...
Validation loss decreased (0.459846 --> 0.459805).  Saving model ...
Validation loss decreased (0.459805 --> 0.459763).  Saving model ...
Validation loss decreased (0.459763 --> 0.459722).  Saving model ...
Validation loss decreased (0.459722 --> 0.459680).  Saving model ...
Validation loss decreased (0.459680 --> 0.459638).  Saving model ...
Validation loss decreased (0.459638 --> 0.459596).  Saving model ...
Validation loss decreased (0.459596 --> 0.459554).  Saving model ...
Validation loss decreased (0.459554 --> 0.459512).  Saving model ...
epoch 1401, loss 0.4595, train acc 78.97%, f1 0.6822, precision 0.7253, recall 0.6439, auc 0.7562
Validation loss decreased (0.459512 --> 0.459470).  Saving model ...
Validation loss decreased (0.459470 --> 0.459428).  Saving model ...
Validation loss decreased (0.459428 --> 0.459385).  Saving model ...
Validation loss decreased (0.459385 --> 0.459343).  Saving model ...
Validation loss decreased (0.459343 --> 0.459301).  Saving model ...
Validation loss decreased (0.459301 --> 0.459258).  Saving model ...
Validation loss decreased (0.459258 --> 0.459215).  Saving model ...
Validation loss decreased (0.459215 --> 0.459173).  Saving model ...
Validation loss decreased (0.459173 --> 0.459130).  Saving model ...
Validation loss decreased (0.459130 --> 0.459087).  Saving model ...
Validation loss decreased (0.459087 --> 0.459044).  Saving model ...
Validation loss decreased (0.459044 --> 0.459001).  Saving model ...
Validation loss decreased (0.459001 --> 0.458958).  Saving model ...
Validation loss decreased (0.458958 --> 0.458915).  Saving model ...
Validation loss decreased (0.458915 --> 0.458872).  Saving model ...
Validation loss decreased (0.458872 --> 0.458829).  Saving model ...
Validation loss decreased (0.458829 --> 0.458785).  Saving model ...
Validation loss decreased (0.458785 --> 0.458742).  Saving model ...
Validation loss decreased (0.458742 --> 0.458699).  Saving model ...
Validation loss decreased (0.458699 --> 0.458655).  Saving model ...
Validation loss decreased (0.458655 --> 0.458611).  Saving model ...
Validation loss decreased (0.458611 --> 0.458568).  Saving model ...
Validation loss decreased (0.458568 --> 0.458524).  Saving model ...
Validation loss decreased (0.458524 --> 0.458480).  Saving model ...
Validation loss decreased (0.458480 --> 0.458436).  Saving model ...
Validation loss decreased (0.458436 --> 0.458392).  Saving model ...
Validation loss decreased (0.458392 --> 0.458348).  Saving model ...
Validation loss decreased (0.458348 --> 0.458304).  Saving model ...
Validation loss decreased (0.458304 --> 0.458260).  Saving model ...
Validation loss decreased (0.458260 --> 0.458215).  Saving model ...
Validation loss decreased (0.458215 --> 0.458171).  Saving model ...
Validation loss decreased (0.458171 --> 0.458126).  Saving model ...
Validation loss decreased (0.458126 --> 0.458082).  Saving model ...
Validation loss decreased (0.458082 --> 0.458037).  Saving model ...
Validation loss decreased (0.458037 --> 0.457993).  Saving model ...
Validation loss decreased (0.457993 --> 0.457948).  Saving model ...
Validation loss decreased (0.457948 --> 0.457903).  Saving model ...
Validation loss decreased (0.457903 --> 0.457858).  Saving model ...
Validation loss decreased (0.457858 --> 0.457813).  Saving model ...
Validation loss decreased (0.457813 --> 0.457768).  Saving model ...
Validation loss decreased (0.457768 --> 0.457723).  Saving model ...
Validation loss decreased (0.457723 --> 0.457678).  Saving model ...
Validation loss decreased (0.457678 --> 0.457633).  Saving model ...
Validation loss decreased (0.457633 --> 0.457587).  Saving model ...
Validation loss decreased (0.457587 --> 0.457542).  Saving model ...
Validation loss decreased (0.457542 --> 0.457496).  Saving model ...
Validation loss decreased (0.457496 --> 0.457451).  Saving model ...
Validation loss decreased (0.457451 --> 0.457405).  Saving model ...
Validation loss decreased (0.457405 --> 0.457360).  Saving model ...
Validation loss decreased (0.457360 --> 0.457314).  Saving model ...
Validation loss decreased (0.457314 --> 0.457268).  Saving model ...
Validation loss decreased (0.457268 --> 0.457222).  Saving model ...
Validation loss decreased (0.457222 --> 0.457176).  Saving model ...
Validation loss decreased (0.457176 --> 0.457130).  Saving model ...
Validation loss decreased (0.457130 --> 0.457084).  Saving model ...
Validation loss decreased (0.457084 --> 0.457038).  Saving model ...
Validation loss decreased (0.457038 --> 0.456992).  Saving model ...
Validation loss decreased (0.456992 --> 0.456945).  Saving model ...
Validation loss decreased (0.456945 --> 0.456899).  Saving model ...
Validation loss decreased (0.456899 --> 0.456853).  Saving model ...
Validation loss decreased (0.456853 --> 0.456806).  Saving model ...
Validation loss decreased (0.456806 --> 0.456759).  Saving model ...
Validation loss decreased (0.456759 --> 0.456713).  Saving model ...
Validation loss decreased (0.456713 --> 0.456666).  Saving model ...
Validation loss decreased (0.456666 --> 0.456619).  Saving model ...
Validation loss decreased (0.456619 --> 0.456573).  Saving model ...
Validation loss decreased (0.456573 --> 0.456526).  Saving model ...
Validation loss decreased (0.456526 --> 0.456479).  Saving model ...
Validation loss decreased (0.456479 --> 0.456431).  Saving model ...
Validation loss decreased (0.456431 --> 0.456384).  Saving model ...
Validation loss decreased (0.456384 --> 0.456337).  Saving model ...
Validation loss decreased (0.456337 --> 0.456290).  Saving model ...
Validation loss decreased (0.456290 --> 0.456243).  Saving model ...
Validation loss decreased (0.456243 --> 0.456195).  Saving model ...
Validation loss decreased (0.456195 --> 0.456148).  Saving model ...
Validation loss decreased (0.456148 --> 0.456100).  Saving model ...
Validation loss decreased (0.456100 --> 0.456053).  Saving model ...
Validation loss decreased (0.456053 --> 0.456005).  Saving model ...
Validation loss decreased (0.456005 --> 0.455957).  Saving model ...
Validation loss decreased (0.455957 --> 0.455909).  Saving model ...
Validation loss decreased (0.455909 --> 0.455862).  Saving model ...
Validation loss decreased (0.455862 --> 0.455814).  Saving model ...
Validation loss decreased (0.455814 --> 0.455766).  Saving model ...
Validation loss decreased (0.455766 --> 0.455718).  Saving model ...
Validation loss decreased (0.455718 --> 0.455670).  Saving model ...
Validation loss decreased (0.455670 --> 0.455621).  Saving model ...
Validation loss decreased (0.455621 --> 0.455573).  Saving model ...
Validation loss decreased (0.455573 --> 0.455525).  Saving model ...
Validation loss decreased (0.455525 --> 0.455477).  Saving model ...
Validation loss decreased (0.455477 --> 0.455428).  Saving model ...
Validation loss decreased (0.455428 --> 0.455380).  Saving model ...
Validation loss decreased (0.455380 --> 0.455331).  Saving model ...
Validation loss decreased (0.455331 --> 0.455283).  Saving model ...
Validation loss decreased (0.455283 --> 0.455234).  Saving model ...
Validation loss decreased (0.455234 --> 0.455185).  Saving model ...
Validation loss decreased (0.455185 --> 0.455136).  Saving model ...
Validation loss decreased (0.455136 --> 0.455088).  Saving model ...
Validation loss decreased (0.455088 --> 0.455039).  Saving model ...
Validation loss decreased (0.455039 --> 0.454990).  Saving model ...
Validation loss decreased (0.454990 --> 0.454941).  Saving model ...
epoch 1501, loss 0.4549, train acc 78.80%, f1 0.6754, precision 0.7288, recall 0.6293, auc 0.7515
Validation loss decreased (0.454941 --> 0.454892).  Saving model ...
Validation loss decreased (0.454892 --> 0.454843).  Saving model ...
Validation loss decreased (0.454843 --> 0.454793).  Saving model ...
Validation loss decreased (0.454793 --> 0.454744).  Saving model ...
Validation loss decreased (0.454744 --> 0.454695).  Saving model ...
Validation loss decreased (0.454695 --> 0.454645).  Saving model ...
Validation loss decreased (0.454645 --> 0.454596).  Saving model ...
Validation loss decreased (0.454596 --> 0.454547).  Saving model ...
Validation loss decreased (0.454547 --> 0.454497).  Saving model ...
Validation loss decreased (0.454497 --> 0.454447).  Saving model ...
Validation loss decreased (0.454447 --> 0.454398).  Saving model ...
Validation loss decreased (0.454398 --> 0.454348).  Saving model ...
Validation loss decreased (0.454348 --> 0.454298).  Saving model ...
Validation loss decreased (0.454298 --> 0.454249).  Saving model ...
Validation loss decreased (0.454249 --> 0.454199).  Saving model ...
Validation loss decreased (0.454199 --> 0.454149).  Saving model ...
Validation loss decreased (0.454149 --> 0.454099).  Saving model ...
Validation loss decreased (0.454099 --> 0.454049).  Saving model ...
Validation loss decreased (0.454049 --> 0.453999).  Saving model ...
Validation loss decreased (0.453999 --> 0.453949).  Saving model ...
Validation loss decreased (0.453949 --> 0.453899).  Saving model ...
Validation loss decreased (0.453899 --> 0.453848).  Saving model ...
Validation loss decreased (0.453848 --> 0.453798).  Saving model ...
Validation loss decreased (0.453798 --> 0.453748).  Saving model ...
Validation loss decreased (0.453748 --> 0.453697).  Saving model ...
Validation loss decreased (0.453697 --> 0.453647).  Saving model ...
Validation loss decreased (0.453647 --> 0.453597).  Saving model ...
Validation loss decreased (0.453597 --> 0.453546).  Saving model ...
Validation loss decreased (0.453546 --> 0.453496).  Saving model ...
Validation loss decreased (0.453496 --> 0.453445).  Saving model ...
Validation loss decreased (0.453445 --> 0.453394).  Saving model ...
Validation loss decreased (0.453394 --> 0.453344).  Saving model ...
Validation loss decreased (0.453344 --> 0.453293).  Saving model ...
Validation loss decreased (0.453293 --> 0.453242).  Saving model ...
Validation loss decreased (0.453242 --> 0.453191).  Saving model ...
Validation loss decreased (0.453191 --> 0.453140).  Saving model ...
Validation loss decreased (0.453140 --> 0.453089).  Saving model ...
Validation loss decreased (0.453089 --> 0.453038).  Saving model ...
Validation loss decreased (0.453038 --> 0.452987).  Saving model ...
Validation loss decreased (0.452987 --> 0.452936).  Saving model ...
Validation loss decreased (0.452936 --> 0.452885).  Saving model ...
Validation loss decreased (0.452885 --> 0.452834).  Saving model ...
Validation loss decreased (0.452834 --> 0.452783).  Saving model ...
Validation loss decreased (0.452783 --> 0.452732).  Saving model ...
Validation loss decreased (0.452732 --> 0.452680).  Saving model ...
Validation loss decreased (0.452680 --> 0.452629).  Saving model ...
Validation loss decreased (0.452629 --> 0.452578).  Saving model ...
Validation loss decreased (0.452578 --> 0.452527).  Saving model ...
Validation loss decreased (0.452527 --> 0.452475).  Saving model ...
Validation loss decreased (0.452475 --> 0.452424).  Saving model ...
Validation loss decreased (0.452424 --> 0.452372).  Saving model ...
Validation loss decreased (0.452372 --> 0.452321).  Saving model ...
Validation loss decreased (0.452321 --> 0.452269).  Saving model ...
Validation loss decreased (0.452269 --> 0.452217).  Saving model ...
Validation loss decreased (0.452217 --> 0.452166).  Saving model ...
Validation loss decreased (0.452166 --> 0.452114).  Saving model ...
Validation loss decreased (0.452114 --> 0.452062).  Saving model ...
Validation loss decreased (0.452062 --> 0.452011).  Saving model ...
Validation loss decreased (0.452011 --> 0.451959).  Saving model ...
Validation loss decreased (0.451959 --> 0.451907).  Saving model ...
Validation loss decreased (0.451907 --> 0.451855).  Saving model ...
Validation loss decreased (0.451855 --> 0.451803).  Saving model ...
Validation loss decreased (0.451803 --> 0.451751).  Saving model ...
Validation loss decreased (0.451751 --> 0.451699).  Saving model ...
Validation loss decreased (0.451699 --> 0.451647).  Saving model ...
Validation loss decreased (0.451647 --> 0.451596).  Saving model ...
Validation loss decreased (0.451596 --> 0.451543).  Saving model ...
Validation loss decreased (0.451543 --> 0.451491).  Saving model ...
Validation loss decreased (0.451491 --> 0.451439).  Saving model ...
Validation loss decreased (0.451439 --> 0.451387).  Saving model ...
Validation loss decreased (0.451387 --> 0.451335).  Saving model ...
Validation loss decreased (0.451335 --> 0.451283).  Saving model ...
Validation loss decreased (0.451283 --> 0.451231).  Saving model ...
Validation loss decreased (0.451231 --> 0.451178).  Saving model ...
Validation loss decreased (0.451178 --> 0.451126).  Saving model ...
Validation loss decreased (0.451126 --> 0.451074).  Saving model ...
Validation loss decreased (0.451074 --> 0.451021).  Saving model ...
Validation loss decreased (0.451021 --> 0.450969).  Saving model ...
Validation loss decreased (0.450969 --> 0.450917).  Saving model ...
Validation loss decreased (0.450917 --> 0.450864).  Saving model ...
Validation loss decreased (0.450864 --> 0.450812).  Saving model ...
Validation loss decreased (0.450812 --> 0.450760).  Saving model ...
Validation loss decreased (0.450760 --> 0.450707).  Saving model ...
Validation loss decreased (0.450707 --> 0.450655).  Saving model ...
Validation loss decreased (0.450655 --> 0.450602).  Saving model ...
Validation loss decreased (0.450602 --> 0.450550).  Saving model ...
Validation loss decreased (0.450550 --> 0.450497).  Saving model ...
Validation loss decreased (0.450497 --> 0.450444).  Saving model ...
Validation loss decreased (0.450444 --> 0.450392).  Saving model ...
Validation loss decreased (0.450392 --> 0.450339).  Saving model ...
Validation loss decreased (0.450339 --> 0.450287).  Saving model ...
Validation loss decreased (0.450287 --> 0.450234).  Saving model ...
Validation loss decreased (0.450234 --> 0.450181).  Saving model ...
Validation loss decreased (0.450181 --> 0.450128).  Saving model ...
Validation loss decreased (0.450128 --> 0.450076).  Saving model ...
Validation loss decreased (0.450076 --> 0.450023).  Saving model ...
Validation loss decreased (0.450023 --> 0.449970).  Saving model ...
Validation loss decreased (0.449970 --> 0.449918).  Saving model ...
Validation loss decreased (0.449918 --> 0.449865).  Saving model ...
Validation loss decreased (0.449865 --> 0.449812).  Saving model ...
epoch 1601, loss 0.4498, train acc 79.15%, f1 0.6806, precision 0.7345, recall 0.6341, auc 0.7552
Validation loss decreased (0.449812 --> 0.449759).  Saving model ...
Validation loss decreased (0.449759 --> 0.449706).  Saving model ...
Validation loss decreased (0.449706 --> 0.449653).  Saving model ...
Validation loss decreased (0.449653 --> 0.449601).  Saving model ...
Validation loss decreased (0.449601 --> 0.449548).  Saving model ...
Validation loss decreased (0.449548 --> 0.449495).  Saving model ...
Validation loss decreased (0.449495 --> 0.449442).  Saving model ...
Validation loss decreased (0.449442 --> 0.449389).  Saving model ...
Validation loss decreased (0.449389 --> 0.449336).  Saving model ...
Validation loss decreased (0.449336 --> 0.449283).  Saving model ...
Validation loss decreased (0.449283 --> 0.449230).  Saving model ...
Validation loss decreased (0.449230 --> 0.449177).  Saving model ...
Validation loss decreased (0.449177 --> 0.449124).  Saving model ...
Validation loss decreased (0.449124 --> 0.449071).  Saving model ...
Validation loss decreased (0.449071 --> 0.449018).  Saving model ...
Validation loss decreased (0.449018 --> 0.448965).  Saving model ...
Validation loss decreased (0.448965 --> 0.448912).  Saving model ...
Validation loss decreased (0.448912 --> 0.448859).  Saving model ...
Validation loss decreased (0.448859 --> 0.448806).  Saving model ...
Validation loss decreased (0.448806 --> 0.448753).  Saving model ...
Validation loss decreased (0.448753 --> 0.448700).  Saving model ...
Validation loss decreased (0.448700 --> 0.448647).  Saving model ...
Validation loss decreased (0.448647 --> 0.448594).  Saving model ...
Validation loss decreased (0.448594 --> 0.448541).  Saving model ...
Validation loss decreased (0.448541 --> 0.448488).  Saving model ...
Validation loss decreased (0.448488 --> 0.448435).  Saving model ...
Validation loss decreased (0.448435 --> 0.448382).  Saving model ...
Validation loss decreased (0.448382 --> 0.448329).  Saving model ...
Validation loss decreased (0.448329 --> 0.448276).  Saving model ...
Validation loss decreased (0.448276 --> 0.448222).  Saving model ...
Validation loss decreased (0.448222 --> 0.448169).  Saving model ...
Validation loss decreased (0.448169 --> 0.448116).  Saving model ...
Validation loss decreased (0.448116 --> 0.448063).  Saving model ...
Validation loss decreased (0.448063 --> 0.448010).  Saving model ...
Validation loss decreased (0.448010 --> 0.447957).  Saving model ...
Validation loss decreased (0.447957 --> 0.447904).  Saving model ...
Validation loss decreased (0.447904 --> 0.447851).  Saving model ...
Validation loss decreased (0.447851 --> 0.447798).  Saving model ...
Validation loss decreased (0.447798 --> 0.447745).  Saving model ...
Validation loss decreased (0.447745 --> 0.447692).  Saving model ...
Validation loss decreased (0.447692 --> 0.447638).  Saving model ...
Validation loss decreased (0.447638 --> 0.447585).  Saving model ...
Validation loss decreased (0.447585 --> 0.447532).  Saving model ...
Validation loss decreased (0.447532 --> 0.447479).  Saving model ...
Validation loss decreased (0.447479 --> 0.447426).  Saving model ...
Validation loss decreased (0.447426 --> 0.447373).  Saving model ...
Validation loss decreased (0.447373 --> 0.447320).  Saving model ...
Validation loss decreased (0.447320 --> 0.447267).  Saving model ...
Validation loss decreased (0.447267 --> 0.447214).  Saving model ...
Validation loss decreased (0.447214 --> 0.447161).  Saving model ...
Validation loss decreased (0.447161 --> 0.447108).  Saving model ...
Validation loss decreased (0.447108 --> 0.447055).  Saving model ...
Validation loss decreased (0.447055 --> 0.447002).  Saving model ...
Validation loss decreased (0.447002 --> 0.446948).  Saving model ...
Validation loss decreased (0.446948 --> 0.446895).  Saving model ...
Validation loss decreased (0.446895 --> 0.446842).  Saving model ...
Validation loss decreased (0.446842 --> 0.446789).  Saving model ...
Validation loss decreased (0.446789 --> 0.446736).  Saving model ...
Validation loss decreased (0.446736 --> 0.446683).  Saving model ...
Validation loss decreased (0.446683 --> 0.446630).  Saving model ...
Validation loss decreased (0.446630 --> 0.446577).  Saving model ...
Validation loss decreased (0.446577 --> 0.446525).  Saving model ...
Validation loss decreased (0.446525 --> 0.446472).  Saving model ...
Validation loss decreased (0.446472 --> 0.446419).  Saving model ...
Validation loss decreased (0.446419 --> 0.446366).  Saving model ...
Validation loss decreased (0.446366 --> 0.446313).  Saving model ...
Validation loss decreased (0.446313 --> 0.446260).  Saving model ...
Validation loss decreased (0.446260 --> 0.446207).  Saving model ...
Validation loss decreased (0.446207 --> 0.446154).  Saving model ...
Validation loss decreased (0.446154 --> 0.446101).  Saving model ...
Validation loss decreased (0.446101 --> 0.446048).  Saving model ...
Validation loss decreased (0.446048 --> 0.445996).  Saving model ...
Validation loss decreased (0.445996 --> 0.445943).  Saving model ...
Validation loss decreased (0.445943 --> 0.445890).  Saving model ...
Validation loss decreased (0.445890 --> 0.445837).  Saving model ...
Validation loss decreased (0.445837 --> 0.445785).  Saving model ...
Validation loss decreased (0.445785 --> 0.445732).  Saving model ...
Validation loss decreased (0.445732 --> 0.445679).  Saving model ...
Validation loss decreased (0.445679 --> 0.445626).  Saving model ...
Validation loss decreased (0.445626 --> 0.445574).  Saving model ...
Validation loss decreased (0.445574 --> 0.445521).  Saving model ...
Validation loss decreased (0.445521 --> 0.445469).  Saving model ...
Validation loss decreased (0.445469 --> 0.445416).  Saving model ...
Validation loss decreased (0.445416 --> 0.445363).  Saving model ...
Validation loss decreased (0.445363 --> 0.445311).  Saving model ...
Validation loss decreased (0.445311 --> 0.445258).  Saving model ...
Validation loss decreased (0.445258 --> 0.445206).  Saving model ...
Validation loss decreased (0.445206 --> 0.445153).  Saving model ...
Validation loss decreased (0.445153 --> 0.445101).  Saving model ...
Validation loss decreased (0.445101 --> 0.445048).  Saving model ...
Validation loss decreased (0.445048 --> 0.444996).  Saving model ...
Validation loss decreased (0.444996 --> 0.444944).  Saving model ...
Validation loss decreased (0.444944 --> 0.444891).  Saving model ...
Validation loss decreased (0.444891 --> 0.444839).  Saving model ...
Validation loss decreased (0.444839 --> 0.444787).  Saving model ...
Validation loss decreased (0.444787 --> 0.444734).  Saving model ...
Validation loss decreased (0.444734 --> 0.444682).  Saving model ...
Validation loss decreased (0.444682 --> 0.444630).  Saving model ...
Validation loss decreased (0.444630 --> 0.444578).  Saving model ...
Validation loss decreased (0.444578 --> 0.444526).  Saving model ...
epoch 1701, loss 0.4445, train acc 79.15%, f1 0.6789, precision 0.7371, recall 0.6293, auc 0.7541
Validation loss decreased (0.444526 --> 0.444474).  Saving model ...
Validation loss decreased (0.444474 --> 0.444422).  Saving model ...
Validation loss decreased (0.444422 --> 0.444370).  Saving model ...
Validation loss decreased (0.444370 --> 0.444318).  Saving model ...
Validation loss decreased (0.444318 --> 0.444266).  Saving model ...
Validation loss decreased (0.444266 --> 0.444214).  Saving model ...
Validation loss decreased (0.444214 --> 0.444162).  Saving model ...
Validation loss decreased (0.444162 --> 0.444110).  Saving model ...
Validation loss decreased (0.444110 --> 0.444058).  Saving model ...
Validation loss decreased (0.444058 --> 0.444007).  Saving model ...
Validation loss decreased (0.444007 --> 0.443955).  Saving model ...
Validation loss decreased (0.443955 --> 0.443903).  Saving model ...
Validation loss decreased (0.443903 --> 0.443852).  Saving model ...
Validation loss decreased (0.443852 --> 0.443800).  Saving model ...
Validation loss decreased (0.443800 --> 0.443748).  Saving model ...
Validation loss decreased (0.443748 --> 0.443697).  Saving model ...
Validation loss decreased (0.443697 --> 0.443645).  Saving model ...
Validation loss decreased (0.443645 --> 0.443594).  Saving model ...
Validation loss decreased (0.443594 --> 0.443542).  Saving model ...
Validation loss decreased (0.443542 --> 0.443491).  Saving model ...
Validation loss decreased (0.443491 --> 0.443440).  Saving model ...
Validation loss decreased (0.443440 --> 0.443389).  Saving model ...
Validation loss decreased (0.443389 --> 0.443337).  Saving model ...
Validation loss decreased (0.443337 --> 0.443286).  Saving model ...
Validation loss decreased (0.443286 --> 0.443235).  Saving model ...
Validation loss decreased (0.443235 --> 0.443184).  Saving model ...
Validation loss decreased (0.443184 --> 0.443133).  Saving model ...
Validation loss decreased (0.443133 --> 0.443082).  Saving model ...
Validation loss decreased (0.443082 --> 0.443031).  Saving model ...
Validation loss decreased (0.443031 --> 0.442980).  Saving model ...
Validation loss decreased (0.442980 --> 0.442929).  Saving model ...
Validation loss decreased (0.442929 --> 0.442878).  Saving model ...
Validation loss decreased (0.442878 --> 0.442828).  Saving model ...
Validation loss decreased (0.442828 --> 0.442777).  Saving model ...
Validation loss decreased (0.442777 --> 0.442726).  Saving model ...
Validation loss decreased (0.442726 --> 0.442676).  Saving model ...
Validation loss decreased (0.442676 --> 0.442625).  Saving model ...
Validation loss decreased (0.442625 --> 0.442575).  Saving model ...
Validation loss decreased (0.442575 --> 0.442524).  Saving model ...
Validation loss decreased (0.442524 --> 0.442474).  Saving model ...
Validation loss decreased (0.442474 --> 0.442424).  Saving model ...
Validation loss decreased (0.442424 --> 0.442373).  Saving model ...
Validation loss decreased (0.442373 --> 0.442323).  Saving model ...
Validation loss decreased (0.442323 --> 0.442273).  Saving model ...
Validation loss decreased (0.442273 --> 0.442223).  Saving model ...
Validation loss decreased (0.442223 --> 0.442173).  Saving model ...
Validation loss decreased (0.442173 --> 0.442123).  Saving model ...
Validation loss decreased (0.442123 --> 0.442073).  Saving model ...
Validation loss decreased (0.442073 --> 0.442023).  Saving model ...
Validation loss decreased (0.442023 --> 0.441973).  Saving model ...
Validation loss decreased (0.441973 --> 0.441923).  Saving model ...
Validation loss decreased (0.441923 --> 0.441873).  Saving model ...
Validation loss decreased (0.441873 --> 0.441824).  Saving model ...
Validation loss decreased (0.441824 --> 0.441774).  Saving model ...
Validation loss decreased (0.441774 --> 0.441725).  Saving model ...
Validation loss decreased (0.441725 --> 0.441675).  Saving model ...
Validation loss decreased (0.441675 --> 0.441626).  Saving model ...
Validation loss decreased (0.441626 --> 0.441576).  Saving model ...
Validation loss decreased (0.441576 --> 0.441527).  Saving model ...
Validation loss decreased (0.441527 --> 0.441478).  Saving model ...
Validation loss decreased (0.441478 --> 0.441428).  Saving model ...
Validation loss decreased (0.441428 --> 0.441379).  Saving model ...
Validation loss decreased (0.441379 --> 0.441330).  Saving model ...
Validation loss decreased (0.441330 --> 0.441281).  Saving model ...
Validation loss decreased (0.441281 --> 0.441232).  Saving model ...
Validation loss decreased (0.441232 --> 0.441183).  Saving model ...
Validation loss decreased (0.441183 --> 0.441134).  Saving model ...
Validation loss decreased (0.441134 --> 0.441086).  Saving model ...
Validation loss decreased (0.441086 --> 0.441037).  Saving model ...
Validation loss decreased (0.441037 --> 0.440988).  Saving model ...
Validation loss decreased (0.440988 --> 0.440940).  Saving model ...
Validation loss decreased (0.440940 --> 0.440891).  Saving model ...
Validation loss decreased (0.440891 --> 0.440843).  Saving model ...
Validation loss decreased (0.440843 --> 0.440794).  Saving model ...
Validation loss decreased (0.440794 --> 0.440746).  Saving model ...
Validation loss decreased (0.440746 --> 0.440697).  Saving model ...
Validation loss decreased (0.440697 --> 0.440649).  Saving model ...
Validation loss decreased (0.440649 --> 0.440601).  Saving model ...
Validation loss decreased (0.440601 --> 0.440553).  Saving model ...
Validation loss decreased (0.440553 --> 0.440505).  Saving model ...
Validation loss decreased (0.440505 --> 0.440457).  Saving model ...
Validation loss decreased (0.440457 --> 0.440409).  Saving model ...
Validation loss decreased (0.440409 --> 0.440361).  Saving model ...
Validation loss decreased (0.440361 --> 0.440313).  Saving model ...
Validation loss decreased (0.440313 --> 0.440266).  Saving model ...
Validation loss decreased (0.440266 --> 0.440218).  Saving model ...
Validation loss decreased (0.440218 --> 0.440170).  Saving model ...
Validation loss decreased (0.440170 --> 0.440123).  Saving model ...
Validation loss decreased (0.440123 --> 0.440075).  Saving model ...
Validation loss decreased (0.440075 --> 0.440028).  Saving model ...
Validation loss decreased (0.440028 --> 0.439980).  Saving model ...
Validation loss decreased (0.439980 --> 0.439933).  Saving model ...
Validation loss decreased (0.439933 --> 0.439886).  Saving model ...
Validation loss decreased (0.439886 --> 0.439839).  Saving model ...
Validation loss decreased (0.439839 --> 0.439792).  Saving model ...
Validation loss decreased (0.439792 --> 0.439744).  Saving model ...
Validation loss decreased (0.439744 --> 0.439698).  Saving model ...
Validation loss decreased (0.439698 --> 0.439651).  Saving model ...
Validation loss decreased (0.439651 --> 0.439604).  Saving model ...
Validation loss decreased (0.439604 --> 0.439557).  Saving model ...
epoch 1801, loss 0.4396, train acc 79.49%, f1 0.6825, precision 0.7457, recall 0.6293, auc 0.7567
Validation loss decreased (0.439557 --> 0.439510).  Saving model ...
Validation loss decreased (0.439510 --> 0.439464).  Saving model ...
Validation loss decreased (0.439464 --> 0.439417).  Saving model ...
Validation loss decreased (0.439417 --> 0.439370).  Saving model ...
Validation loss decreased (0.439370 --> 0.439324).  Saving model ...
Validation loss decreased (0.439324 --> 0.439278).  Saving model ...
Validation loss decreased (0.439278 --> 0.439231).  Saving model ...
Validation loss decreased (0.439231 --> 0.439185).  Saving model ...
Validation loss decreased (0.439185 --> 0.439139).  Saving model ...
Validation loss decreased (0.439139 --> 0.439093).  Saving model ...
Validation loss decreased (0.439093 --> 0.439047).  Saving model ...
Validation loss decreased (0.439047 --> 0.439001).  Saving model ...
Validation loss decreased (0.439001 --> 0.438955).  Saving model ...
Validation loss decreased (0.438955 --> 0.438909).  Saving model ...
Validation loss decreased (0.438909 --> 0.438863).  Saving model ...
Validation loss decreased (0.438863 --> 0.438817).  Saving model ...
Validation loss decreased (0.438817 --> 0.438771).  Saving model ...
Validation loss decreased (0.438771 --> 0.438726).  Saving model ...
Validation loss decreased (0.438726 --> 0.438680).  Saving model ...
Validation loss decreased (0.438680 --> 0.438635).  Saving model ...
Validation loss decreased (0.438635 --> 0.438589).  Saving model ...
Validation loss decreased (0.438589 --> 0.438544).  Saving model ...
Validation loss decreased (0.438544 --> 0.438499).  Saving model ...
Validation loss decreased (0.438499 --> 0.438453).  Saving model ...
Validation loss decreased (0.438453 --> 0.438408).  Saving model ...
Validation loss decreased (0.438408 --> 0.438363).  Saving model ...
Validation loss decreased (0.438363 --> 0.438318).  Saving model ...
Validation loss decreased (0.438318 --> 0.438273).  Saving model ...
Validation loss decreased (0.438273 --> 0.438228).  Saving model ...
Validation loss decreased (0.438228 --> 0.438183).  Saving model ...
Validation loss decreased (0.438183 --> 0.438139).  Saving model ...
Validation loss decreased (0.438139 --> 0.438094).  Saving model ...
Validation loss decreased (0.438094 --> 0.438049).  Saving model ...
Validation loss decreased (0.438049 --> 0.438005).  Saving model ...
Validation loss decreased (0.438005 --> 0.437960).  Saving model ...
Validation loss decreased (0.437960 --> 0.437916).  Saving model ...
Validation loss decreased (0.437916 --> 0.437871).  Saving model ...
Validation loss decreased (0.437871 --> 0.437827).  Saving model ...
Validation loss decreased (0.437827 --> 0.437783).  Saving model ...
Validation loss decreased (0.437783 --> 0.437739).  Saving model ...
Validation loss decreased (0.437739 --> 0.437694).  Saving model ...
Validation loss decreased (0.437694 --> 0.437650).  Saving model ...
Validation loss decreased (0.437650 --> 0.437606).  Saving model ...
Validation loss decreased (0.437606 --> 0.437562).  Saving model ...
Validation loss decreased (0.437562 --> 0.437518).  Saving model ...
Validation loss decreased (0.437518 --> 0.437475).  Saving model ...
Validation loss decreased (0.437475 --> 0.437431).  Saving model ...
Validation loss decreased (0.437431 --> 0.437387).  Saving model ...
Validation loss decreased (0.437387 --> 0.437344).  Saving model ...
Validation loss decreased (0.437344 --> 0.437300).  Saving model ...
Validation loss decreased (0.437300 --> 0.437256).  Saving model ...
Validation loss decreased (0.437256 --> 0.437213).  Saving model ...
Validation loss decreased (0.437213 --> 0.437170).  Saving model ...
Validation loss decreased (0.437170 --> 0.437126).  Saving model ...
Validation loss decreased (0.437126 --> 0.437083).  Saving model ...
Validation loss decreased (0.437083 --> 0.437040).  Saving model ...
Validation loss decreased (0.437040 --> 0.436997).  Saving model ...
Validation loss decreased (0.436997 --> 0.436954).  Saving model ...
Validation loss decreased (0.436954 --> 0.436911).  Saving model ...
Validation loss decreased (0.436911 --> 0.436868).  Saving model ...
Validation loss decreased (0.436868 --> 0.436825).  Saving model ...
Validation loss decreased (0.436825 --> 0.436782).  Saving model ...
Validation loss decreased (0.436782 --> 0.436740).  Saving model ...
Validation loss decreased (0.436740 --> 0.436697).  Saving model ...
Validation loss decreased (0.436697 --> 0.436654).  Saving model ...
Validation loss decreased (0.436654 --> 0.436612).  Saving model ...
Validation loss decreased (0.436612 --> 0.436569).  Saving model ...
Validation loss decreased (0.436569 --> 0.436527).  Saving model ...
Validation loss decreased (0.436527 --> 0.436484).  Saving model ...
Validation loss decreased (0.436484 --> 0.436442).  Saving model ...
Validation loss decreased (0.436442 --> 0.436400).  Saving model ...
Validation loss decreased (0.436400 --> 0.436358).  Saving model ...
Validation loss decreased (0.436358 --> 0.436316).  Saving model ...
Validation loss decreased (0.436316 --> 0.436274).  Saving model ...
Validation loss decreased (0.436274 --> 0.436232).  Saving model ...
Validation loss decreased (0.436232 --> 0.436190).  Saving model ...
Validation loss decreased (0.436190 --> 0.436148).  Saving model ...
Validation loss decreased (0.436148 --> 0.436106).  Saving model ...
Validation loss decreased (0.436106 --> 0.436064).  Saving model ...
Validation loss decreased (0.436064 --> 0.436023).  Saving model ...
Validation loss decreased (0.436023 --> 0.435981).  Saving model ...
Validation loss decreased (0.435981 --> 0.435939).  Saving model ...
Validation loss decreased (0.435939 --> 0.435898).  Saving model ...
Validation loss decreased (0.435898 --> 0.435856).  Saving model ...
Validation loss decreased (0.435856 --> 0.435815).  Saving model ...
Validation loss decreased (0.435815 --> 0.435774).  Saving model ...
Validation loss decreased (0.435774 --> 0.435732).  Saving model ...
Validation loss decreased (0.435732 --> 0.435691).  Saving model ...
Validation loss decreased (0.435691 --> 0.435650).  Saving model ...
Validation loss decreased (0.435650 --> 0.435609).  Saving model ...
Validation loss decreased (0.435609 --> 0.435568).  Saving model ...
Validation loss decreased (0.435568 --> 0.435527).  Saving model ...
Validation loss decreased (0.435527 --> 0.435486).  Saving model ...
Validation loss decreased (0.435486 --> 0.435445).  Saving model ...
Validation loss decreased (0.435445 --> 0.435405).  Saving model ...
Validation loss decreased (0.435405 --> 0.435364).  Saving model ...
Validation loss decreased (0.435364 --> 0.435323).  Saving model ...
Validation loss decreased (0.435323 --> 0.435282).  Saving model ...
Validation loss decreased (0.435282 --> 0.435242).  Saving model ...
Validation loss decreased (0.435242 --> 0.435202).  Saving model ...
epoch 1901, loss 0.4352, train acc 80.00%, f1 0.6897, precision 0.7558, recall 0.6341, auc 0.7618
Validation loss decreased (0.435202 --> 0.435161).  Saving model ...
Validation loss decreased (0.435161 --> 0.435121).  Saving model ...
Validation loss decreased (0.435121 --> 0.435080).  Saving model ...
Validation loss decreased (0.435080 --> 0.435040).  Saving model ...
Validation loss decreased (0.435040 --> 0.435000).  Saving model ...
Validation loss decreased (0.435000 --> 0.434960).  Saving model ...
Validation loss decreased (0.434960 --> 0.434920).  Saving model ...
Validation loss decreased (0.434920 --> 0.434880).  Saving model ...
Validation loss decreased (0.434880 --> 0.434840).  Saving model ...
Validation loss decreased (0.434840 --> 0.434800).  Saving model ...
Validation loss decreased (0.434800 --> 0.434760).  Saving model ...
Validation loss decreased (0.434760 --> 0.434720).  Saving model ...
Validation loss decreased (0.434720 --> 0.434680).  Saving model ...
Validation loss decreased (0.434680 --> 0.434641).  Saving model ...
Validation loss decreased (0.434641 --> 0.434601).  Saving model ...
Validation loss decreased (0.434601 --> 0.434562).  Saving model ...
Validation loss decreased (0.434562 --> 0.434522).  Saving model ...
Validation loss decreased (0.434522 --> 0.434483).  Saving model ...
Validation loss decreased (0.434483 --> 0.434443).  Saving model ...
Validation loss decreased (0.434443 --> 0.434404).  Saving model ...
Validation loss decreased (0.434404 --> 0.434365).  Saving model ...
Validation loss decreased (0.434365 --> 0.434325).  Saving model ...
Validation loss decreased (0.434325 --> 0.434286).  Saving model ...
Validation loss decreased (0.434286 --> 0.434247).  Saving model ...
Validation loss decreased (0.434247 --> 0.434208).  Saving model ...
Validation loss decreased (0.434208 --> 0.434169).  Saving model ...
Validation loss decreased (0.434169 --> 0.434130).  Saving model ...
Validation loss decreased (0.434130 --> 0.434091).  Saving model ...
Validation loss decreased (0.434091 --> 0.434052).  Saving model ...
Validation loss decreased (0.434052 --> 0.434013).  Saving model ...
Validation loss decreased (0.434013 --> 0.433975).  Saving model ...
Validation loss decreased (0.433975 --> 0.433936).  Saving model ...
Validation loss decreased (0.433936 --> 0.433897).  Saving model ...
Validation loss decreased (0.433897 --> 0.433859).  Saving model ...
Validation loss decreased (0.433859 --> 0.433820).  Saving model ...
Validation loss decreased (0.433820 --> 0.433782).  Saving model ...
Validation loss decreased (0.433782 --> 0.433743).  Saving model ...
Validation loss decreased (0.433743 --> 0.433705).  Saving model ...
Validation loss decreased (0.433705 --> 0.433667).  Saving model ...
Validation loss decreased (0.433667 --> 0.433628).  Saving model ...
Validation loss decreased (0.433628 --> 0.433590).  Saving model ...
Validation loss decreased (0.433590 --> 0.433552).  Saving model ...
Validation loss decreased (0.433552 --> 0.433514).  Saving model ...
Validation loss decreased (0.433514 --> 0.433476).  Saving model ...
Validation loss decreased (0.433476 --> 0.433438).  Saving model ...
Validation loss decreased (0.433438 --> 0.433400).  Saving model ...
Validation loss decreased (0.433400 --> 0.433362).  Saving model ...
Validation loss decreased (0.433362 --> 0.433324).  Saving model ...
Validation loss decreased (0.433324 --> 0.433286).  Saving model ...
Validation loss decreased (0.433286 --> 0.433248).  Saving model ...
Validation loss decreased (0.433248 --> 0.433211).  Saving model ...
Validation loss decreased (0.433211 --> 0.433173).  Saving model ...
Validation loss decreased (0.433173 --> 0.433135).  Saving model ...
Validation loss decreased (0.433135 --> 0.433098).  Saving model ...
Validation loss decreased (0.433098 --> 0.433060).  Saving model ...
Validation loss decreased (0.433060 --> 0.433023).  Saving model ...
Validation loss decreased (0.433023 --> 0.432986).  Saving model ...
Validation loss decreased (0.432986 --> 0.432948).  Saving model ...
Validation loss decreased (0.432948 --> 0.432911).  Saving model ...
Validation loss decreased (0.432911 --> 0.432874).  Saving model ...
Validation loss decreased (0.432874 --> 0.432836).  Saving model ...
Validation loss decreased (0.432836 --> 0.432799).  Saving model ...
Validation loss decreased (0.432799 --> 0.432762).  Saving model ...
Validation loss decreased (0.432762 --> 0.432725).  Saving model ...
Validation loss decreased (0.432725 --> 0.432688).  Saving model ...
Validation loss decreased (0.432688 --> 0.432651).  Saving model ...
Validation loss decreased (0.432651 --> 0.432614).  Saving model ...
Validation loss decreased (0.432614 --> 0.432577).  Saving model ...
Validation loss decreased (0.432577 --> 0.432541).  Saving model ...
Validation loss decreased (0.432541 --> 0.432504).  Saving model ...
Validation loss decreased (0.432504 --> 0.432467).  Saving model ...
Validation loss decreased (0.432467 --> 0.432430).  Saving model ...
Validation loss decreased (0.432430 --> 0.432394).  Saving model ...
Validation loss decreased (0.432394 --> 0.432357).  Saving model ...
Validation loss decreased (0.432357 --> 0.432321).  Saving model ...
Validation loss decreased (0.432321 --> 0.432284).  Saving model ...
Validation loss decreased (0.432284 --> 0.432248).  Saving model ...
Validation loss decreased (0.432248 --> 0.432211).  Saving model ...
Validation loss decreased (0.432211 --> 0.432175).  Saving model ...
Validation loss decreased (0.432175 --> 0.432139).  Saving model ...
Validation loss decreased (0.432139 --> 0.432102).  Saving model ...
Validation loss decreased (0.432102 --> 0.432066).  Saving model ...
Validation loss decreased (0.432066 --> 0.432030).  Saving model ...
Validation loss decreased (0.432030 --> 0.431994).  Saving model ...
Validation loss decreased (0.431994 --> 0.431958).  Saving model ...
Validation loss decreased (0.431958 --> 0.431922).  Saving model ...
Validation loss decreased (0.431922 --> 0.431886).  Saving model ...
Validation loss decreased (0.431886 --> 0.431850).  Saving model ...
Validation loss decreased (0.431850 --> 0.431814).  Saving model ...
Validation loss decreased (0.431814 --> 0.431778).  Saving model ...
Validation loss decreased (0.431778 --> 0.431742).  Saving model ...
Validation loss decreased (0.431742 --> 0.431707).  Saving model ...
Validation loss decreased (0.431707 --> 0.431671).  Saving model ...
Validation loss decreased (0.431671 --> 0.431635).  Saving model ...
Validation loss decreased (0.431635 --> 0.431600).  Saving model ...
Validation loss decreased (0.431600 --> 0.431564).  Saving model ...
Validation loss decreased (0.431564 --> 0.431528).  Saving model ...
Validation loss decreased (0.431528 --> 0.431493).  Saving model ...
Validation loss decreased (0.431493 --> 0.431458).  Saving model ...
Validation loss decreased (0.431458 --> 0.431422).  Saving model ...
epoch 2001, loss 0.4314, train acc 79.66%, f1 0.6860, precision 0.7471, recall 0.6341, auc 0.7592
Validation loss decreased (0.431422 --> 0.431387).  Saving model ...
Validation loss decreased (0.431387 --> 0.431351).  Saving model ...
Validation loss decreased (0.431351 --> 0.431316).  Saving model ...
Validation loss decreased (0.431316 --> 0.431281).  Saving model ...
Validation loss decreased (0.431281 --> 0.431246).  Saving model ...
Validation loss decreased (0.431246 --> 0.431211).  Saving model ...
Validation loss decreased (0.431211 --> 0.431175).  Saving model ...
Validation loss decreased (0.431175 --> 0.431140).  Saving model ...
Validation loss decreased (0.431140 --> 0.431105).  Saving model ...
Validation loss decreased (0.431105 --> 0.431070).  Saving model ...
Validation loss decreased (0.431070 --> 0.431035).  Saving model ...
Validation loss decreased (0.431035 --> 0.431001).  Saving model ...
Validation loss decreased (0.431001 --> 0.430966).  Saving model ...
Validation loss decreased (0.430966 --> 0.430931).  Saving model ...
Validation loss decreased (0.430931 --> 0.430896).  Saving model ...
Validation loss decreased (0.430896 --> 0.430861).  Saving model ...
Validation loss decreased (0.430861 --> 0.430827).  Saving model ...
Validation loss decreased (0.430827 --> 0.430792).  Saving model ...
Validation loss decreased (0.430792 --> 0.430757).  Saving model ...
Validation loss decreased (0.430757 --> 0.430723).  Saving model ...
Validation loss decreased (0.430723 --> 0.430688).  Saving model ...
Validation loss decreased (0.430688 --> 0.430654).  Saving model ...
Validation loss decreased (0.430654 --> 0.430619).  Saving model ...
Validation loss decreased (0.430619 --> 0.430585).  Saving model ...
Validation loss decreased (0.430585 --> 0.430551).  Saving model ...
Validation loss decreased (0.430551 --> 0.430516).  Saving model ...
Validation loss decreased (0.430516 --> 0.430482).  Saving model ...
Validation loss decreased (0.430482 --> 0.430448).  Saving model ...
Validation loss decreased (0.430448 --> 0.430414).  Saving model ...
Validation loss decreased (0.430414 --> 0.430379).  Saving model ...
Validation loss decreased (0.430379 --> 0.430345).  Saving model ...
Validation loss decreased (0.430345 --> 0.430311).  Saving model ...
Validation loss decreased (0.430311 --> 0.430277).  Saving model ...
Validation loss decreased (0.430277 --> 0.430243).  Saving model ...
Validation loss decreased (0.430243 --> 0.430209).  Saving model ...
Validation loss decreased (0.430209 --> 0.430175).  Saving model ...
Validation loss decreased (0.430175 --> 0.430141).  Saving model ...
Validation loss decreased (0.430141 --> 0.430107).  Saving model ...
Validation loss decreased (0.430107 --> 0.430074).  Saving model ...
Validation loss decreased (0.430074 --> 0.430040).  Saving model ...
Validation loss decreased (0.430040 --> 0.430006).  Saving model ...
Validation loss decreased (0.430006 --> 0.429972).  Saving model ...
Validation loss decreased (0.429972 --> 0.429939).  Saving model ...
Validation loss decreased (0.429939 --> 0.429905).  Saving model ...
Validation loss decreased (0.429905 --> 0.429871).  Saving model ...
Validation loss decreased (0.429871 --> 0.429838).  Saving model ...
Validation loss decreased (0.429838 --> 0.429804).  Saving model ...
Validation loss decreased (0.429804 --> 0.429771).  Saving model ...
Validation loss decreased (0.429771 --> 0.429737).  Saving model ...
Validation loss decreased (0.429737 --> 0.429704).  Saving model ...
Validation loss decreased (0.429704 --> 0.429671).  Saving model ...
Validation loss decreased (0.429671 --> 0.429637).  Saving model ...
Validation loss decreased (0.429637 --> 0.429604).  Saving model ...
Validation loss decreased (0.429604 --> 0.429571).  Saving model ...
Validation loss decreased (0.429571 --> 0.429537).  Saving model ...
Validation loss decreased (0.429537 --> 0.429504).  Saving model ...
Validation loss decreased (0.429504 --> 0.429471).  Saving model ...
Validation loss decreased (0.429471 --> 0.429438).  Saving model ...
Validation loss decreased (0.429438 --> 0.429405).  Saving model ...
Validation loss decreased (0.429405 --> 0.429372).  Saving model ...
Validation loss decreased (0.429372 --> 0.429339).  Saving model ...
Validation loss decreased (0.429339 --> 0.429306).  Saving model ...
Validation loss decreased (0.429306 --> 0.429273).  Saving model ...
Validation loss decreased (0.429273 --> 0.429240).  Saving model ...
Validation loss decreased (0.429240 --> 0.429207).  Saving model ...
Validation loss decreased (0.429207 --> 0.429174).  Saving model ...
Validation loss decreased (0.429174 --> 0.429141).  Saving model ...
Validation loss decreased (0.429141 --> 0.429109).  Saving model ...
Validation loss decreased (0.429109 --> 0.429076).  Saving model ...
Validation loss decreased (0.429076 --> 0.429043).  Saving model ...
Validation loss decreased (0.429043 --> 0.429010).  Saving model ...
Validation loss decreased (0.429010 --> 0.428978).  Saving model ...
Validation loss decreased (0.428978 --> 0.428945).  Saving model ...
Validation loss decreased (0.428945 --> 0.428913).  Saving model ...
Validation loss decreased (0.428913 --> 0.428880).  Saving model ...
Validation loss decreased (0.428880 --> 0.428848).  Saving model ...
Validation loss decreased (0.428848 --> 0.428815).  Saving model ...
Validation loss decreased (0.428815 --> 0.428783).  Saving model ...
Validation loss decreased (0.428783 --> 0.428750).  Saving model ...
Validation loss decreased (0.428750 --> 0.428718).  Saving model ...
Validation loss decreased (0.428718 --> 0.428685).  Saving model ...
Validation loss decreased (0.428685 --> 0.428653).  Saving model ...
Validation loss decreased (0.428653 --> 0.428621).  Saving model ...
Validation loss decreased (0.428621 --> 0.428589).  Saving model ...
Validation loss decreased (0.428589 --> 0.428556).  Saving model ...
Validation loss decreased (0.428556 --> 0.428524).  Saving model ...
Validation loss decreased (0.428524 --> 0.428492).  Saving model ...
Validation loss decreased (0.428492 --> 0.428460).  Saving model ...
Validation loss decreased (0.428460 --> 0.428428).  Saving model ...
Validation loss decreased (0.428428 --> 0.428396).  Saving model ...
Validation loss decreased (0.428396 --> 0.428364).  Saving model ...
Validation loss decreased (0.428364 --> 0.428332).  Saving model ...
Validation loss decreased (0.428332 --> 0.428300).  Saving model ...
Validation loss decreased (0.428300 --> 0.428268).  Saving model ...
Validation loss decreased (0.428268 --> 0.428236).  Saving model ...
Validation loss decreased (0.428236 --> 0.428204).  Saving model ...
Validation loss decreased (0.428204 --> 0.428172).  Saving model ...
Validation loss decreased (0.428172 --> 0.428141).  Saving model ...
Validation loss decreased (0.428141 --> 0.428109).  Saving model ...
Validation loss decreased (0.428109 --> 0.428077).  Saving model ...
epoch 2101, loss 0.4281, train acc 78.97%, f1 0.6789, precision 0.7303, recall 0.6341, auc 0.7539
Validation loss decreased (0.428077 --> 0.428045).  Saving model ...
Validation loss decreased (0.428045 --> 0.428014).  Saving model ...
Validation loss decreased (0.428014 --> 0.427982).  Saving model ...
Validation loss decreased (0.427982 --> 0.427950).  Saving model ...
Validation loss decreased (0.427950 --> 0.427919).  Saving model ...
Validation loss decreased (0.427919 --> 0.427887).  Saving model ...
Validation loss decreased (0.427887 --> 0.427856).  Saving model ...
Validation loss decreased (0.427856 --> 0.427824).  Saving model ...
Validation loss decreased (0.427824 --> 0.427793).  Saving model ...
Validation loss decreased (0.427793 --> 0.427761).  Saving model ...
Validation loss decreased (0.427761 --> 0.427730).  Saving model ...
Validation loss decreased (0.427730 --> 0.427698).  Saving model ...
Validation loss decreased (0.427698 --> 0.427667).  Saving model ...
Validation loss decreased (0.427667 --> 0.427636).  Saving model ...
Validation loss decreased (0.427636 --> 0.427604).  Saving model ...
Validation loss decreased (0.427604 --> 0.427573).  Saving model ...
Validation loss decreased (0.427573 --> 0.427542).  Saving model ...
Validation loss decreased (0.427542 --> 0.427511).  Saving model ...
Validation loss decreased (0.427511 --> 0.427480).  Saving model ...
Validation loss decreased (0.427480 --> 0.427448).  Saving model ...
Validation loss decreased (0.427448 --> 0.427417).  Saving model ...
Validation loss decreased (0.427417 --> 0.427386).  Saving model ...
Validation loss decreased (0.427386 --> 0.427355).  Saving model ...
Validation loss decreased (0.427355 --> 0.427324).  Saving model ...
Validation loss decreased (0.427324 --> 0.427293).  Saving model ...
Validation loss decreased (0.427293 --> 0.427262).  Saving model ...
Validation loss decreased (0.427262 --> 0.427231).  Saving model ...
Validation loss decreased (0.427231 --> 0.427200).  Saving model ...
Validation loss decreased (0.427200 --> 0.427169).  Saving model ...
Validation loss decreased (0.427169 --> 0.427138).  Saving model ...
Validation loss decreased (0.427138 --> 0.427108).  Saving model ...
Validation loss decreased (0.427108 --> 0.427077).  Saving model ...
Validation loss decreased (0.427077 --> 0.427046).  Saving model ...
Validation loss decreased (0.427046 --> 0.427015).  Saving model ...
Validation loss decreased (0.427015 --> 0.426984).  Saving model ...
Validation loss decreased (0.426984 --> 0.426954).  Saving model ...
Validation loss decreased (0.426954 --> 0.426923).  Saving model ...
Validation loss decreased (0.426923 --> 0.426892).  Saving model ...
Validation loss decreased (0.426892 --> 0.426862).  Saving model ...
Validation loss decreased (0.426862 --> 0.426831).  Saving model ...
Validation loss decreased (0.426831 --> 0.426801).  Saving model ...
Validation loss decreased (0.426801 --> 0.426770).  Saving model ...
Validation loss decreased (0.426770 --> 0.426740).  Saving model ...
Validation loss decreased (0.426740 --> 0.426709).  Saving model ...
Validation loss decreased (0.426709 --> 0.426679).  Saving model ...
Validation loss decreased (0.426679 --> 0.426648).  Saving model ...
Validation loss decreased (0.426648 --> 0.426618).  Saving model ...
Validation loss decreased (0.426618 --> 0.426587).  Saving model ...
Validation loss decreased (0.426587 --> 0.426557).  Saving model ...
Validation loss decreased (0.426557 --> 0.426527).  Saving model ...
Validation loss decreased (0.426527 --> 0.426496).  Saving model ...
Validation loss decreased (0.426496 --> 0.426466).  Saving model ...
Validation loss decreased (0.426466 --> 0.426436).  Saving model ...
Validation loss decreased (0.426436 --> 0.426405).  Saving model ...
Validation loss decreased (0.426405 --> 0.426375).  Saving model ...
Validation loss decreased (0.426375 --> 0.426345).  Saving model ...
Validation loss decreased (0.426345 --> 0.426315).  Saving model ...
Validation loss decreased (0.426315 --> 0.426285).  Saving model ...
Validation loss decreased (0.426285 --> 0.426255).  Saving model ...
Validation loss decreased (0.426255 --> 0.426224).  Saving model ...
Validation loss decreased (0.426224 --> 0.426194).  Saving model ...
Validation loss decreased (0.426194 --> 0.426164).  Saving model ...
Validation loss decreased (0.426164 --> 0.426134).  Saving model ...
Validation loss decreased (0.426134 --> 0.426104).  Saving model ...
Validation loss decreased (0.426104 --> 0.426074).  Saving model ...
Validation loss decreased (0.426074 --> 0.426044).  Saving model ...
Validation loss decreased (0.426044 --> 0.426014).  Saving model ...
Validation loss decreased (0.426014 --> 0.425985).  Saving model ...
Validation loss decreased (0.425985 --> 0.425955).  Saving model ...
Validation loss decreased (0.425955 --> 0.425925).  Saving model ...
Validation loss decreased (0.425925 --> 0.425895).  Saving model ...
Validation loss decreased (0.425895 --> 0.425865).  Saving model ...
Validation loss decreased (0.425865 --> 0.425835).  Saving model ...
Validation loss decreased (0.425835 --> 0.425805).  Saving model ...
Validation loss decreased (0.425805 --> 0.425776).  Saving model ...
Validation loss decreased (0.425776 --> 0.425746).  Saving model ...
Validation loss decreased (0.425746 --> 0.425716).  Saving model ...
Validation loss decreased (0.425716 --> 0.425687).  Saving model ...
Validation loss decreased (0.425687 --> 0.425657).  Saving model ...
Validation loss decreased (0.425657 --> 0.425627).  Saving model ...
Validation loss decreased (0.425627 --> 0.425598).  Saving model ...
Validation loss decreased (0.425598 --> 0.425568).  Saving model ...
Validation loss decreased (0.425568 --> 0.425539).  Saving model ...
Validation loss decreased (0.425539 --> 0.425509).  Saving model ...
Validation loss decreased (0.425509 --> 0.425479).  Saving model ...
Validation loss decreased (0.425479 --> 0.425450).  Saving model ...
Validation loss decreased (0.425450 --> 0.425420).  Saving model ...
Validation loss decreased (0.425420 --> 0.425391).  Saving model ...
Validation loss decreased (0.425391 --> 0.425362).  Saving model ...
Validation loss decreased (0.425362 --> 0.425332).  Saving model ...
Validation loss decreased (0.425332 --> 0.425303).  Saving model ...
Validation loss decreased (0.425303 --> 0.425273).  Saving model ...
Validation loss decreased (0.425273 --> 0.425244).  Saving model ...
Validation loss decreased (0.425244 --> 0.425215).  Saving model ...
Validation loss decreased (0.425215 --> 0.425185).  Saving model ...
Validation loss decreased (0.425185 --> 0.425156).  Saving model ...
Validation loss decreased (0.425156 --> 0.425127).  Saving model ...
Validation loss decreased (0.425127 --> 0.425097).  Saving model ...
Validation loss decreased (0.425097 --> 0.425068).  Saving model ...
Validation loss decreased (0.425068 --> 0.425039).  Saving model ...
epoch 2201, loss 0.4250, train acc 78.80%, f1 0.6804, precision 0.7213, recall 0.6439, auc 0.7548
Validation loss decreased (0.425039 --> 0.425010).  Saving model ...
Validation loss decreased (0.425010 --> 0.424981).  Saving model ...
Validation loss decreased (0.424981 --> 0.424951).  Saving model ...
Validation loss decreased (0.424951 --> 0.424922).  Saving model ...
Validation loss decreased (0.424922 --> 0.424893).  Saving model ...
Validation loss decreased (0.424893 --> 0.424864).  Saving model ...
Validation loss decreased (0.424864 --> 0.424835).  Saving model ...
Validation loss decreased (0.424835 --> 0.424806).  Saving model ...
Validation loss decreased (0.424806 --> 0.424777).  Saving model ...
Validation loss decreased (0.424777 --> 0.424748).  Saving model ...
Validation loss decreased (0.424748 --> 0.424719).  Saving model ...
Validation loss decreased (0.424719 --> 0.424690).  Saving model ...
Validation loss decreased (0.424690 --> 0.424661).  Saving model ...
Validation loss decreased (0.424661 --> 0.424632).  Saving model ...
Validation loss decreased (0.424632 --> 0.424603).  Saving model ...
Validation loss decreased (0.424603 --> 0.424574).  Saving model ...
Validation loss decreased (0.424574 --> 0.424545).  Saving model ...
Validation loss decreased (0.424545 --> 0.424516).  Saving model ...
Validation loss decreased (0.424516 --> 0.424487).  Saving model ...
Validation loss decreased (0.424487 --> 0.424459).  Saving model ...
Validation loss decreased (0.424459 --> 0.424430).  Saving model ...
Validation loss decreased (0.424430 --> 0.424401).  Saving model ...
Validation loss decreased (0.424401 --> 0.424372).  Saving model ...
Validation loss decreased (0.424372 --> 0.424343).  Saving model ...
Validation loss decreased (0.424343 --> 0.424314).  Saving model ...
Validation loss decreased (0.424314 --> 0.424286).  Saving model ...
Validation loss decreased (0.424286 --> 0.424257).  Saving model ...
Validation loss decreased (0.424257 --> 0.424228).  Saving model ...
Validation loss decreased (0.424228 --> 0.424200).  Saving model ...
Validation loss decreased (0.424200 --> 0.424171).  Saving model ...
Validation loss decreased (0.424171 --> 0.424142).  Saving model ...
Validation loss decreased (0.424142 --> 0.424114).  Saving model ...
Validation loss decreased (0.424114 --> 0.424085).  Saving model ...
Validation loss decreased (0.424085 --> 0.424056).  Saving model ...
Validation loss decreased (0.424056 --> 0.424028).  Saving model ...
Validation loss decreased (0.424028 --> 0.423999).  Saving model ...
Validation loss decreased (0.423999 --> 0.423971).  Saving model ...
Validation loss decreased (0.423971 --> 0.423942).  Saving model ...
Validation loss decreased (0.423942 --> 0.423914).  Saving model ...
Validation loss decreased (0.423914 --> 0.423885).  Saving model ...
Validation loss decreased (0.423885 --> 0.423857).  Saving model ...
Validation loss decreased (0.423857 --> 0.423828).  Saving model ...
Validation loss decreased (0.423828 --> 0.423800).  Saving model ...
Validation loss decreased (0.423800 --> 0.423771).  Saving model ...
Validation loss decreased (0.423771 --> 0.423743).  Saving model ...
Validation loss decreased (0.423743 --> 0.423714).  Saving model ...
Validation loss decreased (0.423714 --> 0.423686).  Saving model ...
Validation loss decreased (0.423686 --> 0.423657).  Saving model ...
Validation loss decreased (0.423657 --> 0.423629).  Saving model ...
Validation loss decreased (0.423629 --> 0.423601).  Saving model ...
Validation loss decreased (0.423601 --> 0.423572).  Saving model ...
Validation loss decreased (0.423572 --> 0.423544).  Saving model ...
Validation loss decreased (0.423544 --> 0.423516).  Saving model ...
Validation loss decreased (0.423516 --> 0.423487).  Saving model ...
Validation loss decreased (0.423487 --> 0.423459).  Saving model ...
Validation loss decreased (0.423459 --> 0.423431).  Saving model ...
Validation loss decreased (0.423431 --> 0.423402).  Saving model ...
Validation loss decreased (0.423402 --> 0.423374).  Saving model ...
Validation loss decreased (0.423374 --> 0.423346).  Saving model ...
Validation loss decreased (0.423346 --> 0.423318).  Saving model ...
Validation loss decreased (0.423318 --> 0.423290).  Saving model ...
Validation loss decreased (0.423290 --> 0.423261).  Saving model ...
Validation loss decreased (0.423261 --> 0.423233).  Saving model ...
Validation loss decreased (0.423233 --> 0.423205).  Saving model ...
Validation loss decreased (0.423205 --> 0.423177).  Saving model ...
Validation loss decreased (0.423177 --> 0.423149).  Saving model ...
Validation loss decreased (0.423149 --> 0.423120).  Saving model ...
Validation loss decreased (0.423120 --> 0.423092).  Saving model ...
Validation loss decreased (0.423092 --> 0.423064).  Saving model ...
Validation loss decreased (0.423064 --> 0.423036).  Saving model ...
Validation loss decreased (0.423036 --> 0.423008).  Saving model ...
Validation loss decreased (0.423008 --> 0.422980).  Saving model ...
Validation loss decreased (0.422980 --> 0.422952).  Saving model ...
Validation loss decreased (0.422952 --> 0.422924).  Saving model ...
Validation loss decreased (0.422924 --> 0.422896).  Saving model ...
Validation loss decreased (0.422896 --> 0.422868).  Saving model ...
Validation loss decreased (0.422868 --> 0.422840).  Saving model ...
Validation loss decreased (0.422840 --> 0.422812).  Saving model ...
Validation loss decreased (0.422812 --> 0.422784).  Saving model ...
Validation loss decreased (0.422784 --> 0.422756).  Saving model ...
Validation loss decreased (0.422756 --> 0.422727).  Saving model ...
Validation loss decreased (0.422727 --> 0.422700).  Saving model ...
Validation loss decreased (0.422700 --> 0.422672).  Saving model ...
Validation loss decreased (0.422672 --> 0.422644).  Saving model ...
Validation loss decreased (0.422644 --> 0.422616).  Saving model ...
Validation loss decreased (0.422616 --> 0.422588).  Saving model ...
Validation loss decreased (0.422588 --> 0.422560).  Saving model ...
Validation loss decreased (0.422560 --> 0.422532).  Saving model ...
Validation loss decreased (0.422532 --> 0.422504).  Saving model ...
Validation loss decreased (0.422504 --> 0.422476).  Saving model ...
Validation loss decreased (0.422476 --> 0.422448).  Saving model ...
Validation loss decreased (0.422448 --> 0.422420).  Saving model ...
Validation loss decreased (0.422420 --> 0.422392).  Saving model ...
Validation loss decreased (0.422392 --> 0.422365).  Saving model ...
Validation loss decreased (0.422365 --> 0.422337).  Saving model ...
Validation loss decreased (0.422337 --> 0.422309).  Saving model ...
Validation loss decreased (0.422309 --> 0.422281).  Saving model ...
Validation loss decreased (0.422281 --> 0.422253).  Saving model ...
Validation loss decreased (0.422253 --> 0.422225).  Saving model ...
Validation loss decreased (0.422225 --> 0.422198).  Saving model ...
epoch 2301, loss 0.4222, train acc 79.15%, f1 0.6856, precision 0.7268, recall 0.6488, auc 0.7586
Validation loss decreased (0.422198 --> 0.422170).  Saving model ...
Validation loss decreased (0.422170 --> 0.422142).  Saving model ...
Validation loss decreased (0.422142 --> 0.422114).  Saving model ...
Validation loss decreased (0.422114 --> 0.422086).  Saving model ...
Validation loss decreased (0.422086 --> 0.422059).  Saving model ...
Validation loss decreased (0.422059 --> 0.422031).  Saving model ...
Validation loss decreased (0.422031 --> 0.422003).  Saving model ...
Validation loss decreased (0.422003 --> 0.421975).  Saving model ...
Validation loss decreased (0.421975 --> 0.421948).  Saving model ...
Validation loss decreased (0.421948 --> 0.421920).  Saving model ...
Validation loss decreased (0.421920 --> 0.421892).  Saving model ...
Validation loss decreased (0.421892 --> 0.421864).  Saving model ...
Validation loss decreased (0.421864 --> 0.421837).  Saving model ...
Validation loss decreased (0.421837 --> 0.421809).  Saving model ...
Validation loss decreased (0.421809 --> 0.421781).  Saving model ...
Validation loss decreased (0.421781 --> 0.421754).  Saving model ...
Validation loss decreased (0.421754 --> 0.421726).  Saving model ...
Validation loss decreased (0.421726 --> 0.421698).  Saving model ...
Validation loss decreased (0.421698 --> 0.421670).  Saving model ...
Validation loss decreased (0.421670 --> 0.421643).  Saving model ...
Validation loss decreased (0.421643 --> 0.421615).  Saving model ...
Validation loss decreased (0.421615 --> 0.421587).  Saving model ...
Validation loss decreased (0.421587 --> 0.421560).  Saving model ...
Validation loss decreased (0.421560 --> 0.421532).  Saving model ...
Validation loss decreased (0.421532 --> 0.421505).  Saving model ...
Validation loss decreased (0.421505 --> 0.421477).  Saving model ...
Validation loss decreased (0.421477 --> 0.421449).  Saving model ...
Validation loss decreased (0.421449 --> 0.421422).  Saving model ...
Validation loss decreased (0.421422 --> 0.421394).  Saving model ...
Validation loss decreased (0.421394 --> 0.421366).  Saving model ...
Validation loss decreased (0.421366 --> 0.421339).  Saving model ...
Validation loss decreased (0.421339 --> 0.421311).  Saving model ...
Validation loss decreased (0.421311 --> 0.421284).  Saving model ...
Validation loss decreased (0.421284 --> 0.421256).  Saving model ...
Validation loss decreased (0.421256 --> 0.421228).  Saving model ...
Validation loss decreased (0.421228 --> 0.421201).  Saving model ...
Validation loss decreased (0.421201 --> 0.421173).  Saving model ...
Validation loss decreased (0.421173 --> 0.421146).  Saving model ...
Validation loss decreased (0.421146 --> 0.421118).  Saving model ...
Validation loss decreased (0.421118 --> 0.421091).  Saving model ...
Validation loss decreased (0.421091 --> 0.421063).  Saving model ...
Validation loss decreased (0.421063 --> 0.421035).  Saving model ...
Validation loss decreased (0.421035 --> 0.421008).  Saving model ...
Validation loss decreased (0.421008 --> 0.420980).  Saving model ...
Validation loss decreased (0.420980 --> 0.420953).  Saving model ...
Validation loss decreased (0.420953 --> 0.420925).  Saving model ...
Validation loss decreased (0.420925 --> 0.420898).  Saving model ...
Validation loss decreased (0.420898 --> 0.420870).  Saving model ...
Validation loss decreased (0.420870 --> 0.420843).  Saving model ...
Validation loss decreased (0.420843 --> 0.420815).  Saving model ...
Validation loss decreased (0.420815 --> 0.420788).  Saving model ...
Validation loss decreased (0.420788 --> 0.420760).  Saving model ...
Validation loss decreased (0.420760 --> 0.420733).  Saving model ...
Validation loss decreased (0.420733 --> 0.420705).  Saving model ...
Validation loss decreased (0.420705 --> 0.420678).  Saving model ...
Validation loss decreased (0.420678 --> 0.420650).  Saving model ...
Validation loss decreased (0.420650 --> 0.420623).  Saving model ...
Validation loss decreased (0.420623 --> 0.420595).  Saving model ...
Validation loss decreased (0.420595 --> 0.420568).  Saving model ...
Validation loss decreased (0.420568 --> 0.420540).  Saving model ...
Validation loss decreased (0.420540 --> 0.420513).  Saving model ...
Validation loss decreased (0.420513 --> 0.420485).  Saving model ...
Validation loss decreased (0.420485 --> 0.420458).  Saving model ...
Validation loss decreased (0.420458 --> 0.420430).  Saving model ...
Validation loss decreased (0.420430 --> 0.420403).  Saving model ...
Validation loss decreased (0.420403 --> 0.420375).  Saving model ...
Validation loss decreased (0.420375 --> 0.420348).  Saving model ...
Validation loss decreased (0.420348 --> 0.420320).  Saving model ...
Validation loss decreased (0.420320 --> 0.420293).  Saving model ...
Validation loss decreased (0.420293 --> 0.420265).  Saving model ...
Validation loss decreased (0.420265 --> 0.420238).  Saving model ...
Validation loss decreased (0.420238 --> 0.420210).  Saving model ...
Validation loss decreased (0.420210 --> 0.420183).  Saving model ...
Validation loss decreased (0.420183 --> 0.420155).  Saving model ...
Validation loss decreased (0.420155 --> 0.420128).  Saving model ...
Validation loss decreased (0.420128 --> 0.420101).  Saving model ...
Validation loss decreased (0.420101 --> 0.420073).  Saving model ...
Validation loss decreased (0.420073 --> 0.420046).  Saving model ...
Validation loss decreased (0.420046 --> 0.420018).  Saving model ...
Validation loss decreased (0.420018 --> 0.419991).  Saving model ...
Validation loss decreased (0.419991 --> 0.419963).  Saving model ...
Validation loss decreased (0.419963 --> 0.419936).  Saving model ...
Validation loss decreased (0.419936 --> 0.419908).  Saving model ...
Validation loss decreased (0.419908 --> 0.419881).  Saving model ...
Validation loss decreased (0.419881 --> 0.419853).  Saving model ...
Validation loss decreased (0.419853 --> 0.419826).  Saving model ...
Validation loss decreased (0.419826 --> 0.419799).  Saving model ...
Validation loss decreased (0.419799 --> 0.419771).  Saving model ...
Validation loss decreased (0.419771 --> 0.419744).  Saving model ...
Validation loss decreased (0.419744 --> 0.419716).  Saving model ...
Validation loss decreased (0.419716 --> 0.419689).  Saving model ...
Validation loss decreased (0.419689 --> 0.419661).  Saving model ...
Validation loss decreased (0.419661 --> 0.419634).  Saving model ...
Validation loss decreased (0.419634 --> 0.419606).  Saving model ...
Validation loss decreased (0.419606 --> 0.419579).  Saving model ...
Validation loss decreased (0.419579 --> 0.419552).  Saving model ...
Validation loss decreased (0.419552 --> 0.419524).  Saving model ...
Validation loss decreased (0.419524 --> 0.419497).  Saving model ...
Validation loss decreased (0.419497 --> 0.419469).  Saving model ...
Validation loss decreased (0.419469 --> 0.419442).  Saving model ...
epoch 2401, loss 0.4194, train acc 79.49%, f1 0.6907, precision 0.7322, recall 0.6537, auc 0.7624
Validation loss decreased (0.419442 --> 0.419414).  Saving model ...
Validation loss decreased (0.419414 --> 0.419387).  Saving model ...
Validation loss decreased (0.419387 --> 0.419359).  Saving model ...
Validation loss decreased (0.419359 --> 0.419332).  Saving model ...
Validation loss decreased (0.419332 --> 0.419305).  Saving model ...
Validation loss decreased (0.419305 --> 0.419277).  Saving model ...
Validation loss decreased (0.419277 --> 0.419250).  Saving model ...
Validation loss decreased (0.419250 --> 0.419222).  Saving model ...
Validation loss decreased (0.419222 --> 0.419195).  Saving model ...
Validation loss decreased (0.419195 --> 0.419167).  Saving model ...
Validation loss decreased (0.419167 --> 0.419140).  Saving model ...
Validation loss decreased (0.419140 --> 0.419113).  Saving model ...
Validation loss decreased (0.419113 --> 0.419085).  Saving model ...
Validation loss decreased (0.419085 --> 0.419058).  Saving model ...
Validation loss decreased (0.419058 --> 0.419030).  Saving model ...
Validation loss decreased (0.419030 --> 0.419003).  Saving model ...
Validation loss decreased (0.419003 --> 0.418975).  Saving model ...
Validation loss decreased (0.418975 --> 0.418948).  Saving model ...
Validation loss decreased (0.418948 --> 0.418920).  Saving model ...
Validation loss decreased (0.418920 --> 0.418893).  Saving model ...
Validation loss decreased (0.418893 --> 0.418866).  Saving model ...
Validation loss decreased (0.418866 --> 0.418838).  Saving model ...
Validation loss decreased (0.418838 --> 0.418811).  Saving model ...
Validation loss decreased (0.418811 --> 0.418783).  Saving model ...
Validation loss decreased (0.418783 --> 0.418756).  Saving model ...
Validation loss decreased (0.418756 --> 0.418728).  Saving model ...
Validation loss decreased (0.418728 --> 0.418701).  Saving model ...
Validation loss decreased (0.418701 --> 0.418673).  Saving model ...
Validation loss decreased (0.418673 --> 0.418646).  Saving model ...
Validation loss decreased (0.418646 --> 0.418618).  Saving model ...
Validation loss decreased (0.418618 --> 0.418591).  Saving model ...
Validation loss decreased (0.418591 --> 0.418563).  Saving model ...
Validation loss decreased (0.418563 --> 0.418536).  Saving model ...
Validation loss decreased (0.418536 --> 0.418509).  Saving model ...
Validation loss decreased (0.418509 --> 0.418481).  Saving model ...
Validation loss decreased (0.418481 --> 0.418454).  Saving model ...
Validation loss decreased (0.418454 --> 0.418426).  Saving model ...
Validation loss decreased (0.418426 --> 0.418399).  Saving model ...
Validation loss decreased (0.418399 --> 0.418371).  Saving model ...
Validation loss decreased (0.418371 --> 0.418344).  Saving model ...
Validation loss decreased (0.418344 --> 0.418316).  Saving model ...
Validation loss decreased (0.418316 --> 0.418289).  Saving model ...
Validation loss decreased (0.418289 --> 0.418261).  Saving model ...
Validation loss decreased (0.418261 --> 0.418234).  Saving model ...
Validation loss decreased (0.418234 --> 0.418206).  Saving model ...
Validation loss decreased (0.418206 --> 0.418179).  Saving model ...
Validation loss decreased (0.418179 --> 0.418151).  Saving model ...
Validation loss decreased (0.418151 --> 0.418124).  Saving model ...
Validation loss decreased (0.418124 --> 0.418096).  Saving model ...
Validation loss decreased (0.418096 --> 0.418069).  Saving model ...
Validation loss decreased (0.418069 --> 0.418041).  Saving model ...
Validation loss decreased (0.418041 --> 0.418014).  Saving model ...
Validation loss decreased (0.418014 --> 0.417986).  Saving model ...
Validation loss decreased (0.417986 --> 0.417959).  Saving model ...
Validation loss decreased (0.417959 --> 0.417931).  Saving model ...
Validation loss decreased (0.417931 --> 0.417904).  Saving model ...
Validation loss decreased (0.417904 --> 0.417876).  Saving model ...
Validation loss decreased (0.417876 --> 0.417849).  Saving model ...
Validation loss decreased (0.417849 --> 0.417821).  Saving model ...
Validation loss decreased (0.417821 --> 0.417793).  Saving model ...
Validation loss decreased (0.417793 --> 0.417766).  Saving model ...
Validation loss decreased (0.417766 --> 0.417738).  Saving model ...
Validation loss decreased (0.417738 --> 0.417711).  Saving model ...
Validation loss decreased (0.417711 --> 0.417683).  Saving model ...
Validation loss decreased (0.417683 --> 0.417656).  Saving model ...
Validation loss decreased (0.417656 --> 0.417628).  Saving model ...
Validation loss decreased (0.417628 --> 0.417601).  Saving model ...
Validation loss decreased (0.417601 --> 0.417573).  Saving model ...
Validation loss decreased (0.417573 --> 0.417545).  Saving model ...
Validation loss decreased (0.417545 --> 0.417518).  Saving model ...
Validation loss decreased (0.417518 --> 0.417490).  Saving model ...
Validation loss decreased (0.417490 --> 0.417463).  Saving model ...
Validation loss decreased (0.417463 --> 0.417435).  Saving model ...
Validation loss decreased (0.417435 --> 0.417408).  Saving model ...
Validation loss decreased (0.417408 --> 0.417380).  Saving model ...
Validation loss decreased (0.417380 --> 0.417352).  Saving model ...
Validation loss decreased (0.417352 --> 0.417325).  Saving model ...
Validation loss decreased (0.417325 --> 0.417297).  Saving model ...
Validation loss decreased (0.417297 --> 0.417270).  Saving model ...
Validation loss decreased (0.417270 --> 0.417242).  Saving model ...
Validation loss decreased (0.417242 --> 0.417214).  Saving model ...
Validation loss decreased (0.417214 --> 0.417187).  Saving model ...
Validation loss decreased (0.417187 --> 0.417159).  Saving model ...
Validation loss decreased (0.417159 --> 0.417131).  Saving model ...
Validation loss decreased (0.417131 --> 0.417104).  Saving model ...
Validation loss decreased (0.417104 --> 0.417076).  Saving model ...
Validation loss decreased (0.417076 --> 0.417049).  Saving model ...
Validation loss decreased (0.417049 --> 0.417021).  Saving model ...
Validation loss decreased (0.417021 --> 0.416993).  Saving model ...
Validation loss decreased (0.416993 --> 0.416966).  Saving model ...
Validation loss decreased (0.416966 --> 0.416938).  Saving model ...
Validation loss decreased (0.416938 --> 0.416910).  Saving model ...
Validation loss decreased (0.416910 --> 0.416883).  Saving model ...
Validation loss decreased (0.416883 --> 0.416855).  Saving model ...
Validation loss decreased (0.416855 --> 0.416827).  Saving model ...
Validation loss decreased (0.416827 --> 0.416800).  Saving model ...
Validation loss decreased (0.416800 --> 0.416772).  Saving model ...
Validation loss decreased (0.416772 --> 0.416744).  Saving model ...
Validation loss decreased (0.416744 --> 0.416716).  Saving model ...
Validation loss decreased (0.416716 --> 0.416689).  Saving model ...
epoch 2501, loss 0.4167, train acc 79.32%, f1 0.6889, precision 0.7283, recall 0.6537, auc 0.7610
Validation loss decreased (0.416689 --> 0.416661).  Saving model ...
Validation loss decreased (0.416661 --> 0.416633).  Saving model ...
Validation loss decreased (0.416633 --> 0.416606).  Saving model ...
Validation loss decreased (0.416606 --> 0.416578).  Saving model ...
Validation loss decreased (0.416578 --> 0.416550).  Saving model ...
Validation loss decreased (0.416550 --> 0.416522).  Saving model ...
Validation loss decreased (0.416522 --> 0.416495).  Saving model ...
Validation loss decreased (0.416495 --> 0.416467).  Saving model ...
Validation loss decreased (0.416467 --> 0.416439).  Saving model ...
Validation loss decreased (0.416439 --> 0.416412).  Saving model ...
Validation loss decreased (0.416412 --> 0.416384).  Saving model ...
Validation loss decreased (0.416384 --> 0.416356).  Saving model ...
Validation loss decreased (0.416356 --> 0.416328).  Saving model ...
Validation loss decreased (0.416328 --> 0.416301).  Saving model ...
Validation loss decreased (0.416301 --> 0.416273).  Saving model ...
Validation loss decreased (0.416273 --> 0.416245).  Saving model ...
Validation loss decreased (0.416245 --> 0.416217).  Saving model ...
Validation loss decreased (0.416217 --> 0.416189).  Saving model ...
Validation loss decreased (0.416189 --> 0.416162).  Saving model ...
Validation loss decreased (0.416162 --> 0.416134).  Saving model ...
Validation loss decreased (0.416134 --> 0.416106).  Saving model ...
Validation loss decreased (0.416106 --> 0.416078).  Saving model ...
Validation loss decreased (0.416078 --> 0.416050).  Saving model ...
Validation loss decreased (0.416050 --> 0.416023).  Saving model ...
Validation loss decreased (0.416023 --> 0.415995).  Saving model ...
Validation loss decreased (0.415995 --> 0.415967).  Saving model ...
Validation loss decreased (0.415967 --> 0.415939).  Saving model ...
Validation loss decreased (0.415939 --> 0.415911).  Saving model ...
Validation loss decreased (0.415911 --> 0.415884).  Saving model ...
Validation loss decreased (0.415884 --> 0.415856).  Saving model ...
Validation loss decreased (0.415856 --> 0.415828).  Saving model ...
Validation loss decreased (0.415828 --> 0.415800).  Saving model ...
Validation loss decreased (0.415800 --> 0.415772).  Saving model ...
Validation loss decreased (0.415772 --> 0.415744).  Saving model ...
Validation loss decreased (0.415744 --> 0.415717).  Saving model ...
Validation loss decreased (0.415717 --> 0.415689).  Saving model ...
Validation loss decreased (0.415689 --> 0.415661).  Saving model ...
Validation loss decreased (0.415661 --> 0.415633).  Saving model ...
Validation loss decreased (0.415633 --> 0.415605).  Saving model ...
Validation loss decreased (0.415605 --> 0.415577).  Saving model ...
Validation loss decreased (0.415577 --> 0.415549).  Saving model ...
Validation loss decreased (0.415549 --> 0.415522).  Saving model ...
Validation loss decreased (0.415522 --> 0.415494).  Saving model ...
Validation loss decreased (0.415494 --> 0.415466).  Saving model ...
Validation loss decreased (0.415466 --> 0.415438).  Saving model ...
Validation loss decreased (0.415438 --> 0.415410).  Saving model ...
Validation loss decreased (0.415410 --> 0.415382).  Saving model ...
Validation loss decreased (0.415382 --> 0.415354).  Saving model ...
Validation loss decreased (0.415354 --> 0.415326).  Saving model ...
Validation loss decreased (0.415326 --> 0.415299).  Saving model ...
Validation loss decreased (0.415299 --> 0.415271).  Saving model ...
Validation loss decreased (0.415271 --> 0.415243).  Saving model ...
Validation loss decreased (0.415243 --> 0.415215).  Saving model ...
Validation loss decreased (0.415215 --> 0.415187).  Saving model ...
Validation loss decreased (0.415187 --> 0.415159).  Saving model ...
Validation loss decreased (0.415159 --> 0.415131).  Saving model ...
Validation loss decreased (0.415131 --> 0.415103).  Saving model ...
Validation loss decreased (0.415103 --> 0.415075).  Saving model ...
Validation loss decreased (0.415075 --> 0.415048).  Saving model ...
Validation loss decreased (0.415048 --> 0.415020).  Saving model ...
Validation loss decreased (0.415020 --> 0.414992).  Saving model ...
Validation loss decreased (0.414992 --> 0.414964).  Saving model ...
Validation loss decreased (0.414964 --> 0.414936).  Saving model ...
Validation loss decreased (0.414936 --> 0.414908).  Saving model ...
Validation loss decreased (0.414908 --> 0.414880).  Saving model ...
Validation loss decreased (0.414880 --> 0.414852).  Saving model ...
Validation loss decreased (0.414852 --> 0.414824).  Saving model ...
Validation loss decreased (0.414824 --> 0.414796).  Saving model ...
Validation loss decreased (0.414796 --> 0.414769).  Saving model ...
Validation loss decreased (0.414769 --> 0.414741).  Saving model ...
Validation loss decreased (0.414741 --> 0.414713).  Saving model ...
Validation loss decreased (0.414713 --> 0.414685).  Saving model ...
Validation loss decreased (0.414685 --> 0.414657).  Saving model ...
Validation loss decreased (0.414657 --> 0.414629).  Saving model ...
Validation loss decreased (0.414629 --> 0.414601).  Saving model ...
Validation loss decreased (0.414601 --> 0.414573).  Saving model ...
Validation loss decreased (0.414573 --> 0.414545).  Saving model ...
Validation loss decreased (0.414545 --> 0.414517).  Saving model ...
Validation loss decreased (0.414517 --> 0.414489).  Saving model ...
Validation loss decreased (0.414489 --> 0.414462).  Saving model ...
Validation loss decreased (0.414462 --> 0.414434).  Saving model ...
Validation loss decreased (0.414434 --> 0.414406).  Saving model ...
Validation loss decreased (0.414406 --> 0.414378).  Saving model ...
Validation loss decreased (0.414378 --> 0.414350).  Saving model ...
Validation loss decreased (0.414350 --> 0.414322).  Saving model ...
Validation loss decreased (0.414322 --> 0.414294).  Saving model ...
Validation loss decreased (0.414294 --> 0.414266).  Saving model ...
Validation loss decreased (0.414266 --> 0.414238).  Saving model ...
Validation loss decreased (0.414238 --> 0.414211).  Saving model ...
Validation loss decreased (0.414211 --> 0.414183).  Saving model ...
Validation loss decreased (0.414183 --> 0.414155).  Saving model ...
Validation loss decreased (0.414155 --> 0.414127).  Saving model ...
Validation loss decreased (0.414127 --> 0.414099).  Saving model ...
Validation loss decreased (0.414099 --> 0.414071).  Saving model ...
Validation loss decreased (0.414071 --> 0.414043).  Saving model ...
Validation loss decreased (0.414043 --> 0.414015).  Saving model ...
Validation loss decreased (0.414015 --> 0.413988).  Saving model ...
Validation loss decreased (0.413988 --> 0.413960).  Saving model ...
Validation loss decreased (0.413960 --> 0.413932).  Saving model ...
Validation loss decreased (0.413932 --> 0.413904).  Saving model ...
epoch 2601, loss 0.4139, train acc 79.83%, f1 0.6974, precision 0.7351, recall 0.6634, auc 0.7672
Validation loss decreased (0.413904 --> 0.413876).  Saving model ...
Validation loss decreased (0.413876 --> 0.413848).  Saving model ...
Validation loss decreased (0.413848 --> 0.413820).  Saving model ...
Validation loss decreased (0.413820 --> 0.413793).  Saving model ...
Validation loss decreased (0.413793 --> 0.413765).  Saving model ...
Validation loss decreased (0.413765 --> 0.413737).  Saving model ...
Validation loss decreased (0.413737 --> 0.413709).  Saving model ...
Validation loss decreased (0.413709 --> 0.413681).  Saving model ...
Validation loss decreased (0.413681 --> 0.413653).  Saving model ...
Validation loss decreased (0.413653 --> 0.413626).  Saving model ...
Validation loss decreased (0.413626 --> 0.413598).  Saving model ...
Validation loss decreased (0.413598 --> 0.413570).  Saving model ...
Validation loss decreased (0.413570 --> 0.413542).  Saving model ...
Validation loss decreased (0.413542 --> 0.413514).  Saving model ...
Validation loss decreased (0.413514 --> 0.413487).  Saving model ...
Validation loss decreased (0.413487 --> 0.413459).  Saving model ...
Validation loss decreased (0.413459 --> 0.413431).  Saving model ...
Validation loss decreased (0.413431 --> 0.413403).  Saving model ...
Validation loss decreased (0.413403 --> 0.413375).  Saving model ...
Validation loss decreased (0.413375 --> 0.413348).  Saving model ...
Validation loss decreased (0.413348 --> 0.413320).  Saving model ...
Validation loss decreased (0.413320 --> 0.413292).  Saving model ...
Validation loss decreased (0.413292 --> 0.413264).  Saving model ...
Validation loss decreased (0.413264 --> 0.413237).  Saving model ...
Validation loss decreased (0.413237 --> 0.413209).  Saving model ...
Validation loss decreased (0.413209 --> 0.413181).  Saving model ...
Validation loss decreased (0.413181 --> 0.413154).  Saving model ...
Validation loss decreased (0.413154 --> 0.413126).  Saving model ...
Validation loss decreased (0.413126 --> 0.413098).  Saving model ...
Validation loss decreased (0.413098 --> 0.413070).  Saving model ...
Validation loss decreased (0.413070 --> 0.413043).  Saving model ...
Validation loss decreased (0.413043 --> 0.413015).  Saving model ...
Validation loss decreased (0.413015 --> 0.412987).  Saving model ...
Validation loss decreased (0.412987 --> 0.412960).  Saving model ...
Validation loss decreased (0.412960 --> 0.412932).  Saving model ...
Validation loss decreased (0.412932 --> 0.412905).  Saving model ...
Validation loss decreased (0.412905 --> 0.412877).  Saving model ...
Validation loss decreased (0.412877 --> 0.412849).  Saving model ...
Validation loss decreased (0.412849 --> 0.412822).  Saving model ...
Validation loss decreased (0.412822 --> 0.412794).  Saving model ...
Validation loss decreased (0.412794 --> 0.412767).  Saving model ...
Validation loss decreased (0.412767 --> 0.412739).  Saving model ...
Validation loss decreased (0.412739 --> 0.412711).  Saving model ...
Validation loss decreased (0.412711 --> 0.412684).  Saving model ...
Validation loss decreased (0.412684 --> 0.412656).  Saving model ...
Validation loss decreased (0.412656 --> 0.412629).  Saving model ...
Validation loss decreased (0.412629 --> 0.412601).  Saving model ...
Validation loss decreased (0.412601 --> 0.412574).  Saving model ...
Validation loss decreased (0.412574 --> 0.412546).  Saving model ...
Validation loss decreased (0.412546 --> 0.412519).  Saving model ...
Validation loss decreased (0.412519 --> 0.412491).  Saving model ...
Validation loss decreased (0.412491 --> 0.412464).  Saving model ...
Validation loss decreased (0.412464 --> 0.412437).  Saving model ...
Validation loss decreased (0.412437 --> 0.412409).  Saving model ...
Validation loss decreased (0.412409 --> 0.412382).  Saving model ...
Validation loss decreased (0.412382 --> 0.412354).  Saving model ...
Validation loss decreased (0.412354 --> 0.412327).  Saving model ...
Validation loss decreased (0.412327 --> 0.412300).  Saving model ...
Validation loss decreased (0.412300 --> 0.412272).  Saving model ...
Validation loss decreased (0.412272 --> 0.412245).  Saving model ...
Validation loss decreased (0.412245 --> 0.412217).  Saving model ...
Validation loss decreased (0.412217 --> 0.412190).  Saving model ...
Validation loss decreased (0.412190 --> 0.412163).  Saving model ...
Validation loss decreased (0.412163 --> 0.412136).  Saving model ...
Validation loss decreased (0.412136 --> 0.412108).  Saving model ...
Validation loss decreased (0.412108 --> 0.412081).  Saving model ...
Validation loss decreased (0.412081 --> 0.412054).  Saving model ...
Validation loss decreased (0.412054 --> 0.412027).  Saving model ...
Validation loss decreased (0.412027 --> 0.411999).  Saving model ...
Validation loss decreased (0.411999 --> 0.411972).  Saving model ...
Validation loss decreased (0.411972 --> 0.411945).  Saving model ...
Validation loss decreased (0.411945 --> 0.411918).  Saving model ...
Validation loss decreased (0.411918 --> 0.411891).  Saving model ...
Validation loss decreased (0.411891 --> 0.411864).  Saving model ...
Validation loss decreased (0.411864 --> 0.411837).  Saving model ...
Validation loss decreased (0.411837 --> 0.411809).  Saving model ...
Validation loss decreased (0.411809 --> 0.411782).  Saving model ...
Validation loss decreased (0.411782 --> 0.411755).  Saving model ...
Validation loss decreased (0.411755 --> 0.411728).  Saving model ...
Validation loss decreased (0.411728 --> 0.411701).  Saving model ...
Validation loss decreased (0.411701 --> 0.411674).  Saving model ...
Validation loss decreased (0.411674 --> 0.411647).  Saving model ...
Validation loss decreased (0.411647 --> 0.411620).  Saving model ...
Validation loss decreased (0.411620 --> 0.411593).  Saving model ...
Validation loss decreased (0.411593 --> 0.411566).  Saving model ...
Validation loss decreased (0.411566 --> 0.411539).  Saving model ...
Validation loss decreased (0.411539 --> 0.411512).  Saving model ...
Validation loss decreased (0.411512 --> 0.411486).  Saving model ...
Validation loss decreased (0.411486 --> 0.411459).  Saving model ...
Validation loss decreased (0.411459 --> 0.411432).  Saving model ...
Validation loss decreased (0.411432 --> 0.411405).  Saving model ...
Validation loss decreased (0.411405 --> 0.411378).  Saving model ...
Validation loss decreased (0.411378 --> 0.411351).  Saving model ...
Validation loss decreased (0.411351 --> 0.411325).  Saving model ...
Validation loss decreased (0.411325 --> 0.411298).  Saving model ...
Validation loss decreased (0.411298 --> 0.411271).  Saving model ...
Validation loss decreased (0.411271 --> 0.411244).  Saving model ...
Validation loss decreased (0.411244 --> 0.411218).  Saving model ...
Validation loss decreased (0.411218 --> 0.411191).  Saving model ...
Validation loss decreased (0.411191 --> 0.411164).  Saving model ...
epoch 2701, loss 0.4112, train acc 80.17%, f1 0.7041, precision 0.7380, recall 0.6732, auc 0.7721
Validation loss decreased (0.411164 --> 0.411138).  Saving model ...
Validation loss decreased (0.411138 --> 0.411111).  Saving model ...
Validation loss decreased (0.411111 --> 0.411084).  Saving model ...
Validation loss decreased (0.411084 --> 0.411058).  Saving model ...
Validation loss decreased (0.411058 --> 0.411031).  Saving model ...
Validation loss decreased (0.411031 --> 0.411005).  Saving model ...
Validation loss decreased (0.411005 --> 0.410978).  Saving model ...
Validation loss decreased (0.410978 --> 0.410952).  Saving model ...
Validation loss decreased (0.410952 --> 0.410925).  Saving model ...
Validation loss decreased (0.410925 --> 0.410899).  Saving model ...
Validation loss decreased (0.410899 --> 0.410872).  Saving model ...
Validation loss decreased (0.410872 --> 0.410846).  Saving model ...
Validation loss decreased (0.410846 --> 0.410819).  Saving model ...
Validation loss decreased (0.410819 --> 0.410793).  Saving model ...
Validation loss decreased (0.410793 --> 0.410766).  Saving model ...
Validation loss decreased (0.410766 --> 0.410740).  Saving model ...
Validation loss decreased (0.410740 --> 0.410714).  Saving model ...
Validation loss decreased (0.410714 --> 0.410687).  Saving model ...
Validation loss decreased (0.410687 --> 0.410661).  Saving model ...
Validation loss decreased (0.410661 --> 0.410635).  Saving model ...
Validation loss decreased (0.410635 --> 0.410609).  Saving model ...
Validation loss decreased (0.410609 --> 0.410582).  Saving model ...
Validation loss decreased (0.410582 --> 0.410556).  Saving model ...
Validation loss decreased (0.410556 --> 0.410530).  Saving model ...
Validation loss decreased (0.410530 --> 0.410504).  Saving model ...
Validation loss decreased (0.410504 --> 0.410478).  Saving model ...
Validation loss decreased (0.410478 --> 0.410451).  Saving model ...
Validation loss decreased (0.410451 --> 0.410425).  Saving model ...
Validation loss decreased (0.410425 --> 0.410399).  Saving model ...
Validation loss decreased (0.410399 --> 0.410373).  Saving model ...
Validation loss decreased (0.410373 --> 0.410347).  Saving model ...
Validation loss decreased (0.410347 --> 0.410321).  Saving model ...
Validation loss decreased (0.410321 --> 0.410295).  Saving model ...
Validation loss decreased (0.410295 --> 0.410269).  Saving model ...
Validation loss decreased (0.410269 --> 0.410243).  Saving model ...
Validation loss decreased (0.410243 --> 0.410217).  Saving model ...
Validation loss decreased (0.410217 --> 0.410191).  Saving model ...
Validation loss decreased (0.410191 --> 0.410165).  Saving model ...
Validation loss decreased (0.410165 --> 0.410139).  Saving model ...
Validation loss decreased (0.410139 --> 0.410114).  Saving model ...
Validation loss decreased (0.410114 --> 0.410088).  Saving model ...
Validation loss decreased (0.410088 --> 0.410062).  Saving model ...
Validation loss decreased (0.410062 --> 0.410036).  Saving model ...
Validation loss decreased (0.410036 --> 0.410010).  Saving model ...
Validation loss decreased (0.410010 --> 0.409984).  Saving model ...
Validation loss decreased (0.409984 --> 0.409959).  Saving model ...
Validation loss decreased (0.409959 --> 0.409933).  Saving model ...
Validation loss decreased (0.409933 --> 0.409907).  Saving model ...
Validation loss decreased (0.409907 --> 0.409882).  Saving model ...
Validation loss decreased (0.409882 --> 0.409856).  Saving model ...
Validation loss decreased (0.409856 --> 0.409830).  Saving model ...
Validation loss decreased (0.409830 --> 0.409805).  Saving model ...
Validation loss decreased (0.409805 --> 0.409779).  Saving model ...
Validation loss decreased (0.409779 --> 0.409754).  Saving model ...
Validation loss decreased (0.409754 --> 0.409728).  Saving model ...
Validation loss decreased (0.409728 --> 0.409702).  Saving model ...
Validation loss decreased (0.409702 --> 0.409677).  Saving model ...
Validation loss decreased (0.409677 --> 0.409651).  Saving model ...
Validation loss decreased (0.409651 --> 0.409626).  Saving model ...
Validation loss decreased (0.409626 --> 0.409601).  Saving model ...
Validation loss decreased (0.409601 --> 0.409575).  Saving model ...
Validation loss decreased (0.409575 --> 0.409550).  Saving model ...
Validation loss decreased (0.409550 --> 0.409524).  Saving model ...
Validation loss decreased (0.409524 --> 0.409499).  Saving model ...
Validation loss decreased (0.409499 --> 0.409474).  Saving model ...
Validation loss decreased (0.409474 --> 0.409448).  Saving model ...
Validation loss decreased (0.409448 --> 0.409423).  Saving model ...
Validation loss decreased (0.409423 --> 0.409398).  Saving model ...
Validation loss decreased (0.409398 --> 0.409372).  Saving model ...
Validation loss decreased (0.409372 --> 0.409347).  Saving model ...
Validation loss decreased (0.409347 --> 0.409322).  Saving model ...
Validation loss decreased (0.409322 --> 0.409297).  Saving model ...
Validation loss decreased (0.409297 --> 0.409272).  Saving model ...
Validation loss decreased (0.409272 --> 0.409247).  Saving model ...
Validation loss decreased (0.409247 --> 0.409221).  Saving model ...
Validation loss decreased (0.409221 --> 0.409196).  Saving model ...
Validation loss decreased (0.409196 --> 0.409171).  Saving model ...
Validation loss decreased (0.409171 --> 0.409146).  Saving model ...
Validation loss decreased (0.409146 --> 0.409121).  Saving model ...
Validation loss decreased (0.409121 --> 0.409096).  Saving model ...
Validation loss decreased (0.409096 --> 0.409071).  Saving model ...
Validation loss decreased (0.409071 --> 0.409046).  Saving model ...
Validation loss decreased (0.409046 --> 0.409021).  Saving model ...
Validation loss decreased (0.409021 --> 0.408996).  Saving model ...
Validation loss decreased (0.408996 --> 0.408971).  Saving model ...
Validation loss decreased (0.408971 --> 0.408946).  Saving model ...
Validation loss decreased (0.408946 --> 0.408922).  Saving model ...
Validation loss decreased (0.408922 --> 0.408897).  Saving model ...
Validation loss decreased (0.408897 --> 0.408872).  Saving model ...
Validation loss decreased (0.408872 --> 0.408847).  Saving model ...
Validation loss decreased (0.408847 --> 0.408822).  Saving model ...
Validation loss decreased (0.408822 --> 0.408797).  Saving model ...
Validation loss decreased (0.408797 --> 0.408773).  Saving model ...
Validation loss decreased (0.408773 --> 0.408748).  Saving model ...
Validation loss decreased (0.408748 --> 0.408723).  Saving model ...
Validation loss decreased (0.408723 --> 0.408699).  Saving model ...
Validation loss decreased (0.408699 --> 0.408674).  Saving model ...
Validation loss decreased (0.408674 --> 0.408649).  Saving model ...
Validation loss decreased (0.408649 --> 0.408625).  Saving model ...
Validation loss decreased (0.408625 --> 0.408600).  Saving model ...
epoch 2801, loss 0.4086, train acc 80.00%, f1 0.7023, precision 0.7340, recall 0.6732, auc 0.7708
Validation loss decreased (0.408600 --> 0.408576).  Saving model ...
Validation loss decreased (0.408576 --> 0.408551).  Saving model ...
Validation loss decreased (0.408551 --> 0.408526).  Saving model ...
Validation loss decreased (0.408526 --> 0.408502).  Saving model ...
Validation loss decreased (0.408502 --> 0.408477).  Saving model ...
Validation loss decreased (0.408477 --> 0.408453).  Saving model ...
Validation loss decreased (0.408453 --> 0.408429).  Saving model ...
Validation loss decreased (0.408429 --> 0.408404).  Saving model ...
Validation loss decreased (0.408404 --> 0.408380).  Saving model ...
Validation loss decreased (0.408380 --> 0.408355).  Saving model ...
Validation loss decreased (0.408355 --> 0.408331).  Saving model ...
Validation loss decreased (0.408331 --> 0.408307).  Saving model ...
Validation loss decreased (0.408307 --> 0.408282).  Saving model ...
Validation loss decreased (0.408282 --> 0.408258).  Saving model ...
Validation loss decreased (0.408258 --> 0.408234).  Saving model ...
Validation loss decreased (0.408234 --> 0.408210).  Saving model ...
Validation loss decreased (0.408210 --> 0.408185).  Saving model ...
Validation loss decreased (0.408185 --> 0.408161).  Saving model ...
Validation loss decreased (0.408161 --> 0.408137).  Saving model ...
Validation loss decreased (0.408137 --> 0.408113).  Saving model ...
Validation loss decreased (0.408113 --> 0.408089).  Saving model ...
Validation loss decreased (0.408089 --> 0.408064).  Saving model ...
Validation loss decreased (0.408064 --> 0.408040).  Saving model ...
Validation loss decreased (0.408040 --> 0.408016).  Saving model ...
Validation loss decreased (0.408016 --> 0.407992).  Saving model ...
Validation loss decreased (0.407992 --> 0.407968).  Saving model ...
Validation loss decreased (0.407968 --> 0.407944).  Saving model ...
Validation loss decreased (0.407944 --> 0.407920).  Saving model ...
Validation loss decreased (0.407920 --> 0.407896).  Saving model ...
Validation loss decreased (0.407896 --> 0.407872).  Saving model ...
Validation loss decreased (0.407872 --> 0.407848).  Saving model ...
Validation loss decreased (0.407848 --> 0.407824).  Saving model ...
Validation loss decreased (0.407824 --> 0.407800).  Saving model ...
Validation loss decreased (0.407800 --> 0.407776).  Saving model ...
Validation loss decreased (0.407776 --> 0.407753).  Saving model ...
Validation loss decreased (0.407753 --> 0.407729).  Saving model ...
Validation loss decreased (0.407729 --> 0.407705).  Saving model ...
Validation loss decreased (0.407705 --> 0.407681).  Saving model ...
Validation loss decreased (0.407681 --> 0.407657).  Saving model ...
Validation loss decreased (0.407657 --> 0.407634).  Saving model ...
Validation loss decreased (0.407634 --> 0.407610).  Saving model ...
Validation loss decreased (0.407610 --> 0.407586).  Saving model ...
Validation loss decreased (0.407586 --> 0.407562).  Saving model ...
Validation loss decreased (0.407562 --> 0.407539).  Saving model ...
Validation loss decreased (0.407539 --> 0.407515).  Saving model ...
Validation loss decreased (0.407515 --> 0.407491).  Saving model ...
Validation loss decreased (0.407491 --> 0.407468).  Saving model ...
Validation loss decreased (0.407468 --> 0.407444).  Saving model ...
Validation loss decreased (0.407444 --> 0.407421).  Saving model ...
Validation loss decreased (0.407421 --> 0.407397).  Saving model ...
Validation loss decreased (0.407397 --> 0.407374).  Saving model ...
Validation loss decreased (0.407374 --> 0.407350).  Saving model ...
Validation loss decreased (0.407350 --> 0.407327).  Saving model ...
Validation loss decreased (0.407327 --> 0.407303).  Saving model ...
Validation loss decreased (0.407303 --> 0.407280).  Saving model ...
Validation loss decreased (0.407280 --> 0.407256).  Saving model ...
Validation loss decreased (0.407256 --> 0.407233).  Saving model ...
Validation loss decreased (0.407233 --> 0.407209).  Saving model ...
Validation loss decreased (0.407209 --> 0.407186).  Saving model ...
Validation loss decreased (0.407186 --> 0.407163).  Saving model ...
Validation loss decreased (0.407163 --> 0.407139).  Saving model ...
Validation loss decreased (0.407139 --> 0.407116).  Saving model ...
Validation loss decreased (0.407116 --> 0.407093).  Saving model ...
Validation loss decreased (0.407093 --> 0.407069).  Saving model ...
Validation loss decreased (0.407069 --> 0.407046).  Saving model ...
Validation loss decreased (0.407046 --> 0.407023).  Saving model ...
Validation loss decreased (0.407023 --> 0.407000).  Saving model ...
Validation loss decreased (0.407000 --> 0.406976).  Saving model ...
Validation loss decreased (0.406976 --> 0.406953).  Saving model ...
Validation loss decreased (0.406953 --> 0.406930).  Saving model ...
Validation loss decreased (0.406930 --> 0.406907).  Saving model ...
Validation loss decreased (0.406907 --> 0.406884).  Saving model ...
Validation loss decreased (0.406884 --> 0.406861).  Saving model ...
Validation loss decreased (0.406861 --> 0.406838).  Saving model ...
Validation loss decreased (0.406838 --> 0.406815).  Saving model ...
Validation loss decreased (0.406815 --> 0.406791).  Saving model ...
Validation loss decreased (0.406791 --> 0.406768).  Saving model ...
Validation loss decreased (0.406768 --> 0.406745).  Saving model ...
Validation loss decreased (0.406745 --> 0.406722).  Saving model ...
Validation loss decreased (0.406722 --> 0.406700).  Saving model ...
Validation loss decreased (0.406700 --> 0.406677).  Saving model ...
Validation loss decreased (0.406677 --> 0.406654).  Saving model ...
Validation loss decreased (0.406654 --> 0.406631).  Saving model ...
Validation loss decreased (0.406631 --> 0.406608).  Saving model ...
Validation loss decreased (0.406608 --> 0.406585).  Saving model ...
Validation loss decreased (0.406585 --> 0.406562).  Saving model ...
Validation loss decreased (0.406562 --> 0.406539).  Saving model ...
Validation loss decreased (0.406539 --> 0.406516).  Saving model ...
Validation loss decreased (0.406516 --> 0.406494).  Saving model ...
Validation loss decreased (0.406494 --> 0.406471).  Saving model ...
Validation loss decreased (0.406471 --> 0.406448).  Saving model ...
Validation loss decreased (0.406448 --> 0.406425).  Saving model ...
Validation loss decreased (0.406425 --> 0.406403).  Saving model ...
Validation loss decreased (0.406403 --> 0.406380).  Saving model ...
Validation loss decreased (0.406380 --> 0.406357).  Saving model ...
Validation loss decreased (0.406357 --> 0.406335).  Saving model ...
Validation loss decreased (0.406335 --> 0.406312).  Saving model ...
Validation loss decreased (0.406312 --> 0.406289).  Saving model ...
Validation loss decreased (0.406289 --> 0.406267).  Saving model ...
Validation loss decreased (0.406267 --> 0.406244).  Saving model ...
epoch 2901, loss 0.4062, train acc 80.00%, f1 0.7023, precision 0.7340, recall 0.6732, auc 0.7708
Validation loss decreased (0.406244 --> 0.406221).  Saving model ...
Validation loss decreased (0.406221 --> 0.406199).  Saving model ...
Validation loss decreased (0.406199 --> 0.406176).  Saving model ...
Validation loss decreased (0.406176 --> 0.406154).  Saving model ...
Validation loss decreased (0.406154 --> 0.406131).  Saving model ...
Validation loss decreased (0.406131 --> 0.406109).  Saving model ...
Validation loss decreased (0.406109 --> 0.406086).  Saving model ...
Validation loss decreased (0.406086 --> 0.406064).  Saving model ...
Validation loss decreased (0.406064 --> 0.406041).  Saving model ...
Validation loss decreased (0.406041 --> 0.406019).  Saving model ...
Validation loss decreased (0.406019 --> 0.405997).  Saving model ...
Validation loss decreased (0.405997 --> 0.405974).  Saving model ...
Validation loss decreased (0.405974 --> 0.405952).  Saving model ...
Validation loss decreased (0.405952 --> 0.405930).  Saving model ...
Validation loss decreased (0.405930 --> 0.405907).  Saving model ...
Validation loss decreased (0.405907 --> 0.405885).  Saving model ...
Validation loss decreased (0.405885 --> 0.405863).  Saving model ...
Validation loss decreased (0.405863 --> 0.405840).  Saving model ...
Validation loss decreased (0.405840 --> 0.405818).  Saving model ...
Validation loss decreased (0.405818 --> 0.405796).  Saving model ...
Validation loss decreased (0.405796 --> 0.405774).  Saving model ...
Validation loss decreased (0.405774 --> 0.405751).  Saving model ...
Validation loss decreased (0.405751 --> 0.405729).  Saving model ...
Validation loss decreased (0.405729 --> 0.405707).  Saving model ...
Validation loss decreased (0.405707 --> 0.405685).  Saving model ...
Validation loss decreased (0.405685 --> 0.405663).  Saving model ...
Validation loss decreased (0.405663 --> 0.405641).  Saving model ...
Validation loss decreased (0.405641 --> 0.405618).  Saving model ...
Validation loss decreased (0.405618 --> 0.405596).  Saving model ...
Validation loss decreased (0.405596 --> 0.405574).  Saving model ...
Validation loss decreased (0.405574 --> 0.405552).  Saving model ...
Validation loss decreased (0.405552 --> 0.405530).  Saving model ...
Validation loss decreased (0.405530 --> 0.405508).  Saving model ...
Validation loss decreased (0.405508 --> 0.405486).  Saving model ...
Validation loss decreased (0.405486 --> 0.405464).  Saving model ...
Validation loss decreased (0.405464 --> 0.405442).  Saving model ...
Validation loss decreased (0.405442 --> 0.405420).  Saving model ...
Validation loss decreased (0.405420 --> 0.405398).  Saving model ...
Validation loss decreased (0.405398 --> 0.405376).  Saving model ...
Validation loss decreased (0.405376 --> 0.405355).  Saving model ...
Validation loss decreased (0.405355 --> 0.405333).  Saving model ...
Validation loss decreased (0.405333 --> 0.405311).  Saving model ...
Validation loss decreased (0.405311 --> 0.405289).  Saving model ...
Validation loss decreased (0.405289 --> 0.405267).  Saving model ...
Validation loss decreased (0.405267 --> 0.405245).  Saving model ...
Validation loss decreased (0.405245 --> 0.405223).  Saving model ...
Validation loss decreased (0.405223 --> 0.405202).  Saving model ...
Validation loss decreased (0.405202 --> 0.405180).  Saving model ...
Validation loss decreased (0.405180 --> 0.405158).  Saving model ...
Validation loss decreased (0.405158 --> 0.405136).  Saving model ...
Validation loss decreased (0.405136 --> 0.405115).  Saving model ...
Validation loss decreased (0.405115 --> 0.405093).  Saving model ...
Validation loss decreased (0.405093 --> 0.405071).  Saving model ...
Validation loss decreased (0.405071 --> 0.405050).  Saving model ...
Validation loss decreased (0.405050 --> 0.405028).  Saving model ...
Validation loss decreased (0.405028 --> 0.405006).  Saving model ...
Validation loss decreased (0.405006 --> 0.404985).  Saving model ...
Validation loss decreased (0.404985 --> 0.404963).  Saving model ...
Validation loss decreased (0.404963 --> 0.404941).  Saving model ...
Validation loss decreased (0.404941 --> 0.404920).  Saving model ...
Validation loss decreased (0.404920 --> 0.404898).  Saving model ...
Validation loss decreased (0.404898 --> 0.404877).  Saving model ...
Validation loss decreased (0.404877 --> 0.404855).  Saving model ...
Validation loss decreased (0.404855 --> 0.404834).  Saving model ...
Validation loss decreased (0.404834 --> 0.404812).  Saving model ...
Validation loss decreased (0.404812 --> 0.404790).  Saving model ...
Validation loss decreased (0.404790 --> 0.404769).  Saving model ...
Validation loss decreased (0.404769 --> 0.404748).  Saving model ...
Validation loss decreased (0.404748 --> 0.404726).  Saving model ...
Validation loss decreased (0.404726 --> 0.404705).  Saving model ...
Validation loss decreased (0.404705 --> 0.404683).  Saving model ...
Validation loss decreased (0.404683 --> 0.404662).  Saving model ...
Validation loss decreased (0.404662 --> 0.404640).  Saving model ...
Validation loss decreased (0.404640 --> 0.404619).  Saving model ...
Validation loss decreased (0.404619 --> 0.404598).  Saving model ...
Validation loss decreased (0.404598 --> 0.404576).  Saving model ...
Validation loss decreased (0.404576 --> 0.404555).  Saving model ...
Validation loss decreased (0.404555 --> 0.404534).  Saving model ...
Validation loss decreased (0.404534 --> 0.404512).  Saving model ...
Validation loss decreased (0.404512 --> 0.404491).  Saving model ...
Validation loss decreased (0.404491 --> 0.404470).  Saving model ...
Validation loss decreased (0.404470 --> 0.404448).  Saving model ...
Validation loss decreased (0.404448 --> 0.404427).  Saving model ...
Validation loss decreased (0.404427 --> 0.404406).  Saving model ...
Validation loss decreased (0.404406 --> 0.404385).  Saving model ...
Validation loss decreased (0.404385 --> 0.404363).  Saving model ...
Validation loss decreased (0.404363 --> 0.404342).  Saving model ...
Validation loss decreased (0.404342 --> 0.404321).  Saving model ...
Validation loss decreased (0.404321 --> 0.404300).  Saving model ...
Validation loss decreased (0.404300 --> 0.404279).  Saving model ...
Validation loss decreased (0.404279 --> 0.404258).  Saving model ...
Validation loss decreased (0.404258 --> 0.404236).  Saving model ...
Validation loss decreased (0.404236 --> 0.404215).  Saving model ...
Validation loss decreased (0.404215 --> 0.404194).  Saving model ...
Validation loss decreased (0.404194 --> 0.404173).  Saving model ...
Validation loss decreased (0.404173 --> 0.404152).  Saving model ...
Validation loss decreased (0.404152 --> 0.404131).  Saving model ...
Validation loss decreased (0.404131 --> 0.404110).  Saving model ...
Validation loss decreased (0.404110 --> 0.404089).  Saving model ...
Validation loss decreased (0.404089 --> 0.404068).  Saving model ...
epoch 3001, loss 0.4041, train acc 80.34%, f1 0.7089, precision 0.7368, recall 0.6829, auc 0.7757
Validation loss decreased (0.404068 --> 0.404047).  Saving model ...
Validation loss decreased (0.404047 --> 0.404026).  Saving model ...
Validation loss decreased (0.404026 --> 0.404005).  Saving model ...
Validation loss decreased (0.404005 --> 0.403984).  Saving model ...
Validation loss decreased (0.403984 --> 0.403963).  Saving model ...
Validation loss decreased (0.403963 --> 0.403942).  Saving model ...
Validation loss decreased (0.403942 --> 0.403921).  Saving model ...
Validation loss decreased (0.403921 --> 0.403900).  Saving model ...
Validation loss decreased (0.403900 --> 0.403879).  Saving model ...
Validation loss decreased (0.403879 --> 0.403858).  Saving model ...
Validation loss decreased (0.403858 --> 0.403837).  Saving model ...
Validation loss decreased (0.403837 --> 0.403816).  Saving model ...
Validation loss decreased (0.403816 --> 0.403795).  Saving model ...
Validation loss decreased (0.403795 --> 0.403775).  Saving model ...
Validation loss decreased (0.403775 --> 0.403754).  Saving model ...
Validation loss decreased (0.403754 --> 0.403733).  Saving model ...
Validation loss decreased (0.403733 --> 0.403712).  Saving model ...
Validation loss decreased (0.403712 --> 0.403691).  Saving model ...
Validation loss decreased (0.403691 --> 0.403670).  Saving model ...
Validation loss decreased (0.403670 --> 0.403650).  Saving model ...
Validation loss decreased (0.403650 --> 0.403629).  Saving model ...
Validation loss decreased (0.403629 --> 0.403608).  Saving model ...
Validation loss decreased (0.403608 --> 0.403587).  Saving model ...
Validation loss decreased (0.403587 --> 0.403566).  Saving model ...
Validation loss decreased (0.403566 --> 0.403546).  Saving model ...
Validation loss decreased (0.403546 --> 0.403525).  Saving model ...
Validation loss decreased (0.403525 --> 0.403504).  Saving model ...
Validation loss decreased (0.403504 --> 0.403484).  Saving model ...
Validation loss decreased (0.403484 --> 0.403463).  Saving model ...
Validation loss decreased (0.403463 --> 0.403442).  Saving model ...
Validation loss decreased (0.403442 --> 0.403421).  Saving model ...
Validation loss decreased (0.403421 --> 0.403401).  Saving model ...
Validation loss decreased (0.403401 --> 0.403380).  Saving model ...
Validation loss decreased (0.403380 --> 0.403359).  Saving model ...
Validation loss decreased (0.403359 --> 0.403339).  Saving model ...
Validation loss decreased (0.403339 --> 0.403318).  Saving model ...
Validation loss decreased (0.403318 --> 0.403298).  Saving model ...
Validation loss decreased (0.403298 --> 0.403277).  Saving model ...
Validation loss decreased (0.403277 --> 0.403256).  Saving model ...
Validation loss decreased (0.403256 --> 0.403236).  Saving model ...
Validation loss decreased (0.403236 --> 0.403215).  Saving model ...
Validation loss decreased (0.403215 --> 0.403195).  Saving model ...
Validation loss decreased (0.403195 --> 0.403174).  Saving model ...
Validation loss decreased (0.403174 --> 0.403153).  Saving model ...
Validation loss decreased (0.403153 --> 0.403133).  Saving model ...
Validation loss decreased (0.403133 --> 0.403112).  Saving model ...
Validation loss decreased (0.403112 --> 0.403092).  Saving model ...
Validation loss decreased (0.403092 --> 0.403071).  Saving model ...
Validation loss decreased (0.403071 --> 0.403051).  Saving model ...
Validation loss decreased (0.403051 --> 0.403030).  Saving model ...
Validation loss decreased (0.403030 --> 0.403010).  Saving model ...
Validation loss decreased (0.403010 --> 0.402989).  Saving model ...
Validation loss decreased (0.402989 --> 0.402969).  Saving model ...
Validation loss decreased (0.402969 --> 0.402948).  Saving model ...
Validation loss decreased (0.402948 --> 0.402928).  Saving model ...
Validation loss decreased (0.402928 --> 0.402907).  Saving model ...
Validation loss decreased (0.402907 --> 0.402887).  Saving model ...
Validation loss decreased (0.402887 --> 0.402866).  Saving model ...
Validation loss decreased (0.402866 --> 0.402846).  Saving model ...
Validation loss decreased (0.402846 --> 0.402826).  Saving model ...
Validation loss decreased (0.402826 --> 0.402805).  Saving model ...
Validation loss decreased (0.402805 --> 0.402785).  Saving model ...
Validation loss decreased (0.402785 --> 0.402764).  Saving model ...
Validation loss decreased (0.402764 --> 0.402744).  Saving model ...
Validation loss decreased (0.402744 --> 0.402724).  Saving model ...
Validation loss decreased (0.402724 --> 0.402703).  Saving model ...
Validation loss decreased (0.402703 --> 0.402683).  Saving model ...
Validation loss decreased (0.402683 --> 0.402662).  Saving model ...
Validation loss decreased (0.402662 --> 0.402642).  Saving model ...
Validation loss decreased (0.402642 --> 0.402622).  Saving model ...
Validation loss decreased (0.402622 --> 0.402601).  Saving model ...
Validation loss decreased (0.402601 --> 0.402581).  Saving model ...
Validation loss decreased (0.402581 --> 0.402561).  Saving model ...
Validation loss decreased (0.402561 --> 0.402540).  Saving model ...
Validation loss decreased (0.402540 --> 0.402520).  Saving model ...
Validation loss decreased (0.402520 --> 0.402500).  Saving model ...
Validation loss decreased (0.402500 --> 0.402480).  Saving model ...
Validation loss decreased (0.402480 --> 0.402459).  Saving model ...
Validation loss decreased (0.402459 --> 0.402439).  Saving model ...
Validation loss decreased (0.402439 --> 0.402419).  Saving model ...
Validation loss decreased (0.402419 --> 0.402398).  Saving model ...
Validation loss decreased (0.402398 --> 0.402378).  Saving model ...
Validation loss decreased (0.402378 --> 0.402358).  Saving model ...
Validation loss decreased (0.402358 --> 0.402338).  Saving model ...
Validation loss decreased (0.402338 --> 0.402317).  Saving model ...
Validation loss decreased (0.402317 --> 0.402297).  Saving model ...
Validation loss decreased (0.402297 --> 0.402277).  Saving model ...
Validation loss decreased (0.402277 --> 0.402257).  Saving model ...
Validation loss decreased (0.402257 --> 0.402236).  Saving model ...
Validation loss decreased (0.402236 --> 0.402216).  Saving model ...
Validation loss decreased (0.402216 --> 0.402196).  Saving model ...
Validation loss decreased (0.402196 --> 0.402176).  Saving model ...
Validation loss decreased (0.402176 --> 0.402156).  Saving model ...
Validation loss decreased (0.402156 --> 0.402135).  Saving model ...
Validation loss decreased (0.402135 --> 0.402115).  Saving model ...
Validation loss decreased (0.402115 --> 0.402095).  Saving model ...
Validation loss decreased (0.402095 --> 0.402075).  Saving model ...
Validation loss decreased (0.402075 --> 0.402055).  Saving model ...
Validation loss decreased (0.402055 --> 0.402035).  Saving model ...
Validation loss decreased (0.402035 --> 0.402014).  Saving model ...
epoch 3101, loss 0.4020, train acc 80.68%, f1 0.7139, precision 0.7421, recall 0.6878, auc 0.7794
Validation loss decreased (0.402014 --> 0.401994).  Saving model ...
Validation loss decreased (0.401994 --> 0.401974).  Saving model ...
Validation loss decreased (0.401974 --> 0.401954).  Saving model ...
Validation loss decreased (0.401954 --> 0.401934).  Saving model ...
Validation loss decreased (0.401934 --> 0.401914).  Saving model ...
Validation loss decreased (0.401914 --> 0.401894).  Saving model ...
Validation loss decreased (0.401894 --> 0.401873).  Saving model ...
Validation loss decreased (0.401873 --> 0.401853).  Saving model ...
Validation loss decreased (0.401853 --> 0.401833).  Saving model ...
Validation loss decreased (0.401833 --> 0.401813).  Saving model ...
Validation loss decreased (0.401813 --> 0.401793).  Saving model ...
Validation loss decreased (0.401793 --> 0.401773).  Saving model ...
Validation loss decreased (0.401773 --> 0.401753).  Saving model ...
Validation loss decreased (0.401753 --> 0.401733).  Saving model ...
Validation loss decreased (0.401733 --> 0.401713).  Saving model ...
Validation loss decreased (0.401713 --> 0.401693).  Saving model ...
Validation loss decreased (0.401693 --> 0.401673).  Saving model ...
Validation loss decreased (0.401673 --> 0.401653).  Saving model ...
Validation loss decreased (0.401653 --> 0.401633).  Saving model ...
Validation loss decreased (0.401633 --> 0.401612).  Saving model ...
Validation loss decreased (0.401612 --> 0.401592).  Saving model ...
Validation loss decreased (0.401592 --> 0.401572).  Saving model ...
Validation loss decreased (0.401572 --> 0.401552).  Saving model ...
Validation loss decreased (0.401552 --> 0.401532).  Saving model ...
Validation loss decreased (0.401532 --> 0.401512).  Saving model ...
Validation loss decreased (0.401512 --> 0.401492).  Saving model ...
Validation loss decreased (0.401492 --> 0.401472).  Saving model ...
Validation loss decreased (0.401472 --> 0.401452).  Saving model ...
Validation loss decreased (0.401452 --> 0.401432).  Saving model ...
Validation loss decreased (0.401432 --> 0.401412).  Saving model ...
Validation loss decreased (0.401412 --> 0.401392).  Saving model ...
Validation loss decreased (0.401392 --> 0.401373).  Saving model ...
Validation loss decreased (0.401373 --> 0.401353).  Saving model ...
Validation loss decreased (0.401353 --> 0.401333).  Saving model ...
Validation loss decreased (0.401333 --> 0.401313).  Saving model ...
Validation loss decreased (0.401313 --> 0.401293).  Saving model ...
Validation loss decreased (0.401293 --> 0.401273).  Saving model ...
Validation loss decreased (0.401273 --> 0.401253).  Saving model ...
Validation loss decreased (0.401253 --> 0.401233).  Saving model ...
Validation loss decreased (0.401233 --> 0.401213).  Saving model ...
Validation loss decreased (0.401213 --> 0.401193).  Saving model ...
Validation loss decreased (0.401193 --> 0.401173).  Saving model ...
Validation loss decreased (0.401173 --> 0.401153).  Saving model ...
Validation loss decreased (0.401153 --> 0.401133).  Saving model ...
Validation loss decreased (0.401133 --> 0.401114).  Saving model ...
Validation loss decreased (0.401114 --> 0.401094).  Saving model ...
Validation loss decreased (0.401094 --> 0.401074).  Saving model ...
Validation loss decreased (0.401074 --> 0.401054).  Saving model ...
Validation loss decreased (0.401054 --> 0.401034).  Saving model ...
Validation loss decreased (0.401034 --> 0.401014).  Saving model ...
Validation loss decreased (0.401014 --> 0.400994).  Saving model ...
Validation loss decreased (0.400994 --> 0.400975).  Saving model ...
Validation loss decreased (0.400975 --> 0.400955).  Saving model ...
Validation loss decreased (0.400955 --> 0.400935).  Saving model ...
Validation loss decreased (0.400935 --> 0.400915).  Saving model ...
Validation loss decreased (0.400915 --> 0.400895).  Saving model ...
Validation loss decreased (0.400895 --> 0.400876).  Saving model ...
Validation loss decreased (0.400876 --> 0.400856).  Saving model ...
Validation loss decreased (0.400856 --> 0.400836).  Saving model ...
Validation loss decreased (0.400836 --> 0.400816).  Saving model ...
Validation loss decreased (0.400816 --> 0.400796).  Saving model ...
Validation loss decreased (0.400796 --> 0.400777).  Saving model ...
Validation loss decreased (0.400777 --> 0.400757).  Saving model ...
Validation loss decreased (0.400757 --> 0.400737).  Saving model ...
Validation loss decreased (0.400737 --> 0.400717).  Saving model ...
Validation loss decreased (0.400717 --> 0.400698).  Saving model ...
Validation loss decreased (0.400698 --> 0.400678).  Saving model ...
Validation loss decreased (0.400678 --> 0.400658).  Saving model ...
Validation loss decreased (0.400658 --> 0.400639).  Saving model ...
Validation loss decreased (0.400639 --> 0.400619).  Saving model ...
Validation loss decreased (0.400619 --> 0.400599).  Saving model ...
Validation loss decreased (0.400599 --> 0.400580).  Saving model ...
Validation loss decreased (0.400580 --> 0.400560).  Saving model ...
Validation loss decreased (0.400560 --> 0.400540).  Saving model ...
Validation loss decreased (0.400540 --> 0.400521).  Saving model ...
Validation loss decreased (0.400521 --> 0.400501).  Saving model ...
Validation loss decreased (0.400501 --> 0.400481).  Saving model ...
Validation loss decreased (0.400481 --> 0.400462).  Saving model ...
Validation loss decreased (0.400462 --> 0.400442).  Saving model ...
Validation loss decreased (0.400442 --> 0.400423).  Saving model ...
Validation loss decreased (0.400423 --> 0.400403).  Saving model ...
Validation loss decreased (0.400403 --> 0.400383).  Saving model ...
Validation loss decreased (0.400383 --> 0.400364).  Saving model ...
Validation loss decreased (0.400364 --> 0.400344).  Saving model ...
Validation loss decreased (0.400344 --> 0.400325).  Saving model ...
Validation loss decreased (0.400325 --> 0.400305).  Saving model ...
Validation loss decreased (0.400305 --> 0.400286).  Saving model ...
Validation loss decreased (0.400286 --> 0.400266).  Saving model ...
Validation loss decreased (0.400266 --> 0.400247).  Saving model ...
Validation loss decreased (0.400247 --> 0.400227).  Saving model ...
Validation loss decreased (0.400227 --> 0.400207).  Saving model ...
Validation loss decreased (0.400207 --> 0.400188).  Saving model ...
Validation loss decreased (0.400188 --> 0.400169).  Saving model ...
Validation loss decreased (0.400169 --> 0.400149).  Saving model ...
Validation loss decreased (0.400149 --> 0.400130).  Saving model ...
Validation loss decreased (0.400130 --> 0.400110).  Saving model ...
Validation loss decreased (0.400110 --> 0.400091).  Saving model ...
Validation loss decreased (0.400091 --> 0.400071).  Saving model ...
Validation loss decreased (0.400071 --> 0.400052).  Saving model ...
Validation loss decreased (0.400052 --> 0.400032).  Saving model ...
epoch 3201, loss 0.4000, train acc 80.85%, f1 0.7186, precision 0.7409, recall 0.6976, auc 0.7830
Validation loss decreased (0.400032 --> 0.400013).  Saving model ...
Validation loss decreased (0.400013 --> 0.399994).  Saving model ...
Validation loss decreased (0.399994 --> 0.399974).  Saving model ...
Validation loss decreased (0.399974 --> 0.399955).  Saving model ...
Validation loss decreased (0.399955 --> 0.399935).  Saving model ...
Validation loss decreased (0.399935 --> 0.399916).  Saving model ...
Validation loss decreased (0.399916 --> 0.399897).  Saving model ...
Validation loss decreased (0.399897 --> 0.399877).  Saving model ...
Validation loss decreased (0.399877 --> 0.399858).  Saving model ...
Validation loss decreased (0.399858 --> 0.399839).  Saving model ...
Validation loss decreased (0.399839 --> 0.399819).  Saving model ...
Validation loss decreased (0.399819 --> 0.399800).  Saving model ...
Validation loss decreased (0.399800 --> 0.399781).  Saving model ...
Validation loss decreased (0.399781 --> 0.399761).  Saving model ...
Validation loss decreased (0.399761 --> 0.399742).  Saving model ...
Validation loss decreased (0.399742 --> 0.399723).  Saving model ...
Validation loss decreased (0.399723 --> 0.399704).  Saving model ...
Validation loss decreased (0.399704 --> 0.399684).  Saving model ...
Validation loss decreased (0.399684 --> 0.399665).  Saving model ...
Validation loss decreased (0.399665 --> 0.399646).  Saving model ...
Validation loss decreased (0.399646 --> 0.399627).  Saving model ...
Validation loss decreased (0.399627 --> 0.399607).  Saving model ...
Validation loss decreased (0.399607 --> 0.399588).  Saving model ...
Validation loss decreased (0.399588 --> 0.399569).  Saving model ...
Validation loss decreased (0.399569 --> 0.399550).  Saving model ...
Validation loss decreased (0.399550 --> 0.399530).  Saving model ...
Validation loss decreased (0.399530 --> 0.399511).  Saving model ...
Validation loss decreased (0.399511 --> 0.399492).  Saving model ...
Validation loss decreased (0.399492 --> 0.399473).  Saving model ...
Validation loss decreased (0.399473 --> 0.399454).  Saving model ...
Validation loss decreased (0.399454 --> 0.399435).  Saving model ...
Validation loss decreased (0.399435 --> 0.399416).  Saving model ...
Validation loss decreased (0.399416 --> 0.399396).  Saving model ...
Validation loss decreased (0.399396 --> 0.399377).  Saving model ...
Validation loss decreased (0.399377 --> 0.399358).  Saving model ...
Validation loss decreased (0.399358 --> 0.399339).  Saving model ...
Validation loss decreased (0.399339 --> 0.399320).  Saving model ...
Validation loss decreased (0.399320 --> 0.399301).  Saving model ...
Validation loss decreased (0.399301 --> 0.399282).  Saving model ...
Validation loss decreased (0.399282 --> 0.399263).  Saving model ...
Validation loss decreased (0.399263 --> 0.399244).  Saving model ...
Validation loss decreased (0.399244 --> 0.399225).  Saving model ...
Validation loss decreased (0.399225 --> 0.399206).  Saving model ...
Validation loss decreased (0.399206 --> 0.399187).  Saving model ...
Validation loss decreased (0.399187 --> 0.399168).  Saving model ...
Validation loss decreased (0.399168 --> 0.399149).  Saving model ...
Validation loss decreased (0.399149 --> 0.399130).  Saving model ...
Validation loss decreased (0.399130 --> 0.399111).  Saving model ...
Validation loss decreased (0.399111 --> 0.399092).  Saving model ...
Validation loss decreased (0.399092 --> 0.399073).  Saving model ...
Validation loss decreased (0.399073 --> 0.399054).  Saving model ...
Validation loss decreased (0.399054 --> 0.399035).  Saving model ...
Validation loss decreased (0.399035 --> 0.399016).  Saving model ...
Validation loss decreased (0.399016 --> 0.398997).  Saving model ...
Validation loss decreased (0.398997 --> 0.398978).  Saving model ...
Validation loss decreased (0.398978 --> 0.398959).  Saving model ...
Validation loss decreased (0.398959 --> 0.398940).  Saving model ...
Validation loss decreased (0.398940 --> 0.398921).  Saving model ...
Validation loss decreased (0.398921 --> 0.398902).  Saving model ...
Validation loss decreased (0.398902 --> 0.398883).  Saving model ...
Validation loss decreased (0.398883 --> 0.398864).  Saving model ...
Validation loss decreased (0.398864 --> 0.398845).  Saving model ...
Validation loss decreased (0.398845 --> 0.398827).  Saving model ...
Validation loss decreased (0.398827 --> 0.398808).  Saving model ...
Validation loss decreased (0.398808 --> 0.398789).  Saving model ...
Validation loss decreased (0.398789 --> 0.398770).  Saving model ...
Validation loss decreased (0.398770 --> 0.398751).  Saving model ...
Validation loss decreased (0.398751 --> 0.398732).  Saving model ...
Validation loss decreased (0.398732 --> 0.398713).  Saving model ...
Validation loss decreased (0.398713 --> 0.398695).  Saving model ...
Validation loss decreased (0.398695 --> 0.398676).  Saving model ...
Validation loss decreased (0.398676 --> 0.398657).  Saving model ...
Validation loss decreased (0.398657 --> 0.398638).  Saving model ...
Validation loss decreased (0.398638 --> 0.398619).  Saving model ...
Validation loss decreased (0.398619 --> 0.398601).  Saving model ...
Validation loss decreased (0.398601 --> 0.398582).  Saving model ...
Validation loss decreased (0.398582 --> 0.398563).  Saving model ...
Validation loss decreased (0.398563 --> 0.398544).  Saving model ...
Validation loss decreased (0.398544 --> 0.398526).  Saving model ...
Validation loss decreased (0.398526 --> 0.398507).  Saving model ...
Validation loss decreased (0.398507 --> 0.398488).  Saving model ...
Validation loss decreased (0.398488 --> 0.398470).  Saving model ...
Validation loss decreased (0.398470 --> 0.398451).  Saving model ...
Validation loss decreased (0.398451 --> 0.398432).  Saving model ...
Validation loss decreased (0.398432 --> 0.398413).  Saving model ...
Validation loss decreased (0.398413 --> 0.398395).  Saving model ...
Validation loss decreased (0.398395 --> 0.398376).  Saving model ...
Validation loss decreased (0.398376 --> 0.398357).  Saving model ...
Validation loss decreased (0.398357 --> 0.398339).  Saving model ...
Validation loss decreased (0.398339 --> 0.398320).  Saving model ...
Validation loss decreased (0.398320 --> 0.398301).  Saving model ...
Validation loss decreased (0.398301 --> 0.398283).  Saving model ...
Validation loss decreased (0.398283 --> 0.398264).  Saving model ...
Validation loss decreased (0.398264 --> 0.398245).  Saving model ...
Validation loss decreased (0.398245 --> 0.398227).  Saving model ...
Validation loss decreased (0.398227 --> 0.398208).  Saving model ...
Validation loss decreased (0.398208 --> 0.398190).  Saving model ...
Validation loss decreased (0.398190 --> 0.398171).  Saving model ...
Validation loss decreased (0.398171 --> 0.398152).  Saving model ...
Validation loss decreased (0.398152 --> 0.398134).  Saving model ...
epoch 3301, loss 0.3981, train acc 81.20%, f1 0.7222, precision 0.7487, recall 0.6976, auc 0.7856
Validation loss decreased (0.398134 --> 0.398115).  Saving model ...
Validation loss decreased (0.398115 --> 0.398097).  Saving model ...
Validation loss decreased (0.398097 --> 0.398078).  Saving model ...
Validation loss decreased (0.398078 --> 0.398060).  Saving model ...
Validation loss decreased (0.398060 --> 0.398041).  Saving model ...
Validation loss decreased (0.398041 --> 0.398022).  Saving model ...
Validation loss decreased (0.398022 --> 0.398004).  Saving model ...
Validation loss decreased (0.398004 --> 0.397985).  Saving model ...
Validation loss decreased (0.397985 --> 0.397967).  Saving model ...
Validation loss decreased (0.397967 --> 0.397948).  Saving model ...
Validation loss decreased (0.397948 --> 0.397930).  Saving model ...
Validation loss decreased (0.397930 --> 0.397911).  Saving model ...
Validation loss decreased (0.397911 --> 0.397893).  Saving model ...
Validation loss decreased (0.397893 --> 0.397874).  Saving model ...
Validation loss decreased (0.397874 --> 0.397856).  Saving model ...
Validation loss decreased (0.397856 --> 0.397837).  Saving model ...
Validation loss decreased (0.397837 --> 0.397819).  Saving model ...
Validation loss decreased (0.397819 --> 0.397801).  Saving model ...
Validation loss decreased (0.397801 --> 0.397782).  Saving model ...
Validation loss decreased (0.397782 --> 0.397764).  Saving model ...
Validation loss decreased (0.397764 --> 0.397745).  Saving model ...
Validation loss decreased (0.397745 --> 0.397727).  Saving model ...
Validation loss decreased (0.397727 --> 0.397708).  Saving model ...
Validation loss decreased (0.397708 --> 0.397690).  Saving model ...
Validation loss decreased (0.397690 --> 0.397672).  Saving model ...
Validation loss decreased (0.397672 --> 0.397653).  Saving model ...
Validation loss decreased (0.397653 --> 0.397635).  Saving model ...
Validation loss decreased (0.397635 --> 0.397616).  Saving model ...
Validation loss decreased (0.397616 --> 0.397598).  Saving model ...
Validation loss decreased (0.397598 --> 0.397580).  Saving model ...
Validation loss decreased (0.397580 --> 0.397561).  Saving model ...
Validation loss decreased (0.397561 --> 0.397543).  Saving model ...
Validation loss decreased (0.397543 --> 0.397525).  Saving model ...
Validation loss decreased (0.397525 --> 0.397506).  Saving model ...
Validation loss decreased (0.397506 --> 0.397488).  Saving model ...
Validation loss decreased (0.397488 --> 0.397470).  Saving model ...
Validation loss decreased (0.397470 --> 0.397451).  Saving model ...
Validation loss decreased (0.397451 --> 0.397433).  Saving model ...
Validation loss decreased (0.397433 --> 0.397415).  Saving model ...
Validation loss decreased (0.397415 --> 0.397396).  Saving model ...
Validation loss decreased (0.397396 --> 0.397378).  Saving model ...
Validation loss decreased (0.397378 --> 0.397360).  Saving model ...
Validation loss decreased (0.397360 --> 0.397342).  Saving model ...
Validation loss decreased (0.397342 --> 0.397323).  Saving model ...
Validation loss decreased (0.397323 --> 0.397305).  Saving model ...
Validation loss decreased (0.397305 --> 0.397287).  Saving model ...
Validation loss decreased (0.397287 --> 0.397269).  Saving model ...
Validation loss decreased (0.397269 --> 0.397250).  Saving model ...
Validation loss decreased (0.397250 --> 0.397232).  Saving model ...
Validation loss decreased (0.397232 --> 0.397214).  Saving model ...
Validation loss decreased (0.397214 --> 0.397196).  Saving model ...
Validation loss decreased (0.397196 --> 0.397178).  Saving model ...
Validation loss decreased (0.397178 --> 0.397159).  Saving model ...
Validation loss decreased (0.397159 --> 0.397141).  Saving model ...
Validation loss decreased (0.397141 --> 0.397123).  Saving model ...
Validation loss decreased (0.397123 --> 0.397105).  Saving model ...
Validation loss decreased (0.397105 --> 0.397087).  Saving model ...
Validation loss decreased (0.397087 --> 0.397068).  Saving model ...
Validation loss decreased (0.397068 --> 0.397050).  Saving model ...
Validation loss decreased (0.397050 --> 0.397032).  Saving model ...
Validation loss decreased (0.397032 --> 0.397014).  Saving model ...
Validation loss decreased (0.397014 --> 0.396996).  Saving model ...
Validation loss decreased (0.396996 --> 0.396978).  Saving model ...
Validation loss decreased (0.396978 --> 0.396960).  Saving model ...
Validation loss decreased (0.396960 --> 0.396941).  Saving model ...
Validation loss decreased (0.396941 --> 0.396923).  Saving model ...
Validation loss decreased (0.396923 --> 0.396905).  Saving model ...
Validation loss decreased (0.396905 --> 0.396887).  Saving model ...
Validation loss decreased (0.396887 --> 0.396869).  Saving model ...
Validation loss decreased (0.396869 --> 0.396851).  Saving model ...
Validation loss decreased (0.396851 --> 0.396833).  Saving model ...
Validation loss decreased (0.396833 --> 0.396815).  Saving model ...
Validation loss decreased (0.396815 --> 0.396797).  Saving model ...
Validation loss decreased (0.396797 --> 0.396779).  Saving model ...
Validation loss decreased (0.396779 --> 0.396761).  Saving model ...
Validation loss decreased (0.396761 --> 0.396743).  Saving model ...
Validation loss decreased (0.396743 --> 0.396725).  Saving model ...
Validation loss decreased (0.396725 --> 0.396707).  Saving model ...
Validation loss decreased (0.396707 --> 0.396689).  Saving model ...
Validation loss decreased (0.396689 --> 0.396671).  Saving model ...
Validation loss decreased (0.396671 --> 0.396653).  Saving model ...
Validation loss decreased (0.396653 --> 0.396635).  Saving model ...
Validation loss decreased (0.396635 --> 0.396617).  Saving model ...
Validation loss decreased (0.396617 --> 0.396599).  Saving model ...
Validation loss decreased (0.396599 --> 0.396581).  Saving model ...
Validation loss decreased (0.396581 --> 0.396563).  Saving model ...
Validation loss decreased (0.396563 --> 0.396545).  Saving model ...
Validation loss decreased (0.396545 --> 0.396527).  Saving model ...
Validation loss decreased (0.396527 --> 0.396509).  Saving model ...
Validation loss decreased (0.396509 --> 0.396491).  Saving model ...
Validation loss decreased (0.396491 --> 0.396473).  Saving model ...
Validation loss decreased (0.396473 --> 0.396455).  Saving model ...
Validation loss decreased (0.396455 --> 0.396437).  Saving model ...
Validation loss decreased (0.396437 --> 0.396419).  Saving model ...
Validation loss decreased (0.396419 --> 0.396401).  Saving model ...
Validation loss decreased (0.396401 --> 0.396383).  Saving model ...
Validation loss decreased (0.396383 --> 0.396366).  Saving model ...
Validation loss decreased (0.396366 --> 0.396348).  Saving model ...
Validation loss decreased (0.396348 --> 0.396330).  Saving model ...
Validation loss decreased (0.396330 --> 0.396312).  Saving model ...
epoch 3401, loss 0.3963, train acc 81.71%, f1 0.7318, precision 0.7526, recall 0.7122, auc 0.7929
Validation loss decreased (0.396312 --> 0.396294).  Saving model ...
Validation loss decreased (0.396294 --> 0.396276).  Saving model ...
Validation loss decreased (0.396276 --> 0.396258).  Saving model ...
Validation loss decreased (0.396258 --> 0.396241).  Saving model ...
Validation loss decreased (0.396241 --> 0.396223).  Saving model ...
Validation loss decreased (0.396223 --> 0.396205).  Saving model ...
Validation loss decreased (0.396205 --> 0.396187).  Saving model ...
Validation loss decreased (0.396187 --> 0.396169).  Saving model ...
Validation loss decreased (0.396169 --> 0.396151).  Saving model ...
Validation loss decreased (0.396151 --> 0.396134).  Saving model ...
Validation loss decreased (0.396134 --> 0.396116).  Saving model ...
Validation loss decreased (0.396116 --> 0.396098).  Saving model ...
Validation loss decreased (0.396098 --> 0.396080).  Saving model ...
Validation loss decreased (0.396080 --> 0.396062).  Saving model ...
Validation loss decreased (0.396062 --> 0.396045).  Saving model ...
Validation loss decreased (0.396045 --> 0.396027).  Saving model ...
Validation loss decreased (0.396027 --> 0.396009).  Saving model ...
Validation loss decreased (0.396009 --> 0.395991).  Saving model ...
Validation loss decreased (0.395991 --> 0.395974).  Saving model ...
Validation loss decreased (0.395974 --> 0.395956).  Saving model ...
Validation loss decreased (0.395956 --> 0.395938).  Saving model ...
Validation loss decreased (0.395938 --> 0.395921).  Saving model ...
Validation loss decreased (0.395921 --> 0.395903).  Saving model ...
Validation loss decreased (0.395903 --> 0.395885).  Saving model ...
Validation loss decreased (0.395885 --> 0.395867).  Saving model ...
Validation loss decreased (0.395867 --> 0.395850).  Saving model ...
Validation loss decreased (0.395850 --> 0.395832).  Saving model ...
Validation loss decreased (0.395832 --> 0.395814).  Saving model ...
Validation loss decreased (0.395814 --> 0.395797).  Saving model ...
Validation loss decreased (0.395797 --> 0.395779).  Saving model ...
Validation loss decreased (0.395779 --> 0.395761).  Saving model ...
Validation loss decreased (0.395761 --> 0.395744).  Saving model ...
Validation loss decreased (0.395744 --> 0.395726).  Saving model ...
Validation loss decreased (0.395726 --> 0.395708).  Saving model ...
Validation loss decreased (0.395708 --> 0.395691).  Saving model ...
Validation loss decreased (0.395691 --> 0.395673).  Saving model ...
Validation loss decreased (0.395673 --> 0.395656).  Saving model ...
Validation loss decreased (0.395656 --> 0.395638).  Saving model ...
Validation loss decreased (0.395638 --> 0.395620).  Saving model ...
Validation loss decreased (0.395620 --> 0.395603).  Saving model ...
Validation loss decreased (0.395603 --> 0.395585).  Saving model ...
Validation loss decreased (0.395585 --> 0.395568).  Saving model ...
Validation loss decreased (0.395568 --> 0.395550).  Saving model ...
Validation loss decreased (0.395550 --> 0.395532).  Saving model ...
Validation loss decreased (0.395532 --> 0.395515).  Saving model ...
Validation loss decreased (0.395515 --> 0.395497).  Saving model ...
Validation loss decreased (0.395497 --> 0.395480).  Saving model ...
Validation loss decreased (0.395480 --> 0.395462).  Saving model ...
Validation loss decreased (0.395462 --> 0.395445).  Saving model ...
Validation loss decreased (0.395445 --> 0.395427).  Saving model ...
Validation loss decreased (0.395427 --> 0.395410).  Saving model ...
Validation loss decreased (0.395410 --> 0.395392).  Saving model ...
Validation loss decreased (0.395392 --> 0.395375).  Saving model ...
Validation loss decreased (0.395375 --> 0.395357).  Saving model ...
Validation loss decreased (0.395357 --> 0.395340).  Saving model ...
Validation loss decreased (0.395340 --> 0.395322).  Saving model ...
Validation loss decreased (0.395322 --> 0.395305).  Saving model ...
Validation loss decreased (0.395305 --> 0.395287).  Saving model ...
Validation loss decreased (0.395287 --> 0.395270).  Saving model ...
Validation loss decreased (0.395270 --> 0.395252).  Saving model ...
Validation loss decreased (0.395252 --> 0.395235).  Saving model ...
Validation loss decreased (0.395235 --> 0.395217).  Saving model ...
Validation loss decreased (0.395217 --> 0.395200).  Saving model ...
Validation loss decreased (0.395200 --> 0.395182).  Saving model ...
Validation loss decreased (0.395182 --> 0.395165).  Saving model ...
Validation loss decreased (0.395165 --> 0.395148).  Saving model ...
Validation loss decreased (0.395148 --> 0.395130).  Saving model ...
Validation loss decreased (0.395130 --> 0.395113).  Saving model ...
Validation loss decreased (0.395113 --> 0.395095).  Saving model ...
Validation loss decreased (0.395095 --> 0.395078).  Saving model ...
Validation loss decreased (0.395078 --> 0.395060).  Saving model ...
Validation loss decreased (0.395060 --> 0.395043).  Saving model ...
Validation loss decreased (0.395043 --> 0.395026).  Saving model ...
Validation loss decreased (0.395026 --> 0.395008).  Saving model ...
Validation loss decreased (0.395008 --> 0.394991).  Saving model ...
Validation loss decreased (0.394991 --> 0.394974).  Saving model ...
Validation loss decreased (0.394974 --> 0.394956).  Saving model ...
Validation loss decreased (0.394956 --> 0.394939).  Saving model ...
Validation loss decreased (0.394939 --> 0.394922).  Saving model ...
Validation loss decreased (0.394922 --> 0.394904).  Saving model ...
Validation loss decreased (0.394904 --> 0.394887).  Saving model ...
Validation loss decreased (0.394887 --> 0.394870).  Saving model ...
Validation loss decreased (0.394870 --> 0.394852).  Saving model ...
Validation loss decreased (0.394852 --> 0.394835).  Saving model ...
Validation loss decreased (0.394835 --> 0.394818).  Saving model ...
Validation loss decreased (0.394818 --> 0.394800).  Saving model ...
Validation loss decreased (0.394800 --> 0.394783).  Saving model ...
Validation loss decreased (0.394783 --> 0.394766).  Saving model ...
Validation loss decreased (0.394766 --> 0.394748).  Saving model ...
Validation loss decreased (0.394748 --> 0.394731).  Saving model ...
Validation loss decreased (0.394731 --> 0.394714).  Saving model ...
Validation loss decreased (0.394714 --> 0.394697).  Saving model ...
Validation loss decreased (0.394697 --> 0.394679).  Saving model ...
Validation loss decreased (0.394679 --> 0.394662).  Saving model ...
Validation loss decreased (0.394662 --> 0.394645).  Saving model ...
Validation loss decreased (0.394645 --> 0.394628).  Saving model ...
Validation loss decreased (0.394628 --> 0.394610).  Saving model ...
Validation loss decreased (0.394610 --> 0.394593).  Saving model ...
Validation loss decreased (0.394593 --> 0.394576).  Saving model ...
Validation loss decreased (0.394576 --> 0.394559).  Saving model ...
epoch 3501, loss 0.3946, train acc 82.05%, f1 0.7368, precision 0.7577, recall 0.7171, auc 0.7967
Validation loss decreased (0.394559 --> 0.394541).  Saving model ...
Validation loss decreased (0.394541 --> 0.394524).  Saving model ...
Validation loss decreased (0.394524 --> 0.394507).  Saving model ...
Validation loss decreased (0.394507 --> 0.394490).  Saving model ...
Validation loss decreased (0.394490 --> 0.394473).  Saving model ...
Validation loss decreased (0.394473 --> 0.394455).  Saving model ...
Validation loss decreased (0.394455 --> 0.394438).  Saving model ...
Validation loss decreased (0.394438 --> 0.394421).  Saving model ...
Validation loss decreased (0.394421 --> 0.394404).  Saving model ...
Validation loss decreased (0.394404 --> 0.394387).  Saving model ...
Validation loss decreased (0.394387 --> 0.394369).  Saving model ...
Validation loss decreased (0.394369 --> 0.394352).  Saving model ...
Validation loss decreased (0.394352 --> 0.394335).  Saving model ...
Validation loss decreased (0.394335 --> 0.394318).  Saving model ...
Validation loss decreased (0.394318 --> 0.394301).  Saving model ...
Validation loss decreased (0.394301 --> 0.394284).  Saving model ...
Validation loss decreased (0.394284 --> 0.394267).  Saving model ...
Validation loss decreased (0.394267 --> 0.394249).  Saving model ...
Validation loss decreased (0.394249 --> 0.394232).  Saving model ...
Validation loss decreased (0.394232 --> 0.394215).  Saving model ...
Validation loss decreased (0.394215 --> 0.394198).  Saving model ...
Validation loss decreased (0.394198 --> 0.394181).  Saving model ...
Validation loss decreased (0.394181 --> 0.394164).  Saving model ...
Validation loss decreased (0.394164 --> 0.394147).  Saving model ...
Validation loss decreased (0.394147 --> 0.394130).  Saving model ...
Validation loss decreased (0.394130 --> 0.394113).  Saving model ...
Validation loss decreased (0.394113 --> 0.394095).  Saving model ...
Validation loss decreased (0.394095 --> 0.394078).  Saving model ...
Validation loss decreased (0.394078 --> 0.394061).  Saving model ...
Validation loss decreased (0.394061 --> 0.394044).  Saving model ...
Validation loss decreased (0.394044 --> 0.394027).  Saving model ...
Validation loss decreased (0.394027 --> 0.394010).  Saving model ...
Validation loss decreased (0.394010 --> 0.393993).  Saving model ...
Validation loss decreased (0.393993 --> 0.393976).  Saving model ...
Validation loss decreased (0.393976 --> 0.393959).  Saving model ...
Validation loss decreased (0.393959 --> 0.393942).  Saving model ...
Validation loss decreased (0.393942 --> 0.393925).  Saving model ...
Validation loss decreased (0.393925 --> 0.393908).  Saving model ...
Validation loss decreased (0.393908 --> 0.393891).  Saving model ...
Validation loss decreased (0.393891 --> 0.393874).  Saving model ...
Validation loss decreased (0.393874 --> 0.393857).  Saving model ...
Validation loss decreased (0.393857 --> 0.393840).  Saving model ...
Validation loss decreased (0.393840 --> 0.393823).  Saving model ...
Validation loss decreased (0.393823 --> 0.393806).  Saving model ...
Validation loss decreased (0.393806 --> 0.393789).  Saving model ...
Validation loss decreased (0.393789 --> 0.393772).  Saving model ...
Validation loss decreased (0.393772 --> 0.393755).  Saving model ...
Validation loss decreased (0.393755 --> 0.393738).  Saving model ...
Validation loss decreased (0.393738 --> 0.393721).  Saving model ...
Validation loss decreased (0.393721 --> 0.393704).  Saving model ...
Validation loss decreased (0.393704 --> 0.393687).  Saving model ...
Validation loss decreased (0.393687 --> 0.393670).  Saving model ...
Validation loss decreased (0.393670 --> 0.393653).  Saving model ...
Validation loss decreased (0.393653 --> 0.393636).  Saving model ...
Validation loss decreased (0.393636 --> 0.393619).  Saving model ...
Validation loss decreased (0.393619 --> 0.393602).  Saving model ...
Validation loss decreased (0.393602 --> 0.393585).  Saving model ...
Validation loss decreased (0.393585 --> 0.393568).  Saving model ...
Validation loss decreased (0.393568 --> 0.393551).  Saving model ...
Validation loss decreased (0.393551 --> 0.393534).  Saving model ...
Validation loss decreased (0.393534 --> 0.393517).  Saving model ...
Validation loss decreased (0.393517 --> 0.393500).  Saving model ...
Validation loss decreased (0.393500 --> 0.393483).  Saving model ...
Validation loss decreased (0.393483 --> 0.393466).  Saving model ...
Validation loss decreased (0.393466 --> 0.393449).  Saving model ...
Validation loss decreased (0.393449 --> 0.393433).  Saving model ...
Validation loss decreased (0.393433 --> 0.393416).  Saving model ...
Validation loss decreased (0.393416 --> 0.393399).  Saving model ...
Validation loss decreased (0.393399 --> 0.393382).  Saving model ...
Validation loss decreased (0.393382 --> 0.393365).  Saving model ...
Validation loss decreased (0.393365 --> 0.393348).  Saving model ...
Validation loss decreased (0.393348 --> 0.393331).  Saving model ...
Validation loss decreased (0.393331 --> 0.393314).  Saving model ...
Validation loss decreased (0.393314 --> 0.393297).  Saving model ...
Validation loss decreased (0.393297 --> 0.393280).  Saving model ...
Validation loss decreased (0.393280 --> 0.393263).  Saving model ...
Validation loss decreased (0.393263 --> 0.393247).  Saving model ...
Validation loss decreased (0.393247 --> 0.393230).  Saving model ...
Validation loss decreased (0.393230 --> 0.393213).  Saving model ...
Validation loss decreased (0.393213 --> 0.393196).  Saving model ...
Validation loss decreased (0.393196 --> 0.393179).  Saving model ...
Validation loss decreased (0.393179 --> 0.393162).  Saving model ...
Validation loss decreased (0.393162 --> 0.393145).  Saving model ...
Validation loss decreased (0.393145 --> 0.393128).  Saving model ...
Validation loss decreased (0.393128 --> 0.393112).  Saving model ...
Validation loss decreased (0.393112 --> 0.393095).  Saving model ...
Validation loss decreased (0.393095 --> 0.393078).  Saving model ...
Validation loss decreased (0.393078 --> 0.393061).  Saving model ...
Validation loss decreased (0.393061 --> 0.393044).  Saving model ...
Validation loss decreased (0.393044 --> 0.393027).  Saving model ...
Validation loss decreased (0.393027 --> 0.393010).  Saving model ...
Validation loss decreased (0.393010 --> 0.392994).  Saving model ...
Validation loss decreased (0.392994 --> 0.392977).  Saving model ...
Validation loss decreased (0.392977 --> 0.392960).  Saving model ...
Validation loss decreased (0.392960 --> 0.392943).  Saving model ...
Validation loss decreased (0.392943 --> 0.392926).  Saving model ...
Validation loss decreased (0.392926 --> 0.392909).  Saving model ...
Validation loss decreased (0.392909 --> 0.392893).  Saving model ...
Validation loss decreased (0.392893 --> 0.392876).  Saving model ...
Validation loss decreased (0.392876 --> 0.392859).  Saving model ...
epoch 3601, loss 0.3929, train acc 82.05%, f1 0.7368, precision 0.7577, recall 0.7171, auc 0.7967
Validation loss decreased (0.392859 --> 0.392842).  Saving model ...
Validation loss decreased (0.392842 --> 0.392825).  Saving model ...
Validation loss decreased (0.392825 --> 0.392808).  Saving model ...
Validation loss decreased (0.392808 --> 0.392792).  Saving model ...
Validation loss decreased (0.392792 --> 0.392775).  Saving model ...
Validation loss decreased (0.392775 --> 0.392758).  Saving model ...
Validation loss decreased (0.392758 --> 0.392741).  Saving model ...
Validation loss decreased (0.392741 --> 0.392724).  Saving model ...
Validation loss decreased (0.392724 --> 0.392707).  Saving model ...
Validation loss decreased (0.392707 --> 0.392691).  Saving model ...
Validation loss decreased (0.392691 --> 0.392674).  Saving model ...
Validation loss decreased (0.392674 --> 0.392657).  Saving model ...
Validation loss decreased (0.392657 --> 0.392640).  Saving model ...
Validation loss decreased (0.392640 --> 0.392623).  Saving model ...
Validation loss decreased (0.392623 --> 0.392607).  Saving model ...
Validation loss decreased (0.392607 --> 0.392590).  Saving model ...
Validation loss decreased (0.392590 --> 0.392573).  Saving model ...
Validation loss decreased (0.392573 --> 0.392556).  Saving model ...
Validation loss decreased (0.392556 --> 0.392539).  Saving model ...
Validation loss decreased (0.392539 --> 0.392523).  Saving model ...
Validation loss decreased (0.392523 --> 0.392506).  Saving model ...
Validation loss decreased (0.392506 --> 0.392489).  Saving model ...
Validation loss decreased (0.392489 --> 0.392472).  Saving model ...
Validation loss decreased (0.392472 --> 0.392455).  Saving model ...
Validation loss decreased (0.392455 --> 0.392439).  Saving model ...
Validation loss decreased (0.392439 --> 0.392422).  Saving model ...
Validation loss decreased (0.392422 --> 0.392405).  Saving model ...
Validation loss decreased (0.392405 --> 0.392388).  Saving model ...
Validation loss decreased (0.392388 --> 0.392371).  Saving model ...
Validation loss decreased (0.392371 --> 0.392355).  Saving model ...
Validation loss decreased (0.392355 --> 0.392338).  Saving model ...
Validation loss decreased (0.392338 --> 0.392321).  Saving model ...
Validation loss decreased (0.392321 --> 0.392304).  Saving model ...
Validation loss decreased (0.392304 --> 0.392287).  Saving model ...
Validation loss decreased (0.392287 --> 0.392271).  Saving model ...
Validation loss decreased (0.392271 --> 0.392254).  Saving model ...
Validation loss decreased (0.392254 --> 0.392237).  Saving model ...
Validation loss decreased (0.392237 --> 0.392220).  Saving model ...
Validation loss decreased (0.392220 --> 0.392204).  Saving model ...
Validation loss decreased (0.392204 --> 0.392187).  Saving model ...
Validation loss decreased (0.392187 --> 0.392170).  Saving model ...
Validation loss decreased (0.392170 --> 0.392153).  Saving model ...
Validation loss decreased (0.392153 --> 0.392136).  Saving model ...
Validation loss decreased (0.392136 --> 0.392120).  Saving model ...
Validation loss decreased (0.392120 --> 0.392103).  Saving model ...
Validation loss decreased (0.392103 --> 0.392086).  Saving model ...
Validation loss decreased (0.392086 --> 0.392069).  Saving model ...
Validation loss decreased (0.392069 --> 0.392052).  Saving model ...
Validation loss decreased (0.392052 --> 0.392036).  Saving model ...
Validation loss decreased (0.392036 --> 0.392019).  Saving model ...
Validation loss decreased (0.392019 --> 0.392002).  Saving model ...
Validation loss decreased (0.392002 --> 0.391985).  Saving model ...
Validation loss decreased (0.391985 --> 0.391968).  Saving model ...
Validation loss decreased (0.391968 --> 0.391952).  Saving model ...
Validation loss decreased (0.391952 --> 0.391935).  Saving model ...
Validation loss decreased (0.391935 --> 0.391918).  Saving model ...
Validation loss decreased (0.391918 --> 0.391901).  Saving model ...
Validation loss decreased (0.391901 --> 0.391884).  Saving model ...
Validation loss decreased (0.391884 --> 0.391868).  Saving model ...
Validation loss decreased (0.391868 --> 0.391851).  Saving model ...
Validation loss decreased (0.391851 --> 0.391834).  Saving model ...
Validation loss decreased (0.391834 --> 0.391817).  Saving model ...
Validation loss decreased (0.391817 --> 0.391800).  Saving model ...
Validation loss decreased (0.391800 --> 0.391784).  Saving model ...
Validation loss decreased (0.391784 --> 0.391767).  Saving model ...
Validation loss decreased (0.391767 --> 0.391750).  Saving model ...
Validation loss decreased (0.391750 --> 0.391733).  Saving model ...
Validation loss decreased (0.391733 --> 0.391716).  Saving model ...
Validation loss decreased (0.391716 --> 0.391700).  Saving model ...
Validation loss decreased (0.391700 --> 0.391683).  Saving model ...
Validation loss decreased (0.391683 --> 0.391666).  Saving model ...
Validation loss decreased (0.391666 --> 0.391649).  Saving model ...
Validation loss decreased (0.391649 --> 0.391632).  Saving model ...
Validation loss decreased (0.391632 --> 0.391615).  Saving model ...
Validation loss decreased (0.391615 --> 0.391599).  Saving model ...
Validation loss decreased (0.391599 --> 0.391582).  Saving model ...
Validation loss decreased (0.391582 --> 0.391565).  Saving model ...
Validation loss decreased (0.391565 --> 0.391548).  Saving model ...
Validation loss decreased (0.391548 --> 0.391531).  Saving model ...
Validation loss decreased (0.391531 --> 0.391515).  Saving model ...
Validation loss decreased (0.391515 --> 0.391498).  Saving model ...
Validation loss decreased (0.391498 --> 0.391481).  Saving model ...
Validation loss decreased (0.391481 --> 0.391464).  Saving model ...
Validation loss decreased (0.391464 --> 0.391447).  Saving model ...
Validation loss decreased (0.391447 --> 0.391430).  Saving model ...
Validation loss decreased (0.391430 --> 0.391414).  Saving model ...
Validation loss decreased (0.391414 --> 0.391397).  Saving model ...
Validation loss decreased (0.391397 --> 0.391380).  Saving model ...
Validation loss decreased (0.391380 --> 0.391363).  Saving model ...
Validation loss decreased (0.391363 --> 0.391346).  Saving model ...
Validation loss decreased (0.391346 --> 0.391329).  Saving model ...
Validation loss decreased (0.391329 --> 0.391312).  Saving model ...
Validation loss decreased (0.391312 --> 0.391295).  Saving model ...
Validation loss decreased (0.391295 --> 0.391279).  Saving model ...
Validation loss decreased (0.391279 --> 0.391262).  Saving model ...
Validation loss decreased (0.391262 --> 0.391245).  Saving model ...
Validation loss decreased (0.391245 --> 0.391228).  Saving model ...
Validation loss decreased (0.391228 --> 0.391211).  Saving model ...
Validation loss decreased (0.391211 --> 0.391194).  Saving model ...
Validation loss decreased (0.391194 --> 0.391177).  Saving model ...
epoch 3701, loss 0.3912, train acc 82.39%, f1 0.7419, precision 0.7629, recall 0.7220, auc 0.8004
Validation loss decreased (0.391177 --> 0.391160).  Saving model ...
Validation loss decreased (0.391160 --> 0.391144).  Saving model ...
Validation loss decreased (0.391144 --> 0.391127).  Saving model ...
Validation loss decreased (0.391127 --> 0.391110).  Saving model ...
Validation loss decreased (0.391110 --> 0.391093).  Saving model ...
Validation loss decreased (0.391093 --> 0.391076).  Saving model ...
Validation loss decreased (0.391076 --> 0.391059).  Saving model ...
Validation loss decreased (0.391059 --> 0.391042).  Saving model ...
Validation loss decreased (0.391042 --> 0.391025).  Saving model ...
Validation loss decreased (0.391025 --> 0.391008).  Saving model ...
Validation loss decreased (0.391008 --> 0.390991).  Saving model ...
Validation loss decreased (0.390991 --> 0.390974).  Saving model ...
Validation loss decreased (0.390974 --> 0.390958).  Saving model ...
Validation loss decreased (0.390958 --> 0.390941).  Saving model ...
Validation loss decreased (0.390941 --> 0.390924).  Saving model ...
Validation loss decreased (0.390924 --> 0.390907).  Saving model ...
Validation loss decreased (0.390907 --> 0.390890).  Saving model ...
Validation loss decreased (0.390890 --> 0.390873).  Saving model ...
Validation loss decreased (0.390873 --> 0.390856).  Saving model ...
Validation loss decreased (0.390856 --> 0.390839).  Saving model ...
Validation loss decreased (0.390839 --> 0.390822).  Saving model ...
Validation loss decreased (0.390822 --> 0.390805).  Saving model ...
Validation loss decreased (0.390805 --> 0.390788).  Saving model ...
Validation loss decreased (0.390788 --> 0.390771).  Saving model ...
Validation loss decreased (0.390771 --> 0.390754).  Saving model ...
Validation loss decreased (0.390754 --> 0.390737).  Saving model ...
Validation loss decreased (0.390737 --> 0.390720).  Saving model ...
Validation loss decreased (0.390720 --> 0.390703).  Saving model ...
Validation loss decreased (0.390703 --> 0.390686).  Saving model ...
Validation loss decreased (0.390686 --> 0.390669).  Saving model ...
Validation loss decreased (0.390669 --> 0.390652).  Saving model ...
Validation loss decreased (0.390652 --> 0.390635).  Saving model ...
Validation loss decreased (0.390635 --> 0.390618).  Saving model ...
Validation loss decreased (0.390618 --> 0.390601).  Saving model ...
Validation loss decreased (0.390601 --> 0.390584).  Saving model ...
Validation loss decreased (0.390584 --> 0.390567).  Saving model ...
Validation loss decreased (0.390567 --> 0.390550).  Saving model ...
Validation loss decreased (0.390550 --> 0.390533).  Saving model ...
Validation loss decreased (0.390533 --> 0.390516).  Saving model ...
Validation loss decreased (0.390516 --> 0.390499).  Saving model ...
Validation loss decreased (0.390499 --> 0.390482).  Saving model ...
Validation loss decreased (0.390482 --> 0.390465).  Saving model ...
Validation loss decreased (0.390465 --> 0.390447).  Saving model ...
Validation loss decreased (0.390447 --> 0.390430).  Saving model ...
Validation loss decreased (0.390430 --> 0.390413).  Saving model ...
Validation loss decreased (0.390413 --> 0.390396).  Saving model ...
Validation loss decreased (0.390396 --> 0.390379).  Saving model ...
Validation loss decreased (0.390379 --> 0.390362).  Saving model ...
Validation loss decreased (0.390362 --> 0.390345).  Saving model ...
Validation loss decreased (0.390345 --> 0.390328).  Saving model ...
Validation loss decreased (0.390328 --> 0.390311).  Saving model ...
Validation loss decreased (0.390311 --> 0.390293).  Saving model ...
Validation loss decreased (0.390293 --> 0.390276).  Saving model ...
Validation loss decreased (0.390276 --> 0.390259).  Saving model ...
Validation loss decreased (0.390259 --> 0.390242).  Saving model ...
Validation loss decreased (0.390242 --> 0.390225).  Saving model ...
Validation loss decreased (0.390225 --> 0.390208).  Saving model ...
Validation loss decreased (0.390208 --> 0.390191).  Saving model ...
Validation loss decreased (0.390191 --> 0.390173).  Saving model ...
Validation loss decreased (0.390173 --> 0.390156).  Saving model ...
Validation loss decreased (0.390156 --> 0.390139).  Saving model ...
Validation loss decreased (0.390139 --> 0.390122).  Saving model ...
Validation loss decreased (0.390122 --> 0.390104).  Saving model ...
Validation loss decreased (0.390104 --> 0.390087).  Saving model ...
Validation loss decreased (0.390087 --> 0.390070).  Saving model ...
Validation loss decreased (0.390070 --> 0.390053).  Saving model ...
Validation loss decreased (0.390053 --> 0.390035).  Saving model ...
Validation loss decreased (0.390035 --> 0.390018).  Saving model ...
Validation loss decreased (0.390018 --> 0.390001).  Saving model ...
Validation loss decreased (0.390001 --> 0.389984).  Saving model ...
Validation loss decreased (0.389984 --> 0.389966).  Saving model ...
Validation loss decreased (0.389966 --> 0.389949).  Saving model ...
Validation loss decreased (0.389949 --> 0.389932).  Saving model ...
Validation loss decreased (0.389932 --> 0.389914).  Saving model ...
Validation loss decreased (0.389914 --> 0.389897).  Saving model ...
Validation loss decreased (0.389897 --> 0.389880).  Saving model ...
Validation loss decreased (0.389880 --> 0.389862).  Saving model ...
Validation loss decreased (0.389862 --> 0.389845).  Saving model ...
Validation loss decreased (0.389845 --> 0.389827).  Saving model ...
Validation loss decreased (0.389827 --> 0.389810).  Saving model ...
Validation loss decreased (0.389810 --> 0.389793).  Saving model ...
Validation loss decreased (0.389793 --> 0.389775).  Saving model ...
Validation loss decreased (0.389775 --> 0.389758).  Saving model ...
Validation loss decreased (0.389758 --> 0.389740).  Saving model ...
Validation loss decreased (0.389740 --> 0.389723).  Saving model ...
Validation loss decreased (0.389723 --> 0.389705).  Saving model ...
Validation loss decreased (0.389705 --> 0.389688).  Saving model ...
Validation loss decreased (0.389688 --> 0.389670).  Saving model ...
Validation loss decreased (0.389670 --> 0.389653).  Saving model ...
Validation loss decreased (0.389653 --> 0.389635).  Saving model ...
Validation loss decreased (0.389635 --> 0.389618).  Saving model ...
Validation loss decreased (0.389618 --> 0.389600).  Saving model ...
Validation loss decreased (0.389600 --> 0.389582).  Saving model ...
Validation loss decreased (0.389582 --> 0.389565).  Saving model ...
Validation loss decreased (0.389565 --> 0.389547).  Saving model ...
Validation loss decreased (0.389547 --> 0.389529).  Saving model ...
Validation loss decreased (0.389529 --> 0.389512).  Saving model ...
Validation loss decreased (0.389512 --> 0.389494).  Saving model ...
Validation loss decreased (0.389494 --> 0.389476).  Saving model ...
Validation loss decreased (0.389476 --> 0.389459).  Saving model ...
epoch 3801, loss 0.3895, train acc 82.22%, f1 0.7374, precision 0.7644, recall 0.7122, auc 0.7969
Validation loss decreased (0.389459 --> 0.389441).  Saving model ...
Validation loss decreased (0.389441 --> 0.389423).  Saving model ...
Validation loss decreased (0.389423 --> 0.389405).  Saving model ...
Validation loss decreased (0.389405 --> 0.389387).  Saving model ...
Validation loss decreased (0.389387 --> 0.389370).  Saving model ...
Validation loss decreased (0.389370 --> 0.389352).  Saving model ...
Validation loss decreased (0.389352 --> 0.389334).  Saving model ...
Validation loss decreased (0.389334 --> 0.389316).  Saving model ...
Validation loss decreased (0.389316 --> 0.389298).  Saving model ...
Validation loss decreased (0.389298 --> 0.389280).  Saving model ...
Validation loss decreased (0.389280 --> 0.389262).  Saving model ...
Validation loss decreased (0.389262 --> 0.389244).  Saving model ...
Validation loss decreased (0.389244 --> 0.389226).  Saving model ...
Validation loss decreased (0.389226 --> 0.389208).  Saving model ...
Validation loss decreased (0.389208 --> 0.389189).  Saving model ...
Validation loss decreased (0.389189 --> 0.389171).  Saving model ...
Validation loss decreased (0.389171 --> 0.389153).  Saving model ...
Validation loss decreased (0.389153 --> 0.389135).  Saving model ...
Validation loss decreased (0.389135 --> 0.389117).  Saving model ...
Validation loss decreased (0.389117 --> 0.389098).  Saving model ...
Validation loss decreased (0.389098 --> 0.389080).  Saving model ...
Validation loss decreased (0.389080 --> 0.389062).  Saving model ...
Validation loss decreased (0.389062 --> 0.389043).  Saving model ...
Validation loss decreased (0.389043 --> 0.389025).  Saving model ...
Validation loss decreased (0.389025 --> 0.389006).  Saving model ...
Validation loss decreased (0.389006 --> 0.388988).  Saving model ...
Validation loss decreased (0.388988 --> 0.388969).  Saving model ...
Validation loss decreased (0.388969 --> 0.388951).  Saving model ...
Validation loss decreased (0.388951 --> 0.388932).  Saving model ...
Validation loss decreased (0.388932 --> 0.388913).  Saving model ...
Validation loss decreased (0.388913 --> 0.388895).  Saving model ...
Validation loss decreased (0.388895 --> 0.388876).  Saving model ...
Validation loss decreased (0.388876 --> 0.388857).  Saving model ...
Validation loss decreased (0.388857 --> 0.388838).  Saving model ...
Validation loss decreased (0.388838 --> 0.388820).  Saving model ...
Validation loss decreased (0.388820 --> 0.388801).  Saving model ...
Validation loss decreased (0.388801 --> 0.388782).  Saving model ...
Validation loss decreased (0.388782 --> 0.388763).  Saving model ...
Validation loss decreased (0.388763 --> 0.388744).  Saving model ...
Validation loss decreased (0.388744 --> 0.388725).  Saving model ...
Validation loss decreased (0.388725 --> 0.388706).  Saving model ...
Validation loss decreased (0.388706 --> 0.388687).  Saving model ...
Validation loss decreased (0.388687 --> 0.388668).  Saving model ...
Validation loss decreased (0.388668 --> 0.388649).  Saving model ...
Validation loss decreased (0.388649 --> 0.388629).  Saving model ...
Validation loss decreased (0.388629 --> 0.388610).  Saving model ...
Validation loss decreased (0.388610 --> 0.388591).  Saving model ...
Validation loss decreased (0.388591 --> 0.388572).  Saving model ...
Validation loss decreased (0.388572 --> 0.388553).  Saving model ...
Validation loss decreased (0.388553 --> 0.388533).  Saving model ...
Validation loss decreased (0.388533 --> 0.388514).  Saving model ...
Validation loss decreased (0.388514 --> 0.388495).  Saving model ...
Validation loss decreased (0.388495 --> 0.388475).  Saving model ...
Validation loss decreased (0.388475 --> 0.388456).  Saving model ...
Validation loss decreased (0.388456 --> 0.388436).  Saving model ...
Validation loss decreased (0.388436 --> 0.388417).  Saving model ...
Validation loss decreased (0.388417 --> 0.388397).  Saving model ...
Validation loss decreased (0.388397 --> 0.388378).  Saving model ...
Validation loss decreased (0.388378 --> 0.388359).  Saving model ...
Validation loss decreased (0.388359 --> 0.388339).  Saving model ...
Validation loss decreased (0.388339 --> 0.388320).  Saving model ...
Validation loss decreased (0.388320 --> 0.388300).  Saving model ...
Validation loss decreased (0.388300 --> 0.388281).  Saving model ...
Validation loss decreased (0.388281 --> 0.388261).  Saving model ...
Validation loss decreased (0.388261 --> 0.388241).  Saving model ...
Validation loss decreased (0.388241 --> 0.388222).  Saving model ...
Validation loss decreased (0.388222 --> 0.388202).  Saving model ...
Validation loss decreased (0.388202 --> 0.388183).  Saving model ...
Validation loss decreased (0.388183 --> 0.388163).  Saving model ...
Validation loss decreased (0.388163 --> 0.388144).  Saving model ...
Validation loss decreased (0.388144 --> 0.388124).  Saving model ...
Validation loss decreased (0.388124 --> 0.388105).  Saving model ...
Validation loss decreased (0.388105 --> 0.388085).  Saving model ...
Validation loss decreased (0.388085 --> 0.388066).  Saving model ...
Validation loss decreased (0.388066 --> 0.388046).  Saving model ...
Validation loss decreased (0.388046 --> 0.388027).  Saving model ...
Validation loss decreased (0.388027 --> 0.388007).  Saving model ...
Validation loss decreased (0.388007 --> 0.387988).  Saving model ...
Validation loss decreased (0.387988 --> 0.387968).  Saving model ...
Validation loss decreased (0.387968 --> 0.387949).  Saving model ...
Validation loss decreased (0.387949 --> 0.387929).  Saving model ...
Validation loss decreased (0.387929 --> 0.387910).  Saving model ...
Validation loss decreased (0.387910 --> 0.387890).  Saving model ...
Validation loss decreased (0.387890 --> 0.387871).  Saving model ...
Validation loss decreased (0.387871 --> 0.387851).  Saving model ...
Validation loss decreased (0.387851 --> 0.387832).  Saving model ...
Validation loss decreased (0.387832 --> 0.387812).  Saving model ...
Validation loss decreased (0.387812 --> 0.387793).  Saving model ...
Validation loss decreased (0.387793 --> 0.387774).  Saving model ...
Validation loss decreased (0.387774 --> 0.387754).  Saving model ...
Validation loss decreased (0.387754 --> 0.387735).  Saving model ...
Validation loss decreased (0.387735 --> 0.387715).  Saving model ...
Validation loss decreased (0.387715 --> 0.387696).  Saving model ...
Validation loss decreased (0.387696 --> 0.387677).  Saving model ...
Validation loss decreased (0.387677 --> 0.387657).  Saving model ...
Validation loss decreased (0.387657 --> 0.387638).  Saving model ...
Validation loss decreased (0.387638 --> 0.387619).  Saving model ...
Validation loss decreased (0.387619 --> 0.387600).  Saving model ...
Validation loss decreased (0.387600 --> 0.387580).  Saving model ...
Validation loss decreased (0.387580 --> 0.387561).  Saving model ...
epoch 3901, loss 0.3876, train acc 82.39%, f1 0.7406, precision 0.7656, recall 0.7171, auc 0.7993
Validation loss decreased (0.387561 --> 0.387542).  Saving model ...
Validation loss decreased (0.387542 --> 0.387523).  Saving model ...
Validation loss decreased (0.387523 --> 0.387504).  Saving model ...
Validation loss decreased (0.387504 --> 0.387484).  Saving model ...
Validation loss decreased (0.387484 --> 0.387465).  Saving model ...
Validation loss decreased (0.387465 --> 0.387446).  Saving model ...
Validation loss decreased (0.387446 --> 0.387427).  Saving model ...
Validation loss decreased (0.387427 --> 0.387408).  Saving model ...
Validation loss decreased (0.387408 --> 0.387389).  Saving model ...
Validation loss decreased (0.387389 --> 0.387370).  Saving model ...
Validation loss decreased (0.387370 --> 0.387351).  Saving model ...
Validation loss decreased (0.387351 --> 0.387331).  Saving model ...
Validation loss decreased (0.387331 --> 0.387312).  Saving model ...
Validation loss decreased (0.387312 --> 0.387293).  Saving model ...
Validation loss decreased (0.387293 --> 0.387274).  Saving model ...
Validation loss decreased (0.387274 --> 0.387255).  Saving model ...
Validation loss decreased (0.387255 --> 0.387236).  Saving model ...
Validation loss decreased (0.387236 --> 0.387217).  Saving model ...
Validation loss decreased (0.387217 --> 0.387198).  Saving model ...
Validation loss decreased (0.387198 --> 0.387179).  Saving model ...
Validation loss decreased (0.387179 --> 0.387160).  Saving model ...
Validation loss decreased (0.387160 --> 0.387141).  Saving model ...
Validation loss decreased (0.387141 --> 0.387122).  Saving model ...
Validation loss decreased (0.387122 --> 0.387104).  Saving model ...
Validation loss decreased (0.387104 --> 0.387085).  Saving model ...
Validation loss decreased (0.387085 --> 0.387066).  Saving model ...
Validation loss decreased (0.387066 --> 0.387047).  Saving model ...
Validation loss decreased (0.387047 --> 0.387028).  Saving model ...
Validation loss decreased (0.387028 --> 0.387009).  Saving model ...
Validation loss decreased (0.387009 --> 0.386990).  Saving model ...
Validation loss decreased (0.386990 --> 0.386972).  Saving model ...
Validation loss decreased (0.386972 --> 0.386953).  Saving model ...
Validation loss decreased (0.386953 --> 0.386934).  Saving model ...
Validation loss decreased (0.386934 --> 0.386915).  Saving model ...
Validation loss decreased (0.386915 --> 0.386896).  Saving model ...
Validation loss decreased (0.386896 --> 0.386877).  Saving model ...
Validation loss decreased (0.386877 --> 0.386859).  Saving model ...
Validation loss decreased (0.386859 --> 0.386840).  Saving model ...
Validation loss decreased (0.386840 --> 0.386821).  Saving model ...
Validation loss decreased (0.386821 --> 0.386802).  Saving model ...
Validation loss decreased (0.386802 --> 0.386784).  Saving model ...
Validation loss decreased (0.386784 --> 0.386765).  Saving model ...
Validation loss decreased (0.386765 --> 0.386746).  Saving model ...
Validation loss decreased (0.386746 --> 0.386728).  Saving model ...
Validation loss decreased (0.386728 --> 0.386709).  Saving model ...
Validation loss decreased (0.386709 --> 0.386690).  Saving model ...
Validation loss decreased (0.386690 --> 0.386671).  Saving model ...
Validation loss decreased (0.386671 --> 0.386653).  Saving model ...
Validation loss decreased (0.386653 --> 0.386634).  Saving model ...
Validation loss decreased (0.386634 --> 0.386616).  Saving model ...
Validation loss decreased (0.386616 --> 0.386597).  Saving model ...
Validation loss decreased (0.386597 --> 0.386578).  Saving model ...
Validation loss decreased (0.386578 --> 0.386560).  Saving model ...
Validation loss decreased (0.386560 --> 0.386541).  Saving model ...
Validation loss decreased (0.386541 --> 0.386522).  Saving model ...
Validation loss decreased (0.386522 --> 0.386504).  Saving model ...
Validation loss decreased (0.386504 --> 0.386485).  Saving model ...
Validation loss decreased (0.386485 --> 0.386467).  Saving model ...
Validation loss decreased (0.386467 --> 0.386448).  Saving model ...
Validation loss decreased (0.386448 --> 0.386429).  Saving model ...
Validation loss decreased (0.386429 --> 0.386411).  Saving model ...
Validation loss decreased (0.386411 --> 0.386392).  Saving model ...
Validation loss decreased (0.386392 --> 0.386374).  Saving model ...
Validation loss decreased (0.386374 --> 0.386355).  Saving model ...
Validation loss decreased (0.386355 --> 0.386337).  Saving model ...
Validation loss decreased (0.386337 --> 0.386318).  Saving model ...
Validation loss decreased (0.386318 --> 0.386300).  Saving model ...
Validation loss decreased (0.386300 --> 0.386281).  Saving model ...
Validation loss decreased (0.386281 --> 0.386263).  Saving model ...
Validation loss decreased (0.386263 --> 0.386244).  Saving model ...
Validation loss decreased (0.386244 --> 0.386226).  Saving model ...
Validation loss decreased (0.386226 --> 0.386207).  Saving model ...
Validation loss decreased (0.386207 --> 0.386189).  Saving model ...
Validation loss decreased (0.386189 --> 0.386170).  Saving model ...
Validation loss decreased (0.386170 --> 0.386152).  Saving model ...
Validation loss decreased (0.386152 --> 0.386133).  Saving model ...
Validation loss decreased (0.386133 --> 0.386115).  Saving model ...
Validation loss decreased (0.386115 --> 0.386097).  Saving model ...
Validation loss decreased (0.386097 --> 0.386078).  Saving model ...
Validation loss decreased (0.386078 --> 0.386060).  Saving model ...
Validation loss decreased (0.386060 --> 0.386041).  Saving model ...
Validation loss decreased (0.386041 --> 0.386023).  Saving model ...
Validation loss decreased (0.386023 --> 0.386005).  Saving model ...
Validation loss decreased (0.386005 --> 0.385986).  Saving model ...
Validation loss decreased (0.385986 --> 0.385968).  Saving model ...
Validation loss decreased (0.385968 --> 0.385950).  Saving model ...
Validation loss decreased (0.385950 --> 0.385931).  Saving model ...
Validation loss decreased (0.385931 --> 0.385913).  Saving model ...
Validation loss decreased (0.385913 --> 0.385895).  Saving model ...
Validation loss decreased (0.385895 --> 0.385876).  Saving model ...
Validation loss decreased (0.385876 --> 0.385858).  Saving model ...
Validation loss decreased (0.385858 --> 0.385839).  Saving model ...
Validation loss decreased (0.385839 --> 0.385821).  Saving model ...
Validation loss decreased (0.385821 --> 0.385803).  Saving model ...
Validation loss decreased (0.385803 --> 0.385785).  Saving model ...
Validation loss decreased (0.385785 --> 0.385766).  Saving model ...
Validation loss decreased (0.385766 --> 0.385748).  Saving model ...
Validation loss decreased (0.385748 --> 0.385730).  Saving model ...
Validation loss decreased (0.385730 --> 0.385711).  Saving model ...
Validation loss decreased (0.385711 --> 0.385693).  Saving model ...
epoch 4001, loss 0.3857, train acc 82.22%, f1 0.7387, precision 0.7617, recall 0.7171, auc 0.7980
Validation loss decreased (0.385693 --> 0.385675).  Saving model ...
Validation loss decreased (0.385675 --> 0.385657).  Saving model ...
Validation loss decreased (0.385657 --> 0.385638).  Saving model ...
Validation loss decreased (0.385638 --> 0.385620).  Saving model ...
Validation loss decreased (0.385620 --> 0.385602).  Saving model ...
Validation loss decreased (0.385602 --> 0.385584).  Saving model ...
Validation loss decreased (0.385584 --> 0.385566).  Saving model ...
Validation loss decreased (0.385566 --> 0.385547).  Saving model ...
Validation loss decreased (0.385547 --> 0.385529).  Saving model ...
Validation loss decreased (0.385529 --> 0.385511).  Saving model ...
Validation loss decreased (0.385511 --> 0.385493).  Saving model ...
Validation loss decreased (0.385493 --> 0.385475).  Saving model ...
Validation loss decreased (0.385475 --> 0.385456).  Saving model ...
Validation loss decreased (0.385456 --> 0.385438).  Saving model ...
Validation loss decreased (0.385438 --> 0.385420).  Saving model ...
Validation loss decreased (0.385420 --> 0.385402).  Saving model ...
Validation loss decreased (0.385402 --> 0.385384).  Saving model ...
Validation loss decreased (0.385384 --> 0.385366).  Saving model ...
Validation loss decreased (0.385366 --> 0.385348).  Saving model ...
Validation loss decreased (0.385348 --> 0.385329).  Saving model ...
Validation loss decreased (0.385329 --> 0.385311).  Saving model ...
Validation loss decreased (0.385311 --> 0.385293).  Saving model ...
Validation loss decreased (0.385293 --> 0.385275).  Saving model ...
Validation loss decreased (0.385275 --> 0.385257).  Saving model ...
Validation loss decreased (0.385257 --> 0.385239).  Saving model ...
Validation loss decreased (0.385239 --> 0.385221).  Saving model ...
Validation loss decreased (0.385221 --> 0.385203).  Saving model ...
Validation loss decreased (0.385203 --> 0.385185).  Saving model ...
Validation loss decreased (0.385185 --> 0.385167).  Saving model ...
Validation loss decreased (0.385167 --> 0.385149).  Saving model ...
Validation loss decreased (0.385149 --> 0.385131).  Saving model ...
Validation loss decreased (0.385131 --> 0.385113).  Saving model ...
Validation loss decreased (0.385113 --> 0.385095).  Saving model ...
Validation loss decreased (0.385095 --> 0.385077).  Saving model ...
Validation loss decreased (0.385077 --> 0.385058).  Saving model ...
Validation loss decreased (0.385058 --> 0.385040).  Saving model ...
Validation loss decreased (0.385040 --> 0.385022).  Saving model ...
Validation loss decreased (0.385022 --> 0.385005).  Saving model ...
Validation loss decreased (0.385005 --> 0.384987).  Saving model ...
Validation loss decreased (0.384987 --> 0.384969).  Saving model ...
Validation loss decreased (0.384969 --> 0.384951).  Saving model ...
Validation loss decreased (0.384951 --> 0.384933).  Saving model ...
Validation loss decreased (0.384933 --> 0.384915).  Saving model ...
Validation loss decreased (0.384915 --> 0.384897).  Saving model ...
Validation loss decreased (0.384897 --> 0.384879).  Saving model ...
Validation loss decreased (0.384879 --> 0.384861).  Saving model ...
Validation loss decreased (0.384861 --> 0.384843).  Saving model ...
Validation loss decreased (0.384843 --> 0.384825).  Saving model ...
Validation loss decreased (0.384825 --> 0.384807).  Saving model ...
Validation loss decreased (0.384807 --> 0.384789).  Saving model ...
Validation loss decreased (0.384789 --> 0.384771).  Saving model ...
Validation loss decreased (0.384771 --> 0.384753).  Saving model ...
Validation loss decreased (0.384753 --> 0.384735).  Saving model ...
Validation loss decreased (0.384735 --> 0.384718).  Saving model ...
Validation loss decreased (0.384718 --> 0.384700).  Saving model ...
Validation loss decreased (0.384700 --> 0.384682).  Saving model ...
Validation loss decreased (0.384682 --> 0.384664).  Saving model ...
Validation loss decreased (0.384664 --> 0.384646).  Saving model ...
Validation loss decreased (0.384646 --> 0.384628).  Saving model ...
Validation loss decreased (0.384628 --> 0.384610).  Saving model ...
Validation loss decreased (0.384610 --> 0.384593).  Saving model ...
Validation loss decreased (0.384593 --> 0.384575).  Saving model ...
Validation loss decreased (0.384575 --> 0.384557).  Saving model ...
Validation loss decreased (0.384557 --> 0.384539).  Saving model ...
Validation loss decreased (0.384539 --> 0.384521).  Saving model ...
Validation loss decreased (0.384521 --> 0.384503).  Saving model ...
Validation loss decreased (0.384503 --> 0.384486).  Saving model ...
Validation loss decreased (0.384486 --> 0.384468).  Saving model ...
Validation loss decreased (0.384468 --> 0.384450).  Saving model ...
Validation loss decreased (0.384450 --> 0.384432).  Saving model ...
Validation loss decreased (0.384432 --> 0.384415).  Saving model ...
Validation loss decreased (0.384415 --> 0.384397).  Saving model ...
Validation loss decreased (0.384397 --> 0.384379).  Saving model ...
Validation loss decreased (0.384379 --> 0.384361).  Saving model ...
Validation loss decreased (0.384361 --> 0.384344).  Saving model ...
Validation loss decreased (0.384344 --> 0.384326).  Saving model ...
Validation loss decreased (0.384326 --> 0.384308).  Saving model ...
Validation loss decreased (0.384308 --> 0.384290).  Saving model ...
Validation loss decreased (0.384290 --> 0.384273).  Saving model ...
Validation loss decreased (0.384273 --> 0.384255).  Saving model ...
Validation loss decreased (0.384255 --> 0.384237).  Saving model ...
Validation loss decreased (0.384237 --> 0.384219).  Saving model ...
Validation loss decreased (0.384219 --> 0.384202).  Saving model ...
Validation loss decreased (0.384202 --> 0.384184).  Saving model ...
Validation loss decreased (0.384184 --> 0.384166).  Saving model ...
Validation loss decreased (0.384166 --> 0.384149).  Saving model ...
Validation loss decreased (0.384149 --> 0.384131).  Saving model ...
Validation loss decreased (0.384131 --> 0.384113).  Saving model ...
Validation loss decreased (0.384113 --> 0.384096).  Saving model ...
Validation loss decreased (0.384096 --> 0.384078).  Saving model ...
Validation loss decreased (0.384078 --> 0.384060).  Saving model ...
Validation loss decreased (0.384060 --> 0.384043).  Saving model ...
Validation loss decreased (0.384043 --> 0.384025).  Saving model ...
Validation loss decreased (0.384025 --> 0.384007).  Saving model ...
Validation loss decreased (0.384007 --> 0.383990).  Saving model ...
Validation loss decreased (0.383990 --> 0.383972).  Saving model ...
Validation loss decreased (0.383972 --> 0.383954).  Saving model ...
Validation loss decreased (0.383954 --> 0.383937).  Saving model ...
Validation loss decreased (0.383937 --> 0.383919).  Saving model ...
Validation loss decreased (0.383919 --> 0.383902).  Saving model ...
epoch 4101, loss 0.3839, train acc 82.22%, f1 0.7387, precision 0.7617, recall 0.7171, auc 0.7980
Validation loss decreased (0.383902 --> 0.383884).  Saving model ...
Validation loss decreased (0.383884 --> 0.383866).  Saving model ...
Validation loss decreased (0.383866 --> 0.383849).  Saving model ...
Validation loss decreased (0.383849 --> 0.383831).  Saving model ...
Validation loss decreased (0.383831 --> 0.383814).  Saving model ...
Validation loss decreased (0.383814 --> 0.383796).  Saving model ...
Validation loss decreased (0.383796 --> 0.383778).  Saving model ...
Validation loss decreased (0.383778 --> 0.383761).  Saving model ...
Validation loss decreased (0.383761 --> 0.383743).  Saving model ...
Validation loss decreased (0.383743 --> 0.383726).  Saving model ...
Validation loss decreased (0.383726 --> 0.383708).  Saving model ...
Validation loss decreased (0.383708 --> 0.383691).  Saving model ...
Validation loss decreased (0.383691 --> 0.383673).  Saving model ...
Validation loss decreased (0.383673 --> 0.383655).  Saving model ...
Validation loss decreased (0.383655 --> 0.383638).  Saving model ...
Validation loss decreased (0.383638 --> 0.383620).  Saving model ...
Validation loss decreased (0.383620 --> 0.383603).  Saving model ...
Validation loss decreased (0.383603 --> 0.383585).  Saving model ...
Validation loss decreased (0.383585 --> 0.383568).  Saving model ...
Validation loss decreased (0.383568 --> 0.383550).  Saving model ...
Validation loss decreased (0.383550 --> 0.383532).  Saving model ...
Validation loss decreased (0.383532 --> 0.383515).  Saving model ...
Validation loss decreased (0.383515 --> 0.383497).  Saving model ...
Validation loss decreased (0.383497 --> 0.383480).  Saving model ...
Validation loss decreased (0.383480 --> 0.383462).  Saving model ...
Validation loss decreased (0.383462 --> 0.383445).  Saving model ...
Validation loss decreased (0.383445 --> 0.383427).  Saving model ...
Validation loss decreased (0.383427 --> 0.383410).  Saving model ...
Validation loss decreased (0.383410 --> 0.383392).  Saving model ...
Validation loss decreased (0.383392 --> 0.383375).  Saving model ...
Validation loss decreased (0.383375 --> 0.383357).  Saving model ...
Validation loss decreased (0.383357 --> 0.383340).  Saving model ...
Validation loss decreased (0.383340 --> 0.383322).  Saving model ...
Validation loss decreased (0.383322 --> 0.383304).  Saving model ...
Validation loss decreased (0.383304 --> 0.383287).  Saving model ...
Validation loss decreased (0.383287 --> 0.383269).  Saving model ...
Validation loss decreased (0.383269 --> 0.383252).  Saving model ...
Validation loss decreased (0.383252 --> 0.383234).  Saving model ...
Validation loss decreased (0.383234 --> 0.383217).  Saving model ...
Validation loss decreased (0.383217 --> 0.383199).  Saving model ...
Validation loss decreased (0.383199 --> 0.383182).  Saving model ...
Validation loss decreased (0.383182 --> 0.383164).  Saving model ...
Validation loss decreased (0.383164 --> 0.383146).  Saving model ...
Validation loss decreased (0.383146 --> 0.383129).  Saving model ...
Validation loss decreased (0.383129 --> 0.383111).  Saving model ...
Validation loss decreased (0.383111 --> 0.383094).  Saving model ...
Validation loss decreased (0.383094 --> 0.383076).  Saving model ...
Validation loss decreased (0.383076 --> 0.383059).  Saving model ...
Validation loss decreased (0.383059 --> 0.383041).  Saving model ...
Validation loss decreased (0.383041 --> 0.383023).  Saving model ...
Validation loss decreased (0.383023 --> 0.383006).  Saving model ...
Validation loss decreased (0.383006 --> 0.382988).  Saving model ...
Validation loss decreased (0.382988 --> 0.382971).  Saving model ...
Validation loss decreased (0.382971 --> 0.382953).  Saving model ...
Validation loss decreased (0.382953 --> 0.382935).  Saving model ...
Validation loss decreased (0.382935 --> 0.382918).  Saving model ...
Validation loss decreased (0.382918 --> 0.382900).  Saving model ...
Validation loss decreased (0.382900 --> 0.382882).  Saving model ...
Validation loss decreased (0.382882 --> 0.382865).  Saving model ...
Validation loss decreased (0.382865 --> 0.382847).  Saving model ...
Validation loss decreased (0.382847 --> 0.382829).  Saving model ...
Validation loss decreased (0.382829 --> 0.382812).  Saving model ...
Validation loss decreased (0.382812 --> 0.382794).  Saving model ...
Validation loss decreased (0.382794 --> 0.382776).  Saving model ...
Validation loss decreased (0.382776 --> 0.382759).  Saving model ...
Validation loss decreased (0.382759 --> 0.382741).  Saving model ...
Validation loss decreased (0.382741 --> 0.382723).  Saving model ...
Validation loss decreased (0.382723 --> 0.382706).  Saving model ...
Validation loss decreased (0.382706 --> 0.382688).  Saving model ...
Validation loss decreased (0.382688 --> 0.382670).  Saving model ...
Validation loss decreased (0.382670 --> 0.382652).  Saving model ...
Validation loss decreased (0.382652 --> 0.382635).  Saving model ...
Validation loss decreased (0.382635 --> 0.382617).  Saving model ...
Validation loss decreased (0.382617 --> 0.382599).  Saving model ...
Validation loss decreased (0.382599 --> 0.382581).  Saving model ...
Validation loss decreased (0.382581 --> 0.382563).  Saving model ...
Validation loss decreased (0.382563 --> 0.382545).  Saving model ...
Validation loss decreased (0.382545 --> 0.382527).  Saving model ...
Validation loss decreased (0.382527 --> 0.382510).  Saving model ...
Validation loss decreased (0.382510 --> 0.382492).  Saving model ...
Validation loss decreased (0.382492 --> 0.382474).  Saving model ...
Validation loss decreased (0.382474 --> 0.382456).  Saving model ...
Validation loss decreased (0.382456 --> 0.382438).  Saving model ...
Validation loss decreased (0.382438 --> 0.382420).  Saving model ...
Validation loss decreased (0.382420 --> 0.382402).  Saving model ...
Validation loss decreased (0.382402 --> 0.382384).  Saving model ...
Validation loss decreased (0.382384 --> 0.382366).  Saving model ...
Validation loss decreased (0.382366 --> 0.382348).  Saving model ...
Validation loss decreased (0.382348 --> 0.382330).  Saving model ...
Validation loss decreased (0.382330 --> 0.382311).  Saving model ...
Validation loss decreased (0.382311 --> 0.382293).  Saving model ...
Validation loss decreased (0.382293 --> 0.382275).  Saving model ...
Validation loss decreased (0.382275 --> 0.382257).  Saving model ...
Validation loss decreased (0.382257 --> 0.382239).  Saving model ...
Validation loss decreased (0.382239 --> 0.382220).  Saving model ...
Validation loss decreased (0.382220 --> 0.382202).  Saving model ...
Validation loss decreased (0.382202 --> 0.382184).  Saving model ...
Validation loss decreased (0.382184 --> 0.382165).  Saving model ...
Validation loss decreased (0.382165 --> 0.382147).  Saving model ...
Validation loss decreased (0.382147 --> 0.382129).  Saving model ...
epoch 4201, loss 0.3821, train acc 82.22%, f1 0.7387, precision 0.7617, recall 0.7171, auc 0.7980
Validation loss decreased (0.382129 --> 0.382110).  Saving model ...
Validation loss decreased (0.382110 --> 0.382092).  Saving model ...
Validation loss decreased (0.382092 --> 0.382073).  Saving model ...
Validation loss decreased (0.382073 --> 0.382055).  Saving model ...
Validation loss decreased (0.382055 --> 0.382036).  Saving model ...
Validation loss decreased (0.382036 --> 0.382018).  Saving model ...
Validation loss decreased (0.382018 --> 0.381999).  Saving model ...
Validation loss decreased (0.381999 --> 0.381980).  Saving model ...
Validation loss decreased (0.381980 --> 0.381961).  Saving model ...
Validation loss decreased (0.381961 --> 0.381943).  Saving model ...
Validation loss decreased (0.381943 --> 0.381924).  Saving model ...
Validation loss decreased (0.381924 --> 0.381905).  Saving model ...
Validation loss decreased (0.381905 --> 0.381886).  Saving model ...
Validation loss decreased (0.381886 --> 0.381867).  Saving model ...
Validation loss decreased (0.381867 --> 0.381848).  Saving model ...
Validation loss decreased (0.381848 --> 0.381829).  Saving model ...
Validation loss decreased (0.381829 --> 0.381810).  Saving model ...
Validation loss decreased (0.381810 --> 0.381791).  Saving model ...
Validation loss decreased (0.381791 --> 0.381772).  Saving model ...
Validation loss decreased (0.381772 --> 0.381752).  Saving model ...
Validation loss decreased (0.381752 --> 0.381733).  Saving model ...
Validation loss decreased (0.381733 --> 0.381714).  Saving model ...
Validation loss decreased (0.381714 --> 0.381694).  Saving model ...
Validation loss decreased (0.381694 --> 0.381675).  Saving model ...
Validation loss decreased (0.381675 --> 0.381655).  Saving model ...
Validation loss decreased (0.381655 --> 0.381636).  Saving model ...
Validation loss decreased (0.381636 --> 0.381616).  Saving model ...
Validation loss decreased (0.381616 --> 0.381597).  Saving model ...
Validation loss decreased (0.381597 --> 0.381577).  Saving model ...
Validation loss decreased (0.381577 --> 0.381557).  Saving model ...
Validation loss decreased (0.381557 --> 0.381537).  Saving model ...
Validation loss decreased (0.381537 --> 0.381517).  Saving model ...
Validation loss decreased (0.381517 --> 0.381497).  Saving model ...
Validation loss decreased (0.381497 --> 0.381477).  Saving model ...
Validation loss decreased (0.381477 --> 0.381457).  Saving model ...
Validation loss decreased (0.381457 --> 0.381436).  Saving model ...
Validation loss decreased (0.381436 --> 0.381416).  Saving model ...
Validation loss decreased (0.381416 --> 0.381396).  Saving model ...
Validation loss decreased (0.381396 --> 0.381375).  Saving model ...
Validation loss decreased (0.381375 --> 0.381355).  Saving model ...
Validation loss decreased (0.381355 --> 0.381334).  Saving model ...
Validation loss decreased (0.381334 --> 0.381313).  Saving model ...
Validation loss decreased (0.381313 --> 0.381293).  Saving model ...
Validation loss decreased (0.381293 --> 0.381272).  Saving model ...
Validation loss decreased (0.381272 --> 0.381251).  Saving model ...
Validation loss decreased (0.381251 --> 0.381230).  Saving model ...
Validation loss decreased (0.381230 --> 0.381209).  Saving model ...
Validation loss decreased (0.381209 --> 0.381187).  Saving model ...
Validation loss decreased (0.381187 --> 0.381166).  Saving model ...
Validation loss decreased (0.381166 --> 0.381145).  Saving model ...
Validation loss decreased (0.381145 --> 0.381123).  Saving model ...
Validation loss decreased (0.381123 --> 0.381102).  Saving model ...
Validation loss decreased (0.381102 --> 0.381080).  Saving model ...
Validation loss decreased (0.381080 --> 0.381058).  Saving model ...
Validation loss decreased (0.381058 --> 0.381037).  Saving model ...
Validation loss decreased (0.381037 --> 0.381015).  Saving model ...
Validation loss decreased (0.381015 --> 0.380993).  Saving model ...
Validation loss decreased (0.380993 --> 0.380971).  Saving model ...
Validation loss decreased (0.380971 --> 0.380948).  Saving model ...
Validation loss decreased (0.380948 --> 0.380926).  Saving model ...
Validation loss decreased (0.380926 --> 0.380904).  Saving model ...
Validation loss decreased (0.380904 --> 0.380882).  Saving model ...
Validation loss decreased (0.380882 --> 0.380859).  Saving model ...
Validation loss decreased (0.380859 --> 0.380837).  Saving model ...
Validation loss decreased (0.380837 --> 0.380814).  Saving model ...
Validation loss decreased (0.380814 --> 0.380791).  Saving model ...
Validation loss decreased (0.380791 --> 0.380769).  Saving model ...
Validation loss decreased (0.380769 --> 0.380746).  Saving model ...
Validation loss decreased (0.380746 --> 0.380723).  Saving model ...
Validation loss decreased (0.380723 --> 0.380700).  Saving model ...
Validation loss decreased (0.380700 --> 0.380677).  Saving model ...
Validation loss decreased (0.380677 --> 0.380654).  Saving model ...
Validation loss decreased (0.380654 --> 0.380631).  Saving model ...
Validation loss decreased (0.380631 --> 0.380608).  Saving model ...
Validation loss decreased (0.380608 --> 0.380584).  Saving model ...
Validation loss decreased (0.380584 --> 0.380561).  Saving model ...
Validation loss decreased (0.380561 --> 0.380538).  Saving model ...
Validation loss decreased (0.380538 --> 0.380515).  Saving model ...
Validation loss decreased (0.380515 --> 0.380491).  Saving model ...
Validation loss decreased (0.380491 --> 0.380468).  Saving model ...
Validation loss decreased (0.380468 --> 0.380445).  Saving model ...
Validation loss decreased (0.380445 --> 0.380421).  Saving model ...
Validation loss decreased (0.380421 --> 0.380398).  Saving model ...
Validation loss decreased (0.380398 --> 0.380374).  Saving model ...
Validation loss decreased (0.380374 --> 0.380351).  Saving model ...
Validation loss decreased (0.380351 --> 0.380328).  Saving model ...
Validation loss decreased (0.380328 --> 0.380304).  Saving model ...
Validation loss decreased (0.380304 --> 0.380281).  Saving model ...
Validation loss decreased (0.380281 --> 0.380258).  Saving model ...
Validation loss decreased (0.380258 --> 0.380234).  Saving model ...
Validation loss decreased (0.380234 --> 0.380211).  Saving model ...
Validation loss decreased (0.380211 --> 0.380188).  Saving model ...
Validation loss decreased (0.380188 --> 0.380164).  Saving model ...
Validation loss decreased (0.380164 --> 0.380141).  Saving model ...
Validation loss decreased (0.380141 --> 0.380118).  Saving model ...
Validation loss decreased (0.380118 --> 0.380095).  Saving model ...
Validation loss decreased (0.380095 --> 0.380071).  Saving model ...
Validation loss decreased (0.380071 --> 0.380048).  Saving model ...
Validation loss decreased (0.380048 --> 0.380025).  Saving model ...
Validation loss decreased (0.380025 --> 0.380002).  Saving model ...
epoch 4301, loss 0.3800, train acc 82.74%, f1 0.7456, precision 0.7708, recall 0.7220, auc 0.8031
Validation loss decreased (0.380002 --> 0.379979).  Saving model ...
Validation loss decreased (0.379979 --> 0.379956).  Saving model ...
Validation loss decreased (0.379956 --> 0.379934).  Saving model ...
Validation loss decreased (0.379934 --> 0.379911).  Saving model ...
Validation loss decreased (0.379911 --> 0.379888).  Saving model ...
Validation loss decreased (0.379888 --> 0.379865).  Saving model ...
Validation loss decreased (0.379865 --> 0.379843).  Saving model ...
Validation loss decreased (0.379843 --> 0.379820).  Saving model ...
Validation loss decreased (0.379820 --> 0.379798).  Saving model ...
Validation loss decreased (0.379798 --> 0.379775).  Saving model ...
Validation loss decreased (0.379775 --> 0.379753).  Saving model ...
Validation loss decreased (0.379753 --> 0.379730).  Saving model ...
Validation loss decreased (0.379730 --> 0.379708).  Saving model ...
Validation loss decreased (0.379708 --> 0.379686).  Saving model ...
Validation loss decreased (0.379686 --> 0.379664).  Saving model ...
Validation loss decreased (0.379664 --> 0.379642).  Saving model ...
Validation loss decreased (0.379642 --> 0.379619).  Saving model ...
Validation loss decreased (0.379619 --> 0.379597).  Saving model ...
Validation loss decreased (0.379597 --> 0.379575).  Saving model ...
Validation loss decreased (0.379575 --> 0.379554).  Saving model ...
Validation loss decreased (0.379554 --> 0.379532).  Saving model ...
Validation loss decreased (0.379532 --> 0.379510).  Saving model ...
Validation loss decreased (0.379510 --> 0.379488).  Saving model ...
Validation loss decreased (0.379488 --> 0.379466).  Saving model ...
Validation loss decreased (0.379466 --> 0.379445).  Saving model ...
Validation loss decreased (0.379445 --> 0.379423).  Saving model ...
Validation loss decreased (0.379423 --> 0.379402).  Saving model ...
Validation loss decreased (0.379402 --> 0.379380).  Saving model ...
Validation loss decreased (0.379380 --> 0.379359).  Saving model ...
Validation loss decreased (0.379359 --> 0.379337).  Saving model ...
Validation loss decreased (0.379337 --> 0.379316).  Saving model ...
Validation loss decreased (0.379316 --> 0.379295).  Saving model ...
Validation loss decreased (0.379295 --> 0.379273).  Saving model ...
Validation loss decreased (0.379273 --> 0.379252).  Saving model ...
Validation loss decreased (0.379252 --> 0.379231).  Saving model ...
Validation loss decreased (0.379231 --> 0.379210).  Saving model ...
Validation loss decreased (0.379210 --> 0.379189).  Saving model ...
Validation loss decreased (0.379189 --> 0.379168).  Saving model ...
Validation loss decreased (0.379168 --> 0.379147).  Saving model ...
Validation loss decreased (0.379147 --> 0.379125).  Saving model ...
Validation loss decreased (0.379125 --> 0.379105).  Saving model ...
Validation loss decreased (0.379105 --> 0.379084).  Saving model ...
Validation loss decreased (0.379084 --> 0.379063).  Saving model ...
Validation loss decreased (0.379063 --> 0.379042).  Saving model ...
Validation loss decreased (0.379042 --> 0.379021).  Saving model ...
Validation loss decreased (0.379021 --> 0.379000).  Saving model ...
Validation loss decreased (0.379000 --> 0.378979).  Saving model ...
Validation loss decreased (0.378979 --> 0.378959).  Saving model ...
Validation loss decreased (0.378959 --> 0.378938).  Saving model ...
Validation loss decreased (0.378938 --> 0.378917).  Saving model ...
Validation loss decreased (0.378917 --> 0.378896).  Saving model ...
Validation loss decreased (0.378896 --> 0.378876).  Saving model ...
Validation loss decreased (0.378876 --> 0.378855).  Saving model ...
Validation loss decreased (0.378855 --> 0.378835).  Saving model ...
Validation loss decreased (0.378835 --> 0.378814).  Saving model ...
Validation loss decreased (0.378814 --> 0.378793).  Saving model ...
Validation loss decreased (0.378793 --> 0.378773).  Saving model ...
Validation loss decreased (0.378773 --> 0.378752).  Saving model ...
Validation loss decreased (0.378752 --> 0.378732).  Saving model ...
Validation loss decreased (0.378732 --> 0.378711).  Saving model ...
Validation loss decreased (0.378711 --> 0.378691).  Saving model ...
Validation loss decreased (0.378691 --> 0.378671).  Saving model ...
Validation loss decreased (0.378671 --> 0.378650).  Saving model ...
Validation loss decreased (0.378650 --> 0.378630).  Saving model ...
Validation loss decreased (0.378630 --> 0.378609).  Saving model ...
Validation loss decreased (0.378609 --> 0.378589).  Saving model ...
Validation loss decreased (0.378589 --> 0.378569).  Saving model ...
Validation loss decreased (0.378569 --> 0.378548).  Saving model ...
Validation loss decreased (0.378548 --> 0.378528).  Saving model ...
Validation loss decreased (0.378528 --> 0.378508).  Saving model ...
Validation loss decreased (0.378508 --> 0.378488).  Saving model ...
Validation loss decreased (0.378488 --> 0.378467).  Saving model ...
Validation loss decreased (0.378467 --> 0.378447).  Saving model ...
Validation loss decreased (0.378447 --> 0.378427).  Saving model ...
Validation loss decreased (0.378427 --> 0.378407).  Saving model ...
Validation loss decreased (0.378407 --> 0.378386).  Saving model ...
Validation loss decreased (0.378386 --> 0.378366).  Saving model ...
Validation loss decreased (0.378366 --> 0.378346).  Saving model ...
Validation loss decreased (0.378346 --> 0.378326).  Saving model ...
Validation loss decreased (0.378326 --> 0.378306).  Saving model ...
Validation loss decreased (0.378306 --> 0.378286).  Saving model ...
Validation loss decreased (0.378286 --> 0.378266).  Saving model ...
Validation loss decreased (0.378266 --> 0.378246).  Saving model ...
Validation loss decreased (0.378246 --> 0.378225).  Saving model ...
Validation loss decreased (0.378225 --> 0.378205).  Saving model ...
Validation loss decreased (0.378205 --> 0.378185).  Saving model ...
Validation loss decreased (0.378185 --> 0.378165).  Saving model ...
Validation loss decreased (0.378165 --> 0.378145).  Saving model ...
Validation loss decreased (0.378145 --> 0.378125).  Saving model ...
Validation loss decreased (0.378125 --> 0.378105).  Saving model ...
Validation loss decreased (0.378105 --> 0.378085).  Saving model ...
Validation loss decreased (0.378085 --> 0.378065).  Saving model ...
Validation loss decreased (0.378065 --> 0.378045).  Saving model ...
Validation loss decreased (0.378045 --> 0.378025).  Saving model ...
Validation loss decreased (0.378025 --> 0.378005).  Saving model ...
Validation loss decreased (0.378005 --> 0.377985).  Saving model ...
Validation loss decreased (0.377985 --> 0.377965).  Saving model ...
Validation loss decreased (0.377965 --> 0.377945).  Saving model ...
Validation loss decreased (0.377945 --> 0.377925).  Saving model ...
Validation loss decreased (0.377925 --> 0.377905).  Saving model ...
epoch 4401, loss 0.3779, train acc 83.08%, f1 0.7506, precision 0.7760, recall 0.7268, auc 0.8068
Validation loss decreased (0.377905 --> 0.377885).  Saving model ...
Validation loss decreased (0.377885 --> 0.377865).  Saving model ...
Validation loss decreased (0.377865 --> 0.377846).  Saving model ...
Validation loss decreased (0.377846 --> 0.377826).  Saving model ...
Validation loss decreased (0.377826 --> 0.377806).  Saving model ...
Validation loss decreased (0.377806 --> 0.377786).  Saving model ...
Validation loss decreased (0.377786 --> 0.377766).  Saving model ...
Validation loss decreased (0.377766 --> 0.377746).  Saving model ...
Validation loss decreased (0.377746 --> 0.377726).  Saving model ...
Validation loss decreased (0.377726 --> 0.377706).  Saving model ...
Validation loss decreased (0.377706 --> 0.377686).  Saving model ...
Validation loss decreased (0.377686 --> 0.377667).  Saving model ...
Validation loss decreased (0.377667 --> 0.377647).  Saving model ...
Validation loss decreased (0.377647 --> 0.377627).  Saving model ...
Validation loss decreased (0.377627 --> 0.377607).  Saving model ...
Validation loss decreased (0.377607 --> 0.377587).  Saving model ...
Validation loss decreased (0.377587 --> 0.377567).  Saving model ...
Validation loss decreased (0.377567 --> 0.377548).  Saving model ...
Validation loss decreased (0.377548 --> 0.377528).  Saving model ...
Validation loss decreased (0.377528 --> 0.377508).  Saving model ...
Validation loss decreased (0.377508 --> 0.377488).  Saving model ...
Validation loss decreased (0.377488 --> 0.377468).  Saving model ...
Validation loss decreased (0.377468 --> 0.377448).  Saving model ...
Validation loss decreased (0.377448 --> 0.377429).  Saving model ...
Validation loss decreased (0.377429 --> 0.377409).  Saving model ...
Validation loss decreased (0.377409 --> 0.377389).  Saving model ...
Validation loss decreased (0.377389 --> 0.377369).  Saving model ...
Validation loss decreased (0.377369 --> 0.377349).  Saving model ...
Validation loss decreased (0.377349 --> 0.377330).  Saving model ...
Validation loss decreased (0.377330 --> 0.377310).  Saving model ...
Validation loss decreased (0.377310 --> 0.377290).  Saving model ...
Validation loss decreased (0.377290 --> 0.377270).  Saving model ...
Validation loss decreased (0.377270 --> 0.377250).  Saving model ...
Validation loss decreased (0.377250 --> 0.377231).  Saving model ...
Validation loss decreased (0.377231 --> 0.377211).  Saving model ...
Validation loss decreased (0.377211 --> 0.377191).  Saving model ...
Validation loss decreased (0.377191 --> 0.377171).  Saving model ...
Validation loss decreased (0.377171 --> 0.377152).  Saving model ...
Validation loss decreased (0.377152 --> 0.377132).  Saving model ...
Validation loss decreased (0.377132 --> 0.377112).  Saving model ...
Validation loss decreased (0.377112 --> 0.377092).  Saving model ...
Validation loss decreased (0.377092 --> 0.377073).  Saving model ...
Validation loss decreased (0.377073 --> 0.377053).  Saving model ...
Validation loss decreased (0.377053 --> 0.377033).  Saving model ...
Validation loss decreased (0.377033 --> 0.377013).  Saving model ...
Validation loss decreased (0.377013 --> 0.376994).  Saving model ...
Validation loss decreased (0.376994 --> 0.376974).  Saving model ...
Validation loss decreased (0.376974 --> 0.376954).  Saving model ...
Validation loss decreased (0.376954 --> 0.376934).  Saving model ...
Validation loss decreased (0.376934 --> 0.376915).  Saving model ...
Validation loss decreased (0.376915 --> 0.376895).  Saving model ...
Validation loss decreased (0.376895 --> 0.376875).  Saving model ...
Validation loss decreased (0.376875 --> 0.376855).  Saving model ...
Validation loss decreased (0.376855 --> 0.376836).  Saving model ...
Validation loss decreased (0.376836 --> 0.376816).  Saving model ...
Validation loss decreased (0.376816 --> 0.376796).  Saving model ...
Validation loss decreased (0.376796 --> 0.376776).  Saving model ...
Validation loss decreased (0.376776 --> 0.376757).  Saving model ...
Validation loss decreased (0.376757 --> 0.376737).  Saving model ...
Validation loss decreased (0.376737 --> 0.376717).  Saving model ...
Validation loss decreased (0.376717 --> 0.376697).  Saving model ...
Validation loss decreased (0.376697 --> 0.376678).  Saving model ...
Validation loss decreased (0.376678 --> 0.376658).  Saving model ...
Validation loss decreased (0.376658 --> 0.376638).  Saving model ...
Validation loss decreased (0.376638 --> 0.376618).  Saving model ...
Validation loss decreased (0.376618 --> 0.376599).  Saving model ...
Validation loss decreased (0.376599 --> 0.376579).  Saving model ...
Validation loss decreased (0.376579 --> 0.376559).  Saving model ...
Validation loss decreased (0.376559 --> 0.376539).  Saving model ...
Validation loss decreased (0.376539 --> 0.376520).  Saving model ...
Validation loss decreased (0.376520 --> 0.376500).  Saving model ...
Validation loss decreased (0.376500 --> 0.376480).  Saving model ...
Validation loss decreased (0.376480 --> 0.376460).  Saving model ...
Validation loss decreased (0.376460 --> 0.376441).  Saving model ...
Validation loss decreased (0.376441 --> 0.376421).  Saving model ...
Validation loss decreased (0.376421 --> 0.376401).  Saving model ...
Validation loss decreased (0.376401 --> 0.376381).  Saving model ...
Validation loss decreased (0.376381 --> 0.376362).  Saving model ...
Validation loss decreased (0.376362 --> 0.376342).  Saving model ...
Validation loss decreased (0.376342 --> 0.376322).  Saving model ...
Validation loss decreased (0.376322 --> 0.376302).  Saving model ...
Validation loss decreased (0.376302 --> 0.376283).  Saving model ...
Validation loss decreased (0.376283 --> 0.376263).  Saving model ...
Validation loss decreased (0.376263 --> 0.376243).  Saving model ...
Validation loss decreased (0.376243 --> 0.376223).  Saving model ...
Validation loss decreased (0.376223 --> 0.376204).  Saving model ...
Validation loss decreased (0.376204 --> 0.376184).  Saving model ...
Validation loss decreased (0.376184 --> 0.376164).  Saving model ...
Validation loss decreased (0.376164 --> 0.376144).  Saving model ...
Validation loss decreased (0.376144 --> 0.376125).  Saving model ...
Validation loss decreased (0.376125 --> 0.376105).  Saving model ...
Validation loss decreased (0.376105 --> 0.376085).  Saving model ...
Validation loss decreased (0.376085 --> 0.376065).  Saving model ...
Validation loss decreased (0.376065 --> 0.376045).  Saving model ...
Validation loss decreased (0.376045 --> 0.376026).  Saving model ...
Validation loss decreased (0.376026 --> 0.376006).  Saving model ...
Validation loss decreased (0.376006 --> 0.375986).  Saving model ...
Validation loss decreased (0.375986 --> 0.375966).  Saving model ...
Validation loss decreased (0.375966 --> 0.375947).  Saving model ...
Validation loss decreased (0.375947 --> 0.375927).  Saving model ...
epoch 4501, loss 0.3759, train acc 83.25%, f1 0.7513, precision 0.7831, recall 0.7220, auc 0.8070
Validation loss decreased (0.375927 --> 0.375907).  Saving model ...
Validation loss decreased (0.375907 --> 0.375887).  Saving model ...
Validation loss decreased (0.375887 --> 0.375867).  Saving model ...
Validation loss decreased (0.375867 --> 0.375847).  Saving model ...
Validation loss decreased (0.375847 --> 0.375828).  Saving model ...
Validation loss decreased (0.375828 --> 0.375808).  Saving model ...
Validation loss decreased (0.375808 --> 0.375788).  Saving model ...
Validation loss decreased (0.375788 --> 0.375768).  Saving model ...
Validation loss decreased (0.375768 --> 0.375748).  Saving model ...
Validation loss decreased (0.375748 --> 0.375729).  Saving model ...
Validation loss decreased (0.375729 --> 0.375709).  Saving model ...
Validation loss decreased (0.375709 --> 0.375689).  Saving model ...
Validation loss decreased (0.375689 --> 0.375669).  Saving model ...
Validation loss decreased (0.375669 --> 0.375649).  Saving model ...
Validation loss decreased (0.375649 --> 0.375630).  Saving model ...
Validation loss decreased (0.375630 --> 0.375610).  Saving model ...
Validation loss decreased (0.375610 --> 0.375590).  Saving model ...
Validation loss decreased (0.375590 --> 0.375570).  Saving model ...
Validation loss decreased (0.375570 --> 0.375550).  Saving model ...
Validation loss decreased (0.375550 --> 0.375530).  Saving model ...
Validation loss decreased (0.375530 --> 0.375510).  Saving model ...
Validation loss decreased (0.375510 --> 0.375491).  Saving model ...
Validation loss decreased (0.375491 --> 0.375471).  Saving model ...
Validation loss decreased (0.375471 --> 0.375451).  Saving model ...
Validation loss decreased (0.375451 --> 0.375431).  Saving model ...
Validation loss decreased (0.375431 --> 0.375411).  Saving model ...
Validation loss decreased (0.375411 --> 0.375391).  Saving model ...
Validation loss decreased (0.375391 --> 0.375371).  Saving model ...
Validation loss decreased (0.375371 --> 0.375351).  Saving model ...
Validation loss decreased (0.375351 --> 0.375332).  Saving model ...
Validation loss decreased (0.375332 --> 0.375312).  Saving model ...
Validation loss decreased (0.375312 --> 0.375292).  Saving model ...
Validation loss decreased (0.375292 --> 0.375272).  Saving model ...
Validation loss decreased (0.375272 --> 0.375252).  Saving model ...
Validation loss decreased (0.375252 --> 0.375232).  Saving model ...
Validation loss decreased (0.375232 --> 0.375212).  Saving model ...
Validation loss decreased (0.375212 --> 0.375192).  Saving model ...
Validation loss decreased (0.375192 --> 0.375172).  Saving model ...
Validation loss decreased (0.375172 --> 0.375152).  Saving model ...
Validation loss decreased (0.375152 --> 0.375133).  Saving model ...
Validation loss decreased (0.375133 --> 0.375113).  Saving model ...
Validation loss decreased (0.375113 --> 0.375093).  Saving model ...
Validation loss decreased (0.375093 --> 0.375073).  Saving model ...
Validation loss decreased (0.375073 --> 0.375053).  Saving model ...
Validation loss decreased (0.375053 --> 0.375033).  Saving model ...
Validation loss decreased (0.375033 --> 0.375013).  Saving model ...
Validation loss decreased (0.375013 --> 0.374993).  Saving model ...
Validation loss decreased (0.374993 --> 0.374973).  Saving model ...
Validation loss decreased (0.374973 --> 0.374953).  Saving model ...
Validation loss decreased (0.374953 --> 0.374933).  Saving model ...
Validation loss decreased (0.374933 --> 0.374913).  Saving model ...
Validation loss decreased (0.374913 --> 0.374893).  Saving model ...
Validation loss decreased (0.374893 --> 0.374873).  Saving model ...
Validation loss decreased (0.374873 --> 0.374853).  Saving model ...
Validation loss decreased (0.374853 --> 0.374833).  Saving model ...
Validation loss decreased (0.374833 --> 0.374813).  Saving model ...
Validation loss decreased (0.374813 --> 0.374793).  Saving model ...
Validation loss decreased (0.374793 --> 0.374773).  Saving model ...
Validation loss decreased (0.374773 --> 0.374753).  Saving model ...
Validation loss decreased (0.374753 --> 0.374733).  Saving model ...
Validation loss decreased (0.374733 --> 0.374713).  Saving model ...
Validation loss decreased (0.374713 --> 0.374693).  Saving model ...
Validation loss decreased (0.374693 --> 0.374673).  Saving model ...
Validation loss decreased (0.374673 --> 0.374653).  Saving model ...
Validation loss decreased (0.374653 --> 0.374633).  Saving model ...
Validation loss decreased (0.374633 --> 0.374613).  Saving model ...
Validation loss decreased (0.374613 --> 0.374593).  Saving model ...
Validation loss decreased (0.374593 --> 0.374573).  Saving model ...
Validation loss decreased (0.374573 --> 0.374552).  Saving model ...
Validation loss decreased (0.374552 --> 0.374532).  Saving model ...
Validation loss decreased (0.374532 --> 0.374512).  Saving model ...
Validation loss decreased (0.374512 --> 0.374492).  Saving model ...
Validation loss decreased (0.374492 --> 0.374472).  Saving model ...
Validation loss decreased (0.374472 --> 0.374452).  Saving model ...
Validation loss decreased (0.374452 --> 0.374432).  Saving model ...
Validation loss decreased (0.374432 --> 0.374412).  Saving model ...
Validation loss decreased (0.374412 --> 0.374392).  Saving model ...
Validation loss decreased (0.374392 --> 0.374371).  Saving model ...
Validation loss decreased (0.374371 --> 0.374351).  Saving model ...
Validation loss decreased (0.374351 --> 0.374331).  Saving model ...
Validation loss decreased (0.374331 --> 0.374311).  Saving model ...
Validation loss decreased (0.374311 --> 0.374291).  Saving model ...
Validation loss decreased (0.374291 --> 0.374271).  Saving model ...
Validation loss decreased (0.374271 --> 0.374251).  Saving model ...
Validation loss decreased (0.374251 --> 0.374231).  Saving model ...
Validation loss decreased (0.374231 --> 0.374210).  Saving model ...
Validation loss decreased (0.374210 --> 0.374190).  Saving model ...
Validation loss decreased (0.374190 --> 0.374170).  Saving model ...
Validation loss decreased (0.374170 --> 0.374150).  Saving model ...
Validation loss decreased (0.374150 --> 0.374130).  Saving model ...
Validation loss decreased (0.374130 --> 0.374109).  Saving model ...
Validation loss decreased (0.374109 --> 0.374089).  Saving model ...
Validation loss decreased (0.374089 --> 0.374069).  Saving model ...
Validation loss decreased (0.374069 --> 0.374049).  Saving model ...
Validation loss decreased (0.374049 --> 0.374029).  Saving model ...
Validation loss decreased (0.374029 --> 0.374008).  Saving model ...
Validation loss decreased (0.374008 --> 0.373988).  Saving model ...
Validation loss decreased (0.373988 --> 0.373968).  Saving model ...
Validation loss decreased (0.373968 --> 0.373948).  Saving model ...
Validation loss decreased (0.373948 --> 0.373927).  Saving model ...
epoch 4601, loss 0.3739, train acc 83.25%, f1 0.7513, precision 0.7831, recall 0.7220, auc 0.8070
Validation loss decreased (0.373927 --> 0.373907).  Saving model ...
Validation loss decreased (0.373907 --> 0.373887).  Saving model ...
Validation loss decreased (0.373887 --> 0.373866).  Saving model ...
Validation loss decreased (0.373866 --> 0.373846).  Saving model ...
Validation loss decreased (0.373846 --> 0.373826).  Saving model ...
Validation loss decreased (0.373826 --> 0.373806).  Saving model ...
Validation loss decreased (0.373806 --> 0.373785).  Saving model ...
Validation loss decreased (0.373785 --> 0.373765).  Saving model ...
Validation loss decreased (0.373765 --> 0.373745).  Saving model ...
Validation loss decreased (0.373745 --> 0.373724).  Saving model ...
Validation loss decreased (0.373724 --> 0.373704).  Saving model ...
Validation loss decreased (0.373704 --> 0.373684).  Saving model ...
Validation loss decreased (0.373684 --> 0.373663).  Saving model ...
Validation loss decreased (0.373663 --> 0.373643).  Saving model ...
Validation loss decreased (0.373643 --> 0.373623).  Saving model ...
Validation loss decreased (0.373623 --> 0.373602).  Saving model ...
Validation loss decreased (0.373602 --> 0.373582).  Saving model ...
Validation loss decreased (0.373582 --> 0.373562).  Saving model ...
Validation loss decreased (0.373562 --> 0.373541).  Saving model ...
Validation loss decreased (0.373541 --> 0.373521).  Saving model ...
Validation loss decreased (0.373521 --> 0.373500).  Saving model ...
Validation loss decreased (0.373500 --> 0.373480).  Saving model ...
Validation loss decreased (0.373480 --> 0.373460).  Saving model ...
Validation loss decreased (0.373460 --> 0.373439).  Saving model ...
Validation loss decreased (0.373439 --> 0.373419).  Saving model ...
Validation loss decreased (0.373419 --> 0.373398).  Saving model ...
Validation loss decreased (0.373398 --> 0.373378).  Saving model ...
Validation loss decreased (0.373378 --> 0.373358).  Saving model ...
Validation loss decreased (0.373358 --> 0.373337).  Saving model ...
Validation loss decreased (0.373337 --> 0.373317).  Saving model ...
Validation loss decreased (0.373317 --> 0.373296).  Saving model ...
Validation loss decreased (0.373296 --> 0.373276).  Saving model ...
Validation loss decreased (0.373276 --> 0.373255).  Saving model ...
Validation loss decreased (0.373255 --> 0.373235).  Saving model ...
Validation loss decreased (0.373235 --> 0.373214).  Saving model ...
Validation loss decreased (0.373214 --> 0.373194).  Saving model ...
Validation loss decreased (0.373194 --> 0.373173).  Saving model ...
Validation loss decreased (0.373173 --> 0.373153).  Saving model ...
Validation loss decreased (0.373153 --> 0.373132).  Saving model ...
Validation loss decreased (0.373132 --> 0.373112).  Saving model ...
Validation loss decreased (0.373112 --> 0.373091).  Saving model ...
Validation loss decreased (0.373091 --> 0.373071).  Saving model ...
Validation loss decreased (0.373071 --> 0.373050).  Saving model ...
Validation loss decreased (0.373050 --> 0.373030).  Saving model ...
Validation loss decreased (0.373030 --> 0.373009).  Saving model ...
Validation loss decreased (0.373009 --> 0.372989).  Saving model ...
Validation loss decreased (0.372989 --> 0.372968).  Saving model ...
Validation loss decreased (0.372968 --> 0.372948).  Saving model ...
Validation loss decreased (0.372948 --> 0.372927).  Saving model ...
Validation loss decreased (0.372927 --> 0.372907).  Saving model ...
Validation loss decreased (0.372907 --> 0.372886).  Saving model ...
Validation loss decreased (0.372886 --> 0.372865).  Saving model ...
Validation loss decreased (0.372865 --> 0.372845).  Saving model ...
Validation loss decreased (0.372845 --> 0.372824).  Saving model ...
Validation loss decreased (0.372824 --> 0.372804).  Saving model ...
Validation loss decreased (0.372804 --> 0.372783).  Saving model ...
Validation loss decreased (0.372783 --> 0.372762).  Saving model ...
Validation loss decreased (0.372762 --> 0.372742).  Saving model ...
Validation loss decreased (0.372742 --> 0.372721).  Saving model ...
Validation loss decreased (0.372721 --> 0.372701).  Saving model ...
Validation loss decreased (0.372701 --> 0.372680).  Saving model ...
Validation loss decreased (0.372680 --> 0.372659).  Saving model ...
Validation loss decreased (0.372659 --> 0.372639).  Saving model ...
Validation loss decreased (0.372639 --> 0.372618).  Saving model ...
Validation loss decreased (0.372618 --> 0.372597).  Saving model ...
Validation loss decreased (0.372597 --> 0.372577).  Saving model ...
Validation loss decreased (0.372577 --> 0.372556).  Saving model ...
Validation loss decreased (0.372556 --> 0.372535).  Saving model ...
Validation loss decreased (0.372535 --> 0.372515).  Saving model ...
Validation loss decreased (0.372515 --> 0.372494).  Saving model ...
Validation loss decreased (0.372494 --> 0.372473).  Saving model ...
Validation loss decreased (0.372473 --> 0.372453).  Saving model ...
Validation loss decreased (0.372453 --> 0.372432).  Saving model ...
Validation loss decreased (0.372432 --> 0.372411).  Saving model ...
Validation loss decreased (0.372411 --> 0.372391).  Saving model ...
Validation loss decreased (0.372391 --> 0.372370).  Saving model ...
Validation loss decreased (0.372370 --> 0.372349).  Saving model ...
Validation loss decreased (0.372349 --> 0.372328).  Saving model ...
Validation loss decreased (0.372328 --> 0.372308).  Saving model ...
Validation loss decreased (0.372308 --> 0.372287).  Saving model ...
Validation loss decreased (0.372287 --> 0.372266).  Saving model ...
Validation loss decreased (0.372266 --> 0.372246).  Saving model ...
Validation loss decreased (0.372246 --> 0.372225).  Saving model ...
Validation loss decreased (0.372225 --> 0.372204).  Saving model ...
Validation loss decreased (0.372204 --> 0.372183).  Saving model ...
Validation loss decreased (0.372183 --> 0.372163).  Saving model ...
Validation loss decreased (0.372163 --> 0.372142).  Saving model ...
Validation loss decreased (0.372142 --> 0.372121).  Saving model ...
Validation loss decreased (0.372121 --> 0.372100).  Saving model ...
Validation loss decreased (0.372100 --> 0.372080).  Saving model ...
Validation loss decreased (0.372080 --> 0.372059).  Saving model ...
Validation loss decreased (0.372059 --> 0.372038).  Saving model ...
Validation loss decreased (0.372038 --> 0.372017).  Saving model ...
Validation loss decreased (0.372017 --> 0.371997).  Saving model ...
Validation loss decreased (0.371997 --> 0.371976).  Saving model ...
Validation loss decreased (0.371976 --> 0.371955).  Saving model ...
Validation loss decreased (0.371955 --> 0.371934).  Saving model ...
Validation loss decreased (0.371934 --> 0.371913).  Saving model ...
Validation loss decreased (0.371913 --> 0.371893).  Saving model ...
Validation loss decreased (0.371893 --> 0.371872).  Saving model ...
epoch 4701, loss 0.3719, train acc 83.42%, f1 0.7544, precision 0.7842, recall 0.7268, auc 0.8095
Validation loss decreased (0.371872 --> 0.371851).  Saving model ...
Validation loss decreased (0.371851 --> 0.371830).  Saving model ...
Validation loss decreased (0.371830 --> 0.371809).  Saving model ...
Validation loss decreased (0.371809 --> 0.371789).  Saving model ...
Validation loss decreased (0.371789 --> 0.371768).  Saving model ...
Validation loss decreased (0.371768 --> 0.371747).  Saving model ...
Validation loss decreased (0.371747 --> 0.371726).  Saving model ...
Validation loss decreased (0.371726 --> 0.371705).  Saving model ...
Validation loss decreased (0.371705 --> 0.371684).  Saving model ...
Validation loss decreased (0.371684 --> 0.371664).  Saving model ...
Validation loss decreased (0.371664 --> 0.371643).  Saving model ...
Validation loss decreased (0.371643 --> 0.371622).  Saving model ...
Validation loss decreased (0.371622 --> 0.371601).  Saving model ...
Validation loss decreased (0.371601 --> 0.371580).  Saving model ...
Validation loss decreased (0.371580 --> 0.371560).  Saving model ...
Validation loss decreased (0.371560 --> 0.371539).  Saving model ...
Validation loss decreased (0.371539 --> 0.371518).  Saving model ...
Validation loss decreased (0.371518 --> 0.371497).  Saving model ...
Validation loss decreased (0.371497 --> 0.371476).  Saving model ...
Validation loss decreased (0.371476 --> 0.371455).  Saving model ...
Validation loss decreased (0.371455 --> 0.371434).  Saving model ...
Validation loss decreased (0.371434 --> 0.371414).  Saving model ...
Validation loss decreased (0.371414 --> 0.371393).  Saving model ...
Validation loss decreased (0.371393 --> 0.371372).  Saving model ...
Validation loss decreased (0.371372 --> 0.371351).  Saving model ...
Validation loss decreased (0.371351 --> 0.371330).  Saving model ...
Validation loss decreased (0.371330 --> 0.371309).  Saving model ...
Validation loss decreased (0.371309 --> 0.371288).  Saving model ...
Validation loss decreased (0.371288 --> 0.371268).  Saving model ...
Validation loss decreased (0.371268 --> 0.371247).  Saving model ...
Validation loss decreased (0.371247 --> 0.371226).  Saving model ...
Validation loss decreased (0.371226 --> 0.371205).  Saving model ...
Validation loss decreased (0.371205 --> 0.371184).  Saving model ...
Validation loss decreased (0.371184 --> 0.371163).  Saving model ...
Validation loss decreased (0.371163 --> 0.371142).  Saving model ...
Validation loss decreased (0.371142 --> 0.371121).  Saving model ...
Validation loss decreased (0.371121 --> 0.371101).  Saving model ...
Validation loss decreased (0.371101 --> 0.371080).  Saving model ...
Validation loss decreased (0.371080 --> 0.371059).  Saving model ...
Validation loss decreased (0.371059 --> 0.371038).  Saving model ...
Validation loss decreased (0.371038 --> 0.371017).  Saving model ...
Validation loss decreased (0.371017 --> 0.370996).  Saving model ...
Validation loss decreased (0.370996 --> 0.370975).  Saving model ...
Validation loss decreased (0.370975 --> 0.370954).  Saving model ...
Validation loss decreased (0.370954 --> 0.370934).  Saving model ...
Validation loss decreased (0.370934 --> 0.370913).  Saving model ...
Validation loss decreased (0.370913 --> 0.370892).  Saving model ...
Validation loss decreased (0.370892 --> 0.370871).  Saving model ...
Validation loss decreased (0.370871 --> 0.370850).  Saving model ...
Validation loss decreased (0.370850 --> 0.370829).  Saving model ...
Validation loss decreased (0.370829 --> 0.370808).  Saving model ...
Validation loss decreased (0.370808 --> 0.370787).  Saving model ...
Validation loss decreased (0.370787 --> 0.370766).  Saving model ...
Validation loss decreased (0.370766 --> 0.370746).  Saving model ...
Validation loss decreased (0.370746 --> 0.370725).  Saving model ...
Validation loss decreased (0.370725 --> 0.370704).  Saving model ...
Validation loss decreased (0.370704 --> 0.370683).  Saving model ...
Validation loss decreased (0.370683 --> 0.370662).  Saving model ...
Validation loss decreased (0.370662 --> 0.370641).  Saving model ...
Validation loss decreased (0.370641 --> 0.370620).  Saving model ...
Validation loss decreased (0.370620 --> 0.370599).  Saving model ...
Validation loss decreased (0.370599 --> 0.370578).  Saving model ...
Validation loss decreased (0.370578 --> 0.370557).  Saving model ...
Validation loss decreased (0.370557 --> 0.370537).  Saving model ...
Validation loss decreased (0.370537 --> 0.370516).  Saving model ...
Validation loss decreased (0.370516 --> 0.370495).  Saving model ...
Validation loss decreased (0.370495 --> 0.370474).  Saving model ...
Validation loss decreased (0.370474 --> 0.370453).  Saving model ...
Validation loss decreased (0.370453 --> 0.370432).  Saving model ...
Validation loss decreased (0.370432 --> 0.370411).  Saving model ...
Validation loss decreased (0.370411 --> 0.370390).  Saving model ...
Validation loss decreased (0.370390 --> 0.370369).  Saving model ...
Validation loss decreased (0.370369 --> 0.370349).  Saving model ...
Validation loss decreased (0.370349 --> 0.370328).  Saving model ...
Validation loss decreased (0.370328 --> 0.370307).  Saving model ...
Validation loss decreased (0.370307 --> 0.370286).  Saving model ...
Validation loss decreased (0.370286 --> 0.370265).  Saving model ...
Validation loss decreased (0.370265 --> 0.370244).  Saving model ...
Validation loss decreased (0.370244 --> 0.370223).  Saving model ...
Validation loss decreased (0.370223 --> 0.370202).  Saving model ...
Validation loss decreased (0.370202 --> 0.370181).  Saving model ...
Validation loss decreased (0.370181 --> 0.370161).  Saving model ...
Validation loss decreased (0.370161 --> 0.370140).  Saving model ...
Validation loss decreased (0.370140 --> 0.370119).  Saving model ...
Validation loss decreased (0.370119 --> 0.370098).  Saving model ...
Validation loss decreased (0.370098 --> 0.370077).  Saving model ...
Validation loss decreased (0.370077 --> 0.370056).  Saving model ...
Validation loss decreased (0.370056 --> 0.370035).  Saving model ...
Validation loss decreased (0.370035 --> 0.370014).  Saving model ...
Validation loss decreased (0.370014 --> 0.369993).  Saving model ...
Validation loss decreased (0.369993 --> 0.369973).  Saving model ...
Validation loss decreased (0.369973 --> 0.369952).  Saving model ...
Validation loss decreased (0.369952 --> 0.369931).  Saving model ...
Validation loss decreased (0.369931 --> 0.369910).  Saving model ...
Validation loss decreased (0.369910 --> 0.369889).  Saving model ...
Validation loss decreased (0.369889 --> 0.369868).  Saving model ...
Validation loss decreased (0.369868 --> 0.369847).  Saving model ...
Validation loss decreased (0.369847 --> 0.369826).  Saving model ...
Validation loss decreased (0.369826 --> 0.369805).  Saving model ...
Validation loss decreased (0.369805 --> 0.369785).  Saving model ...
epoch 4801, loss 0.3698, train acc 83.93%, f1 0.7626, precision 0.7906, recall 0.7366, auc 0.8157
Validation loss decreased (0.369785 --> 0.369764).  Saving model ...
Validation loss decreased (0.369764 --> 0.369743).  Saving model ...
Validation loss decreased (0.369743 --> 0.369722).  Saving model ...
Validation loss decreased (0.369722 --> 0.369701).  Saving model ...
Validation loss decreased (0.369701 --> 0.369680).  Saving model ...
Validation loss decreased (0.369680 --> 0.369659).  Saving model ...
Validation loss decreased (0.369659 --> 0.369639).  Saving model ...
Validation loss decreased (0.369639 --> 0.369618).  Saving model ...
Validation loss decreased (0.369618 --> 0.369597).  Saving model ...
Validation loss decreased (0.369597 --> 0.369576).  Saving model ...
Validation loss decreased (0.369576 --> 0.369555).  Saving model ...
Validation loss decreased (0.369555 --> 0.369534).  Saving model ...
Validation loss decreased (0.369534 --> 0.369513).  Saving model ...
Validation loss decreased (0.369513 --> 0.369492).  Saving model ...
Validation loss decreased (0.369492 --> 0.369471).  Saving model ...
Validation loss decreased (0.369471 --> 0.369451).  Saving model ...
Validation loss decreased (0.369451 --> 0.369430).  Saving model ...
Validation loss decreased (0.369430 --> 0.369409).  Saving model ...
Validation loss decreased (0.369409 --> 0.369388).  Saving model ...
Validation loss decreased (0.369388 --> 0.369367).  Saving model ...
Validation loss decreased (0.369367 --> 0.369346).  Saving model ...
Validation loss decreased (0.369346 --> 0.369325).  Saving model ...
Validation loss decreased (0.369325 --> 0.369305).  Saving model ...
Validation loss decreased (0.369305 --> 0.369284).  Saving model ...
Validation loss decreased (0.369284 --> 0.369263).  Saving model ...
Validation loss decreased (0.369263 --> 0.369242).  Saving model ...
Validation loss decreased (0.369242 --> 0.369221).  Saving model ...
Validation loss decreased (0.369221 --> 0.369200).  Saving model ...
Validation loss decreased (0.369200 --> 0.369179).  Saving model ...
Validation loss decreased (0.369179 --> 0.369158).  Saving model ...
Validation loss decreased (0.369158 --> 0.369138).  Saving model ...
Validation loss decreased (0.369138 --> 0.369117).  Saving model ...
Validation loss decreased (0.369117 --> 0.369096).  Saving model ...
Validation loss decreased (0.369096 --> 0.369075).  Saving model ...
Validation loss decreased (0.369075 --> 0.369054).  Saving model ...
Validation loss decreased (0.369054 --> 0.369033).  Saving model ...
Validation loss decreased (0.369033 --> 0.369012).  Saving model ...
Validation loss decreased (0.369012 --> 0.368992).  Saving model ...
Validation loss decreased (0.368992 --> 0.368971).  Saving model ...
Validation loss decreased (0.368971 --> 0.368950).  Saving model ...
Validation loss decreased (0.368950 --> 0.368929).  Saving model ...
Validation loss decreased (0.368929 --> 0.368908).  Saving model ...
Validation loss decreased (0.368908 --> 0.368887).  Saving model ...
Validation loss decreased (0.368887 --> 0.368866).  Saving model ...
Validation loss decreased (0.368866 --> 0.368845).  Saving model ...
Validation loss decreased (0.368845 --> 0.368825).  Saving model ...
Validation loss decreased (0.368825 --> 0.368804).  Saving model ...
Validation loss decreased (0.368804 --> 0.368783).  Saving model ...
Validation loss decreased (0.368783 --> 0.368762).  Saving model ...
Validation loss decreased (0.368762 --> 0.368741).  Saving model ...
Validation loss decreased (0.368741 --> 0.368720).  Saving model ...
Validation loss decreased (0.368720 --> 0.368699).  Saving model ...
Validation loss decreased (0.368699 --> 0.368679).  Saving model ...
Validation loss decreased (0.368679 --> 0.368658).  Saving model ...
Validation loss decreased (0.368658 --> 0.368637).  Saving model ...
Validation loss decreased (0.368637 --> 0.368616).  Saving model ...
Validation loss decreased (0.368616 --> 0.368595).  Saving model ...
Validation loss decreased (0.368595 --> 0.368574).  Saving model ...
Validation loss decreased (0.368574 --> 0.368553).  Saving model ...
Validation loss decreased (0.368553 --> 0.368532).  Saving model ...
Validation loss decreased (0.368532 --> 0.368512).  Saving model ...
Validation loss decreased (0.368512 --> 0.368491).  Saving model ...
Validation loss decreased (0.368491 --> 0.368470).  Saving model ...
Validation loss decreased (0.368470 --> 0.368449).  Saving model ...
Validation loss decreased (0.368449 --> 0.368428).  Saving model ...
Validation loss decreased (0.368428 --> 0.368407).  Saving model ...
Validation loss decreased (0.368407 --> 0.368386).  Saving model ...
Validation loss decreased (0.368386 --> 0.368365).  Saving model ...
Validation loss decreased (0.368365 --> 0.368345).  Saving model ...
Validation loss decreased (0.368345 --> 0.368324).  Saving model ...
Validation loss decreased (0.368324 --> 0.368303).  Saving model ...
Validation loss decreased (0.368303 --> 0.368282).  Saving model ...
Validation loss decreased (0.368282 --> 0.368261).  Saving model ...
Validation loss decreased (0.368261 --> 0.368240).  Saving model ...
Validation loss decreased (0.368240 --> 0.368219).  Saving model ...
Validation loss decreased (0.368219 --> 0.368198).  Saving model ...
Validation loss decreased (0.368198 --> 0.368178).  Saving model ...
Validation loss decreased (0.368178 --> 0.368157).  Saving model ...
Validation loss decreased (0.368157 --> 0.368136).  Saving model ...
Validation loss decreased (0.368136 --> 0.368115).  Saving model ...
Validation loss decreased (0.368115 --> 0.368094).  Saving model ...
Validation loss decreased (0.368094 --> 0.368073).  Saving model ...
Validation loss decreased (0.368073 --> 0.368052).  Saving model ...
Validation loss decreased (0.368052 --> 0.368031).  Saving model ...
Validation loss decreased (0.368031 --> 0.368010).  Saving model ...
Validation loss decreased (0.368010 --> 0.367990).  Saving model ...
Validation loss decreased (0.367990 --> 0.367969).  Saving model ...
Validation loss decreased (0.367969 --> 0.367948).  Saving model ...
Validation loss decreased (0.367948 --> 0.367927).  Saving model ...
Validation loss decreased (0.367927 --> 0.367906).  Saving model ...
Validation loss decreased (0.367906 --> 0.367885).  Saving model ...
Validation loss decreased (0.367885 --> 0.367864).  Saving model ...
Validation loss decreased (0.367864 --> 0.367843).  Saving model ...
Validation loss decreased (0.367843 --> 0.367822).  Saving model ...
Validation loss decreased (0.367822 --> 0.367801).  Saving model ...
Validation loss decreased (0.367801 --> 0.367780).  Saving model ...
Validation loss decreased (0.367780 --> 0.367759).  Saving model ...
Validation loss decreased (0.367759 --> 0.367739).  Saving model ...
Validation loss decreased (0.367739 --> 0.367718).  Saving model ...
Validation loss decreased (0.367718 --> 0.367697).  Saving model ...
epoch 4901, loss 0.3677, train acc 83.93%, f1 0.7626, precision 0.7906, recall 0.7366, auc 0.8157
Validation loss decreased (0.367697 --> 0.367676).  Saving model ...
Validation loss decreased (0.367676 --> 0.367655).  Saving model ...
Validation loss decreased (0.367655 --> 0.367634).  Saving model ...
Validation loss decreased (0.367634 --> 0.367613).  Saving model ...
Validation loss decreased (0.367613 --> 0.367592).  Saving model ...
Validation loss decreased (0.367592 --> 0.367571).  Saving model ...
Validation loss decreased (0.367571 --> 0.367550).  Saving model ...
Validation loss decreased (0.367550 --> 0.367529).  Saving model ...
Validation loss decreased (0.367529 --> 0.367508).  Saving model ...
Validation loss decreased (0.367508 --> 0.367487).  Saving model ...
Validation loss decreased (0.367487 --> 0.367466).  Saving model ...
Validation loss decreased (0.367466 --> 0.367445).  Saving model ...
Validation loss decreased (0.367445 --> 0.367424).  Saving model ...
Validation loss decreased (0.367424 --> 0.367403).  Saving model ...
Validation loss decreased (0.367403 --> 0.367382).  Saving model ...
Validation loss decreased (0.367382 --> 0.367361).  Saving model ...
Validation loss decreased (0.367361 --> 0.367340).  Saving model ...
Validation loss decreased (0.367340 --> 0.367319).  Saving model ...
Validation loss decreased (0.367319 --> 0.367298).  Saving model ...
Validation loss decreased (0.367298 --> 0.367277).  Saving model ...
Validation loss decreased (0.367277 --> 0.367256).  Saving model ...
Validation loss decreased (0.367256 --> 0.367235).  Saving model ...
Validation loss decreased (0.367235 --> 0.367214).  Saving model ...
Validation loss decreased (0.367214 --> 0.367193).  Saving model ...
Validation loss decreased (0.367193 --> 0.367172).  Saving model ...
Validation loss decreased (0.367172 --> 0.367151).  Saving model ...
Validation loss decreased (0.367151 --> 0.367130).  Saving model ...
Validation loss decreased (0.367130 --> 0.367109).  Saving model ...
Validation loss decreased (0.367109 --> 0.367088).  Saving model ...
Validation loss decreased (0.367088 --> 0.367067).  Saving model ...
Validation loss decreased (0.367067 --> 0.367046).  Saving model ...
Validation loss decreased (0.367046 --> 0.367024).  Saving model ...
Validation loss decreased (0.367024 --> 0.367003).  Saving model ...
Validation loss decreased (0.367003 --> 0.366982).  Saving model ...
Validation loss decreased (0.366982 --> 0.366961).  Saving model ...
Validation loss decreased (0.366961 --> 0.366940).  Saving model ...
Validation loss decreased (0.366940 --> 0.366919).  Saving model ...
Validation loss decreased (0.366919 --> 0.366898).  Saving model ...
Validation loss decreased (0.366898 --> 0.366877).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.366877 --> 0.366855).  Saving model ...
Validation loss decreased (0.366855 --> 0.366834).  Saving model ...
Validation loss decreased (0.366834 --> 0.366813).  Saving model ...
Validation loss decreased (0.366813 --> 0.366792).  Saving model ...
Validation loss decreased (0.366792 --> 0.366771).  Saving model ...
Validation loss decreased (0.366771 --> 0.366749).  Saving model ...
Validation loss decreased (0.366749 --> 0.366728).  Saving model ...
Validation loss decreased (0.366728 --> 0.366707).  Saving model ...
Validation loss decreased (0.366707 --> 0.366686).  Saving model ...
Validation loss decreased (0.366686 --> 0.366665).  Saving model ...
Validation loss decreased (0.366665 --> 0.366643).  Saving model ...
Validation loss decreased (0.366643 --> 0.366622).  Saving model ...
Validation loss decreased (0.366622 --> 0.366601).  Saving model ...
Validation loss decreased (0.366601 --> 0.366579).  Saving model ...
Validation loss decreased (0.366579 --> 0.366558).  Saving model ...
Validation loss decreased (0.366558 --> 0.366537).  Saving model ...
Validation loss decreased (0.366537 --> 0.366515).  Saving model ...
Validation loss decreased (0.366515 --> 0.366494).  Saving model ...
Validation loss decreased (0.366494 --> 0.366473).  Saving model ...
Validation loss decreased (0.366473 --> 0.366451).  Saving model ...
Validation loss decreased (0.366451 --> 0.366430).  Saving model ...
Validation loss decreased (0.366430 --> 0.366408).  Saving model ...
Validation loss decreased (0.366408 --> 0.366387).  Saving model ...
Validation loss decreased (0.366387 --> 0.366366).  Saving model ...
Validation loss decreased (0.366366 --> 0.366344).  Saving model ...
Validation loss decreased (0.366344 --> 0.366323).  Saving model ...
Validation loss decreased (0.366323 --> 0.366301).  Saving model ...
Validation loss decreased (0.366301 --> 0.366279).  Saving model ...
Validation loss decreased (0.366279 --> 0.366258).  Saving model ...
Validation loss decreased (0.366258 --> 0.366236).  Saving model ...
Validation loss decreased (0.366236 --> 0.366215).  Saving model ...
Validation loss decreased (0.366215 --> 0.366193).  Saving model ...
Validation loss decreased (0.366193 --> 0.366172).  Saving model ...
Validation loss decreased (0.366172 --> 0.366150).  Saving model ...
Validation loss decreased (0.366150 --> 0.366128).  Saving model ...
Validation loss decreased (0.366128 --> 0.366106).  Saving model ...
Validation loss decreased (0.366106 --> 0.366085).  Saving model ...
Validation loss decreased (0.366085 --> 0.366063).  Saving model ...
Validation loss decreased (0.366063 --> 0.366041).  Saving model ...
Validation loss decreased (0.366041 --> 0.366019).  Saving model ...
Validation loss decreased (0.366019 --> 0.365997).  Saving model ...
Validation loss decreased (0.365997 --> 0.365976).  Saving model ...
Validation loss decreased (0.365976 --> 0.365954).  Saving model ...
Validation loss decreased (0.365954 --> 0.365932).  Saving model ...
Validation loss decreased (0.365932 --> 0.365910).  Saving model ...
Validation loss decreased (0.365910 --> 0.365888).  Saving model ...
Validation loss decreased (0.365888 --> 0.365866).  Saving model ...
Validation loss decreased (0.365866 --> 0.365844).  Saving model ...
Validation loss decreased (0.365844 --> 0.365821).  Saving model ...
Validation loss decreased (0.365821 --> 0.365799).  Saving model ...
Validation loss decreased (0.365799 --> 0.365777).  Saving model ...
Validation loss decreased (0.365777 --> 0.365755).  Saving model ...
Validation loss decreased (0.365755 --> 0.365733).  Saving model ...
Validation loss decreased (0.365733 --> 0.365710).  Saving model ...
Validation loss decreased (0.365710 --> 0.365688).  Saving model ...
Validation loss decreased (0.365688 --> 0.365665).  Saving model ...
Validation loss decreased (0.365665 --> 0.365643).  Saving model ...
Validation loss decreased (0.365643 --> 0.365620).  Saving model ...
Validation loss decreased (0.365620 --> 0.365598).  Saving model ...
Validation loss decreased (0.365598 --> 0.365575).  Saving model ...
Validation loss decreased (0.365575 --> 0.365553).  Saving model ...
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_4.csv
./test_pima/standlization_data/pima_std_test_4.csv
MLP_normal_True
normal_normal
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_4
./test_pima/result_MLP_normal_True_normal_normal/record_1/
----------------------



Traceback (most recent call last):
  File "./classifier_MLP/test.py", line 193, in <module>
    transform_method, ref_data_type, ref_num_type, ref_times, boundary_type = get_test_info(test_method)
  File "./classifier_MLP/test.py", line 137, in get_test_info
    return transform_method, ref_data_type, ref_num_type, ref_times, boundary_type
UnboundLocalError: local variable 'transform_method' referenced before assignment
