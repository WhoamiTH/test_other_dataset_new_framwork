nohup: ignoring input
./test_abalone19/standlization_data/abalone19_std_train_5.csv
./test_abalone19/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_5
----------------------



epoch 1, loss 0.6931, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.692812).  Saving model ...
Validation loss decreased (0.692812 --> 0.692515).  Saving model ...
Validation loss decreased (0.692515 --> 0.692197).  Saving model ...
Validation loss decreased (0.692197 --> 0.691845).  Saving model ...
Validation loss decreased (0.691845 --> 0.691451).  Saving model ...
Validation loss decreased (0.691451 --> 0.691009).  Saving model ...
Validation loss decreased (0.691009 --> 0.690516).  Saving model ...
Validation loss decreased (0.690516 --> 0.689969).  Saving model ...
Validation loss decreased (0.689969 --> 0.689367).  Saving model ...
Validation loss decreased (0.689367 --> 0.688706).  Saving model ...
Validation loss decreased (0.688706 --> 0.687985).  Saving model ...
Validation loss decreased (0.687985 --> 0.687201).  Saving model ...
Validation loss decreased (0.687201 --> 0.686351).  Saving model ...
Validation loss decreased (0.686351 --> 0.685435).  Saving model ...
Validation loss decreased (0.685435 --> 0.684449).  Saving model ...
Validation loss decreased (0.684449 --> 0.683393).  Saving model ...
Validation loss decreased (0.683393 --> 0.682266).  Saving model ...
Validation loss decreased (0.682266 --> 0.681064).  Saving model ...
Validation loss decreased (0.681064 --> 0.679788).  Saving model ...
Validation loss decreased (0.679788 --> 0.678436).  Saving model ...
Validation loss decreased (0.678436 --> 0.677008).  Saving model ...
Validation loss decreased (0.677008 --> 0.675502).  Saving model ...
Validation loss decreased (0.675502 --> 0.673917).  Saving model ...
Validation loss decreased (0.673917 --> 0.672254).  Saving model ...
Validation loss decreased (0.672254 --> 0.670512).  Saving model ...
Validation loss decreased (0.670512 --> 0.668691).  Saving model ...
Validation loss decreased (0.668691 --> 0.666790).  Saving model ...
Validation loss decreased (0.666790 --> 0.664810).  Saving model ...
Validation loss decreased (0.664810 --> 0.662751).  Saving model ...
Validation loss decreased (0.662751 --> 0.660613).  Saving model ...
Validation loss decreased (0.660613 --> 0.658396).  Saving model ...
Validation loss decreased (0.658396 --> 0.656103).  Saving model ...
Validation loss decreased (0.656103 --> 0.653733).  Saving model ...
Validation loss decreased (0.653733 --> 0.651289).  Saving model ...
Validation loss decreased (0.651289 --> 0.648772).  Saving model ...
Validation loss decreased (0.648772 --> 0.646182).  Saving model ...
Validation loss decreased (0.646182 --> 0.643523).  Saving model ...
Validation loss decreased (0.643523 --> 0.640795).  Saving model ...
Validation loss decreased (0.640795 --> 0.638002).  Saving model ...
Validation loss decreased (0.638002 --> 0.635144).  Saving model ...
Validation loss decreased (0.635144 --> 0.632225).  Saving model ...
Validation loss decreased (0.632225 --> 0.629247).  Saving model ...
Validation loss decreased (0.629247 --> 0.626212).  Saving model ...
Validation loss decreased (0.626212 --> 0.623124).  Saving model ...
Validation loss decreased (0.623124 --> 0.619984).  Saving model ...
Validation loss decreased (0.619984 --> 0.616797).  Saving model ...
Validation loss decreased (0.616797 --> 0.613565).  Saving model ...
Validation loss decreased (0.613565 --> 0.610291).  Saving model ...
Validation loss decreased (0.610291 --> 0.606978).  Saving model ...
Validation loss decreased (0.606978 --> 0.603631).  Saving model ...
Validation loss decreased (0.603631 --> 0.600251).  Saving model ...
Validation loss decreased (0.600251 --> 0.596843).  Saving model ...
Validation loss decreased (0.596843 --> 0.593410).  Saving model ...
Validation loss decreased (0.593410 --> 0.589956).  Saving model ...
Validation loss decreased (0.589956 --> 0.586483).  Saving model ...
Validation loss decreased (0.586483 --> 0.582994).  Saving model ...
Validation loss decreased (0.582994 --> 0.579494).  Saving model ...
Validation loss decreased (0.579494 --> 0.575985).  Saving model ...
Validation loss decreased (0.575985 --> 0.572471).  Saving model ...
Validation loss decreased (0.572471 --> 0.568953).  Saving model ...
Validation loss decreased (0.568953 --> 0.565436).  Saving model ...
Validation loss decreased (0.565436 --> 0.561922).  Saving model ...
Validation loss decreased (0.561922 --> 0.558415).  Saving model ...
Validation loss decreased (0.558415 --> 0.554919).  Saving model ...
Validation loss decreased (0.554919 --> 0.551435).  Saving model ...
Validation loss decreased (0.551435 --> 0.547967).  Saving model ...
Validation loss decreased (0.547967 --> 0.544515).  Saving model ...
Validation loss decreased (0.544515 --> 0.541084).  Saving model ...
Validation loss decreased (0.541084 --> 0.537675).  Saving model ...
Validation loss decreased (0.537675 --> 0.534290).  Saving model ...
Validation loss decreased (0.534290 --> 0.530932).  Saving model ...
Validation loss decreased (0.530932 --> 0.527602).  Saving model ...
Validation loss decreased (0.527602 --> 0.524303).  Saving model ...
Validation loss decreased (0.524303 --> 0.521036).  Saving model ...
Validation loss decreased (0.521036 --> 0.517803).  Saving model ...
Validation loss decreased (0.517803 --> 0.514606).  Saving model ...
Validation loss decreased (0.514606 --> 0.511445).  Saving model ...
Validation loss decreased (0.511445 --> 0.508322).  Saving model ...
Validation loss decreased (0.508322 --> 0.505238).  Saving model ...
Validation loss decreased (0.505238 --> 0.502193).  Saving model ...
Validation loss decreased (0.502193 --> 0.499187).  Saving model ...
Validation loss decreased (0.499187 --> 0.496223).  Saving model ...
Validation loss decreased (0.496223 --> 0.493301).  Saving model ...
Validation loss decreased (0.493301 --> 0.490421).  Saving model ...
Validation loss decreased (0.490421 --> 0.487584).  Saving model ...
Validation loss decreased (0.487584 --> 0.484789).  Saving model ...
Validation loss decreased (0.484789 --> 0.482036).  Saving model ...
Validation loss decreased (0.482036 --> 0.479328).  Saving model ...
Validation loss decreased (0.479328 --> 0.476664).  Saving model ...
Validation loss decreased (0.476664 --> 0.474043).  Saving model ...
Validation loss decreased (0.474043 --> 0.471466).  Saving model ...
Validation loss decreased (0.471466 --> 0.468931).  Saving model ...
Validation loss decreased (0.468931 --> 0.466439).  Saving model ...
Validation loss decreased (0.466439 --> 0.463988).  Saving model ...
Validation loss decreased (0.463988 --> 0.461579).  Saving model ...
Validation loss decreased (0.461579 --> 0.459213).  Saving model ...
Validation loss decreased (0.459213 --> 0.456889).  Saving model ...
Validation loss decreased (0.456889 --> 0.454603).  Saving model ...
Validation loss decreased (0.454603 --> 0.452359).  Saving model ...
Validation loss decreased (0.452359 --> 0.450154).  Saving model ...
epoch 101, loss 0.5255, train acc 85.76%, f1 0.8571, precision 0.8598, recall 0.8545, auc 0.8576
Validation loss decreased (0.450154 --> 0.447988).  Saving model ...
Validation loss decreased (0.447988 --> 0.445859).  Saving model ...
Validation loss decreased (0.445859 --> 0.443768).  Saving model ...
Validation loss decreased (0.443768 --> 0.441714).  Saving model ...
Validation loss decreased (0.441714 --> 0.439696).  Saving model ...
Validation loss decreased (0.439696 --> 0.437714).  Saving model ...
Validation loss decreased (0.437714 --> 0.435766).  Saving model ...
Validation loss decreased (0.435766 --> 0.433851).  Saving model ...
Validation loss decreased (0.433851 --> 0.431968).  Saving model ...
Validation loss decreased (0.431968 --> 0.430117).  Saving model ...
Validation loss decreased (0.430117 --> 0.428299).  Saving model ...
Validation loss decreased (0.428299 --> 0.426512).  Saving model ...
Validation loss decreased (0.426512 --> 0.424754).  Saving model ...
Validation loss decreased (0.424754 --> 0.423025).  Saving model ...
Validation loss decreased (0.423025 --> 0.421325).  Saving model ...
Validation loss decreased (0.421325 --> 0.419653).  Saving model ...
Validation loss decreased (0.419653 --> 0.418009).  Saving model ...
Validation loss decreased (0.418009 --> 0.416392).  Saving model ...
Validation loss decreased (0.416392 --> 0.414801).  Saving model ...
Validation loss decreased (0.414801 --> 0.413233).  Saving model ...
Validation loss decreased (0.413233 --> 0.411690).  Saving model ...
Validation loss decreased (0.411690 --> 0.410170).  Saving model ...
Validation loss decreased (0.410170 --> 0.408671).  Saving model ...
Validation loss decreased (0.408671 --> 0.407197).  Saving model ...
Validation loss decreased (0.407197 --> 0.405744).  Saving model ...
Validation loss decreased (0.405744 --> 0.404312).  Saving model ...
Validation loss decreased (0.404312 --> 0.402902).  Saving model ...
Validation loss decreased (0.402902 --> 0.401511).  Saving model ...
Validation loss decreased (0.401511 --> 0.400140).  Saving model ...
Validation loss decreased (0.400140 --> 0.398788).  Saving model ...
Validation loss decreased (0.398788 --> 0.397454).  Saving model ...
Validation loss decreased (0.397454 --> 0.396139).  Saving model ...
Validation loss decreased (0.396139 --> 0.394840).  Saving model ...
Validation loss decreased (0.394840 --> 0.393558).  Saving model ...
Validation loss decreased (0.393558 --> 0.392293).  Saving model ...
Validation loss decreased (0.392293 --> 0.391043).  Saving model ...
Validation loss decreased (0.391043 --> 0.389808).  Saving model ...
Validation loss decreased (0.389808 --> 0.388588).  Saving model ...
Validation loss decreased (0.388588 --> 0.387383).  Saving model ...
Validation loss decreased (0.387383 --> 0.386191).  Saving model ...
Validation loss decreased (0.386191 --> 0.385013).  Saving model ...
Validation loss decreased (0.385013 --> 0.383847).  Saving model ...
Validation loss decreased (0.383847 --> 0.382694).  Saving model ...
Validation loss decreased (0.382694 --> 0.381553).  Saving model ...
Validation loss decreased (0.381553 --> 0.380423).  Saving model ...
Validation loss decreased (0.380423 --> 0.379305).  Saving model ...
Validation loss decreased (0.379305 --> 0.378198).  Saving model ...
Validation loss decreased (0.378198 --> 0.377102).  Saving model ...
Validation loss decreased (0.377102 --> 0.376016).  Saving model ...
Validation loss decreased (0.376016 --> 0.374938).  Saving model ...
Validation loss decreased (0.374938 --> 0.373869).  Saving model ...
Validation loss decreased (0.373869 --> 0.372810).  Saving model ...
Validation loss decreased (0.372810 --> 0.371760).  Saving model ...
Validation loss decreased (0.371760 --> 0.370720).  Saving model ...
Validation loss decreased (0.370720 --> 0.369687).  Saving model ...
Validation loss decreased (0.369687 --> 0.368663).  Saving model ...
Validation loss decreased (0.368663 --> 0.367646).  Saving model ...
Validation loss decreased (0.367646 --> 0.366638).  Saving model ...
Validation loss decreased (0.366638 --> 0.365636).  Saving model ...
Validation loss decreased (0.365636 --> 0.364642).  Saving model ...
Validation loss decreased (0.364642 --> 0.363654).  Saving model ...
Validation loss decreased (0.363654 --> 0.362673).  Saving model ...
Validation loss decreased (0.362673 --> 0.361697).  Saving model ...
Validation loss decreased (0.361697 --> 0.360728).  Saving model ...
Validation loss decreased (0.360728 --> 0.359764).  Saving model ...
Validation loss decreased (0.359764 --> 0.358806).  Saving model ...
Validation loss decreased (0.358806 --> 0.357853).  Saving model ...
Validation loss decreased (0.357853 --> 0.356904).  Saving model ...
Validation loss decreased (0.356904 --> 0.355959).  Saving model ...
Validation loss decreased (0.355959 --> 0.355018).  Saving model ...
Validation loss decreased (0.355018 --> 0.354083).  Saving model ...
Validation loss decreased (0.354083 --> 0.353151).  Saving model ...
Validation loss decreased (0.353151 --> 0.352223).  Saving model ...
Validation loss decreased (0.352223 --> 0.351298).  Saving model ...
Validation loss decreased (0.351298 --> 0.350375).  Saving model ...
Validation loss decreased (0.350375 --> 0.349456).  Saving model ...
Validation loss decreased (0.349456 --> 0.348540).  Saving model ...
Validation loss decreased (0.348540 --> 0.347627).  Saving model ...
Validation loss decreased (0.347627 --> 0.346716).  Saving model ...
Validation loss decreased (0.346716 --> 0.345808).  Saving model ...
Validation loss decreased (0.345808 --> 0.344904).  Saving model ...
Validation loss decreased (0.344904 --> 0.344001).  Saving model ...
Validation loss decreased (0.344001 --> 0.343100).  Saving model ...
Validation loss decreased (0.343100 --> 0.342202).  Saving model ...
Validation loss decreased (0.342202 --> 0.341306).  Saving model ...
Validation loss decreased (0.341306 --> 0.340412).  Saving model ...
Validation loss decreased (0.340412 --> 0.339520).  Saving model ...
Validation loss decreased (0.339520 --> 0.338629).  Saving model ...
Validation loss decreased (0.338629 --> 0.337740).  Saving model ...
Validation loss decreased (0.337740 --> 0.336852).  Saving model ...
Validation loss decreased (0.336852 --> 0.335966).  Saving model ...
Validation loss decreased (0.335966 --> 0.335081).  Saving model ...
Validation loss decreased (0.335081 --> 0.334197).  Saving model ...
Validation loss decreased (0.334197 --> 0.333313).  Saving model ...
Validation loss decreased (0.333313 --> 0.332430).  Saving model ...
Validation loss decreased (0.332430 --> 0.331548).  Saving model ...
Validation loss decreased (0.331548 --> 0.330667).  Saving model ...
Validation loss decreased (0.330667 --> 0.329786).  Saving model ...
Validation loss decreased (0.329786 --> 0.328907).  Saving model ...
Validation loss decreased (0.328907 --> 0.328027).  Saving model ...
epoch 201, loss 0.4452, train acc 92.42%, f1 0.9240, precision 0.9268, recall 0.9212, auc 0.9242
Validation loss decreased (0.328027 --> 0.327148).  Saving model ...
Validation loss decreased (0.327148 --> 0.326269).  Saving model ...
Validation loss decreased (0.326269 --> 0.325391).  Saving model ...
Validation loss decreased (0.325391 --> 0.324513).  Saving model ...
Validation loss decreased (0.324513 --> 0.323635).  Saving model ...
Validation loss decreased (0.323635 --> 0.322757).  Saving model ...
Validation loss decreased (0.322757 --> 0.321880).  Saving model ...
Validation loss decreased (0.321880 --> 0.321002).  Saving model ...
Validation loss decreased (0.321002 --> 0.320124).  Saving model ...
Validation loss decreased (0.320124 --> 0.319246).  Saving model ...
Validation loss decreased (0.319246 --> 0.318367).  Saving model ...
Validation loss decreased (0.318367 --> 0.317488).  Saving model ...
Validation loss decreased (0.317488 --> 0.316607).  Saving model ...
Validation loss decreased (0.316607 --> 0.315726).  Saving model ...
Validation loss decreased (0.315726 --> 0.314843).  Saving model ...
Validation loss decreased (0.314843 --> 0.313958).  Saving model ...
Validation loss decreased (0.313958 --> 0.313073).  Saving model ...
Validation loss decreased (0.313073 --> 0.312186).  Saving model ...
Validation loss decreased (0.312186 --> 0.311299).  Saving model ...
Validation loss decreased (0.311299 --> 0.310411).  Saving model ...
Validation loss decreased (0.310411 --> 0.309522).  Saving model ...
Validation loss decreased (0.309522 --> 0.308633).  Saving model ...
Validation loss decreased (0.308633 --> 0.307744).  Saving model ...
Validation loss decreased (0.307744 --> 0.306854).  Saving model ...
Validation loss decreased (0.306854 --> 0.305963).  Saving model ...
Validation loss decreased (0.305963 --> 0.305070).  Saving model ...
Validation loss decreased (0.305070 --> 0.304176).  Saving model ...
Validation loss decreased (0.304176 --> 0.303281).  Saving model ...
Validation loss decreased (0.303281 --> 0.302384).  Saving model ...
Validation loss decreased (0.302384 --> 0.301485).  Saving model ...
Validation loss decreased (0.301485 --> 0.300585).  Saving model ...
Validation loss decreased (0.300585 --> 0.299683).  Saving model ...
Validation loss decreased (0.299683 --> 0.298778).  Saving model ...
Validation loss decreased (0.298778 --> 0.297872).  Saving model ...
Validation loss decreased (0.297872 --> 0.296964).  Saving model ...
Validation loss decreased (0.296964 --> 0.296054).  Saving model ...
Validation loss decreased (0.296054 --> 0.295143).  Saving model ...
Validation loss decreased (0.295143 --> 0.294231).  Saving model ...
Validation loss decreased (0.294231 --> 0.293318).  Saving model ...
Validation loss decreased (0.293318 --> 0.292404).  Saving model ...
Validation loss decreased (0.292404 --> 0.291488).  Saving model ...
Validation loss decreased (0.291488 --> 0.290571).  Saving model ...
Validation loss decreased (0.290571 --> 0.289653).  Saving model ...
Validation loss decreased (0.289653 --> 0.288735).  Saving model ...
Validation loss decreased (0.288735 --> 0.287815).  Saving model ...
Validation loss decreased (0.287815 --> 0.286893).  Saving model ...
Validation loss decreased (0.286893 --> 0.285969).  Saving model ...
Validation loss decreased (0.285969 --> 0.285043).  Saving model ...
Validation loss decreased (0.285043 --> 0.284114).  Saving model ...
Validation loss decreased (0.284114 --> 0.283184).  Saving model ...
Validation loss decreased (0.283184 --> 0.282253).  Saving model ...
Validation loss decreased (0.282253 --> 0.281320).  Saving model ...
Validation loss decreased (0.281320 --> 0.280384).  Saving model ...
Validation loss decreased (0.280384 --> 0.279446).  Saving model ...
Validation loss decreased (0.279446 --> 0.278506).  Saving model ...
Validation loss decreased (0.278506 --> 0.277564).  Saving model ...
Validation loss decreased (0.277564 --> 0.276620).  Saving model ...
Validation loss decreased (0.276620 --> 0.275676).  Saving model ...
Validation loss decreased (0.275676 --> 0.274729).  Saving model ...
Validation loss decreased (0.274729 --> 0.273782).  Saving model ...
Validation loss decreased (0.273782 --> 0.272833).  Saving model ...
Validation loss decreased (0.272833 --> 0.271884).  Saving model ...
Validation loss decreased (0.271884 --> 0.270934).  Saving model ...
Validation loss decreased (0.270934 --> 0.269984).  Saving model ...
Validation loss decreased (0.269984 --> 0.269031).  Saving model ...
Validation loss decreased (0.269031 --> 0.268078).  Saving model ...
Validation loss decreased (0.268078 --> 0.267125).  Saving model ...
Validation loss decreased (0.267125 --> 0.266171).  Saving model ...
Validation loss decreased (0.266171 --> 0.265215).  Saving model ...
Validation loss decreased (0.265215 --> 0.264258).  Saving model ...
Validation loss decreased (0.264258 --> 0.263299).  Saving model ...
Validation loss decreased (0.263299 --> 0.262341).  Saving model ...
Validation loss decreased (0.262341 --> 0.261383).  Saving model ...
Validation loss decreased (0.261383 --> 0.260422).  Saving model ...
Validation loss decreased (0.260422 --> 0.259458).  Saving model ...
Validation loss decreased (0.259458 --> 0.258494).  Saving model ...
Validation loss decreased (0.258494 --> 0.257531).  Saving model ...
Validation loss decreased (0.257531 --> 0.256568).  Saving model ...
Validation loss decreased (0.256568 --> 0.255603).  Saving model ...
Validation loss decreased (0.255603 --> 0.254639).  Saving model ...
Validation loss decreased (0.254639 --> 0.253674).  Saving model ...
Validation loss decreased (0.253674 --> 0.252710).  Saving model ...
Validation loss decreased (0.252710 --> 0.251746).  Saving model ...
Validation loss decreased (0.251746 --> 0.250782).  Saving model ...
Validation loss decreased (0.250782 --> 0.249817).  Saving model ...
Validation loss decreased (0.249817 --> 0.248851).  Saving model ...
Validation loss decreased (0.248851 --> 0.247887).  Saving model ...
Validation loss decreased (0.247887 --> 0.246925).  Saving model ...
Validation loss decreased (0.246925 --> 0.245965).  Saving model ...
Validation loss decreased (0.245965 --> 0.245003).  Saving model ...
Validation loss decreased (0.245003 --> 0.244041).  Saving model ...
Validation loss decreased (0.244041 --> 0.243080).  Saving model ...
Validation loss decreased (0.243080 --> 0.242119).  Saving model ...
Validation loss decreased (0.242119 --> 0.241159).  Saving model ...
Validation loss decreased (0.241159 --> 0.240199).  Saving model ...
Validation loss decreased (0.240199 --> 0.239243).  Saving model ...
Validation loss decreased (0.239243 --> 0.238288).  Saving model ...
Validation loss decreased (0.238288 --> 0.237332).  Saving model ...
Validation loss decreased (0.237332 --> 0.236376).  Saving model ...
Validation loss decreased (0.236376 --> 0.235422).  Saving model ...
epoch 301, loss 0.3560, train acc 96.97%, f1 0.9697, precision 0.9697, recall 0.9697, auc 0.9697
Validation loss decreased (0.235422 --> 0.234468).  Saving model ...
Validation loss decreased (0.234468 --> 0.233517).  Saving model ...
Validation loss decreased (0.233517 --> 0.232568).  Saving model ...
Validation loss decreased (0.232568 --> 0.231619).  Saving model ...
Validation loss decreased (0.231619 --> 0.230671).  Saving model ...
Validation loss decreased (0.230671 --> 0.229725).  Saving model ...
Validation loss decreased (0.229725 --> 0.228781).  Saving model ...
Validation loss decreased (0.228781 --> 0.227840).  Saving model ...
Validation loss decreased (0.227840 --> 0.226900).  Saving model ...
Validation loss decreased (0.226900 --> 0.225961).  Saving model ...
Validation loss decreased (0.225961 --> 0.225022).  Saving model ...
Validation loss decreased (0.225022 --> 0.224086).  Saving model ...
Validation loss decreased (0.224086 --> 0.223152).  Saving model ...
Validation loss decreased (0.223152 --> 0.222219).  Saving model ...
Validation loss decreased (0.222219 --> 0.221288).  Saving model ...
Validation loss decreased (0.221288 --> 0.220357).  Saving model ...
Validation loss decreased (0.220357 --> 0.219429).  Saving model ...
Validation loss decreased (0.219429 --> 0.218503).  Saving model ...
Validation loss decreased (0.218503 --> 0.217581).  Saving model ...
Validation loss decreased (0.217581 --> 0.216660).  Saving model ...
Validation loss decreased (0.216660 --> 0.215744).  Saving model ...
Validation loss decreased (0.215744 --> 0.214833).  Saving model ...
Validation loss decreased (0.214833 --> 0.213924).  Saving model ...
Validation loss decreased (0.213924 --> 0.213017).  Saving model ...
Validation loss decreased (0.213017 --> 0.212115).  Saving model ...
Validation loss decreased (0.212115 --> 0.211217).  Saving model ...
Validation loss decreased (0.211217 --> 0.210323).  Saving model ...
Validation loss decreased (0.210323 --> 0.209433).  Saving model ...
Validation loss decreased (0.209433 --> 0.208546).  Saving model ...
Validation loss decreased (0.208546 --> 0.207662).  Saving model ...
Validation loss decreased (0.207662 --> 0.206783).  Saving model ...
Validation loss decreased (0.206783 --> 0.205907).  Saving model ...
Validation loss decreased (0.205907 --> 0.205036).  Saving model ...
Validation loss decreased (0.205036 --> 0.204169).  Saving model ...
Validation loss decreased (0.204169 --> 0.203309).  Saving model ...
Validation loss decreased (0.203309 --> 0.202452).  Saving model ...
Validation loss decreased (0.202452 --> 0.201601).  Saving model ...
Validation loss decreased (0.201601 --> 0.200752).  Saving model ...
Validation loss decreased (0.200752 --> 0.199907).  Saving model ...
Validation loss decreased (0.199907 --> 0.199068).  Saving model ...
Validation loss decreased (0.199068 --> 0.198232).  Saving model ...
Validation loss decreased (0.198232 --> 0.197401).  Saving model ...
Validation loss decreased (0.197401 --> 0.196574).  Saving model ...
Validation loss decreased (0.196574 --> 0.195753).  Saving model ...
Validation loss decreased (0.195753 --> 0.194935).  Saving model ...
Validation loss decreased (0.194935 --> 0.194121).  Saving model ...
Validation loss decreased (0.194121 --> 0.193312).  Saving model ...
Validation loss decreased (0.193312 --> 0.192505).  Saving model ...
Validation loss decreased (0.192505 --> 0.191702).  Saving model ...
Validation loss decreased (0.191702 --> 0.190906).  Saving model ...
Validation loss decreased (0.190906 --> 0.190114).  Saving model ...
Validation loss decreased (0.190114 --> 0.189326).  Saving model ...
Validation loss decreased (0.189326 --> 0.188543).  Saving model ...
Validation loss decreased (0.188543 --> 0.187763).  Saving model ...
Validation loss decreased (0.187763 --> 0.186987).  Saving model ...
Validation loss decreased (0.186987 --> 0.186217).  Saving model ...
Validation loss decreased (0.186217 --> 0.185451).  Saving model ...
Validation loss decreased (0.185451 --> 0.184690).  Saving model ...
Validation loss decreased (0.184690 --> 0.183935).  Saving model ...
Validation loss decreased (0.183935 --> 0.183184).  Saving model ...
Validation loss decreased (0.183184 --> 0.182437).  Saving model ...
Validation loss decreased (0.182437 --> 0.181695).  Saving model ...
Validation loss decreased (0.181695 --> 0.180958).  Saving model ...
Validation loss decreased (0.180958 --> 0.180224).  Saving model ...
Validation loss decreased (0.180224 --> 0.179495).  Saving model ...
Validation loss decreased (0.179495 --> 0.178770).  Saving model ...
Validation loss decreased (0.178770 --> 0.178050).  Saving model ...
Validation loss decreased (0.178050 --> 0.177335).  Saving model ...
Validation loss decreased (0.177335 --> 0.176624).  Saving model ...
Validation loss decreased (0.176624 --> 0.175918).  Saving model ...
Validation loss decreased (0.175918 --> 0.175214).  Saving model ...
Validation loss decreased (0.175214 --> 0.174515).  Saving model ...
Validation loss decreased (0.174515 --> 0.173818).  Saving model ...
Validation loss decreased (0.173818 --> 0.173128).  Saving model ...
Validation loss decreased (0.173128 --> 0.172443).  Saving model ...
Validation loss decreased (0.172443 --> 0.171763).  Saving model ...
Validation loss decreased (0.171763 --> 0.171086).  Saving model ...
Validation loss decreased (0.171086 --> 0.170414).  Saving model ...
Validation loss decreased (0.170414 --> 0.169745).  Saving model ...
Validation loss decreased (0.169745 --> 0.169082).  Saving model ...
Validation loss decreased (0.169082 --> 0.168423).  Saving model ...
Validation loss decreased (0.168423 --> 0.167770).  Saving model ...
Validation loss decreased (0.167770 --> 0.167121).  Saving model ...
Validation loss decreased (0.167121 --> 0.166477).  Saving model ...
Validation loss decreased (0.166477 --> 0.165836).  Saving model ...
Validation loss decreased (0.165836 --> 0.165200).  Saving model ...
Validation loss decreased (0.165200 --> 0.164568).  Saving model ...
Validation loss decreased (0.164568 --> 0.163941).  Saving model ...
Validation loss decreased (0.163941 --> 0.163320).  Saving model ...
Validation loss decreased (0.163320 --> 0.162704).  Saving model ...
Validation loss decreased (0.162704 --> 0.162092).  Saving model ...
Validation loss decreased (0.162092 --> 0.161483).  Saving model ...
Validation loss decreased (0.161483 --> 0.160879).  Saving model ...
Validation loss decreased (0.160879 --> 0.160276).  Saving model ...
Validation loss decreased (0.160276 --> 0.159677).  Saving model ...
Validation loss decreased (0.159677 --> 0.159082).  Saving model ...
Validation loss decreased (0.159082 --> 0.158493).  Saving model ...
Validation loss decreased (0.158493 --> 0.157907).  Saving model ...
Validation loss decreased (0.157907 --> 0.157327).  Saving model ...
Validation loss decreased (0.157327 --> 0.156751).  Saving model ...
epoch 401, loss 0.2869, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.156751 --> 0.156178).  Saving model ...
Validation loss decreased (0.156178 --> 0.155610).  Saving model ...
Validation loss decreased (0.155610 --> 0.155045).  Saving model ...
Validation loss decreased (0.155045 --> 0.154482).  Saving model ...
Validation loss decreased (0.154482 --> 0.153925).  Saving model ...
Validation loss decreased (0.153925 --> 0.153373).  Saving model ...
Validation loss decreased (0.153373 --> 0.152823).  Saving model ...
Validation loss decreased (0.152823 --> 0.152278).  Saving model ...
Validation loss decreased (0.152278 --> 0.151737).  Saving model ...
Validation loss decreased (0.151737 --> 0.151201).  Saving model ...
Validation loss decreased (0.151201 --> 0.150668).  Saving model ...
Validation loss decreased (0.150668 --> 0.150141).  Saving model ...
Validation loss decreased (0.150141 --> 0.149617).  Saving model ...
Validation loss decreased (0.149617 --> 0.149096).  Saving model ...
Validation loss decreased (0.149096 --> 0.148579).  Saving model ...
Validation loss decreased (0.148579 --> 0.148063).  Saving model ...
Validation loss decreased (0.148063 --> 0.147549).  Saving model ...
Validation loss decreased (0.147549 --> 0.147039).  Saving model ...
Validation loss decreased (0.147039 --> 0.146534).  Saving model ...
Validation loss decreased (0.146534 --> 0.146034).  Saving model ...
Validation loss decreased (0.146034 --> 0.145539).  Saving model ...
Validation loss decreased (0.145539 --> 0.145049).  Saving model ...
Validation loss decreased (0.145049 --> 0.144563).  Saving model ...
Validation loss decreased (0.144563 --> 0.144082).  Saving model ...
Validation loss decreased (0.144082 --> 0.143603).  Saving model ...
Validation loss decreased (0.143603 --> 0.143129).  Saving model ...
Validation loss decreased (0.143129 --> 0.142658).  Saving model ...
Validation loss decreased (0.142658 --> 0.142192).  Saving model ...
Validation loss decreased (0.142192 --> 0.141730).  Saving model ...
Validation loss decreased (0.141730 --> 0.141272).  Saving model ...
Validation loss decreased (0.141272 --> 0.140819).  Saving model ...
Validation loss decreased (0.140819 --> 0.140368).  Saving model ...
Validation loss decreased (0.140368 --> 0.139920).  Saving model ...
Validation loss decreased (0.139920 --> 0.139476).  Saving model ...
Validation loss decreased (0.139476 --> 0.139036).  Saving model ...
Validation loss decreased (0.139036 --> 0.138599).  Saving model ...
Validation loss decreased (0.138599 --> 0.138165).  Saving model ...
Validation loss decreased (0.138165 --> 0.137733).  Saving model ...
Validation loss decreased (0.137733 --> 0.137305).  Saving model ...
Validation loss decreased (0.137305 --> 0.136879).  Saving model ...
Validation loss decreased (0.136879 --> 0.136455).  Saving model ...
Validation loss decreased (0.136455 --> 0.136035).  Saving model ...
Validation loss decreased (0.136035 --> 0.135619).  Saving model ...
Validation loss decreased (0.135619 --> 0.135203).  Saving model ...
Validation loss decreased (0.135203 --> 0.134791).  Saving model ...
Validation loss decreased (0.134791 --> 0.134381).  Saving model ...
Validation loss decreased (0.134381 --> 0.133976).  Saving model ...
Validation loss decreased (0.133976 --> 0.133572).  Saving model ...
Validation loss decreased (0.133572 --> 0.133172).  Saving model ...
Validation loss decreased (0.133172 --> 0.132774).  Saving model ...
Validation loss decreased (0.132774 --> 0.132378).  Saving model ...
Validation loss decreased (0.132378 --> 0.131987).  Saving model ...
Validation loss decreased (0.131987 --> 0.131599).  Saving model ...
Validation loss decreased (0.131599 --> 0.131214).  Saving model ...
Validation loss decreased (0.131214 --> 0.130833).  Saving model ...
Validation loss decreased (0.130833 --> 0.130457).  Saving model ...
Validation loss decreased (0.130457 --> 0.130086).  Saving model ...
Validation loss decreased (0.130086 --> 0.129718).  Saving model ...
Validation loss decreased (0.129718 --> 0.129354).  Saving model ...
Validation loss decreased (0.129354 --> 0.128993).  Saving model ...
Validation loss decreased (0.128993 --> 0.128634).  Saving model ...
Validation loss decreased (0.128634 --> 0.128275).  Saving model ...
Validation loss decreased (0.128275 --> 0.127920).  Saving model ...
Validation loss decreased (0.127920 --> 0.127567).  Saving model ...
Validation loss decreased (0.127567 --> 0.127217).  Saving model ...
Validation loss decreased (0.127217 --> 0.126866).  Saving model ...
Validation loss decreased (0.126866 --> 0.126517).  Saving model ...
Validation loss decreased (0.126517 --> 0.126173).  Saving model ...
Validation loss decreased (0.126173 --> 0.125833).  Saving model ...
Validation loss decreased (0.125833 --> 0.125493).  Saving model ...
Validation loss decreased (0.125493 --> 0.125157).  Saving model ...
Validation loss decreased (0.125157 --> 0.124824).  Saving model ...
Validation loss decreased (0.124824 --> 0.124493).  Saving model ...
Validation loss decreased (0.124493 --> 0.124165).  Saving model ...
Validation loss decreased (0.124165 --> 0.123842).  Saving model ...
Validation loss decreased (0.123842 --> 0.123521).  Saving model ...
Validation loss decreased (0.123521 --> 0.123204).  Saving model ...
Validation loss decreased (0.123204 --> 0.122889).  Saving model ...
Validation loss decreased (0.122889 --> 0.122577).  Saving model ...
Validation loss decreased (0.122577 --> 0.122264).  Saving model ...
Validation loss decreased (0.122264 --> 0.121954).  Saving model ...
Validation loss decreased (0.121954 --> 0.121647).  Saving model ...
Validation loss decreased (0.121647 --> 0.121342).  Saving model ...
Validation loss decreased (0.121342 --> 0.121039).  Saving model ...
Validation loss decreased (0.121039 --> 0.120741).  Saving model ...
Validation loss decreased (0.120741 --> 0.120445).  Saving model ...
Validation loss decreased (0.120445 --> 0.120152).  Saving model ...
Validation loss decreased (0.120152 --> 0.119861).  Saving model ...
Validation loss decreased (0.119861 --> 0.119572).  Saving model ...
Validation loss decreased (0.119572 --> 0.119286).  Saving model ...
Validation loss decreased (0.119286 --> 0.119003).  Saving model ...
Validation loss decreased (0.119003 --> 0.118723).  Saving model ...
Validation loss decreased (0.118723 --> 0.118445).  Saving model ...
Validation loss decreased (0.118445 --> 0.118169).  Saving model ...
Validation loss decreased (0.118169 --> 0.117895).  Saving model ...
Validation loss decreased (0.117895 --> 0.117624).  Saving model ...
Validation loss decreased (0.117624 --> 0.117357).  Saving model ...
Validation loss decreased (0.117357 --> 0.117091).  Saving model ...
Validation loss decreased (0.117091 --> 0.116825).  Saving model ...
Validation loss decreased (0.116825 --> 0.116561).  Saving model ...
epoch 501, loss 0.2509, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.116561 --> 0.116295).  Saving model ...
Validation loss decreased (0.116295 --> 0.116032).  Saving model ...
Validation loss decreased (0.116032 --> 0.115771).  Saving model ...
Validation loss decreased (0.115771 --> 0.115513).  Saving model ...
Validation loss decreased (0.115513 --> 0.115254).  Saving model ...
Validation loss decreased (0.115254 --> 0.114999).  Saving model ...
Validation loss decreased (0.114999 --> 0.114747).  Saving model ...
Validation loss decreased (0.114747 --> 0.114498).  Saving model ...
Validation loss decreased (0.114498 --> 0.114250).  Saving model ...
Validation loss decreased (0.114250 --> 0.114005).  Saving model ...
Validation loss decreased (0.114005 --> 0.113763).  Saving model ...
Validation loss decreased (0.113763 --> 0.113524).  Saving model ...
Validation loss decreased (0.113524 --> 0.113288).  Saving model ...
Validation loss decreased (0.113288 --> 0.113052).  Saving model ...
Validation loss decreased (0.113052 --> 0.112816).  Saving model ...
Validation loss decreased (0.112816 --> 0.112581).  Saving model ...
Validation loss decreased (0.112581 --> 0.112348).  Saving model ...
Validation loss decreased (0.112348 --> 0.112118).  Saving model ...
Validation loss decreased (0.112118 --> 0.111888).  Saving model ...
Validation loss decreased (0.111888 --> 0.111662).  Saving model ...
Validation loss decreased (0.111662 --> 0.111437).  Saving model ...
Validation loss decreased (0.111437 --> 0.111212).  Saving model ...
Validation loss decreased (0.111212 --> 0.110990).  Saving model ...
Validation loss decreased (0.110990 --> 0.110770).  Saving model ...
Validation loss decreased (0.110770 --> 0.110554).  Saving model ...
Validation loss decreased (0.110554 --> 0.110340).  Saving model ...
Validation loss decreased (0.110340 --> 0.110126).  Saving model ...
Validation loss decreased (0.110126 --> 0.109914).  Saving model ...
Validation loss decreased (0.109914 --> 0.109703).  Saving model ...
Validation loss decreased (0.109703 --> 0.109497).  Saving model ...
Validation loss decreased (0.109497 --> 0.109291).  Saving model ...
Validation loss decreased (0.109291 --> 0.109086).  Saving model ...
Validation loss decreased (0.109086 --> 0.108879).  Saving model ...
Validation loss decreased (0.108879 --> 0.108677).  Saving model ...
Validation loss decreased (0.108677 --> 0.108476).  Saving model ...
Validation loss decreased (0.108476 --> 0.108273).  Saving model ...
Validation loss decreased (0.108273 --> 0.108072).  Saving model ...
Validation loss decreased (0.108072 --> 0.107870).  Saving model ...
Validation loss decreased (0.107870 --> 0.107670).  Saving model ...
Validation loss decreased (0.107670 --> 0.107471).  Saving model ...
Validation loss decreased (0.107471 --> 0.107275).  Saving model ...
Validation loss decreased (0.107275 --> 0.107082).  Saving model ...
Validation loss decreased (0.107082 --> 0.106890).  Saving model ...
Validation loss decreased (0.106890 --> 0.106701).  Saving model ...
Validation loss decreased (0.106701 --> 0.106514).  Saving model ...
Validation loss decreased (0.106514 --> 0.106331).  Saving model ...
Validation loss decreased (0.106331 --> 0.106150).  Saving model ...
Validation loss decreased (0.106150 --> 0.105971).  Saving model ...
Validation loss decreased (0.105971 --> 0.105796).  Saving model ...
Validation loss decreased (0.105796 --> 0.105621).  Saving model ...
Validation loss decreased (0.105621 --> 0.105447).  Saving model ...
Validation loss decreased (0.105447 --> 0.105276).  Saving model ...
Validation loss decreased (0.105276 --> 0.105106).  Saving model ...
Validation loss decreased (0.105106 --> 0.104938).  Saving model ...
Validation loss decreased (0.104938 --> 0.104767).  Saving model ...
Validation loss decreased (0.104767 --> 0.104598).  Saving model ...
Validation loss decreased (0.104598 --> 0.104428).  Saving model ...
Validation loss decreased (0.104428 --> 0.104261).  Saving model ...
Validation loss decreased (0.104261 --> 0.104094).  Saving model ...
Validation loss decreased (0.104094 --> 0.103928).  Saving model ...
Validation loss decreased (0.103928 --> 0.103761).  Saving model ...
Validation loss decreased (0.103761 --> 0.103597).  Saving model ...
Validation loss decreased (0.103597 --> 0.103432).  Saving model ...
Validation loss decreased (0.103432 --> 0.103269).  Saving model ...
Validation loss decreased (0.103269 --> 0.103107).  Saving model ...
Validation loss decreased (0.103107 --> 0.102950).  Saving model ...
Validation loss decreased (0.102950 --> 0.102793).  Saving model ...
Validation loss decreased (0.102793 --> 0.102639).  Saving model ...
Validation loss decreased (0.102639 --> 0.102487).  Saving model ...
Validation loss decreased (0.102487 --> 0.102336).  Saving model ...
Validation loss decreased (0.102336 --> 0.102187).  Saving model ...
Validation loss decreased (0.102187 --> 0.102040).  Saving model ...
Validation loss decreased (0.102040 --> 0.101894).  Saving model ...
Validation loss decreased (0.101894 --> 0.101748).  Saving model ...
Validation loss decreased (0.101748 --> 0.101604).  Saving model ...
Validation loss decreased (0.101604 --> 0.101461).  Saving model ...
Validation loss decreased (0.101461 --> 0.101320).  Saving model ...
Validation loss decreased (0.101320 --> 0.101177).  Saving model ...
Validation loss decreased (0.101177 --> 0.101036).  Saving model ...
Validation loss decreased (0.101036 --> 0.100897).  Saving model ...
Validation loss decreased (0.100897 --> 0.100759).  Saving model ...
Validation loss decreased (0.100759 --> 0.100622).  Saving model ...
Validation loss decreased (0.100622 --> 0.100485).  Saving model ...
Validation loss decreased (0.100485 --> 0.100347).  Saving model ...
Validation loss decreased (0.100347 --> 0.100210).  Saving model ...
Validation loss decreased (0.100210 --> 0.100076).  Saving model ...
Validation loss decreased (0.100076 --> 0.099942).  Saving model ...
Validation loss decreased (0.099942 --> 0.099807).  Saving model ...
Validation loss decreased (0.099807 --> 0.099672).  Saving model ...
Validation loss decreased (0.099672 --> 0.099538).  Saving model ...
Validation loss decreased (0.099538 --> 0.099407).  Saving model ...
Validation loss decreased (0.099407 --> 0.099278).  Saving model ...
Validation loss decreased (0.099278 --> 0.099150).  Saving model ...
Validation loss decreased (0.099150 --> 0.099024).  Saving model ...
Validation loss decreased (0.099024 --> 0.098899).  Saving model ...
Validation loss decreased (0.098899 --> 0.098773).  Saving model ...
Validation loss decreased (0.098773 --> 0.098645).  Saving model ...
Validation loss decreased (0.098645 --> 0.098517).  Saving model ...
Validation loss decreased (0.098517 --> 0.098391).  Saving model ...
Validation loss decreased (0.098391 --> 0.098267).  Saving model ...
epoch 601, loss 0.2342, train acc 98.79%, f1 0.9879, precision 0.9879, recall 0.9879, auc 0.9879
Validation loss decreased (0.098267 --> 0.098144).  Saving model ...
Validation loss decreased (0.098144 --> 0.098023).  Saving model ...
Validation loss decreased (0.098023 --> 0.097906).  Saving model ...
Validation loss decreased (0.097906 --> 0.097787).  Saving model ...
Validation loss decreased (0.097787 --> 0.097671).  Saving model ...
Validation loss decreased (0.097671 --> 0.097554).  Saving model ...
Validation loss decreased (0.097554 --> 0.097436).  Saving model ...
Validation loss decreased (0.097436 --> 0.097322).  Saving model ...
Validation loss decreased (0.097322 --> 0.097210).  Saving model ...
Validation loss decreased (0.097210 --> 0.097097).  Saving model ...
Validation loss decreased (0.097097 --> 0.096985).  Saving model ...
Validation loss decreased (0.096985 --> 0.096873).  Saving model ...
Validation loss decreased (0.096873 --> 0.096763).  Saving model ...
Validation loss decreased (0.096763 --> 0.096653).  Saving model ...
Validation loss decreased (0.096653 --> 0.096542).  Saving model ...
Validation loss decreased (0.096542 --> 0.096433).  Saving model ...
Validation loss decreased (0.096433 --> 0.096323).  Saving model ...
Validation loss decreased (0.096323 --> 0.096215).  Saving model ...
Validation loss decreased (0.096215 --> 0.096108).  Saving model ...
Validation loss decreased (0.096108 --> 0.096004).  Saving model ...
Validation loss decreased (0.096004 --> 0.095900).  Saving model ...
Validation loss decreased (0.095900 --> 0.095796).  Saving model ...
Validation loss decreased (0.095796 --> 0.095695).  Saving model ...
Validation loss decreased (0.095695 --> 0.095595).  Saving model ...
Validation loss decreased (0.095595 --> 0.095496).  Saving model ...
Validation loss decreased (0.095496 --> 0.095398).  Saving model ...
Validation loss decreased (0.095398 --> 0.095302).  Saving model ...
Validation loss decreased (0.095302 --> 0.095206).  Saving model ...
Validation loss decreased (0.095206 --> 0.095112).  Saving model ...
Validation loss decreased (0.095112 --> 0.095018).  Saving model ...
Validation loss decreased (0.095018 --> 0.094925).  Saving model ...
Validation loss decreased (0.094925 --> 0.094833).  Saving model ...
Validation loss decreased (0.094833 --> 0.094741).  Saving model ...
Validation loss decreased (0.094741 --> 0.094651).  Saving model ...
Validation loss decreased (0.094651 --> 0.094561).  Saving model ...
Validation loss decreased (0.094561 --> 0.094471).  Saving model ...
Validation loss decreased (0.094471 --> 0.094382).  Saving model ...
Validation loss decreased (0.094382 --> 0.094297).  Saving model ...
Validation loss decreased (0.094297 --> 0.094211).  Saving model ...
Validation loss decreased (0.094211 --> 0.094128).  Saving model ...
Validation loss decreased (0.094128 --> 0.094045).  Saving model ...
Validation loss decreased (0.094045 --> 0.093963).  Saving model ...
Validation loss decreased (0.093963 --> 0.093880).  Saving model ...
Validation loss decreased (0.093880 --> 0.093799).  Saving model ...
Validation loss decreased (0.093799 --> 0.093717).  Saving model ...
Validation loss decreased (0.093717 --> 0.093634).  Saving model ...
Validation loss decreased (0.093634 --> 0.093551).  Saving model ...
Validation loss decreased (0.093551 --> 0.093467).  Saving model ...
Validation loss decreased (0.093467 --> 0.093384).  Saving model ...
Validation loss decreased (0.093384 --> 0.093298).  Saving model ...
Validation loss decreased (0.093298 --> 0.093211).  Saving model ...
Validation loss decreased (0.093211 --> 0.093126).  Saving model ...
Validation loss decreased (0.093126 --> 0.093042).  Saving model ...
Validation loss decreased (0.093042 --> 0.092960).  Saving model ...
Validation loss decreased (0.092960 --> 0.092877).  Saving model ...
Validation loss decreased (0.092877 --> 0.092795).  Saving model ...
Validation loss decreased (0.092795 --> 0.092713).  Saving model ...
Validation loss decreased (0.092713 --> 0.092630).  Saving model ...
Validation loss decreased (0.092630 --> 0.092549).  Saving model ...
Validation loss decreased (0.092549 --> 0.092469).  Saving model ...
Validation loss decreased (0.092469 --> 0.092391).  Saving model ...
Validation loss decreased (0.092391 --> 0.092316).  Saving model ...
Validation loss decreased (0.092316 --> 0.092242).  Saving model ...
Validation loss decreased (0.092242 --> 0.092168).  Saving model ...
Validation loss decreased (0.092168 --> 0.092095).  Saving model ...
Validation loss decreased (0.092095 --> 0.092024).  Saving model ...
Validation loss decreased (0.092024 --> 0.091952).  Saving model ...
Validation loss decreased (0.091952 --> 0.091880).  Saving model ...
Validation loss decreased (0.091880 --> 0.091807).  Saving model ...
Validation loss decreased (0.091807 --> 0.091736).  Saving model ...
Validation loss decreased (0.091736 --> 0.091662).  Saving model ...
Validation loss decreased (0.091662 --> 0.091590).  Saving model ...
Validation loss decreased (0.091590 --> 0.091521).  Saving model ...
Validation loss decreased (0.091521 --> 0.091454).  Saving model ...
Validation loss decreased (0.091454 --> 0.091386).  Saving model ...
Validation loss decreased (0.091386 --> 0.091321).  Saving model ...
Validation loss decreased (0.091321 --> 0.091255).  Saving model ...
Validation loss decreased (0.091255 --> 0.091191).  Saving model ...
Validation loss decreased (0.091191 --> 0.091129).  Saving model ...
Validation loss decreased (0.091129 --> 0.091069).  Saving model ...
Validation loss decreased (0.091069 --> 0.091010).  Saving model ...
Validation loss decreased (0.091010 --> 0.090952).  Saving model ...
Validation loss decreased (0.090952 --> 0.090896).  Saving model ...
Validation loss decreased (0.090896 --> 0.090841).  Saving model ...
Validation loss decreased (0.090841 --> 0.090786).  Saving model ...
Validation loss decreased (0.090786 --> 0.090733).  Saving model ...
Validation loss decreased (0.090733 --> 0.090679).  Saving model ...
Validation loss decreased (0.090679 --> 0.090626).  Saving model ...
Validation loss decreased (0.090626 --> 0.090573).  Saving model ...
Validation loss decreased (0.090573 --> 0.090519).  Saving model ...
Validation loss decreased (0.090519 --> 0.090463).  Saving model ...
Validation loss decreased (0.090463 --> 0.090406).  Saving model ...
Validation loss decreased (0.090406 --> 0.090348).  Saving model ...
Validation loss decreased (0.090348 --> 0.090289).  Saving model ...
Validation loss decreased (0.090289 --> 0.090231).  Saving model ...
Validation loss decreased (0.090231 --> 0.090171).  Saving model ...
Validation loss decreased (0.090171 --> 0.090112).  Saving model ...
Validation loss decreased (0.090112 --> 0.090051).  Saving model ...
Validation loss decreased (0.090051 --> 0.089989).  Saving model ...
Validation loss decreased (0.089989 --> 0.089927).  Saving model ...
epoch 701, loss 0.2238, train acc 98.18%, f1 0.9818, precision 0.9818, recall 0.9818, auc 0.9818
Validation loss decreased (0.089927 --> 0.089869).  Saving model ...
Validation loss decreased (0.089869 --> 0.089813).  Saving model ...
Validation loss decreased (0.089813 --> 0.089758).  Saving model ...
Validation loss decreased (0.089758 --> 0.089703).  Saving model ...
Validation loss decreased (0.089703 --> 0.089648).  Saving model ...
Validation loss decreased (0.089648 --> 0.089591).  Saving model ...
Validation loss decreased (0.089591 --> 0.089535).  Saving model ...
Validation loss decreased (0.089535 --> 0.089481).  Saving model ...
Validation loss decreased (0.089481 --> 0.089427).  Saving model ...
Validation loss decreased (0.089427 --> 0.089374).  Saving model ...
Validation loss decreased (0.089374 --> 0.089322).  Saving model ...
Validation loss decreased (0.089322 --> 0.089272).  Saving model ...
Validation loss decreased (0.089272 --> 0.089225).  Saving model ...
Validation loss decreased (0.089225 --> 0.089178).  Saving model ...
Validation loss decreased (0.089178 --> 0.089132).  Saving model ...
Validation loss decreased (0.089132 --> 0.089086).  Saving model ...
Validation loss decreased (0.089086 --> 0.089041).  Saving model ...
Validation loss decreased (0.089041 --> 0.088995).  Saving model ...
Validation loss decreased (0.088995 --> 0.088951).  Saving model ...
Validation loss decreased (0.088951 --> 0.088907).  Saving model ...
Validation loss decreased (0.088907 --> 0.088862).  Saving model ...
Validation loss decreased (0.088862 --> 0.088819).  Saving model ...
Validation loss decreased (0.088819 --> 0.088774).  Saving model ...
Validation loss decreased (0.088774 --> 0.088731).  Saving model ...
Validation loss decreased (0.088731 --> 0.088689).  Saving model ...
Validation loss decreased (0.088689 --> 0.088647).  Saving model ...
Validation loss decreased (0.088647 --> 0.088605).  Saving model ...
Validation loss decreased (0.088605 --> 0.088564).  Saving model ...
Validation loss decreased (0.088564 --> 0.088522).  Saving model ...
Validation loss decreased (0.088522 --> 0.088477).  Saving model ...
Validation loss decreased (0.088477 --> 0.088434).  Saving model ...
Validation loss decreased (0.088434 --> 0.088391).  Saving model ...
Validation loss decreased (0.088391 --> 0.088349).  Saving model ...
Validation loss decreased (0.088349 --> 0.088307).  Saving model ...
Validation loss decreased (0.088307 --> 0.088267).  Saving model ...
Validation loss decreased (0.088267 --> 0.088226).  Saving model ...
Validation loss decreased (0.088226 --> 0.088185).  Saving model ...
Validation loss decreased (0.088185 --> 0.088145).  Saving model ...
Validation loss decreased (0.088145 --> 0.088106).  Saving model ...
Validation loss decreased (0.088106 --> 0.088065).  Saving model ...
Validation loss decreased (0.088065 --> 0.088024).  Saving model ...
Validation loss decreased (0.088024 --> 0.087984).  Saving model ...
Validation loss decreased (0.087984 --> 0.087943).  Saving model ...
Validation loss decreased (0.087943 --> 0.087900).  Saving model ...
Validation loss decreased (0.087900 --> 0.087858).  Saving model ...
Validation loss decreased (0.087858 --> 0.087814).  Saving model ...
Validation loss decreased (0.087814 --> 0.087770).  Saving model ...
Validation loss decreased (0.087770 --> 0.087724).  Saving model ...
Validation loss decreased (0.087724 --> 0.087681).  Saving model ...
Validation loss decreased (0.087681 --> 0.087638).  Saving model ...
Validation loss decreased (0.087638 --> 0.087595).  Saving model ...
Validation loss decreased (0.087595 --> 0.087551).  Saving model ...
Validation loss decreased (0.087551 --> 0.087510).  Saving model ...
Validation loss decreased (0.087510 --> 0.087470).  Saving model ...
Validation loss decreased (0.087470 --> 0.087432).  Saving model ...
Validation loss decreased (0.087432 --> 0.087395).  Saving model ...
Validation loss decreased (0.087395 --> 0.087361).  Saving model ...
Validation loss decreased (0.087361 --> 0.087329).  Saving model ...
Validation loss decreased (0.087329 --> 0.087295).  Saving model ...
Validation loss decreased (0.087295 --> 0.087264).  Saving model ...
Validation loss decreased (0.087264 --> 0.087233).  Saving model ...
Validation loss decreased (0.087233 --> 0.087203).  Saving model ...
Validation loss decreased (0.087203 --> 0.087174).  Saving model ...
Validation loss decreased (0.087174 --> 0.087143).  Saving model ...
Validation loss decreased (0.087143 --> 0.087112).  Saving model ...
Validation loss decreased (0.087112 --> 0.087083).  Saving model ...
Validation loss decreased (0.087083 --> 0.087053).  Saving model ...
Validation loss decreased (0.087053 --> 0.087025).  Saving model ...
Validation loss decreased (0.087025 --> 0.086994).  Saving model ...
Validation loss decreased (0.086994 --> 0.086965).  Saving model ...
Validation loss decreased (0.086965 --> 0.086936).  Saving model ...
Validation loss decreased (0.086936 --> 0.086908).  Saving model ...
Validation loss decreased (0.086908 --> 0.086881).  Saving model ...
Validation loss decreased (0.086881 --> 0.086853).  Saving model ...
Validation loss decreased (0.086853 --> 0.086825).  Saving model ...
Validation loss decreased (0.086825 --> 0.086796).  Saving model ...
Validation loss decreased (0.086796 --> 0.086766).  Saving model ...
Validation loss decreased (0.086766 --> 0.086737).  Saving model ...
Validation loss decreased (0.086737 --> 0.086708).  Saving model ...
Validation loss decreased (0.086708 --> 0.086678).  Saving model ...
Validation loss decreased (0.086678 --> 0.086651).  Saving model ...
Validation loss decreased (0.086651 --> 0.086623).  Saving model ...
Validation loss decreased (0.086623 --> 0.086596).  Saving model ...
Validation loss decreased (0.086596 --> 0.086569).  Saving model ...
Validation loss decreased (0.086569 --> 0.086541).  Saving model ...
Validation loss decreased (0.086541 --> 0.086514).  Saving model ...
Validation loss decreased (0.086514 --> 0.086488).  Saving model ...
Validation loss decreased (0.086488 --> 0.086464).  Saving model ...
Validation loss decreased (0.086464 --> 0.086440).  Saving model ...
Validation loss decreased (0.086440 --> 0.086418).  Saving model ...
Validation loss decreased (0.086418 --> 0.086394).  Saving model ...
Validation loss decreased (0.086394 --> 0.086373).  Saving model ...
Validation loss decreased (0.086373 --> 0.086352).  Saving model ...
Validation loss decreased (0.086352 --> 0.086331).  Saving model ...
Validation loss decreased (0.086331 --> 0.086310).  Saving model ...
Validation loss decreased (0.086310 --> 0.086290).  Saving model ...
Validation loss decreased (0.086290 --> 0.086269).  Saving model ...
Validation loss decreased (0.086269 --> 0.086248).  Saving model ...
Validation loss decreased (0.086248 --> 0.086226).  Saving model ...
Validation loss decreased (0.086226 --> 0.086205).  Saving model ...
epoch 801, loss 0.2177, train acc 98.18%, f1 0.9818, precision 0.9818, recall 0.9818, auc 0.9818
Validation loss decreased (0.086205 --> 0.086184).  Saving model ...
Validation loss decreased (0.086184 --> 0.086162).  Saving model ...
Validation loss decreased (0.086162 --> 0.086140).  Saving model ...
Validation loss decreased (0.086140 --> 0.086119).  Saving model ...
Validation loss decreased (0.086119 --> 0.086099).  Saving model ...
Validation loss decreased (0.086099 --> 0.086077).  Saving model ...
Validation loss decreased (0.086077 --> 0.086055).  Saving model ...
Validation loss decreased (0.086055 --> 0.086033).  Saving model ...
Validation loss decreased (0.086033 --> 0.086012).  Saving model ...
Validation loss decreased (0.086012 --> 0.085988).  Saving model ...
Validation loss decreased (0.085988 --> 0.085965).  Saving model ...
Validation loss decreased (0.085965 --> 0.085942).  Saving model ...
Validation loss decreased (0.085942 --> 0.085919).  Saving model ...
Validation loss decreased (0.085919 --> 0.085896).  Saving model ...
Validation loss decreased (0.085896 --> 0.085875).  Saving model ...
Validation loss decreased (0.085875 --> 0.085853).  Saving model ...
Validation loss decreased (0.085853 --> 0.085834).  Saving model ...
Validation loss decreased (0.085834 --> 0.085815).  Saving model ...
Validation loss decreased (0.085815 --> 0.085795).  Saving model ...
Validation loss decreased (0.085795 --> 0.085773).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.085773 --> 0.085750).  Saving model ...
Validation loss decreased (0.085750 --> 0.085727).  Saving model ...
Validation loss decreased (0.085727 --> 0.085706).  Saving model ...
Validation loss decreased (0.085706 --> 0.085686).  Saving model ...
Validation loss decreased (0.085686 --> 0.085667).  Saving model ...
Validation loss decreased (0.085667 --> 0.085648).  Saving model ...
Validation loss decreased (0.085648 --> 0.085627).  Saving model ...
Validation loss decreased (0.085627 --> 0.085603).  Saving model ...
Validation loss decreased (0.085603 --> 0.085580).  Saving model ...
Validation loss decreased (0.085580 --> 0.085559).  Saving model ...
Validation loss decreased (0.085559 --> 0.085537).  Saving model ...
Validation loss decreased (0.085537 --> 0.085517).  Saving model ...
Validation loss decreased (0.085517 --> 0.085499).  Saving model ...
Validation loss decreased (0.085499 --> 0.085483).  Saving model ...
Validation loss decreased (0.085483 --> 0.085467).  Saving model ...
Validation loss decreased (0.085467 --> 0.085451).  Saving model ...
Validation loss decreased (0.085451 --> 0.085437).  Saving model ...
Validation loss decreased (0.085437 --> 0.085426).  Saving model ...
Validation loss decreased (0.085426 --> 0.085416).  Saving model ...
Validation loss decreased (0.085416 --> 0.085407).  Saving model ...
Validation loss decreased (0.085407 --> 0.085398).  Saving model ...
Validation loss decreased (0.085398 --> 0.085390).  Saving model ...
Validation loss decreased (0.085390 --> 0.085382).  Saving model ...
Validation loss decreased (0.085382 --> 0.085375).  Saving model ...
Validation loss decreased (0.085375 --> 0.085367).  Saving model ...
Validation loss decreased (0.085367 --> 0.085357).  Saving model ...
Validation loss decreased (0.085357 --> 0.085346).  Saving model ...
Validation loss decreased (0.085346 --> 0.085336).  Saving model ...
Validation loss decreased (0.085336 --> 0.085326).  Saving model ...
Validation loss decreased (0.085326 --> 0.085316).  Saving model ...
Validation loss decreased (0.085316 --> 0.085304).  Saving model ...
Validation loss decreased (0.085304 --> 0.085294).  Saving model ...
Validation loss decreased (0.085294 --> 0.085282).  Saving model ...
Validation loss decreased (0.085282 --> 0.085271).  Saving model ...
Validation loss decreased (0.085271 --> 0.085260).  Saving model ...
Validation loss decreased (0.085260 --> 0.085252).  Saving model ...
Validation loss decreased (0.085252 --> 0.085244).  Saving model ...
Validation loss decreased (0.085244 --> 0.085239).  Saving model ...
Validation loss decreased (0.085239 --> 0.085231).  Saving model ...
Validation loss decreased (0.085231 --> 0.085223).  Saving model ...
Validation loss decreased (0.085223 --> 0.085216).  Saving model ...
Validation loss decreased (0.085216 --> 0.085206).  Saving model ...
Validation loss decreased (0.085206 --> 0.085197).  Saving model ...
Validation loss decreased (0.085197 --> 0.085188).  Saving model ...
Validation loss decreased (0.085188 --> 0.085178).  Saving model ...
Validation loss decreased (0.085178 --> 0.085171).  Saving model ...
Validation loss decreased (0.085171 --> 0.085163).  Saving model ...
Validation loss decreased (0.085163 --> 0.085157).  Saving model ...
Validation loss decreased (0.085157 --> 0.085152).  Saving model ...
Validation loss decreased (0.085152 --> 0.085150).  Saving model ...
Validation loss decreased (0.085150 --> 0.085149).  Saving model ...
Validation loss decreased (0.085149 --> 0.085147).  Saving model ...
Validation loss decreased (0.085147 --> 0.085144).  Saving model ...
Validation loss decreased (0.085144 --> 0.085141).  Saving model ...
Validation loss decreased (0.085141 --> 0.085140).  Saving model ...
Validation loss decreased (0.085140 --> 0.085138).  Saving model ...
Validation loss decreased (0.085138 --> 0.085136).  Saving model ...
Validation loss decreased (0.085136 --> 0.085135).  Saving model ...
Validation loss decreased (0.085135 --> 0.085134).  Saving model ...
Validation loss decreased (0.085134 --> 0.085130).  Saving model ...
Validation loss decreased (0.085130 --> 0.085126).  Saving model ...
Validation loss decreased (0.085126 --> 0.085124).  Saving model ...
Validation loss decreased (0.085124 --> 0.085123).  Saving model ...
Validation loss decreased (0.085123 --> 0.085121).  Saving model ...
Validation loss decreased (0.085121 --> 0.085119).  Saving model ...
Validation loss decreased (0.085119 --> 0.085117).  Saving model ...
Validation loss decreased (0.085117 --> 0.085112).  Saving model ...
Validation loss decreased (0.085112 --> 0.085107).  Saving model ...
Validation loss decreased (0.085107 --> 0.085103).  Saving model ...
Validation loss decreased (0.085103 --> 0.085101).  Saving model ...
Validation loss decreased (0.085101 --> 0.085096).  Saving model ...
Validation loss decreased (0.085096 --> 0.085094).  Saving model ...
Validation loss decreased (0.085094 --> 0.085090).  Saving model ...
Validation loss decreased (0.085090 --> 0.085085).  Saving model ...
Validation loss decreased (0.085085 --> 0.085082).  Saving model ...
Validation loss decreased (0.085082 --> 0.085080).  Saving model ...
Validation loss decreased (0.085080 --> 0.085078).  Saving model ...
Validation loss decreased (0.085078 --> 0.085076).  Saving model ...
Validation loss decreased (0.085076 --> 0.085076).  Saving model ...
EarlyStopping counter: 1 out of 20
epoch 901, loss 0.2120, train acc 98.18%, f1 0.9818, precision 0.9818, recall 0.9818, auc 0.9818
Validation loss decreased (0.085076 --> 0.085074).  Saving model ...
Validation loss decreased (0.085074 --> 0.085072).  Saving model ...
Validation loss decreased (0.085072 --> 0.085072).  Saving model ...
Validation loss decreased (0.085072 --> 0.085071).  Saving model ...
Validation loss decreased (0.085071 --> 0.085070).  Saving model ...
Validation loss decreased (0.085070 --> 0.085068).  Saving model ...
Validation loss decreased (0.085068 --> 0.085066).  Saving model ...
Validation loss decreased (0.085066 --> 0.085064).  Saving model ...
Validation loss decreased (0.085064 --> 0.085063).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 929, loss 0.2115, train acc 98.18%, f1 0.9818, precision 0.9818, recall 0.9818, auc 0.9818



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_abalone19/standlization_data/abalone19_std_train_5.csv
./test_abalone19/standlization_data/abalone19_std_test_5.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_abalone19/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_5
./test_abalone19/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.8950542822677925

the Fscore is 0.05434782608695652

the precision is 0.027932960893854747

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_abalone19/standlization_data/abalone19_std_train_5.csv
./test_abalone19/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_5
----------------------



epoch 1, loss 0.6934, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5232, train acc 75.02%, f1 0.7502, precision 0.7501, recall 0.7503, auc 0.7502
epoch 201, loss 0.4404, train acc 79.32%, f1 0.7936, precision 0.7922, recall 0.7949, auc 0.7932
epoch 301, loss 0.3514, train acc 86.49%, f1 0.8649, precision 0.8645, recall 0.8653, auc 0.8649
epoch 401, loss 0.2816, train acc 90.47%, f1 0.9047, precision 0.9046, recall 0.9049, auc 0.9047
epoch 501, loss 0.2457, train acc 91.71%, f1 0.9171, precision 0.9169, recall 0.9173, auc 0.9171
epoch 601, loss 0.2280, train acc 92.17%, f1 0.9217, precision 0.9214, recall 0.9221, auc 0.9217
epoch 701, loss 0.2185, train acc 92.48%, f1 0.9248, precision 0.9245, recall 0.9251, auc 0.9248
epoch 801, loss 0.2126, train acc 92.63%, f1 0.9263, precision 0.9259, recall 0.9267, auc 0.9263
epoch 901, loss 0.2078, train acc 92.79%, f1 0.9279, precision 0.9275, recall 0.9283, auc 0.9279
epoch 1001, loss 0.2022, train acc 92.91%, f1 0.9291, precision 0.9287, recall 0.9295, auc 0.9291
epoch 1101, loss 0.1959, train acc 93.05%, f1 0.9306, precision 0.9300, recall 0.9311, auc 0.9305
epoch 1201, loss 0.1893, train acc 93.23%, f1 0.9324, precision 0.9319, recall 0.9329, auc 0.9323
epoch 1301, loss 0.1831, train acc 93.41%, f1 0.9341, precision 0.9335, recall 0.9347, auc 0.9341
epoch 1401, loss 0.1775, train acc 93.57%, f1 0.9357, precision 0.9352, recall 0.9362, auc 0.9357
epoch 1501, loss 0.1725, train acc 93.70%, f1 0.9371, precision 0.9366, recall 0.9375, auc 0.9370
epoch 1601, loss 0.1678, train acc 93.81%, f1 0.9381, precision 0.9376, recall 0.9386, auc 0.9381
epoch 1701, loss 0.1634, train acc 93.88%, f1 0.9389, precision 0.9384, recall 0.9393, auc 0.9388
epoch 1801, loss 0.1598, train acc 93.98%, f1 0.9398, precision 0.9393, recall 0.9403, auc 0.9398
epoch 1901, loss 0.1559, train acc 94.05%, f1 0.9406, precision 0.9400, recall 0.9411, auc 0.9405
epoch 2001, loss 0.1520, train acc 94.14%, f1 0.9415, precision 0.9410, recall 0.9419, auc 0.9414
epoch 2101, loss 0.1482, train acc 94.25%, f1 0.9425, precision 0.9419, recall 0.9431, auc 0.9425
epoch 2201, loss 0.1447, train acc 94.32%, f1 0.9432, precision 0.9427, recall 0.9437, auc 0.9432
epoch 2301, loss 0.1412, train acc 94.39%, f1 0.9439, precision 0.9433, recall 0.9445, auc 0.9439
epoch 2401, loss 0.1381, train acc 94.47%, f1 0.9447, precision 0.9440, recall 0.9454, auc 0.9447
epoch 2501, loss 0.1350, train acc 94.53%, f1 0.9454, precision 0.9448, recall 0.9459, auc 0.9453
epoch 2601, loss 0.1322, train acc 94.61%, f1 0.9461, precision 0.9455, recall 0.9467, auc 0.9461
epoch 2701, loss 0.1294, train acc 94.68%, f1 0.9469, precision 0.9463, recall 0.9475, auc 0.9468
epoch 2801, loss 0.1269, train acc 94.75%, f1 0.9475, precision 0.9469, recall 0.9481, auc 0.9475
epoch 2901, loss 0.1244, train acc 94.81%, f1 0.9481, precision 0.9475, recall 0.9487, auc 0.9481
epoch 3001, loss 0.1219, train acc 94.88%, f1 0.9488, precision 0.9484, recall 0.9492, auc 0.9488
epoch 3101, loss 0.1193, train acc 94.94%, f1 0.9495, precision 0.9491, recall 0.9498, auc 0.9494
epoch 3201, loss 0.1171, train acc 95.02%, f1 0.9502, precision 0.9500, recall 0.9505, auc 0.9502
epoch 3301, loss 0.1147, train acc 95.10%, f1 0.9510, precision 0.9507, recall 0.9513, auc 0.9510
epoch 3401, loss 0.1126, train acc 95.19%, f1 0.9519, precision 0.9518, recall 0.9521, auc 0.9519
epoch 3501, loss 0.1104, train acc 95.25%, f1 0.9525, precision 0.9524, recall 0.9526, auc 0.9525
epoch 3601, loss 0.1084, train acc 95.32%, f1 0.9532, precision 0.9529, recall 0.9536, auc 0.9532
epoch 3701, loss 0.1064, train acc 95.38%, f1 0.9538, precision 0.9535, recall 0.9542, auc 0.9538
epoch 3801, loss 0.1043, train acc 95.44%, f1 0.9544, precision 0.9540, recall 0.9549, auc 0.9544
epoch 3901, loss 0.1023, train acc 95.53%, f1 0.9553, precision 0.9550, recall 0.9555, auc 0.9553
epoch 4001, loss 0.1003, train acc 95.61%, f1 0.9561, precision 0.9559, recall 0.9564, auc 0.9561
epoch 4101, loss 0.0984, train acc 95.69%, f1 0.9569, precision 0.9567, recall 0.9571, auc 0.9569
epoch 4201, loss 0.0964, train acc 95.78%, f1 0.9578, precision 0.9575, recall 0.9580, auc 0.9578
epoch 4301, loss 0.0944, train acc 95.85%, f1 0.9585, precision 0.9582, recall 0.9588, auc 0.9585
epoch 4401, loss 0.0927, train acc 95.93%, f1 0.9593, precision 0.9590, recall 0.9596, auc 0.9593
epoch 4501, loss 0.0908, train acc 96.01%, f1 0.9601, precision 0.9598, recall 0.9603, auc 0.9601
epoch 4601, loss 0.0890, train acc 96.07%, f1 0.9607, precision 0.9605, recall 0.9608, auc 0.9607
epoch 4701, loss 0.0872, train acc 96.13%, f1 0.9613, precision 0.9611, recall 0.9614, auc 0.9613
epoch 4801, loss 0.0855, train acc 96.20%, f1 0.9620, precision 0.9619, recall 0.9620, auc 0.9620
epoch 4901, loss 0.0837, train acc 96.28%, f1 0.9628, precision 0.9627, recall 0.9629, auc 0.9628
epoch 5001, loss 0.0819, train acc 96.36%, f1 0.9636, precision 0.9635, recall 0.9636, auc 0.9636
epoch 5101, loss 0.0802, train acc 96.43%, f1 0.9643, precision 0.9643, recall 0.9642, auc 0.9643
epoch 5201, loss 0.0781, train acc 96.51%, f1 0.9651, precision 0.9653, recall 0.9649, auc 0.9651
epoch 5301, loss 0.0766, train acc 96.59%, f1 0.9659, precision 0.9661, recall 0.9657, auc 0.9659
epoch 5401, loss 0.0748, train acc 96.68%, f1 0.9668, precision 0.9670, recall 0.9666, auc 0.9668
epoch 5501, loss 0.0729, train acc 96.77%, f1 0.9677, precision 0.9678, recall 0.9675, auc 0.9677
epoch 5601, loss 0.0711, train acc 96.86%, f1 0.9686, precision 0.9687, recall 0.9685, auc 0.9686
epoch 5701, loss 0.0690, train acc 96.96%, f1 0.9696, precision 0.9698, recall 0.9694, auc 0.9696
epoch 5801, loss 0.0672, train acc 97.04%, f1 0.9704, precision 0.9706, recall 0.9701, auc 0.9704
epoch 5901, loss 0.0654, train acc 97.14%, f1 0.9714, precision 0.9715, recall 0.9712, auc 0.9714
epoch 6001, loss 0.0635, train acc 97.23%, f1 0.9723, precision 0.9724, recall 0.9722, auc 0.9723
epoch 6101, loss 0.0616, train acc 97.33%, f1 0.9733, precision 0.9733, recall 0.9733, auc 0.9733
epoch 6201, loss 0.0596, train acc 97.41%, f1 0.9741, precision 0.9741, recall 0.9742, auc 0.9741
epoch 6301, loss 0.0578, train acc 97.51%, f1 0.9751, precision 0.9751, recall 0.9752, auc 0.9751
epoch 6401, loss 0.0559, train acc 97.61%, f1 0.9761, precision 0.9759, recall 0.9763, auc 0.9761
epoch 6501, loss 0.0540, train acc 97.72%, f1 0.9772, precision 0.9771, recall 0.9773, auc 0.9772
epoch 6601, loss 0.0522, train acc 97.82%, f1 0.9782, precision 0.9782, recall 0.9782, auc 0.9782
epoch 6701, loss 0.0504, train acc 97.92%, f1 0.9792, precision 0.9792, recall 0.9791, auc 0.9792
epoch 6801, loss 0.0487, train acc 98.01%, f1 0.9801, precision 0.9800, recall 0.9802, auc 0.9801
epoch 6901, loss 0.0470, train acc 98.11%, f1 0.9811, precision 0.9811, recall 0.9812, auc 0.9811
epoch 7001, loss 0.0453, train acc 98.21%, f1 0.9821, precision 0.9820, recall 0.9821, auc 0.9821
epoch 7101, loss 0.0437, train acc 98.29%, f1 0.9829, precision 0.9827, recall 0.9830, auc 0.9829
epoch 7201, loss 0.0421, train acc 98.36%, f1 0.9836, precision 0.9832, recall 0.9840, auc 0.9836
epoch 7301, loss 0.0406, train acc 98.44%, f1 0.9844, precision 0.9839, recall 0.9849, auc 0.9844
epoch 7401, loss 0.0390, train acc 98.53%, f1 0.9853, precision 0.9847, recall 0.9859, auc 0.9853
epoch 7501, loss 0.0375, train acc 98.61%, f1 0.9861, precision 0.9855, recall 0.9868, auc 0.9861
epoch 7601, loss 0.0360, train acc 98.70%, f1 0.9870, precision 0.9863, recall 0.9877, auc 0.9870
epoch 7701, loss 0.0346, train acc 98.77%, f1 0.9877, precision 0.9870, recall 0.9885, auc 0.9877
epoch 7801, loss 0.0332, train acc 98.83%, f1 0.9883, precision 0.9876, recall 0.9891, auc 0.9883
epoch 7901, loss 0.0320, train acc 98.90%, f1 0.9890, precision 0.9882, recall 0.9897, auc 0.9890
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_abalone19/standlization_data/abalone19_std_train_5.csv
./test_abalone19/standlization_data/abalone19_std_test_5.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_abalone19/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_5
./test_abalone19/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.674065138721351

the Fscore is 0.07999999999999999

the precision is 0.044444444444444446

the recall is 0.4

Done
train_mlp_7_1.sh: line 20: 19109 Terminated              python3 ./classifier_MLP/train_MLP.py dataset_name=abalone19 dataset_index=5 record_index=1 device_id=7 train_method=MLP_concat_Mirror_5000
