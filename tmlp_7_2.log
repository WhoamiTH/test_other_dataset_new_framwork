nohup: ignoring input
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_5
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693110).  Saving model ...
Validation loss decreased (0.693110 --> 0.693032).  Saving model ...
Validation loss decreased (0.693032 --> 0.692963).  Saving model ...
Validation loss decreased (0.692963 --> 0.692886).  Saving model ...
Validation loss decreased (0.692886 --> 0.692798).  Saving model ...
Validation loss decreased (0.692798 --> 0.692691).  Saving model ...
Validation loss decreased (0.692691 --> 0.692566).  Saving model ...
Validation loss decreased (0.692566 --> 0.692434).  Saving model ...
Validation loss decreased (0.692434 --> 0.692294).  Saving model ...
Validation loss decreased (0.692294 --> 0.692132).  Saving model ...
Validation loss decreased (0.692132 --> 0.691937).  Saving model ...
Validation loss decreased (0.691937 --> 0.691714).  Saving model ...
Validation loss decreased (0.691714 --> 0.691466).  Saving model ...
Validation loss decreased (0.691466 --> 0.691188).  Saving model ...
Validation loss decreased (0.691188 --> 0.690886).  Saving model ...
Validation loss decreased (0.690886 --> 0.690564).  Saving model ...
Validation loss decreased (0.690564 --> 0.690223).  Saving model ...
Validation loss decreased (0.690223 --> 0.689842).  Saving model ...
Validation loss decreased (0.689842 --> 0.689432).  Saving model ...
Validation loss decreased (0.689432 --> 0.688980).  Saving model ...
Validation loss decreased (0.688980 --> 0.688514).  Saving model ...
Validation loss decreased (0.688514 --> 0.688013).  Saving model ...
Validation loss decreased (0.688013 --> 0.687473).  Saving model ...
Validation loss decreased (0.687473 --> 0.686900).  Saving model ...
Validation loss decreased (0.686900 --> 0.686281).  Saving model ...
Validation loss decreased (0.686281 --> 0.685609).  Saving model ...
Validation loss decreased (0.685609 --> 0.684893).  Saving model ...
Validation loss decreased (0.684893 --> 0.684140).  Saving model ...
Validation loss decreased (0.684140 --> 0.683344).  Saving model ...
Validation loss decreased (0.683344 --> 0.682514).  Saving model ...
Validation loss decreased (0.682514 --> 0.681647).  Saving model ...
Validation loss decreased (0.681647 --> 0.680738).  Saving model ...
Validation loss decreased (0.680738 --> 0.679769).  Saving model ...
Validation loss decreased (0.679769 --> 0.678769).  Saving model ...
Validation loss decreased (0.678769 --> 0.677723).  Saving model ...
Validation loss decreased (0.677723 --> 0.676641).  Saving model ...
Validation loss decreased (0.676641 --> 0.675525).  Saving model ...
Validation loss decreased (0.675525 --> 0.674393).  Saving model ...
Validation loss decreased (0.674393 --> 0.673243).  Saving model ...
Validation loss decreased (0.673243 --> 0.672043).  Saving model ...
Validation loss decreased (0.672043 --> 0.670808).  Saving model ...
Validation loss decreased (0.670808 --> 0.669501).  Saving model ...
Validation loss decreased (0.669501 --> 0.668179).  Saving model ...
Validation loss decreased (0.668179 --> 0.666812).  Saving model ...
Validation loss decreased (0.666812 --> 0.665444).  Saving model ...
Validation loss decreased (0.665444 --> 0.664073).  Saving model ...
Validation loss decreased (0.664073 --> 0.662641).  Saving model ...
Validation loss decreased (0.662641 --> 0.661189).  Saving model ...
Validation loss decreased (0.661189 --> 0.659665).  Saving model ...
Validation loss decreased (0.659665 --> 0.658117).  Saving model ...
Validation loss decreased (0.658117 --> 0.656513).  Saving model ...
Validation loss decreased (0.656513 --> 0.654884).  Saving model ...
Validation loss decreased (0.654884 --> 0.653201).  Saving model ...
Validation loss decreased (0.653201 --> 0.651470).  Saving model ...
Validation loss decreased (0.651470 --> 0.649697).  Saving model ...
Validation loss decreased (0.649697 --> 0.647886).  Saving model ...
Validation loss decreased (0.647886 --> 0.646068).  Saving model ...
Validation loss decreased (0.646068 --> 0.644218).  Saving model ...
Validation loss decreased (0.644218 --> 0.642339).  Saving model ...
Validation loss decreased (0.642339 --> 0.640414).  Saving model ...
Validation loss decreased (0.640414 --> 0.638475).  Saving model ...
Validation loss decreased (0.638475 --> 0.636437).  Saving model ...
Validation loss decreased (0.636437 --> 0.634365).  Saving model ...
Validation loss decreased (0.634365 --> 0.632206).  Saving model ...
Validation loss decreased (0.632206 --> 0.630028).  Saving model ...
Validation loss decreased (0.630028 --> 0.627943).  Saving model ...
Validation loss decreased (0.627943 --> 0.625790).  Saving model ...
Validation loss decreased (0.625790 --> 0.623704).  Saving model ...
Validation loss decreased (0.623704 --> 0.621652).  Saving model ...
Validation loss decreased (0.621652 --> 0.619518).  Saving model ...
Validation loss decreased (0.619518 --> 0.617379).  Saving model ...
Validation loss decreased (0.617379 --> 0.615208).  Saving model ...
Validation loss decreased (0.615208 --> 0.613052).  Saving model ...
Validation loss decreased (0.613052 --> 0.610849).  Saving model ...
Validation loss decreased (0.610849 --> 0.608619).  Saving model ...
Validation loss decreased (0.608619 --> 0.606378).  Saving model ...
Validation loss decreased (0.606378 --> 0.604139).  Saving model ...
Validation loss decreased (0.604139 --> 0.601877).  Saving model ...
Validation loss decreased (0.601877 --> 0.599658).  Saving model ...
Validation loss decreased (0.599658 --> 0.597504).  Saving model ...
Validation loss decreased (0.597504 --> 0.595379).  Saving model ...
Validation loss decreased (0.595379 --> 0.593209).  Saving model ...
Validation loss decreased (0.593209 --> 0.591080).  Saving model ...
Validation loss decreased (0.591080 --> 0.588955).  Saving model ...
Validation loss decreased (0.588955 --> 0.586747).  Saving model ...
Validation loss decreased (0.586747 --> 0.584539).  Saving model ...
Validation loss decreased (0.584539 --> 0.582317).  Saving model ...
Validation loss decreased (0.582317 --> 0.580054).  Saving model ...
Validation loss decreased (0.580054 --> 0.577769).  Saving model ...
Validation loss decreased (0.577769 --> 0.575531).  Saving model ...
Validation loss decreased (0.575531 --> 0.573252).  Saving model ...
Validation loss decreased (0.573252 --> 0.571007).  Saving model ...
Validation loss decreased (0.571007 --> 0.568849).  Saving model ...
Validation loss decreased (0.568849 --> 0.566715).  Saving model ...
Validation loss decreased (0.566715 --> 0.564581).  Saving model ...
Validation loss decreased (0.564581 --> 0.562461).  Saving model ...
Validation loss decreased (0.562461 --> 0.560429).  Saving model ...
Validation loss decreased (0.560429 --> 0.558400).  Saving model ...
Validation loss decreased (0.558400 --> 0.556383).  Saving model ...
Validation loss decreased (0.556383 --> 0.554338).  Saving model ...
epoch 101, loss 0.5872, train acc 80.00%, f1 0.8000, precision 0.8000, recall 0.8000, auc 0.8000
Validation loss decreased (0.554338 --> 0.552406).  Saving model ...
Validation loss decreased (0.552406 --> 0.550463).  Saving model ...
Validation loss decreased (0.550463 --> 0.548492).  Saving model ...
Validation loss decreased (0.548492 --> 0.546549).  Saving model ...
Validation loss decreased (0.546549 --> 0.544648).  Saving model ...
Validation loss decreased (0.544648 --> 0.542803).  Saving model ...
Validation loss decreased (0.542803 --> 0.540935).  Saving model ...
Validation loss decreased (0.540935 --> 0.539025).  Saving model ...
Validation loss decreased (0.539025 --> 0.537099).  Saving model ...
Validation loss decreased (0.537099 --> 0.535132).  Saving model ...
Validation loss decreased (0.535132 --> 0.533204).  Saving model ...
Validation loss decreased (0.533204 --> 0.531316).  Saving model ...
Validation loss decreased (0.531316 --> 0.529432).  Saving model ...
Validation loss decreased (0.529432 --> 0.527555).  Saving model ...
Validation loss decreased (0.527555 --> 0.525558).  Saving model ...
Validation loss decreased (0.525558 --> 0.523725).  Saving model ...
Validation loss decreased (0.523725 --> 0.521922).  Saving model ...
Validation loss decreased (0.521922 --> 0.520193).  Saving model ...
Validation loss decreased (0.520193 --> 0.518471).  Saving model ...
Validation loss decreased (0.518471 --> 0.516792).  Saving model ...
Validation loss decreased (0.516792 --> 0.514955).  Saving model ...
Validation loss decreased (0.514955 --> 0.513113).  Saving model ...
Validation loss decreased (0.513113 --> 0.511271).  Saving model ...
Validation loss decreased (0.511271 --> 0.509398).  Saving model ...
Validation loss decreased (0.509398 --> 0.507557).  Saving model ...
Validation loss decreased (0.507557 --> 0.505728).  Saving model ...
Validation loss decreased (0.505728 --> 0.503982).  Saving model ...
Validation loss decreased (0.503982 --> 0.502177).  Saving model ...
Validation loss decreased (0.502177 --> 0.500419).  Saving model ...
Validation loss decreased (0.500419 --> 0.498540).  Saving model ...
Validation loss decreased (0.498540 --> 0.496769).  Saving model ...
Validation loss decreased (0.496769 --> 0.494937).  Saving model ...
Validation loss decreased (0.494937 --> 0.493107).  Saving model ...
Validation loss decreased (0.493107 --> 0.491411).  Saving model ...
Validation loss decreased (0.491411 --> 0.489693).  Saving model ...
Validation loss decreased (0.489693 --> 0.488048).  Saving model ...
Validation loss decreased (0.488048 --> 0.486408).  Saving model ...
Validation loss decreased (0.486408 --> 0.484905).  Saving model ...
Validation loss decreased (0.484905 --> 0.483351).  Saving model ...
Validation loss decreased (0.483351 --> 0.481814).  Saving model ...
Validation loss decreased (0.481814 --> 0.480360).  Saving model ...
Validation loss decreased (0.480360 --> 0.479041).  Saving model ...
Validation loss decreased (0.479041 --> 0.477695).  Saving model ...
Validation loss decreased (0.477695 --> 0.476227).  Saving model ...
Validation loss decreased (0.476227 --> 0.474749).  Saving model ...
Validation loss decreased (0.474749 --> 0.473230).  Saving model ...
Validation loss decreased (0.473230 --> 0.471731).  Saving model ...
Validation loss decreased (0.471731 --> 0.470291).  Saving model ...
Validation loss decreased (0.470291 --> 0.468958).  Saving model ...
Validation loss decreased (0.468958 --> 0.467708).  Saving model ...
Validation loss decreased (0.467708 --> 0.466355).  Saving model ...
Validation loss decreased (0.466355 --> 0.465061).  Saving model ...
Validation loss decreased (0.465061 --> 0.463791).  Saving model ...
Validation loss decreased (0.463791 --> 0.462547).  Saving model ...
Validation loss decreased (0.462547 --> 0.461285).  Saving model ...
Validation loss decreased (0.461285 --> 0.460084).  Saving model ...
Validation loss decreased (0.460084 --> 0.458905).  Saving model ...
Validation loss decreased (0.458905 --> 0.457680).  Saving model ...
Validation loss decreased (0.457680 --> 0.456618).  Saving model ...
Validation loss decreased (0.456618 --> 0.455564).  Saving model ...
Validation loss decreased (0.455564 --> 0.454475).  Saving model ...
Validation loss decreased (0.454475 --> 0.453377).  Saving model ...
Validation loss decreased (0.453377 --> 0.452342).  Saving model ...
Validation loss decreased (0.452342 --> 0.451353).  Saving model ...
Validation loss decreased (0.451353 --> 0.450377).  Saving model ...
Validation loss decreased (0.450377 --> 0.449498).  Saving model ...
Validation loss decreased (0.449498 --> 0.448579).  Saving model ...
Validation loss decreased (0.448579 --> 0.447763).  Saving model ...
Validation loss decreased (0.447763 --> 0.447006).  Saving model ...
Validation loss decreased (0.447006 --> 0.446322).  Saving model ...
Validation loss decreased (0.446322 --> 0.445528).  Saving model ...
Validation loss decreased (0.445528 --> 0.444651).  Saving model ...
Validation loss decreased (0.444651 --> 0.443768).  Saving model ...
Validation loss decreased (0.443768 --> 0.442910).  Saving model ...
Validation loss decreased (0.442910 --> 0.442185).  Saving model ...
Validation loss decreased (0.442185 --> 0.441352).  Saving model ...
Validation loss decreased (0.441352 --> 0.440652).  Saving model ...
Validation loss decreased (0.440652 --> 0.439941).  Saving model ...
Validation loss decreased (0.439941 --> 0.439218).  Saving model ...
Validation loss decreased (0.439218 --> 0.438457).  Saving model ...
Validation loss decreased (0.438457 --> 0.437802).  Saving model ...
Validation loss decreased (0.437802 --> 0.437241).  Saving model ...
Validation loss decreased (0.437241 --> 0.436733).  Saving model ...
Validation loss decreased (0.436733 --> 0.436288).  Saving model ...
Validation loss decreased (0.436288 --> 0.435794).  Saving model ...
Validation loss decreased (0.435794 --> 0.435445).  Saving model ...
Validation loss decreased (0.435445 --> 0.435093).  Saving model ...
Validation loss decreased (0.435093 --> 0.434742).  Saving model ...
Validation loss decreased (0.434742 --> 0.434427).  Saving model ...
Validation loss decreased (0.434427 --> 0.434058).  Saving model ...
Validation loss decreased (0.434058 --> 0.433737).  Saving model ...
Validation loss decreased (0.433737 --> 0.433409).  Saving model ...
Validation loss decreased (0.433409 --> 0.433215).  Saving model ...
Validation loss decreased (0.433215 --> 0.432916).  Saving model ...
Validation loss decreased (0.432916 --> 0.432645).  Saving model ...
Validation loss decreased (0.432645 --> 0.432309).  Saving model ...
Validation loss decreased (0.432309 --> 0.431898).  Saving model ...
Validation loss decreased (0.431898 --> 0.431457).  Saving model ...
Validation loss decreased (0.431457 --> 0.431017).  Saving model ...
Validation loss decreased (0.431017 --> 0.430576).  Saving model ...
epoch 201, loss 0.3528, train acc 83.50%, f1 0.8350, precision 0.8350, recall 0.8350, auc 0.8350
Validation loss decreased (0.430576 --> 0.430156).  Saving model ...
Validation loss decreased (0.430156 --> 0.429675).  Saving model ...
Validation loss decreased (0.429675 --> 0.429131).  Saving model ...
Validation loss decreased (0.429131 --> 0.428623).  Saving model ...
Validation loss decreased (0.428623 --> 0.428056).  Saving model ...
Validation loss decreased (0.428056 --> 0.427577).  Saving model ...
Validation loss decreased (0.427577 --> 0.427008).  Saving model ...
Validation loss decreased (0.427008 --> 0.426485).  Saving model ...
Validation loss decreased (0.426485 --> 0.426079).  Saving model ...
Validation loss decreased (0.426079 --> 0.425610).  Saving model ...
Validation loss decreased (0.425610 --> 0.425301).  Saving model ...
Validation loss decreased (0.425301 --> 0.424913).  Saving model ...
Validation loss decreased (0.424913 --> 0.424461).  Saving model ...
Validation loss decreased (0.424461 --> 0.424002).  Saving model ...
Validation loss decreased (0.424002 --> 0.423583).  Saving model ...
Validation loss decreased (0.423583 --> 0.423314).  Saving model ...
Validation loss decreased (0.423314 --> 0.422976).  Saving model ...
Validation loss decreased (0.422976 --> 0.422673).  Saving model ...
Validation loss decreased (0.422673 --> 0.422415).  Saving model ...
Validation loss decreased (0.422415 --> 0.422338).  Saving model ...
Validation loss decreased (0.422338 --> 0.422129).  Saving model ...
Validation loss decreased (0.422129 --> 0.421918).  Saving model ...
Validation loss decreased (0.421918 --> 0.421701).  Saving model ...
Validation loss decreased (0.421701 --> 0.421426).  Saving model ...
Validation loss decreased (0.421426 --> 0.421224).  Saving model ...
Validation loss decreased (0.421224 --> 0.421150).  Saving model ...
Validation loss decreased (0.421150 --> 0.420956).  Saving model ...
Validation loss decreased (0.420956 --> 0.420793).  Saving model ...
Validation loss decreased (0.420793 --> 0.420620).  Saving model ...
Validation loss decreased (0.420620 --> 0.420417).  Saving model ...
Validation loss decreased (0.420417 --> 0.420317).  Saving model ...
Validation loss decreased (0.420317 --> 0.420198).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.420198 --> 0.420041).  Saving model ...
Validation loss decreased (0.420041 --> 0.419779).  Saving model ...
Validation loss decreased (0.419779 --> 0.419480).  Saving model ...
Validation loss decreased (0.419480 --> 0.419166).  Saving model ...
Validation loss decreased (0.419166 --> 0.418881).  Saving model ...
Validation loss decreased (0.418881 --> 0.418574).  Saving model ...
Validation loss decreased (0.418574 --> 0.418323).  Saving model ...
Validation loss decreased (0.418323 --> 0.418042).  Saving model ...
Validation loss decreased (0.418042 --> 0.417990).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.417990 --> 0.417923).  Saving model ...
Validation loss decreased (0.417923 --> 0.417869).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 264, loss 0.4939, train acc 82.00%, f1 0.8200, precision 0.8200, recall 0.8200, auc 0.8200



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_5
./test_pima/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6061320754716981

the Fscore is 0.5698324022346369

the precision is 0.40476190476190477

the recall is 0.9622641509433962

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_5
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5644, train acc 78.58%, f1 0.7861, precision 0.7851, recall 0.7871, auc 0.7858
epoch 201, loss 0.4029, train acc 82.13%, f1 0.8213, precision 0.8216, recall 0.8209, auc 0.8213
epoch 301, loss 0.3903, train acc 83.37%, f1 0.8337, precision 0.8339, recall 0.8334, auc 0.8337
epoch 401, loss 0.3846, train acc 83.96%, f1 0.8395, precision 0.8398, recall 0.8393, auc 0.8396
epoch 501, loss 0.3648, train acc 84.10%, f1 0.8410, precision 0.8413, recall 0.8407, auc 0.8410
epoch 601, loss 0.3876, train acc 84.21%, f1 0.8420, precision 0.8422, recall 0.8418, auc 0.8421
epoch 701, loss 0.2367, train acc 84.22%, f1 0.8422, precision 0.8423, recall 0.8421, auc 0.8422
epoch 801, loss 0.4155, train acc 84.25%, f1 0.8425, precision 0.8426, recall 0.8423, auc 0.8425
epoch 901, loss 0.3342, train acc 84.26%, f1 0.8425, precision 0.8427, recall 0.8424, auc 0.8426
epoch 1001, loss 0.3706, train acc 84.24%, f1 0.8424, precision 0.8425, recall 0.8424, auc 0.8424
epoch 1101, loss 0.3214, train acc 84.21%, f1 0.8421, precision 0.8421, recall 0.8421, auc 0.8421
epoch 1201, loss 0.5071, train acc 84.18%, f1 0.8418, precision 0.8418, recall 0.8418, auc 0.8418
epoch 1301, loss 0.4222, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8423, auc 0.8423
epoch 1401, loss 0.2790, train acc 84.19%, f1 0.8419, precision 0.8420, recall 0.8418, auc 0.8419
epoch 1501, loss 0.3767, train acc 84.17%, f1 0.8417, precision 0.8417, recall 0.8416, auc 0.8417
epoch 1601, loss 0.4371, train acc 84.22%, f1 0.8422, precision 0.8424, recall 0.8419, auc 0.8422
epoch 1701, loss 0.4408, train acc 84.22%, f1 0.8422, precision 0.8423, recall 0.8420, auc 0.8422
epoch 1801, loss 0.2866, train acc 84.23%, f1 0.8422, precision 0.8427, recall 0.8417, auc 0.8423
epoch 1901, loss 0.2811, train acc 84.21%, f1 0.8421, precision 0.8422, recall 0.8420, auc 0.8421
epoch 2001, loss 0.4178, train acc 84.24%, f1 0.8424, precision 0.8425, recall 0.8423, auc 0.8424
epoch 2101, loss 0.3645, train acc 84.27%, f1 0.8426, precision 0.8429, recall 0.8423, auc 0.8427
epoch 2201, loss 0.4015, train acc 84.27%, f1 0.8427, precision 0.8428, recall 0.8426, auc 0.8427
epoch 2301, loss 0.2922, train acc 84.37%, f1 0.8437, precision 0.8439, recall 0.8434, auc 0.8437
epoch 2401, loss 0.3471, train acc 84.38%, f1 0.8437, precision 0.8438, recall 0.8437, auc 0.8438
epoch 2501, loss 0.3239, train acc 84.46%, f1 0.8445, precision 0.8450, recall 0.8439, auc 0.8446
epoch 2601, loss 0.2787, train acc 84.57%, f1 0.8457, precision 0.8458, recall 0.8457, auc 0.8457
epoch 2701, loss 0.4259, train acc 84.74%, f1 0.8473, precision 0.8479, recall 0.8467, auc 0.8474
epoch 2801, loss 0.2527, train acc 84.81%, f1 0.8479, precision 0.8489, recall 0.8468, auc 0.8481
epoch 2901, loss 0.3408, train acc 84.91%, f1 0.8491, precision 0.8490, recall 0.8492, auc 0.8491
epoch 3001, loss 0.2905, train acc 85.02%, f1 0.8501, precision 0.8506, recall 0.8496, auc 0.8502
epoch 3101, loss 0.3822, train acc 85.18%, f1 0.8516, precision 0.8526, recall 0.8507, auc 0.8518
epoch 3201, loss 0.3019, train acc 85.27%, f1 0.8524, precision 0.8538, recall 0.8511, auc 0.8527
epoch 3301, loss 0.4095, train acc 85.34%, f1 0.8533, precision 0.8537, recall 0.8529, auc 0.8534
epoch 3401, loss 0.3193, train acc 85.49%, f1 0.8549, precision 0.8551, recall 0.8547, auc 0.8549
epoch 3501, loss 0.2473, train acc 85.64%, f1 0.8563, precision 0.8569, recall 0.8558, auc 0.8564
epoch 3601, loss 0.2934, train acc 85.78%, f1 0.8577, precision 0.8581, recall 0.8574, auc 0.8578
epoch 3701, loss 0.3394, train acc 85.83%, f1 0.8583, precision 0.8582, recall 0.8584, auc 0.8583
epoch 3801, loss 0.3372, train acc 85.99%, f1 0.8598, precision 0.8600, recall 0.8597, auc 0.8599
epoch 3901, loss 0.2884, train acc 86.05%, f1 0.8603, precision 0.8612, recall 0.8595, auc 0.8605
epoch 4001, loss 0.3549, train acc 86.12%, f1 0.8611, precision 0.8616, recall 0.8606, auc 0.8612
epoch 4101, loss 0.3270, train acc 86.17%, f1 0.8618, precision 0.8615, recall 0.8621, auc 0.8617
epoch 4201, loss 0.2827, train acc 86.22%, f1 0.8622, precision 0.8627, recall 0.8616, auc 0.8622
epoch 4301, loss 0.4088, train acc 86.36%, f1 0.8636, precision 0.8635, recall 0.8638, auc 0.8636
epoch 4401, loss 0.4531, train acc 86.44%, f1 0.8644, precision 0.8647, recall 0.8641, auc 0.8644
epoch 4501, loss 0.3125, train acc 86.52%, f1 0.8651, precision 0.8658, recall 0.8645, auc 0.8652
epoch 4601, loss 0.2412, train acc 86.55%, f1 0.8656, precision 0.8654, recall 0.8657, auc 0.8655
epoch 4701, loss 0.1925, train acc 86.63%, f1 0.8662, precision 0.8667, recall 0.8657, auc 0.8663
epoch 4801, loss 0.2192, train acc 86.71%, f1 0.8673, precision 0.8665, recall 0.8680, auc 0.8671
epoch 4901, loss 0.3243, train acc 86.75%, f1 0.8676, precision 0.8673, recall 0.8678, auc 0.8675
epoch 5001, loss 0.3924, train acc 86.78%, f1 0.8679, precision 0.8672, recall 0.8687, auc 0.8678
epoch 5101, loss 0.2931, train acc 86.83%, f1 0.8683, precision 0.8683, recall 0.8683, auc 0.8683
epoch 5201, loss 0.3352, train acc 86.92%, f1 0.8692, precision 0.8689, recall 0.8696, auc 0.8692
epoch 5301, loss 0.2418, train acc 86.91%, f1 0.8691, precision 0.8696, recall 0.8685, auc 0.8691
epoch 5401, loss 0.4036, train acc 87.03%, f1 0.8703, precision 0.8701, recall 0.8705, auc 0.8703
epoch 5501, loss 0.3513, train acc 87.09%, f1 0.8710, precision 0.8703, recall 0.8717, auc 0.8709
epoch 5601, loss 0.2615, train acc 87.15%, f1 0.8716, precision 0.8710, recall 0.8721, auc 0.8715
epoch 5701, loss 0.3029, train acc 87.20%, f1 0.8718, precision 0.8729, recall 0.8707, auc 0.8720
epoch 5801, loss 0.3735, train acc 87.27%, f1 0.8726, precision 0.8733, recall 0.8720, auc 0.8727
epoch 5901, loss 0.3152, train acc 87.34%, f1 0.8735, precision 0.8732, recall 0.8738, auc 0.8734
epoch 6001, loss 0.2495, train acc 87.35%, f1 0.8735, precision 0.8733, recall 0.8736, auc 0.8735
epoch 6101, loss 0.3459, train acc 87.37%, f1 0.8737, precision 0.8735, recall 0.8740, auc 0.8737
epoch 6201, loss 0.2686, train acc 87.38%, f1 0.8740, precision 0.8727, recall 0.8752, auc 0.8738
epoch 6301, loss 0.2040, train acc 87.48%, f1 0.8748, precision 0.8748, recall 0.8748, auc 0.8748
epoch 6401, loss 0.2953, train acc 87.53%, f1 0.8752, precision 0.8756, recall 0.8748, auc 0.8753
epoch 6501, loss 0.2895, train acc 87.56%, f1 0.8756, precision 0.8758, recall 0.8754, auc 0.8756
epoch 6601, loss 0.2199, train acc 87.64%, f1 0.8765, precision 0.8757, recall 0.8774, auc 0.8764
epoch 6701, loss 0.2262, train acc 87.69%, f1 0.8771, precision 0.8763, recall 0.8779, auc 0.8769
epoch 6801, loss 0.2419, train acc 87.71%, f1 0.8772, precision 0.8769, recall 0.8774, auc 0.8771
epoch 6901, loss 0.3956, train acc 87.78%, f1 0.8779, precision 0.8772, recall 0.8786, auc 0.8778
epoch 7001, loss 0.2427, train acc 87.84%, f1 0.8785, precision 0.8776, recall 0.8793, auc 0.8784
epoch 7101, loss 0.4979, train acc 87.83%, f1 0.8783, precision 0.8785, recall 0.8782, auc 0.8783
epoch 7201, loss 0.2822, train acc 87.93%, f1 0.8793, precision 0.8790, recall 0.8796, auc 0.8793
epoch 7301, loss 0.3511, train acc 87.95%, f1 0.8795, precision 0.8795, recall 0.8795, auc 0.8795
epoch 7401, loss 0.2101, train acc 88.02%, f1 0.8802, precision 0.8801, recall 0.8802, auc 0.8802
epoch 7501, loss 0.2864, train acc 88.12%, f1 0.8812, precision 0.8811, recall 0.8812, auc 0.8812
epoch 7601, loss 0.2658, train acc 88.15%, f1 0.8815, precision 0.8816, recall 0.8814, auc 0.8815
epoch 7701, loss 0.1988, train acc 88.18%, f1 0.8820, precision 0.8808, recall 0.8831, auc 0.8818
epoch 7801, loss 0.2623, train acc 88.31%, f1 0.8833, precision 0.8816, recall 0.8850, auc 0.8831
epoch 7901, loss 0.2547, train acc 88.32%, f1 0.8833, precision 0.8826, recall 0.8840, auc 0.8832
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_5
./test_pima/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6616981132075472

the Fscore is 0.6060606060606061

the precision is 0.44642857142857145

the recall is 0.9433962264150944

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_5
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5445, train acc 78.78%, f1 0.7878, precision 0.7877, recall 0.7878, auc 0.7878
epoch 201, loss 0.3754, train acc 82.19%, f1 0.8219, precision 0.8220, recall 0.8218, auc 0.8219
epoch 301, loss 0.3373, train acc 83.67%, f1 0.8367, precision 0.8367, recall 0.8367, auc 0.8367
epoch 401, loss 0.3797, train acc 84.03%, f1 0.8403, precision 0.8403, recall 0.8402, auc 0.8403
epoch 501, loss 0.3749, train acc 84.12%, f1 0.8412, precision 0.8412, recall 0.8412, auc 0.8412
epoch 601, loss 0.3137, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 701, loss 0.4757, train acc 84.20%, f1 0.8420, precision 0.8420, recall 0.8420, auc 0.8420
epoch 801, loss 0.3091, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 901, loss 0.3671, train acc 84.21%, f1 0.8421, precision 0.8421, recall 0.8422, auc 0.8421
epoch 1001, loss 0.3981, train acc 84.25%, f1 0.8425, precision 0.8424, recall 0.8425, auc 0.8425
epoch 1101, loss 0.4359, train acc 84.28%, f1 0.8428, precision 0.8428, recall 0.8429, auc 0.8428
epoch 1201, loss 0.4149, train acc 84.15%, f1 0.8415, precision 0.8415, recall 0.8415, auc 0.8415
epoch 1301, loss 0.3441, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8424, auc 0.8423
epoch 1401, loss 0.3276, train acc 84.29%, f1 0.8429, precision 0.8429, recall 0.8430, auc 0.8429
epoch 1501, loss 0.3558, train acc 84.25%, f1 0.8425, precision 0.8425, recall 0.8426, auc 0.8425
epoch 1601, loss 0.3183, train acc 84.25%, f1 0.8425, precision 0.8424, recall 0.8425, auc 0.8425
epoch 1701, loss 0.3466, train acc 84.14%, f1 0.8415, precision 0.8414, recall 0.8415, auc 0.8414
epoch 1801, loss 0.2987, train acc 84.15%, f1 0.8415, precision 0.8414, recall 0.8416, auc 0.8415
epoch 1901, loss 0.2873, train acc 84.19%, f1 0.8419, precision 0.8419, recall 0.8419, auc 0.8419
epoch 2001, loss 0.3811, train acc 84.24%, f1 0.8424, precision 0.8422, recall 0.8426, auc 0.8424
epoch 2101, loss 0.3065, train acc 84.25%, f1 0.8426, precision 0.8424, recall 0.8427, auc 0.8425
epoch 2201, loss 0.4219, train acc 84.24%, f1 0.8425, precision 0.8424, recall 0.8425, auc 0.8424
epoch 2301, loss 0.4524, train acc 84.29%, f1 0.8429, precision 0.8428, recall 0.8430, auc 0.8429
epoch 2401, loss 0.4845, train acc 84.31%, f1 0.8432, precision 0.8429, recall 0.8435, auc 0.8431
epoch 2501, loss 0.3104, train acc 84.39%, f1 0.8440, precision 0.8437, recall 0.8442, auc 0.8439
epoch 2601, loss 0.5131, train acc 84.36%, f1 0.8437, precision 0.8433, recall 0.8440, auc 0.8436
epoch 2701, loss 0.2687, train acc 84.44%, f1 0.8445, precision 0.8440, recall 0.8450, auc 0.8444
epoch 2801, loss 0.3150, train acc 84.60%, f1 0.8460, precision 0.8456, recall 0.8465, auc 0.8460
epoch 2901, loss 0.3216, train acc 84.67%, f1 0.8468, precision 0.8463, recall 0.8472, auc 0.8467
epoch 3001, loss 0.2860, train acc 84.78%, f1 0.8478, precision 0.8476, recall 0.8479, auc 0.8478
epoch 3101, loss 0.3548, train acc 84.85%, f1 0.8485, precision 0.8485, recall 0.8484, auc 0.8485
epoch 3201, loss 0.4312, train acc 85.00%, f1 0.8500, precision 0.8501, recall 0.8498, auc 0.8500
epoch 3301, loss 0.3474, train acc 85.11%, f1 0.8512, precision 0.8506, recall 0.8518, auc 0.8511
epoch 3401, loss 0.2865, train acc 85.24%, f1 0.8524, precision 0.8526, recall 0.8522, auc 0.8524
epoch 3501, loss 0.2906, train acc 85.36%, f1 0.8536, precision 0.8537, recall 0.8535, auc 0.8536
epoch 3601, loss 0.2819, train acc 85.48%, f1 0.8548, precision 0.8546, recall 0.8550, auc 0.8548
epoch 3701, loss 0.3204, train acc 85.58%, f1 0.8558, precision 0.8559, recall 0.8557, auc 0.8558
epoch 3801, loss 0.2825, train acc 85.65%, f1 0.8564, precision 0.8565, recall 0.8564, auc 0.8565
epoch 3901, loss 0.3041, train acc 85.81%, f1 0.8580, precision 0.8583, recall 0.8578, auc 0.8581
epoch 4001, loss 0.1994, train acc 85.95%, f1 0.8593, precision 0.8604, recall 0.8582, auc 0.8595
epoch 4101, loss 0.2824, train acc 86.01%, f1 0.8599, precision 0.8612, recall 0.8585, auc 0.8601
epoch 4201, loss 0.2925, train acc 86.11%, f1 0.8609, precision 0.8622, recall 0.8597, auc 0.8611
epoch 4301, loss 0.2679, train acc 86.16%, f1 0.8614, precision 0.8625, recall 0.8603, auc 0.8616
epoch 4401, loss 0.3432, train acc 86.24%, f1 0.8623, precision 0.8629, recall 0.8617, auc 0.8624
epoch 4501, loss 0.2885, train acc 86.36%, f1 0.8637, precision 0.8635, recall 0.8638, auc 0.8636
epoch 4601, loss 0.2419, train acc 86.48%, f1 0.8645, precision 0.8662, recall 0.8629, auc 0.8648
epoch 4701, loss 0.1830, train acc 86.55%, f1 0.8653, precision 0.8662, recall 0.8644, auc 0.8655
epoch 4801, loss 0.3656, train acc 86.61%, f1 0.8658, precision 0.8674, recall 0.8643, auc 0.8661
epoch 4901, loss 0.3166, train acc 86.60%, f1 0.8659, precision 0.8665, recall 0.8654, auc 0.8660
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_Mirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_5
./test_pima/result_MLP_concat_Mirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.651132075471698

the Fscore is 0.6

the precision is 0.4358974358974359

the recall is 0.9622641509433962

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_5
----------------------



epoch 1, loss 0.6934, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5353, train acc 79.30%, f1 0.7906, precision 0.7999, recall 0.7815, auc 0.7930
epoch 201, loss 0.3857, train acc 82.19%, f1 0.8223, precision 0.8206, recall 0.8240, auc 0.8219
epoch 301, loss 0.3780, train acc 83.46%, f1 0.8350, precision 0.8330, recall 0.8370, auc 0.8346
epoch 401, loss 0.3591, train acc 84.00%, f1 0.8405, precision 0.8380, recall 0.8430, auc 0.8400
epoch 501, loss 0.3568, train acc 84.10%, f1 0.8414, precision 0.8396, recall 0.8432, auc 0.8410
epoch 601, loss 0.4557, train acc 84.16%, f1 0.8422, precision 0.8395, recall 0.8448, auc 0.8416
epoch 701, loss 0.5241, train acc 84.20%, f1 0.8424, precision 0.8403, recall 0.8445, auc 0.8420
epoch 801, loss 0.4283, train acc 84.16%, f1 0.8418, precision 0.8405, recall 0.8431, auc 0.8416
epoch 901, loss 0.2405, train acc 84.20%, f1 0.8422, precision 0.8408, recall 0.8437, auc 0.8420
epoch 1001, loss 0.5327, train acc 84.20%, f1 0.8423, precision 0.8404, recall 0.8443, auc 0.8420
epoch 1101, loss 0.2755, train acc 84.21%, f1 0.8423, precision 0.8414, recall 0.8432, auc 0.8421
epoch 1201, loss 0.3055, train acc 84.24%, f1 0.8425, precision 0.8420, recall 0.8430, auc 0.8424
epoch 1301, loss 0.3236, train acc 84.24%, f1 0.8425, precision 0.8420, recall 0.8429, auc 0.8424
epoch 1401, loss 0.3753, train acc 84.22%, f1 0.8423, precision 0.8416, recall 0.8430, auc 0.8422
epoch 1501, loss 0.3167, train acc 84.18%, f1 0.8419, precision 0.8414, recall 0.8425, auc 0.8418
epoch 1601, loss 0.3661, train acc 84.18%, f1 0.8419, precision 0.8416, recall 0.8421, auc 0.8418
epoch 1701, loss 0.3722, train acc 84.18%, f1 0.8419, precision 0.8413, recall 0.8426, auc 0.8418
epoch 1801, loss 0.3248, train acc 84.24%, f1 0.8425, precision 0.8422, recall 0.8427, auc 0.8424
epoch 1901, loss 0.3159, train acc 84.17%, f1 0.8418, precision 0.8413, recall 0.8423, auc 0.8417
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_Mirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_5
./test_pima/result_MLP_concat_Mirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.5711320754716982

the Fscore is 0.5483870967741936

the precision is 0.38345864661654133

the recall is 0.9622641509433962

Done
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_5
----------------------



epoch 1, loss 0.6929, train acc 49.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693575).  Saving model ...
Validation loss decreased (0.693575 --> 0.693290).  Saving model ...
Validation loss decreased (0.693290 --> 0.693014).  Saving model ...
Validation loss decreased (0.693014 --> 0.692755).  Saving model ...
Validation loss decreased (0.692755 --> 0.692487).  Saving model ...
Validation loss decreased (0.692487 --> 0.692238).  Saving model ...
Validation loss decreased (0.692238 --> 0.692008).  Saving model ...
Validation loss decreased (0.692008 --> 0.691827).  Saving model ...
Validation loss decreased (0.691827 --> 0.691639).  Saving model ...
Validation loss decreased (0.691639 --> 0.691445).  Saving model ...
Validation loss decreased (0.691445 --> 0.691253).  Saving model ...
Validation loss decreased (0.691253 --> 0.691058).  Saving model ...
Validation loss decreased (0.691058 --> 0.690867).  Saving model ...
Validation loss decreased (0.690867 --> 0.690666).  Saving model ...
Validation loss decreased (0.690666 --> 0.690406).  Saving model ...
Validation loss decreased (0.690406 --> 0.690114).  Saving model ...
Validation loss decreased (0.690114 --> 0.689811).  Saving model ...
Validation loss decreased (0.689811 --> 0.689460).  Saving model ...
Validation loss decreased (0.689460 --> 0.689052).  Saving model ...
Validation loss decreased (0.689052 --> 0.688602).  Saving model ...
Validation loss decreased (0.688602 --> 0.688112).  Saving model ...
Validation loss decreased (0.688112 --> 0.687593).  Saving model ...
Validation loss decreased (0.687593 --> 0.687051).  Saving model ...
Validation loss decreased (0.687051 --> 0.686461).  Saving model ...
Validation loss decreased (0.686461 --> 0.685836).  Saving model ...
Validation loss decreased (0.685836 --> 0.685172).  Saving model ...
Validation loss decreased (0.685172 --> 0.684445).  Saving model ...
Validation loss decreased (0.684445 --> 0.683678).  Saving model ...
Validation loss decreased (0.683678 --> 0.682881).  Saving model ...
Validation loss decreased (0.682881 --> 0.682066).  Saving model ...
Validation loss decreased (0.682066 --> 0.681196).  Saving model ...
Validation loss decreased (0.681196 --> 0.680267).  Saving model ...
Validation loss decreased (0.680267 --> 0.679283).  Saving model ...
Validation loss decreased (0.679283 --> 0.678232).  Saving model ...
Validation loss decreased (0.678232 --> 0.677106).  Saving model ...
Validation loss decreased (0.677106 --> 0.675912).  Saving model ...
Validation loss decreased (0.675912 --> 0.674658).  Saving model ...
Validation loss decreased (0.674658 --> 0.673343).  Saving model ...
Validation loss decreased (0.673343 --> 0.671972).  Saving model ...
Validation loss decreased (0.671972 --> 0.670526).  Saving model ...
Validation loss decreased (0.670526 --> 0.669039).  Saving model ...
Validation loss decreased (0.669039 --> 0.667483).  Saving model ...
Validation loss decreased (0.667483 --> 0.665854).  Saving model ...
Validation loss decreased (0.665854 --> 0.664147).  Saving model ...
Validation loss decreased (0.664147 --> 0.662419).  Saving model ...
Validation loss decreased (0.662419 --> 0.660586).  Saving model ...
Validation loss decreased (0.660586 --> 0.658692).  Saving model ...
Validation loss decreased (0.658692 --> 0.656738).  Saving model ...
Validation loss decreased (0.656738 --> 0.654674).  Saving model ...
Validation loss decreased (0.654674 --> 0.652549).  Saving model ...
Validation loss decreased (0.652549 --> 0.650404).  Saving model ...
Validation loss decreased (0.650404 --> 0.648190).  Saving model ...
Validation loss decreased (0.648190 --> 0.645915).  Saving model ...
Validation loss decreased (0.645915 --> 0.643611).  Saving model ...
Validation loss decreased (0.643611 --> 0.641306).  Saving model ...
Validation loss decreased (0.641306 --> 0.639030).  Saving model ...
Validation loss decreased (0.639030 --> 0.636644).  Saving model ...
Validation loss decreased (0.636644 --> 0.634177).  Saving model ...
Validation loss decreased (0.634177 --> 0.631643).  Saving model ...
Validation loss decreased (0.631643 --> 0.629066).  Saving model ...
Validation loss decreased (0.629066 --> 0.626451).  Saving model ...
Validation loss decreased (0.626451 --> 0.623795).  Saving model ...
Validation loss decreased (0.623795 --> 0.621137).  Saving model ...
Validation loss decreased (0.621137 --> 0.618427).  Saving model ...
Validation loss decreased (0.618427 --> 0.615695).  Saving model ...
Validation loss decreased (0.615695 --> 0.612889).  Saving model ...
Validation loss decreased (0.612889 --> 0.610090).  Saving model ...
Validation loss decreased (0.610090 --> 0.607187).  Saving model ...
Validation loss decreased (0.607187 --> 0.604264).  Saving model ...
Validation loss decreased (0.604264 --> 0.601395).  Saving model ...
Validation loss decreased (0.601395 --> 0.598392).  Saving model ...
Validation loss decreased (0.598392 --> 0.595402).  Saving model ...
Validation loss decreased (0.595402 --> 0.592341).  Saving model ...
Validation loss decreased (0.592341 --> 0.589319).  Saving model ...
Validation loss decreased (0.589319 --> 0.586222).  Saving model ...
Validation loss decreased (0.586222 --> 0.583140).  Saving model ...
Validation loss decreased (0.583140 --> 0.580046).  Saving model ...
Validation loss decreased (0.580046 --> 0.576910).  Saving model ...
Validation loss decreased (0.576910 --> 0.573673).  Saving model ...
Validation loss decreased (0.573673 --> 0.570457).  Saving model ...
Validation loss decreased (0.570457 --> 0.567243).  Saving model ...
Validation loss decreased (0.567243 --> 0.564107).  Saving model ...
Validation loss decreased (0.564107 --> 0.560904).  Saving model ...
Validation loss decreased (0.560904 --> 0.557798).  Saving model ...
Validation loss decreased (0.557798 --> 0.554640).  Saving model ...
Validation loss decreased (0.554640 --> 0.551441).  Saving model ...
Validation loss decreased (0.551441 --> 0.548362).  Saving model ...
Validation loss decreased (0.548362 --> 0.545282).  Saving model ...
Validation loss decreased (0.545282 --> 0.542229).  Saving model ...
Validation loss decreased (0.542229 --> 0.539201).  Saving model ...
Validation loss decreased (0.539201 --> 0.536155).  Saving model ...
Validation loss decreased (0.536155 --> 0.533086).  Saving model ...
Validation loss decreased (0.533086 --> 0.529973).  Saving model ...
Validation loss decreased (0.529973 --> 0.526826).  Saving model ...
Validation loss decreased (0.526826 --> 0.523601).  Saving model ...
Validation loss decreased (0.523601 --> 0.520423).  Saving model ...
Validation loss decreased (0.520423 --> 0.517322).  Saving model ...
Validation loss decreased (0.517322 --> 0.514290).  Saving model ...
Validation loss decreased (0.514290 --> 0.511392).  Saving model ...
Validation loss decreased (0.511392 --> 0.508477).  Saving model ...
epoch 101, loss 0.5597, train acc 88.00%, f1 0.8812, precision 0.8900, recall 0.8725, auc 0.8802
Validation loss decreased (0.508477 --> 0.505577).  Saving model ...
Validation loss decreased (0.505577 --> 0.502728).  Saving model ...
Validation loss decreased (0.502728 --> 0.499817).  Saving model ...
Validation loss decreased (0.499817 --> 0.496866).  Saving model ...
Validation loss decreased (0.496866 --> 0.493925).  Saving model ...
Validation loss decreased (0.493925 --> 0.491118).  Saving model ...
Validation loss decreased (0.491118 --> 0.488318).  Saving model ...
Validation loss decreased (0.488318 --> 0.485486).  Saving model ...
Validation loss decreased (0.485486 --> 0.482606).  Saving model ...
Validation loss decreased (0.482606 --> 0.479674).  Saving model ...
Validation loss decreased (0.479674 --> 0.476865).  Saving model ...
Validation loss decreased (0.476865 --> 0.473994).  Saving model ...
Validation loss decreased (0.473994 --> 0.471246).  Saving model ...
Validation loss decreased (0.471246 --> 0.468599).  Saving model ...
Validation loss decreased (0.468599 --> 0.465916).  Saving model ...
Validation loss decreased (0.465916 --> 0.463294).  Saving model ...
Validation loss decreased (0.463294 --> 0.460703).  Saving model ...
Validation loss decreased (0.460703 --> 0.458170).  Saving model ...
Validation loss decreased (0.458170 --> 0.455714).  Saving model ...
Validation loss decreased (0.455714 --> 0.453233).  Saving model ...
Validation loss decreased (0.453233 --> 0.450827).  Saving model ...
Validation loss decreased (0.450827 --> 0.448514).  Saving model ...
Validation loss decreased (0.448514 --> 0.446242).  Saving model ...
Validation loss decreased (0.446242 --> 0.443910).  Saving model ...
Validation loss decreased (0.443910 --> 0.441579).  Saving model ...
Validation loss decreased (0.441579 --> 0.439235).  Saving model ...
Validation loss decreased (0.439235 --> 0.437133).  Saving model ...
Validation loss decreased (0.437133 --> 0.435010).  Saving model ...
Validation loss decreased (0.435010 --> 0.432845).  Saving model ...
Validation loss decreased (0.432845 --> 0.430633).  Saving model ...
Validation loss decreased (0.430633 --> 0.428453).  Saving model ...
Validation loss decreased (0.428453 --> 0.426283).  Saving model ...
Validation loss decreased (0.426283 --> 0.424126).  Saving model ...
Validation loss decreased (0.424126 --> 0.422084).  Saving model ...
Validation loss decreased (0.422084 --> 0.420140).  Saving model ...
Validation loss decreased (0.420140 --> 0.418210).  Saving model ...
Validation loss decreased (0.418210 --> 0.416226).  Saving model ...
Validation loss decreased (0.416226 --> 0.414241).  Saving model ...
Validation loss decreased (0.414241 --> 0.412252).  Saving model ...
Validation loss decreased (0.412252 --> 0.410279).  Saving model ...
Validation loss decreased (0.410279 --> 0.408391).  Saving model ...
Validation loss decreased (0.408391 --> 0.406445).  Saving model ...
Validation loss decreased (0.406445 --> 0.404472).  Saving model ...
Validation loss decreased (0.404472 --> 0.402637).  Saving model ...
Validation loss decreased (0.402637 --> 0.400791).  Saving model ...
Validation loss decreased (0.400791 --> 0.398877).  Saving model ...
Validation loss decreased (0.398877 --> 0.397001).  Saving model ...
Validation loss decreased (0.397001 --> 0.395287).  Saving model ...
Validation loss decreased (0.395287 --> 0.393627).  Saving model ...
Validation loss decreased (0.393627 --> 0.392005).  Saving model ...
Validation loss decreased (0.392005 --> 0.390361).  Saving model ...
Validation loss decreased (0.390361 --> 0.388731).  Saving model ...
Validation loss decreased (0.388731 --> 0.387090).  Saving model ...
Validation loss decreased (0.387090 --> 0.385402).  Saving model ...
Validation loss decreased (0.385402 --> 0.383617).  Saving model ...
Validation loss decreased (0.383617 --> 0.381915).  Saving model ...
Validation loss decreased (0.381915 --> 0.380230).  Saving model ...
Validation loss decreased (0.380230 --> 0.378594).  Saving model ...
Validation loss decreased (0.378594 --> 0.376947).  Saving model ...
Validation loss decreased (0.376947 --> 0.375415).  Saving model ...
Validation loss decreased (0.375415 --> 0.373873).  Saving model ...
Validation loss decreased (0.373873 --> 0.372450).  Saving model ...
Validation loss decreased (0.372450 --> 0.371011).  Saving model ...
Validation loss decreased (0.371011 --> 0.369570).  Saving model ...
Validation loss decreased (0.369570 --> 0.368197).  Saving model ...
Validation loss decreased (0.368197 --> 0.366906).  Saving model ...
Validation loss decreased (0.366906 --> 0.365586).  Saving model ...
Validation loss decreased (0.365586 --> 0.364246).  Saving model ...
Validation loss decreased (0.364246 --> 0.362854).  Saving model ...
Validation loss decreased (0.362854 --> 0.361465).  Saving model ...
Validation loss decreased (0.361465 --> 0.360187).  Saving model ...
Validation loss decreased (0.360187 --> 0.358803).  Saving model ...
Validation loss decreased (0.358803 --> 0.357403).  Saving model ...
Validation loss decreased (0.357403 --> 0.356007).  Saving model ...
Validation loss decreased (0.356007 --> 0.354652).  Saving model ...
Validation loss decreased (0.354652 --> 0.353367).  Saving model ...
Validation loss decreased (0.353367 --> 0.352123).  Saving model ...
Validation loss decreased (0.352123 --> 0.350855).  Saving model ...
Validation loss decreased (0.350855 --> 0.349623).  Saving model ...
Validation loss decreased (0.349623 --> 0.348442).  Saving model ...
Validation loss decreased (0.348442 --> 0.347280).  Saving model ...
Validation loss decreased (0.347280 --> 0.346051).  Saving model ...
Validation loss decreased (0.346051 --> 0.344889).  Saving model ...
Validation loss decreased (0.344889 --> 0.343765).  Saving model ...
Validation loss decreased (0.343765 --> 0.342747).  Saving model ...
Validation loss decreased (0.342747 --> 0.341761).  Saving model ...
Validation loss decreased (0.341761 --> 0.340829).  Saving model ...
Validation loss decreased (0.340829 --> 0.339853).  Saving model ...
Validation loss decreased (0.339853 --> 0.338921).  Saving model ...
Validation loss decreased (0.338921 --> 0.337922).  Saving model ...
Validation loss decreased (0.337922 --> 0.336888).  Saving model ...
Validation loss decreased (0.336888 --> 0.335796).  Saving model ...
Validation loss decreased (0.335796 --> 0.334722).  Saving model ...
Validation loss decreased (0.334722 --> 0.333649).  Saving model ...
Validation loss decreased (0.333649 --> 0.332625).  Saving model ...
Validation loss decreased (0.332625 --> 0.331705).  Saving model ...
Validation loss decreased (0.331705 --> 0.330846).  Saving model ...
Validation loss decreased (0.330846 --> 0.330032).  Saving model ...
Validation loss decreased (0.330032 --> 0.329188).  Saving model ...
Validation loss decreased (0.329188 --> 0.328366).  Saving model ...
epoch 201, loss 0.4880, train acc 89.00%, f1 0.8922, precision 0.8922, recall 0.8922, auc 0.8900
Validation loss decreased (0.328366 --> 0.327597).  Saving model ...
Validation loss decreased (0.327597 --> 0.326795).  Saving model ...
Validation loss decreased (0.326795 --> 0.326069).  Saving model ...
Validation loss decreased (0.326069 --> 0.325340).  Saving model ...
Validation loss decreased (0.325340 --> 0.324738).  Saving model ...
Validation loss decreased (0.324738 --> 0.324116).  Saving model ...
Validation loss decreased (0.324116 --> 0.323418).  Saving model ...
Validation loss decreased (0.323418 --> 0.322527).  Saving model ...
Validation loss decreased (0.322527 --> 0.321638).  Saving model ...
Validation loss decreased (0.321638 --> 0.320722).  Saving model ...
Validation loss decreased (0.320722 --> 0.319880).  Saving model ...
Validation loss decreased (0.319880 --> 0.319020).  Saving model ...
Validation loss decreased (0.319020 --> 0.318227).  Saving model ...
Validation loss decreased (0.318227 --> 0.317491).  Saving model ...
Validation loss decreased (0.317491 --> 0.316730).  Saving model ...
Validation loss decreased (0.316730 --> 0.316027).  Saving model ...
Validation loss decreased (0.316027 --> 0.315385).  Saving model ...
Validation loss decreased (0.315385 --> 0.314703).  Saving model ...
Validation loss decreased (0.314703 --> 0.313968).  Saving model ...
Validation loss decreased (0.313968 --> 0.313253).  Saving model ...
Validation loss decreased (0.313253 --> 0.312539).  Saving model ...
Validation loss decreased (0.312539 --> 0.311872).  Saving model ...
Validation loss decreased (0.311872 --> 0.311193).  Saving model ...
Validation loss decreased (0.311193 --> 0.310502).  Saving model ...
Validation loss decreased (0.310502 --> 0.309958).  Saving model ...
Validation loss decreased (0.309958 --> 0.309530).  Saving model ...
Validation loss decreased (0.309530 --> 0.309147).  Saving model ...
Validation loss decreased (0.309147 --> 0.308656).  Saving model ...
Validation loss decreased (0.308656 --> 0.308188).  Saving model ...
Validation loss decreased (0.308188 --> 0.307683).  Saving model ...
Validation loss decreased (0.307683 --> 0.307140).  Saving model ...
Validation loss decreased (0.307140 --> 0.306532).  Saving model ...
Validation loss decreased (0.306532 --> 0.305954).  Saving model ...
Validation loss decreased (0.305954 --> 0.305382).  Saving model ...
Validation loss decreased (0.305382 --> 0.304897).  Saving model ...
Validation loss decreased (0.304897 --> 0.304351).  Saving model ...
Validation loss decreased (0.304351 --> 0.303774).  Saving model ...
Validation loss decreased (0.303774 --> 0.303132).  Saving model ...
Validation loss decreased (0.303132 --> 0.302536).  Saving model ...
Validation loss decreased (0.302536 --> 0.302005).  Saving model ...
Validation loss decreased (0.302005 --> 0.301485).  Saving model ...
Validation loss decreased (0.301485 --> 0.300914).  Saving model ...
Validation loss decreased (0.300914 --> 0.300440).  Saving model ...
Validation loss decreased (0.300440 --> 0.299978).  Saving model ...
Validation loss decreased (0.299978 --> 0.299511).  Saving model ...
Validation loss decreased (0.299511 --> 0.299058).  Saving model ...
Validation loss decreased (0.299058 --> 0.298539).  Saving model ...
Validation loss decreased (0.298539 --> 0.298052).  Saving model ...
Validation loss decreased (0.298052 --> 0.297521).  Saving model ...
Validation loss decreased (0.297521 --> 0.296907).  Saving model ...
Validation loss decreased (0.296907 --> 0.296365).  Saving model ...
Validation loss decreased (0.296365 --> 0.295730).  Saving model ...
Validation loss decreased (0.295730 --> 0.295208).  Saving model ...
Validation loss decreased (0.295208 --> 0.294819).  Saving model ...
Validation loss decreased (0.294819 --> 0.294408).  Saving model ...
Validation loss decreased (0.294408 --> 0.294057).  Saving model ...
Validation loss decreased (0.294057 --> 0.293738).  Saving model ...
Validation loss decreased (0.293738 --> 0.293536).  Saving model ...
Validation loss decreased (0.293536 --> 0.293232).  Saving model ...
Validation loss decreased (0.293232 --> 0.292862).  Saving model ...
Validation loss decreased (0.292862 --> 0.292466).  Saving model ...
Validation loss decreased (0.292466 --> 0.292105).  Saving model ...
Validation loss decreased (0.292105 --> 0.291710).  Saving model ...
Validation loss decreased (0.291710 --> 0.291268).  Saving model ...
Validation loss decreased (0.291268 --> 0.290884).  Saving model ...
Validation loss decreased (0.290884 --> 0.290498).  Saving model ...
Validation loss decreased (0.290498 --> 0.290048).  Saving model ...
Validation loss decreased (0.290048 --> 0.289575).  Saving model ...
Validation loss decreased (0.289575 --> 0.289094).  Saving model ...
Validation loss decreased (0.289094 --> 0.288629).  Saving model ...
Validation loss decreased (0.288629 --> 0.288090).  Saving model ...
Validation loss decreased (0.288090 --> 0.287594).  Saving model ...
Validation loss decreased (0.287594 --> 0.287132).  Saving model ...
Validation loss decreased (0.287132 --> 0.286565).  Saving model ...
Validation loss decreased (0.286565 --> 0.285902).  Saving model ...
Validation loss decreased (0.285902 --> 0.285284).  Saving model ...
Validation loss decreased (0.285284 --> 0.284616).  Saving model ...
Validation loss decreased (0.284616 --> 0.283967).  Saving model ...
Validation loss decreased (0.283967 --> 0.283332).  Saving model ...
Validation loss decreased (0.283332 --> 0.282673).  Saving model ...
Validation loss decreased (0.282673 --> 0.281990).  Saving model ...
Validation loss decreased (0.281990 --> 0.281357).  Saving model ...
Validation loss decreased (0.281357 --> 0.280784).  Saving model ...
Validation loss decreased (0.280784 --> 0.280246).  Saving model ...
Validation loss decreased (0.280246 --> 0.279789).  Saving model ...
Validation loss decreased (0.279789 --> 0.279325).  Saving model ...
Validation loss decreased (0.279325 --> 0.278921).  Saving model ...
Validation loss decreased (0.278921 --> 0.278594).  Saving model ...
Validation loss decreased (0.278594 --> 0.278352).  Saving model ...
Validation loss decreased (0.278352 --> 0.278069).  Saving model ...
Validation loss decreased (0.278069 --> 0.277754).  Saving model ...
Validation loss decreased (0.277754 --> 0.277519).  Saving model ...
Validation loss decreased (0.277519 --> 0.277340).  Saving model ...
Validation loss decreased (0.277340 --> 0.277111).  Saving model ...
Validation loss decreased (0.277111 --> 0.276903).  Saving model ...
Validation loss decreased (0.276903 --> 0.276672).  Saving model ...
Validation loss decreased (0.276672 --> 0.276357).  Saving model ...
Validation loss decreased (0.276357 --> 0.275913).  Saving model ...
Validation loss decreased (0.275913 --> 0.275474).  Saving model ...
Validation loss decreased (0.275474 --> 0.274959).  Saving model ...
epoch 301, loss 0.3950, train acc 90.50%, f1 0.9073, precision 0.9029, recall 0.9118, auc 0.9049
Validation loss decreased (0.274959 --> 0.274427).  Saving model ...
Validation loss decreased (0.274427 --> 0.274027).  Saving model ...
Validation loss decreased (0.274027 --> 0.273586).  Saving model ...
Validation loss decreased (0.273586 --> 0.273056).  Saving model ...
Validation loss decreased (0.273056 --> 0.272586).  Saving model ...
Validation loss decreased (0.272586 --> 0.272288).  Saving model ...
Validation loss decreased (0.272288 --> 0.271961).  Saving model ...
Validation loss decreased (0.271961 --> 0.271660).  Saving model ...
Validation loss decreased (0.271660 --> 0.271488).  Saving model ...
Validation loss decreased (0.271488 --> 0.271408).  Saving model ...
Validation loss decreased (0.271408 --> 0.271359).  Saving model ...
Validation loss decreased (0.271359 --> 0.271302).  Saving model ...
Validation loss decreased (0.271302 --> 0.271137).  Saving model ...
Validation loss decreased (0.271137 --> 0.270963).  Saving model ...
Validation loss decreased (0.270963 --> 0.270825).  Saving model ...
Validation loss decreased (0.270825 --> 0.270676).  Saving model ...
Validation loss decreased (0.270676 --> 0.270445).  Saving model ...
Validation loss decreased (0.270445 --> 0.270141).  Saving model ...
Validation loss decreased (0.270141 --> 0.269838).  Saving model ...
Validation loss decreased (0.269838 --> 0.269480).  Saving model ...
Validation loss decreased (0.269480 --> 0.269138).  Saving model ...
Validation loss decreased (0.269138 --> 0.268814).  Saving model ...
Validation loss decreased (0.268814 --> 0.268659).  Saving model ...
Validation loss decreased (0.268659 --> 0.268529).  Saving model ...
Validation loss decreased (0.268529 --> 0.268465).  Saving model ...
Validation loss decreased (0.268465 --> 0.268444).  Saving model ...
Validation loss decreased (0.268444 --> 0.268350).  Saving model ...
Validation loss decreased (0.268350 --> 0.268257).  Saving model ...
Validation loss decreased (0.268257 --> 0.268190).  Saving model ...
Validation loss decreased (0.268190 --> 0.268146).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
Validation loss decreased (0.268146 --> 0.268017).  Saving model ...
Validation loss decreased (0.268017 --> 0.267777).  Saving model ...
Validation loss decreased (0.267777 --> 0.267552).  Saving model ...
Validation loss decreased (0.267552 --> 0.267292).  Saving model ...
Validation loss decreased (0.267292 --> 0.266945).  Saving model ...
Validation loss decreased (0.266945 --> 0.266722).  Saving model ...
Validation loss decreased (0.266722 --> 0.266620).  Saving model ...
Validation loss decreased (0.266620 --> 0.266504).  Saving model ...
Validation loss decreased (0.266504 --> 0.266384).  Saving model ...
Validation loss decreased (0.266384 --> 0.266311).  Saving model ...
Validation loss decreased (0.266311 --> 0.266110).  Saving model ...
Validation loss decreased (0.266110 --> 0.265903).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.265903 --> 0.265622).  Saving model ...
Validation loss decreased (0.265622 --> 0.265283).  Saving model ...
Validation loss decreased (0.265283 --> 0.264945).  Saving model ...
Validation loss decreased (0.264945 --> 0.264540).  Saving model ...
Validation loss decreased (0.264540 --> 0.264106).  Saving model ...
Validation loss decreased (0.264106 --> 0.263774).  Saving model ...
Validation loss decreased (0.263774 --> 0.263460).  Saving model ...
Validation loss decreased (0.263460 --> 0.263027).  Saving model ...
Validation loss decreased (0.263027 --> 0.262686).  Saving model ...
Validation loss decreased (0.262686 --> 0.262317).  Saving model ...
Validation loss decreased (0.262317 --> 0.261922).  Saving model ...
Validation loss decreased (0.261922 --> 0.261544).  Saving model ...
Validation loss decreased (0.261544 --> 0.261169).  Saving model ...
Validation loss decreased (0.261169 --> 0.260876).  Saving model ...
Validation loss decreased (0.260876 --> 0.260571).  Saving model ...
Validation loss decreased (0.260571 --> 0.260335).  Saving model ...
Validation loss decreased (0.260335 --> 0.260202).  Saving model ...
Validation loss decreased (0.260202 --> 0.260064).  Saving model ...
Validation loss decreased (0.260064 --> 0.259921).  Saving model ...
Validation loss decreased (0.259921 --> 0.259783).  Saving model ...
Validation loss decreased (0.259783 --> 0.259663).  Saving model ...
Validation loss decreased (0.259663 --> 0.259423).  Saving model ...
Validation loss decreased (0.259423 --> 0.259185).  Saving model ...
Validation loss decreased (0.259185 --> 0.258938).  Saving model ...
Validation loss decreased (0.258938 --> 0.258805).  Saving model ...
Validation loss decreased (0.258805 --> 0.258662).  Saving model ...
Validation loss decreased (0.258662 --> 0.258551).  Saving model ...
Validation loss decreased (0.258551 --> 0.258523).  Saving model ...
Validation loss decreased (0.258523 --> 0.258440).  Saving model ...
Validation loss decreased (0.258440 --> 0.258210).  Saving model ...
Validation loss decreased (0.258210 --> 0.257953).  Saving model ...
Validation loss decreased (0.257953 --> 0.257748).  Saving model ...
Validation loss decreased (0.257748 --> 0.257488).  Saving model ...
Validation loss decreased (0.257488 --> 0.257160).  Saving model ...
Validation loss decreased (0.257160 --> 0.256760).  Saving model ...
Validation loss decreased (0.256760 --> 0.256439).  Saving model ...
Validation loss decreased (0.256439 --> 0.256241).  Saving model ...
Validation loss decreased (0.256241 --> 0.256045).  Saving model ...
Validation loss decreased (0.256045 --> 0.255973).  Saving model ...
Validation loss decreased (0.255973 --> 0.255806).  Saving model ...
Validation loss decreased (0.255806 --> 0.255679).  Saving model ...
Validation loss decreased (0.255679 --> 0.255667).  Saving model ...
Validation loss decreased (0.255667 --> 0.255606).  Saving model ...
epoch 401, loss 0.3856, train acc 90.50%, f1 0.9073, precision 0.9029, recall 0.9118, auc 0.9049
Validation loss decreased (0.255606 --> 0.255605).  Saving model ...
Validation loss decreased (0.255605 --> 0.255503).  Saving model ...
Validation loss decreased (0.255503 --> 0.255445).  Saving model ...
Validation loss decreased (0.255445 --> 0.255338).  Saving model ...
Validation loss decreased (0.255338 --> 0.255247).  Saving model ...
Validation loss decreased (0.255247 --> 0.255080).  Saving model ...
Validation loss decreased (0.255080 --> 0.254913).  Saving model ...
Validation loss decreased (0.254913 --> 0.254626).  Saving model ...
Validation loss decreased (0.254626 --> 0.254353).  Saving model ...
Validation loss decreased (0.254353 --> 0.254013).  Saving model ...
Validation loss decreased (0.254013 --> 0.253645).  Saving model ...
Validation loss decreased (0.253645 --> 0.253368).  Saving model ...
Validation loss decreased (0.253368 --> 0.253112).  Saving model ...
Validation loss decreased (0.253112 --> 0.252899).  Saving model ...
Validation loss decreased (0.252899 --> 0.252740).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
Validation loss decreased (0.252740 --> 0.252659).  Saving model ...
Validation loss decreased (0.252659 --> 0.252618).  Saving model ...
Validation loss decreased (0.252618 --> 0.252474).  Saving model ...
Validation loss decreased (0.252474 --> 0.252356).  Saving model ...
Validation loss decreased (0.252356 --> 0.252172).  Saving model ...
Validation loss decreased (0.252172 --> 0.251951).  Saving model ...
Validation loss decreased (0.251951 --> 0.251705).  Saving model ...
Validation loss decreased (0.251705 --> 0.251508).  Saving model ...
Validation loss decreased (0.251508 --> 0.251303).  Saving model ...
Validation loss decreased (0.251303 --> 0.251058).  Saving model ...
Validation loss decreased (0.251058 --> 0.250821).  Saving model ...
Validation loss decreased (0.250821 --> 0.250697).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 456, loss 0.3936, train acc 89.50%, f1 0.8966, precision 0.9010, recall 0.8922, auc 0.8951



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_notMirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_5
./test_pima/result_MLP_concat_notMirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6355660377358491

the Fscore is 0.5909090909090909

the precision is 0.42276422764227645

the recall is 0.9811320754716981

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_5
----------------------



epoch 1, loss 0.6932, train acc 52.96%, f1 0.1528, precision 0.7764, recall 0.0848, auc 0.5301
epoch 101, loss 0.5005, train acc 78.97%, f1 0.7940, precision 0.7791, recall 0.8094, auc 0.7897
epoch 201, loss 0.4534, train acc 82.16%, f1 0.8210, precision 0.8251, recall 0.8169, auc 0.8216
epoch 301, loss 0.4135, train acc 83.47%, f1 0.8347, precision 0.8360, recall 0.8334, auc 0.8347
epoch 401, loss 0.2965, train acc 83.99%, f1 0.8399, precision 0.8413, recall 0.8384, auc 0.8399
epoch 501, loss 0.4614, train acc 84.10%, f1 0.8409, precision 0.8426, recall 0.8393, auc 0.8410
epoch 601, loss 0.3774, train acc 84.19%, f1 0.8419, precision 0.8428, recall 0.8411, auc 0.8419
epoch 701, loss 0.3640, train acc 84.22%, f1 0.8425, precision 0.8419, recall 0.8432, auc 0.8422
epoch 801, loss 0.3891, train acc 84.19%, f1 0.8414, precision 0.8452, recall 0.8376, auc 0.8419
epoch 901, loss 0.3866, train acc 84.21%, f1 0.8420, precision 0.8437, recall 0.8403, auc 0.8421
epoch 1001, loss 0.3786, train acc 84.27%, f1 0.8426, precision 0.8437, recall 0.8416, auc 0.8427
epoch 1101, loss 0.3475, train acc 84.21%, f1 0.8428, precision 0.8402, recall 0.8454, auc 0.8421
epoch 1201, loss 0.3608, train acc 84.27%, f1 0.8425, precision 0.8446, recall 0.8404, auc 0.8427
epoch 1301, loss 0.2262, train acc 84.23%, f1 0.8428, precision 0.8414, recall 0.8442, auc 0.8423
epoch 1401, loss 0.2685, train acc 84.22%, f1 0.8416, precision 0.8458, recall 0.8373, auc 0.8422
epoch 1501, loss 0.3147, train acc 84.20%, f1 0.8415, precision 0.8448, recall 0.8383, auc 0.8420
epoch 1601, loss 0.3055, train acc 84.23%, f1 0.8416, precision 0.8462, recall 0.8371, auc 0.8423
epoch 1701, loss 0.3349, train acc 84.20%, f1 0.8426, precision 0.8404, recall 0.8448, auc 0.8420
epoch 1801, loss 0.2995, train acc 84.24%, f1 0.8426, precision 0.8426, recall 0.8426, auc 0.8424
epoch 1901, loss 0.5174, train acc 84.23%, f1 0.8420, precision 0.8449, recall 0.8391, auc 0.8424
epoch 2001, loss 0.4237, train acc 84.26%, f1 0.8433, precision 0.8402, recall 0.8465, auc 0.8426
epoch 2101, loss 0.4673, train acc 84.30%, f1 0.8424, precision 0.8466, recall 0.8382, auc 0.8430
epoch 2201, loss 0.4007, train acc 84.26%, f1 0.8431, precision 0.8417, recall 0.8445, auc 0.8426
epoch 2301, loss 0.3187, train acc 84.23%, f1 0.8425, precision 0.8426, recall 0.8423, auc 0.8423
epoch 2401, loss 0.2789, train acc 84.20%, f1 0.8426, precision 0.8403, recall 0.8449, auc 0.8420
epoch 2501, loss 0.2470, train acc 84.23%, f1 0.8428, precision 0.8408, recall 0.8449, auc 0.8423
epoch 2601, loss 0.3220, train acc 84.23%, f1 0.8428, precision 0.8411, recall 0.8445, auc 0.8423
epoch 2701, loss 0.3803, train acc 84.28%, f1 0.8434, precision 0.8413, recall 0.8454, auc 0.8428
epoch 2801, loss 0.4148, train acc 84.32%, f1 0.8431, precision 0.8448, recall 0.8415, auc 0.8432
epoch 2901, loss 0.4106, train acc 84.28%, f1 0.8429, precision 0.8434, recall 0.8423, auc 0.8428
epoch 3001, loss 0.4357, train acc 84.37%, f1 0.8439, precision 0.8438, recall 0.8439, auc 0.8437
epoch 3101, loss 0.3128, train acc 84.42%, f1 0.8437, precision 0.8472, recall 0.8403, auc 0.8442
epoch 3201, loss 0.2865, train acc 84.40%, f1 0.8440, precision 0.8452, recall 0.8428, auc 0.8440
epoch 3301, loss 0.3243, train acc 84.47%, f1 0.8450, precision 0.8446, recall 0.8453, auc 0.8447
epoch 3401, loss 0.4600, train acc 84.49%, f1 0.8456, precision 0.8430, recall 0.8482, auc 0.8449
epoch 3501, loss 0.2898, train acc 84.58%, f1 0.8464, precision 0.8440, recall 0.8488, auc 0.8458
epoch 3601, loss 0.4512, train acc 84.69%, f1 0.8471, precision 0.8470, recall 0.8471, auc 0.8469
epoch 3701, loss 0.1879, train acc 84.73%, f1 0.8476, precision 0.8471, recall 0.8480, auc 0.8473
epoch 3801, loss 0.2949, train acc 84.81%, f1 0.8478, precision 0.8504, recall 0.8452, auc 0.8481
epoch 3901, loss 0.2604, train acc 84.90%, f1 0.8490, precision 0.8502, recall 0.8478, auc 0.8490
epoch 4001, loss 0.2765, train acc 84.96%, f1 0.8499, precision 0.8494, recall 0.8504, auc 0.8496
epoch 4101, loss 0.4456, train acc 85.13%, f1 0.8511, precision 0.8533, recall 0.8490, auc 0.8513
epoch 4201, loss 0.2421, train acc 85.24%, f1 0.8535, precision 0.8481, recall 0.8591, auc 0.8524
epoch 4301, loss 0.3897, train acc 85.33%, f1 0.8529, precision 0.8563, recall 0.8494, auc 0.8533
epoch 4401, loss 0.3168, train acc 85.43%, f1 0.8548, precision 0.8527, recall 0.8569, auc 0.8543
epoch 4501, loss 0.2460, train acc 85.52%, f1 0.8557, precision 0.8540, recall 0.8574, auc 0.8552
epoch 4601, loss 0.3630, train acc 85.59%, f1 0.8559, precision 0.8571, recall 0.8547, auc 0.8559
epoch 4701, loss 0.2763, train acc 85.74%, f1 0.8577, precision 0.8570, recall 0.8585, auc 0.8574
epoch 4801, loss 0.3160, train acc 85.84%, f1 0.8588, precision 0.8577, recall 0.8599, auc 0.8584
epoch 4901, loss 0.3986, train acc 85.96%, f1 0.8598, precision 0.8595, recall 0.8602, auc 0.8596
epoch 5001, loss 0.3079, train acc 86.08%, f1 0.8610, precision 0.8608, recall 0.8612, auc 0.8608
epoch 5101, loss 0.2619, train acc 86.18%, f1 0.8623, precision 0.8603, recall 0.8642, auc 0.8618
epoch 5201, loss 0.3249, train acc 86.27%, f1 0.8628, precision 0.8630, recall 0.8627, auc 0.8627
epoch 5301, loss 0.3314, train acc 86.41%, f1 0.8643, precision 0.8640, recall 0.8646, auc 0.8641
epoch 5401, loss 0.3274, train acc 86.47%, f1 0.8654, precision 0.8618, recall 0.8690, auc 0.8646
epoch 5501, loss 0.2725, train acc 86.59%, f1 0.8658, precision 0.8674, recall 0.8643, auc 0.8659
epoch 5601, loss 0.3853, train acc 86.71%, f1 0.8671, precision 0.8684, recall 0.8658, auc 0.8671
epoch 5701, loss 0.3823, train acc 86.83%, f1 0.8682, precision 0.8702, recall 0.8662, auc 0.8684
epoch 5801, loss 0.2412, train acc 86.87%, f1 0.8687, precision 0.8695, recall 0.8679, auc 0.8687
epoch 5901, loss 0.2484, train acc 86.95%, f1 0.8701, precision 0.8673, recall 0.8728, auc 0.8695
epoch 6001, loss 0.3557, train acc 87.02%, f1 0.8705, precision 0.8701, recall 0.8708, auc 0.8702
epoch 6101, loss 0.2901, train acc 87.11%, f1 0.8713, precision 0.8707, recall 0.8719, auc 0.8711
epoch 6201, loss 0.3308, train acc 87.12%, f1 0.8715, precision 0.8705, recall 0.8725, auc 0.8712
epoch 6301, loss 0.3560, train acc 87.26%, f1 0.8734, precision 0.8695, recall 0.8772, auc 0.8726
epoch 6401, loss 0.1925, train acc 87.35%, f1 0.8738, precision 0.8727, recall 0.8750, auc 0.8735
epoch 6501, loss 0.3079, train acc 87.31%, f1 0.8737, precision 0.8702, recall 0.8773, auc 0.8731
epoch 6601, loss 0.4040, train acc 87.50%, f1 0.8750, precision 0.8759, recall 0.8741, auc 0.8750
epoch 6701, loss 0.3024, train acc 87.54%, f1 0.8757, precision 0.8749, recall 0.8765, auc 0.8754
epoch 6801, loss 0.2853, train acc 87.53%, f1 0.8757, precision 0.8739, recall 0.8776, auc 0.8753
epoch 6901, loss 0.2723, train acc 87.62%, f1 0.8763, precision 0.8769, recall 0.8758, auc 0.8762
epoch 7001, loss 0.2960, train acc 87.64%, f1 0.8761, precision 0.8792, recall 0.8731, auc 0.8764
epoch 7101, loss 0.2383, train acc 87.70%, f1 0.8771, precision 0.8770, recall 0.8773, auc 0.8770
epoch 7201, loss 0.2436, train acc 87.76%, f1 0.8780, precision 0.8761, recall 0.8800, auc 0.8776
epoch 7301, loss 0.2679, train acc 87.83%, f1 0.8785, precision 0.8781, recall 0.8790, auc 0.8783
epoch 7401, loss 0.2486, train acc 87.85%, f1 0.8790, precision 0.8763, recall 0.8817, auc 0.8785
epoch 7501, loss 0.2558, train acc 87.92%, f1 0.8795, precision 0.8782, recall 0.8809, auc 0.8792
epoch 7601, loss 0.2314, train acc 87.91%, f1 0.8791, precision 0.8795, recall 0.8787, auc 0.8791
epoch 7701, loss 0.3326, train acc 88.01%, f1 0.8802, precision 0.8802, recall 0.8803, auc 0.8801
epoch 7801, loss 0.2764, train acc 88.08%, f1 0.8808, precision 0.8817, recall 0.8800, auc 0.8808
epoch 7901, loss 0.2682, train acc 88.10%, f1 0.8811, precision 0.8808, recall 0.8815, auc 0.8810
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_notMirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_5
./test_pima/result_MLP_concat_notMirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.7005660377358491

the Fscore is 0.638036809815951

the precision is 0.4727272727272727

the recall is 0.9811320754716981

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_5
----------------------



epoch 1, loss 0.6933, train acc 49.95%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5697, train acc 78.59%, f1 0.7810, precision 0.8000, recall 0.7629, auc 0.7859
epoch 201, loss 0.4451, train acc 81.98%, f1 0.8197, precision 0.8211, recall 0.8183, auc 0.8198
epoch 301, loss 0.3148, train acc 83.37%, f1 0.8345, precision 0.8315, recall 0.8375, auc 0.8337
epoch 401, loss 0.3237, train acc 83.92%, f1 0.8389, precision 0.8411, recall 0.8368, auc 0.8392
epoch 501, loss 0.2353, train acc 84.12%, f1 0.8415, precision 0.8407, recall 0.8424, auc 0.8412
epoch 601, loss 0.4704, train acc 84.18%, f1 0.8425, precision 0.8400, recall 0.8450, auc 0.8418
epoch 701, loss 0.2466, train acc 84.21%, f1 0.8429, precision 0.8395, recall 0.8464, auc 0.8421
epoch 801, loss 0.3822, train acc 84.21%, f1 0.8426, precision 0.8408, recall 0.8444, auc 0.8421
epoch 901, loss 0.3585, train acc 84.26%, f1 0.8432, precision 0.8408, recall 0.8457, auc 0.8426
epoch 1001, loss 0.3801, train acc 84.21%, f1 0.8428, precision 0.8397, recall 0.8460, auc 0.8421
epoch 1101, loss 0.4118, train acc 84.18%, f1 0.8423, precision 0.8408, recall 0.8437, auc 0.8418
epoch 1201, loss 0.4070, train acc 84.19%, f1 0.8428, precision 0.8389, recall 0.8468, auc 0.8419
epoch 1301, loss 0.4413, train acc 84.22%, f1 0.8428, precision 0.8404, recall 0.8452, auc 0.8422
epoch 1401, loss 0.3048, train acc 84.19%, f1 0.8426, precision 0.8395, recall 0.8458, auc 0.8419
epoch 1501, loss 0.4584, train acc 84.28%, f1 0.8435, precision 0.8404, recall 0.8466, auc 0.8428
epoch 1601, loss 0.3068, train acc 84.22%, f1 0.8426, precision 0.8413, recall 0.8440, auc 0.8422
epoch 1701, loss 0.3034, train acc 84.22%, f1 0.8427, precision 0.8411, recall 0.8442, auc 0.8422
epoch 1801, loss 0.4144, train acc 84.23%, f1 0.8429, precision 0.8402, recall 0.8457, auc 0.8423
epoch 1901, loss 0.3307, train acc 84.23%, f1 0.8428, precision 0.8408, recall 0.8449, auc 0.8423
epoch 2001, loss 0.3738, train acc 84.22%, f1 0.8423, precision 0.8426, recall 0.8420, auc 0.8422
epoch 2101, loss 0.3526, train acc 84.19%, f1 0.8429, precision 0.8384, recall 0.8474, auc 0.8419
epoch 2201, loss 0.3111, train acc 84.28%, f1 0.8431, precision 0.8422, recall 0.8439, auc 0.8428
epoch 2301, loss 0.3941, train acc 84.25%, f1 0.8429, precision 0.8415, recall 0.8442, auc 0.8425
epoch 2401, loss 0.3887, train acc 84.26%, f1 0.8428, precision 0.8425, recall 0.8430, auc 0.8426
epoch 2501, loss 0.3977, train acc 84.20%, f1 0.8425, precision 0.8410, recall 0.8439, auc 0.8420
epoch 2601, loss 0.3119, train acc 84.25%, f1 0.8430, precision 0.8411, recall 0.8450, auc 0.8425
epoch 2701, loss 0.3244, train acc 84.29%, f1 0.8428, precision 0.8441, recall 0.8414, auc 0.8429
epoch 2801, loss 0.2874, train acc 84.25%, f1 0.8428, precision 0.8421, recall 0.8436, auc 0.8425
epoch 2901, loss 0.3607, train acc 84.27%, f1 0.8435, precision 0.8404, recall 0.8466, auc 0.8427
epoch 3001, loss 0.3117, train acc 84.32%, f1 0.8435, precision 0.8427, recall 0.8442, auc 0.8432
epoch 3101, loss 0.3143, train acc 84.43%, f1 0.8447, precision 0.8432, recall 0.8461, auc 0.8443
epoch 3201, loss 0.3500, train acc 84.38%, f1 0.8440, precision 0.8438, recall 0.8442, auc 0.8438
epoch 3301, loss 0.3518, train acc 84.45%, f1 0.8446, precision 0.8452, recall 0.8440, auc 0.8445
epoch 3401, loss 0.3073, train acc 84.49%, f1 0.8449, precision 0.8456, recall 0.8442, auc 0.8449
epoch 3501, loss 0.4196, train acc 84.57%, f1 0.8456, precision 0.8473, recall 0.8438, auc 0.8457
epoch 3601, loss 0.2891, train acc 84.68%, f1 0.8466, precision 0.8484, recall 0.8447, auc 0.8468
epoch 3701, loss 0.3784, train acc 84.72%, f1 0.8480, precision 0.8442, recall 0.8518, auc 0.8471
epoch 3801, loss 0.2483, train acc 84.89%, f1 0.8489, precision 0.8497, recall 0.8481, auc 0.8489
epoch 3901, loss 0.4112, train acc 84.94%, f1 0.8494, precision 0.8503, recall 0.8486, auc 0.8494
epoch 4001, loss 0.4134, train acc 84.94%, f1 0.8495, precision 0.8498, recall 0.8491, auc 0.8494
epoch 4101, loss 0.3730, train acc 85.16%, f1 0.8509, precision 0.8556, recall 0.8462, auc 0.8516
epoch 4201, loss 0.3463, train acc 85.22%, f1 0.8517, precision 0.8557, recall 0.8476, auc 0.8522
epoch 4301, loss 0.2617, train acc 85.33%, f1 0.8533, precision 0.8544, recall 0.8522, auc 0.8533
epoch 4401, loss 0.3072, train acc 85.43%, f1 0.8542, precision 0.8556, recall 0.8529, auc 0.8543
epoch 4501, loss 0.4289, train acc 85.54%, f1 0.8550, precision 0.8579, recall 0.8522, auc 0.8554
epoch 4601, loss 0.3533, train acc 85.65%, f1 0.8564, precision 0.8581, recall 0.8547, auc 0.8565
epoch 4701, loss 0.3310, train acc 85.67%, f1 0.8572, precision 0.8549, recall 0.8594, auc 0.8566
epoch 4801, loss 0.2731, train acc 85.79%, f1 0.8576, precision 0.8604, recall 0.8548, auc 0.8579
epoch 4901, loss 0.3741, train acc 85.85%, f1 0.8583, precision 0.8601, recall 0.8565, auc 0.8585
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_notMirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_5
./test_pima/result_MLP_concat_notMirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6561320754716982

the Fscore is 0.6035502958579881

the precision is 0.4396551724137931

the recall is 0.9622641509433962

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_5
----------------------



epoch 1, loss 0.6932, train acc 49.95%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5678, train acc 78.49%, f1 0.7848, precision 0.7860, recall 0.7836, auc 0.7849
epoch 201, loss 0.3071, train acc 81.87%, f1 0.8185, precision 0.8200, recall 0.8170, auc 0.8187
epoch 301, loss 0.4553, train acc 83.44%, f1 0.8348, precision 0.8336, recall 0.8360, auc 0.8344
epoch 401, loss 0.4014, train acc 83.97%, f1 0.8398, precision 0.8401, recall 0.8396, auc 0.8397
epoch 501, loss 0.3703, train acc 84.08%, f1 0.8412, precision 0.8400, recall 0.8424, auc 0.8408
epoch 601, loss 0.3415, train acc 84.21%, f1 0.8420, precision 0.8431, recall 0.8409, auc 0.8421
epoch 701, loss 0.3494, train acc 84.21%, f1 0.8422, precision 0.8422, recall 0.8422, auc 0.8421
epoch 801, loss 0.3920, train acc 84.27%, f1 0.8425, precision 0.8446, recall 0.8403, auc 0.8427
epoch 901, loss 0.2788, train acc 84.23%, f1 0.8421, precision 0.8441, recall 0.8402, auc 0.8424
epoch 1001, loss 0.3402, train acc 84.20%, f1 0.8414, precision 0.8456, recall 0.8372, auc 0.8420
epoch 1101, loss 0.2649, train acc 84.20%, f1 0.8424, precision 0.8410, recall 0.8439, auc 0.8420
epoch 1201, loss 0.4684, train acc 84.24%, f1 0.8424, precision 0.8435, recall 0.8413, auc 0.8424
epoch 1301, loss 0.3489, train acc 84.23%, f1 0.8424, precision 0.8425, recall 0.8423, auc 0.8423
epoch 1401, loss 0.2997, train acc 84.21%, f1 0.8421, precision 0.8432, recall 0.8409, auc 0.8421
epoch 1501, loss 0.4522, train acc 84.15%, f1 0.8415, precision 0.8423, recall 0.8407, auc 0.8415
epoch 1601, loss 0.3600, train acc 84.22%, f1 0.8421, precision 0.8435, recall 0.8408, auc 0.8422
epoch 1701, loss 0.3001, train acc 84.22%, f1 0.8427, precision 0.8406, recall 0.8449, auc 0.8422
epoch 1801, loss 0.4138, train acc 84.24%, f1 0.8423, precision 0.8438, recall 0.8408, auc 0.8424
epoch 1901, loss 0.3045, train acc 84.22%, f1 0.8415, precision 0.8461, recall 0.8369, auc 0.8422
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_concat_notMirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_5
./test_pima/result_MLP_concat_notMirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.5811320754716981

the Fscore is 0.5543478260869565

the precision is 0.3893129770992366

the recall is 0.9622641509433962

Done
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_5
----------------------



epoch 1, loss 0.6931, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693124).  Saving model ...
Validation loss decreased (0.693124 --> 0.693088).  Saving model ...
Validation loss decreased (0.693088 --> 0.693060).  Saving model ...
Validation loss decreased (0.693060 --> 0.693023).  Saving model ...
Validation loss decreased (0.693023 --> 0.692980).  Saving model ...
Validation loss decreased (0.692980 --> 0.692932).  Saving model ...
Validation loss decreased (0.692932 --> 0.692879).  Saving model ...
Validation loss decreased (0.692879 --> 0.692820).  Saving model ...
Validation loss decreased (0.692820 --> 0.692756).  Saving model ...
Validation loss decreased (0.692756 --> 0.692682).  Saving model ...
Validation loss decreased (0.692682 --> 0.692601).  Saving model ...
Validation loss decreased (0.692601 --> 0.692512).  Saving model ...
Validation loss decreased (0.692512 --> 0.692420).  Saving model ...
Validation loss decreased (0.692420 --> 0.692323).  Saving model ...
Validation loss decreased (0.692323 --> 0.692216).  Saving model ...
Validation loss decreased (0.692216 --> 0.692102).  Saving model ...
Validation loss decreased (0.692102 --> 0.691981).  Saving model ...
Validation loss decreased (0.691981 --> 0.691850).  Saving model ...
Validation loss decreased (0.691850 --> 0.691709).  Saving model ...
Validation loss decreased (0.691709 --> 0.691553).  Saving model ...
Validation loss decreased (0.691553 --> 0.691389).  Saving model ...
Validation loss decreased (0.691389 --> 0.691213).  Saving model ...
Validation loss decreased (0.691213 --> 0.691027).  Saving model ...
Validation loss decreased (0.691027 --> 0.690830).  Saving model ...
Validation loss decreased (0.690830 --> 0.690617).  Saving model ...
Validation loss decreased (0.690617 --> 0.690401).  Saving model ...
Validation loss decreased (0.690401 --> 0.690166).  Saving model ...
Validation loss decreased (0.690166 --> 0.689922).  Saving model ...
Validation loss decreased (0.689922 --> 0.689662).  Saving model ...
Validation loss decreased (0.689662 --> 0.689382).  Saving model ...
Validation loss decreased (0.689382 --> 0.689096).  Saving model ...
Validation loss decreased (0.689096 --> 0.688794).  Saving model ...
Validation loss decreased (0.688794 --> 0.688469).  Saving model ...
Validation loss decreased (0.688469 --> 0.688133).  Saving model ...
Validation loss decreased (0.688133 --> 0.687786).  Saving model ...
Validation loss decreased (0.687786 --> 0.687428).  Saving model ...
Validation loss decreased (0.687428 --> 0.687044).  Saving model ...
Validation loss decreased (0.687044 --> 0.686640).  Saving model ...
Validation loss decreased (0.686640 --> 0.686230).  Saving model ...
Validation loss decreased (0.686230 --> 0.685807).  Saving model ...
Validation loss decreased (0.685807 --> 0.685375).  Saving model ...
Validation loss decreased (0.685375 --> 0.684941).  Saving model ...
Validation loss decreased (0.684941 --> 0.684475).  Saving model ...
Validation loss decreased (0.684475 --> 0.684002).  Saving model ...
Validation loss decreased (0.684002 --> 0.683511).  Saving model ...
Validation loss decreased (0.683511 --> 0.683006).  Saving model ...
Validation loss decreased (0.683006 --> 0.682485).  Saving model ...
Validation loss decreased (0.682485 --> 0.681954).  Saving model ...
Validation loss decreased (0.681954 --> 0.681408).  Saving model ...
Validation loss decreased (0.681408 --> 0.680845).  Saving model ...
Validation loss decreased (0.680845 --> 0.680250).  Saving model ...
Validation loss decreased (0.680250 --> 0.679649).  Saving model ...
Validation loss decreased (0.679649 --> 0.679030).  Saving model ...
Validation loss decreased (0.679030 --> 0.678400).  Saving model ...
Validation loss decreased (0.678400 --> 0.677753).  Saving model ...
Validation loss decreased (0.677753 --> 0.677081).  Saving model ...
Validation loss decreased (0.677081 --> 0.676407).  Saving model ...
Validation loss decreased (0.676407 --> 0.675726).  Saving model ...
Validation loss decreased (0.675726 --> 0.675046).  Saving model ...
Validation loss decreased (0.675046 --> 0.674345).  Saving model ...
Validation loss decreased (0.674345 --> 0.673638).  Saving model ...
Validation loss decreased (0.673638 --> 0.672926).  Saving model ...
Validation loss decreased (0.672926 --> 0.672203).  Saving model ...
Validation loss decreased (0.672203 --> 0.671486).  Saving model ...
Validation loss decreased (0.671486 --> 0.670754).  Saving model ...
Validation loss decreased (0.670754 --> 0.670007).  Saving model ...
Validation loss decreased (0.670007 --> 0.669261).  Saving model ...
Validation loss decreased (0.669261 --> 0.668497).  Saving model ...
Validation loss decreased (0.668497 --> 0.667705).  Saving model ...
Validation loss decreased (0.667705 --> 0.666897).  Saving model ...
Validation loss decreased (0.666897 --> 0.666100).  Saving model ...
Validation loss decreased (0.666100 --> 0.665310).  Saving model ...
Validation loss decreased (0.665310 --> 0.664501).  Saving model ...
Validation loss decreased (0.664501 --> 0.663672).  Saving model ...
Validation loss decreased (0.663672 --> 0.662821).  Saving model ...
Validation loss decreased (0.662821 --> 0.661953).  Saving model ...
Validation loss decreased (0.661953 --> 0.661090).  Saving model ...
Validation loss decreased (0.661090 --> 0.660202).  Saving model ...
Validation loss decreased (0.660202 --> 0.659285).  Saving model ...
Validation loss decreased (0.659285 --> 0.658342).  Saving model ...
Validation loss decreased (0.658342 --> 0.657377).  Saving model ...
Validation loss decreased (0.657377 --> 0.656378).  Saving model ...
Validation loss decreased (0.656378 --> 0.655418).  Saving model ...
Validation loss decreased (0.655418 --> 0.654488).  Saving model ...
Validation loss decreased (0.654488 --> 0.653595).  Saving model ...
Validation loss decreased (0.653595 --> 0.652684).  Saving model ...
Validation loss decreased (0.652684 --> 0.651754).  Saving model ...
Validation loss decreased (0.651754 --> 0.650868).  Saving model ...
Validation loss decreased (0.650868 --> 0.649971).  Saving model ...
Validation loss decreased (0.649971 --> 0.649054).  Saving model ...
Validation loss decreased (0.649054 --> 0.648100).  Saving model ...
Validation loss decreased (0.648100 --> 0.647159).  Saving model ...
Validation loss decreased (0.647159 --> 0.646252).  Saving model ...
Validation loss decreased (0.646252 --> 0.645337).  Saving model ...
Validation loss decreased (0.645337 --> 0.644443).  Saving model ...
Validation loss decreased (0.644443 --> 0.643591).  Saving model ...
Validation loss decreased (0.643591 --> 0.642789).  Saving model ...
Validation loss decreased (0.642789 --> 0.641988).  Saving model ...
Validation loss decreased (0.641988 --> 0.641162).  Saving model ...
Validation loss decreased (0.641162 --> 0.640346).  Saving model ...
epoch 101, loss 0.5895, train acc 72.00%, f1 0.7200, precision 0.7200, recall 0.7200, auc 0.7200
Validation loss decreased (0.640346 --> 0.639522).  Saving model ...
Validation loss decreased (0.639522 --> 0.638662).  Saving model ...
Validation loss decreased (0.638662 --> 0.637797).  Saving model ...
Validation loss decreased (0.637797 --> 0.636946).  Saving model ...
Validation loss decreased (0.636946 --> 0.636143).  Saving model ...
Validation loss decreased (0.636143 --> 0.635321).  Saving model ...
Validation loss decreased (0.635321 --> 0.634490).  Saving model ...
Validation loss decreased (0.634490 --> 0.633661).  Saving model ...
Validation loss decreased (0.633661 --> 0.632817).  Saving model ...
Validation loss decreased (0.632817 --> 0.631984).  Saving model ...
Validation loss decreased (0.631984 --> 0.631118).  Saving model ...
Validation loss decreased (0.631118 --> 0.630220).  Saving model ...
Validation loss decreased (0.630220 --> 0.629305).  Saving model ...
Validation loss decreased (0.629305 --> 0.628350).  Saving model ...
Validation loss decreased (0.628350 --> 0.627430).  Saving model ...
Validation loss decreased (0.627430 --> 0.626487).  Saving model ...
Validation loss decreased (0.626487 --> 0.625485).  Saving model ...
Validation loss decreased (0.625485 --> 0.624459).  Saving model ...
Validation loss decreased (0.624459 --> 0.623426).  Saving model ...
Validation loss decreased (0.623426 --> 0.622431).  Saving model ...
Validation loss decreased (0.622431 --> 0.621421).  Saving model ...
Validation loss decreased (0.621421 --> 0.620443).  Saving model ...
Validation loss decreased (0.620443 --> 0.619446).  Saving model ...
Validation loss decreased (0.619446 --> 0.618408).  Saving model ...
Validation loss decreased (0.618408 --> 0.617399).  Saving model ...
Validation loss decreased (0.617399 --> 0.616393).  Saving model ...
Validation loss decreased (0.616393 --> 0.615415).  Saving model ...
Validation loss decreased (0.615415 --> 0.614437).  Saving model ...
Validation loss decreased (0.614437 --> 0.613458).  Saving model ...
Validation loss decreased (0.613458 --> 0.612406).  Saving model ...
Validation loss decreased (0.612406 --> 0.611368).  Saving model ...
Validation loss decreased (0.611368 --> 0.610306).  Saving model ...
Validation loss decreased (0.610306 --> 0.609219).  Saving model ...
Validation loss decreased (0.609219 --> 0.608136).  Saving model ...
Validation loss decreased (0.608136 --> 0.607072).  Saving model ...
Validation loss decreased (0.607072 --> 0.606080).  Saving model ...
Validation loss decreased (0.606080 --> 0.605018).  Saving model ...
Validation loss decreased (0.605018 --> 0.603953).  Saving model ...
Validation loss decreased (0.603953 --> 0.602941).  Saving model ...
Validation loss decreased (0.602941 --> 0.601902).  Saving model ...
Validation loss decreased (0.601902 --> 0.600895).  Saving model ...
Validation loss decreased (0.600895 --> 0.599951).  Saving model ...
Validation loss decreased (0.599951 --> 0.598954).  Saving model ...
Validation loss decreased (0.598954 --> 0.597998).  Saving model ...
Validation loss decreased (0.597998 --> 0.597073).  Saving model ...
Validation loss decreased (0.597073 --> 0.596074).  Saving model ...
Validation loss decreased (0.596074 --> 0.595040).  Saving model ...
Validation loss decreased (0.595040 --> 0.594012).  Saving model ...
Validation loss decreased (0.594012 --> 0.593035).  Saving model ...
Validation loss decreased (0.593035 --> 0.592074).  Saving model ...
Validation loss decreased (0.592074 --> 0.591140).  Saving model ...
Validation loss decreased (0.591140 --> 0.590165).  Saving model ...
Validation loss decreased (0.590165 --> 0.589159).  Saving model ...
Validation loss decreased (0.589159 --> 0.588157).  Saving model ...
Validation loss decreased (0.588157 --> 0.587198).  Saving model ...
Validation loss decreased (0.587198 --> 0.586358).  Saving model ...
Validation loss decreased (0.586358 --> 0.585490).  Saving model ...
Validation loss decreased (0.585490 --> 0.584641).  Saving model ...
Validation loss decreased (0.584641 --> 0.583834).  Saving model ...
Validation loss decreased (0.583834 --> 0.583027).  Saving model ...
Validation loss decreased (0.583027 --> 0.582274).  Saving model ...
Validation loss decreased (0.582274 --> 0.581601).  Saving model ...
Validation loss decreased (0.581601 --> 0.580847).  Saving model ...
Validation loss decreased (0.580847 --> 0.580070).  Saving model ...
Validation loss decreased (0.580070 --> 0.579250).  Saving model ...
Validation loss decreased (0.579250 --> 0.578401).  Saving model ...
Validation loss decreased (0.578401 --> 0.577599).  Saving model ...
Validation loss decreased (0.577599 --> 0.576793).  Saving model ...
Validation loss decreased (0.576793 --> 0.575988).  Saving model ...
Validation loss decreased (0.575988 --> 0.575261).  Saving model ...
Validation loss decreased (0.575261 --> 0.574490).  Saving model ...
Validation loss decreased (0.574490 --> 0.573720).  Saving model ...
Validation loss decreased (0.573720 --> 0.572961).  Saving model ...
Validation loss decreased (0.572961 --> 0.572214).  Saving model ...
Validation loss decreased (0.572214 --> 0.571441).  Saving model ...
Validation loss decreased (0.571441 --> 0.570698).  Saving model ...
Validation loss decreased (0.570698 --> 0.569925).  Saving model ...
Validation loss decreased (0.569925 --> 0.569165).  Saving model ...
Validation loss decreased (0.569165 --> 0.568416).  Saving model ...
Validation loss decreased (0.568416 --> 0.567620).  Saving model ...
Validation loss decreased (0.567620 --> 0.566831).  Saving model ...
Validation loss decreased (0.566831 --> 0.565915).  Saving model ...
Validation loss decreased (0.565915 --> 0.564989).  Saving model ...
Validation loss decreased (0.564989 --> 0.564091).  Saving model ...
Validation loss decreased (0.564091 --> 0.563259).  Saving model ...
Validation loss decreased (0.563259 --> 0.562445).  Saving model ...
Validation loss decreased (0.562445 --> 0.561659).  Saving model ...
Validation loss decreased (0.561659 --> 0.560881).  Saving model ...
Validation loss decreased (0.560881 --> 0.560036).  Saving model ...
Validation loss decreased (0.560036 --> 0.559153).  Saving model ...
Validation loss decreased (0.559153 --> 0.558345).  Saving model ...
Validation loss decreased (0.558345 --> 0.557507).  Saving model ...
Validation loss decreased (0.557507 --> 0.556677).  Saving model ...
Validation loss decreased (0.556677 --> 0.555897).  Saving model ...
Validation loss decreased (0.555897 --> 0.555102).  Saving model ...
Validation loss decreased (0.555102 --> 0.554287).  Saving model ...
Validation loss decreased (0.554287 --> 0.553472).  Saving model ...
Validation loss decreased (0.553472 --> 0.552583).  Saving model ...
Validation loss decreased (0.552583 --> 0.551665).  Saving model ...
Validation loss decreased (0.551665 --> 0.550770).  Saving model ...
epoch 201, loss 0.5112, train acc 74.50%, f1 0.7450, precision 0.7450, recall 0.7450, auc 0.7450
Validation loss decreased (0.550770 --> 0.549850).  Saving model ...
Validation loss decreased (0.549850 --> 0.548944).  Saving model ...
Validation loss decreased (0.548944 --> 0.548109).  Saving model ...
Validation loss decreased (0.548109 --> 0.547335).  Saving model ...
Validation loss decreased (0.547335 --> 0.546608).  Saving model ...
Validation loss decreased (0.546608 --> 0.545831).  Saving model ...
Validation loss decreased (0.545831 --> 0.545106).  Saving model ...
Validation loss decreased (0.545106 --> 0.544416).  Saving model ...
Validation loss decreased (0.544416 --> 0.543763).  Saving model ...
Validation loss decreased (0.543763 --> 0.543060).  Saving model ...
Validation loss decreased (0.543060 --> 0.542375).  Saving model ...
Validation loss decreased (0.542375 --> 0.541731).  Saving model ...
Validation loss decreased (0.541731 --> 0.541034).  Saving model ...
Validation loss decreased (0.541034 --> 0.540329).  Saving model ...
Validation loss decreased (0.540329 --> 0.539612).  Saving model ...
Validation loss decreased (0.539612 --> 0.538966).  Saving model ...
Validation loss decreased (0.538966 --> 0.538359).  Saving model ...
Validation loss decreased (0.538359 --> 0.537658).  Saving model ...
Validation loss decreased (0.537658 --> 0.537026).  Saving model ...
Validation loss decreased (0.537026 --> 0.536409).  Saving model ...
Validation loss decreased (0.536409 --> 0.535807).  Saving model ...
Validation loss decreased (0.535807 --> 0.535217).  Saving model ...
Validation loss decreased (0.535217 --> 0.534652).  Saving model ...
Validation loss decreased (0.534652 --> 0.534097).  Saving model ...
Validation loss decreased (0.534097 --> 0.533546).  Saving model ...
Validation loss decreased (0.533546 --> 0.532979).  Saving model ...
Validation loss decreased (0.532979 --> 0.532445).  Saving model ...
Validation loss decreased (0.532445 --> 0.531952).  Saving model ...
Validation loss decreased (0.531952 --> 0.531420).  Saving model ...
Validation loss decreased (0.531420 --> 0.530988).  Saving model ...
Validation loss decreased (0.530988 --> 0.530443).  Saving model ...
Validation loss decreased (0.530443 --> 0.529825).  Saving model ...
Validation loss decreased (0.529825 --> 0.529191).  Saving model ...
Validation loss decreased (0.529191 --> 0.528570).  Saving model ...
Validation loss decreased (0.528570 --> 0.527936).  Saving model ...
Validation loss decreased (0.527936 --> 0.527332).  Saving model ...
Validation loss decreased (0.527332 --> 0.526740).  Saving model ...
Validation loss decreased (0.526740 --> 0.526144).  Saving model ...
Validation loss decreased (0.526144 --> 0.525615).  Saving model ...
Validation loss decreased (0.525615 --> 0.525160).  Saving model ...
Validation loss decreased (0.525160 --> 0.524714).  Saving model ...
Validation loss decreased (0.524714 --> 0.524190).  Saving model ...
Validation loss decreased (0.524190 --> 0.523772).  Saving model ...
Validation loss decreased (0.523772 --> 0.523365).  Saving model ...
Validation loss decreased (0.523365 --> 0.522920).  Saving model ...
Validation loss decreased (0.522920 --> 0.522527).  Saving model ...
Validation loss decreased (0.522527 --> 0.522111).  Saving model ...
Validation loss decreased (0.522111 --> 0.521694).  Saving model ...
Validation loss decreased (0.521694 --> 0.521295).  Saving model ...
Validation loss decreased (0.521295 --> 0.520987).  Saving model ...
Validation loss decreased (0.520987 --> 0.520564).  Saving model ...
Validation loss decreased (0.520564 --> 0.520166).  Saving model ...
Validation loss decreased (0.520166 --> 0.519765).  Saving model ...
Validation loss decreased (0.519765 --> 0.519299).  Saving model ...
Validation loss decreased (0.519299 --> 0.518851).  Saving model ...
Validation loss decreased (0.518851 --> 0.518300).  Saving model ...
Validation loss decreased (0.518300 --> 0.517794).  Saving model ...
Validation loss decreased (0.517794 --> 0.517199).  Saving model ...
Validation loss decreased (0.517199 --> 0.516641).  Saving model ...
Validation loss decreased (0.516641 --> 0.516079).  Saving model ...
Validation loss decreased (0.516079 --> 0.515537).  Saving model ...
Validation loss decreased (0.515537 --> 0.514920).  Saving model ...
Validation loss decreased (0.514920 --> 0.514280).  Saving model ...
Validation loss decreased (0.514280 --> 0.513663).  Saving model ...
Validation loss decreased (0.513663 --> 0.513156).  Saving model ...
Validation loss decreased (0.513156 --> 0.512663).  Saving model ...
Validation loss decreased (0.512663 --> 0.512208).  Saving model ...
Validation loss decreased (0.512208 --> 0.511718).  Saving model ...
Validation loss decreased (0.511718 --> 0.511254).  Saving model ...
Validation loss decreased (0.511254 --> 0.510840).  Saving model ...
Validation loss decreased (0.510840 --> 0.510506).  Saving model ...
Validation loss decreased (0.510506 --> 0.510223).  Saving model ...
Validation loss decreased (0.510223 --> 0.510016).  Saving model ...
Validation loss decreased (0.510016 --> 0.509803).  Saving model ...
Validation loss decreased (0.509803 --> 0.509598).  Saving model ...
Validation loss decreased (0.509598 --> 0.509304).  Saving model ...
Validation loss decreased (0.509304 --> 0.508977).  Saving model ...
Validation loss decreased (0.508977 --> 0.508610).  Saving model ...
Validation loss decreased (0.508610 --> 0.508172).  Saving model ...
Validation loss decreased (0.508172 --> 0.507698).  Saving model ...
Validation loss decreased (0.507698 --> 0.507239).  Saving model ...
Validation loss decreased (0.507239 --> 0.506810).  Saving model ...
Validation loss decreased (0.506810 --> 0.506425).  Saving model ...
Validation loss decreased (0.506425 --> 0.505978).  Saving model ...
Validation loss decreased (0.505978 --> 0.505440).  Saving model ...
Validation loss decreased (0.505440 --> 0.504868).  Saving model ...
Validation loss decreased (0.504868 --> 0.504335).  Saving model ...
Validation loss decreased (0.504335 --> 0.503752).  Saving model ...
Validation loss decreased (0.503752 --> 0.503105).  Saving model ...
Validation loss decreased (0.503105 --> 0.502500).  Saving model ...
Validation loss decreased (0.502500 --> 0.501851).  Saving model ...
Validation loss decreased (0.501851 --> 0.501263).  Saving model ...
Validation loss decreased (0.501263 --> 0.500651).  Saving model ...
Validation loss decreased (0.500651 --> 0.500094).  Saving model ...
Validation loss decreased (0.500094 --> 0.499526).  Saving model ...
Validation loss decreased (0.499526 --> 0.498935).  Saving model ...
Validation loss decreased (0.498935 --> 0.498394).  Saving model ...
Validation loss decreased (0.498394 --> 0.497906).  Saving model ...
Validation loss decreased (0.497906 --> 0.497458).  Saving model ...
Validation loss decreased (0.497458 --> 0.496968).  Saving model ...
epoch 301, loss 0.4403, train acc 77.50%, f1 0.7750, precision 0.7750, recall 0.7750, auc 0.7750
Validation loss decreased (0.496968 --> 0.496514).  Saving model ...
Validation loss decreased (0.496514 --> 0.496053).  Saving model ...
Validation loss decreased (0.496053 --> 0.495563).  Saving model ...
Validation loss decreased (0.495563 --> 0.495119).  Saving model ...
Validation loss decreased (0.495119 --> 0.494665).  Saving model ...
Validation loss decreased (0.494665 --> 0.494191).  Saving model ...
Validation loss decreased (0.494191 --> 0.493760).  Saving model ...
Validation loss decreased (0.493760 --> 0.493374).  Saving model ...
Validation loss decreased (0.493374 --> 0.493022).  Saving model ...
Validation loss decreased (0.493022 --> 0.492790).  Saving model ...
Validation loss decreased (0.492790 --> 0.492553).  Saving model ...
Validation loss decreased (0.492553 --> 0.492388).  Saving model ...
Validation loss decreased (0.492388 --> 0.492159).  Saving model ...
Validation loss decreased (0.492159 --> 0.491808).  Saving model ...
Validation loss decreased (0.491808 --> 0.491548).  Saving model ...
Validation loss decreased (0.491548 --> 0.491324).  Saving model ...
Validation loss decreased (0.491324 --> 0.491027).  Saving model ...
Validation loss decreased (0.491027 --> 0.490738).  Saving model ...
Validation loss decreased (0.490738 --> 0.490405).  Saving model ...
Validation loss decreased (0.490405 --> 0.490031).  Saving model ...
Validation loss decreased (0.490031 --> 0.489737).  Saving model ...
Validation loss decreased (0.489737 --> 0.489541).  Saving model ...
Validation loss decreased (0.489541 --> 0.489270).  Saving model ...
Validation loss decreased (0.489270 --> 0.488964).  Saving model ...
Validation loss decreased (0.488964 --> 0.488726).  Saving model ...
Validation loss decreased (0.488726 --> 0.488520).  Saving model ...
Validation loss decreased (0.488520 --> 0.488446).  Saving model ...
Validation loss decreased (0.488446 --> 0.488384).  Saving model ...
Validation loss decreased (0.488384 --> 0.488332).  Saving model ...
Validation loss decreased (0.488332 --> 0.488199).  Saving model ...
Validation loss decreased (0.488199 --> 0.488034).  Saving model ...
Validation loss decreased (0.488034 --> 0.487827).  Saving model ...
Validation loss decreased (0.487827 --> 0.487703).  Saving model ...
Validation loss decreased (0.487703 --> 0.487627).  Saving model ...
Validation loss decreased (0.487627 --> 0.487485).  Saving model ...
Validation loss decreased (0.487485 --> 0.487448).  Saving model ...
Validation loss decreased (0.487448 --> 0.487339).  Saving model ...
Validation loss decreased (0.487339 --> 0.487184).  Saving model ...
Validation loss decreased (0.487184 --> 0.487038).  Saving model ...
Validation loss decreased (0.487038 --> 0.486893).  Saving model ...
Validation loss decreased (0.486893 --> 0.486729).  Saving model ...
Validation loss decreased (0.486729 --> 0.486555).  Saving model ...
Validation loss decreased (0.486555 --> 0.486417).  Saving model ...
Validation loss decreased (0.486417 --> 0.486223).  Saving model ...
Validation loss decreased (0.486223 --> 0.486016).  Saving model ...
Validation loss decreased (0.486016 --> 0.485838).  Saving model ...
Validation loss decreased (0.485838 --> 0.485649).  Saving model ...
Validation loss decreased (0.485649 --> 0.485455).  Saving model ...
Validation loss decreased (0.485455 --> 0.485197).  Saving model ...
Validation loss decreased (0.485197 --> 0.484881).  Saving model ...
Validation loss decreased (0.484881 --> 0.484574).  Saving model ...
Validation loss decreased (0.484574 --> 0.484156).  Saving model ...
Validation loss decreased (0.484156 --> 0.483849).  Saving model ...
Validation loss decreased (0.483849 --> 0.483619).  Saving model ...
Validation loss decreased (0.483619 --> 0.483410).  Saving model ...
Validation loss decreased (0.483410 --> 0.483144).  Saving model ...
Validation loss decreased (0.483144 --> 0.483018).  Saving model ...
Validation loss decreased (0.483018 --> 0.482888).  Saving model ...
Validation loss decreased (0.482888 --> 0.482709).  Saving model ...
Validation loss decreased (0.482709 --> 0.482500).  Saving model ...
Validation loss decreased (0.482500 --> 0.482265).  Saving model ...
Validation loss decreased (0.482265 --> 0.482002).  Saving model ...
Validation loss decreased (0.482002 --> 0.481750).  Saving model ...
Validation loss decreased (0.481750 --> 0.481488).  Saving model ...
Validation loss decreased (0.481488 --> 0.481219).  Saving model ...
Validation loss decreased (0.481219 --> 0.480918).  Saving model ...
Validation loss decreased (0.480918 --> 0.480664).  Saving model ...
Validation loss decreased (0.480664 --> 0.480492).  Saving model ...
Validation loss decreased (0.480492 --> 0.480212).  Saving model ...
Validation loss decreased (0.480212 --> 0.479958).  Saving model ...
Validation loss decreased (0.479958 --> 0.479614).  Saving model ...
Validation loss decreased (0.479614 --> 0.479164).  Saving model ...
Validation loss decreased (0.479164 --> 0.478766).  Saving model ...
Validation loss decreased (0.478766 --> 0.478375).  Saving model ...
Validation loss decreased (0.478375 --> 0.478004).  Saving model ...
Validation loss decreased (0.478004 --> 0.477609).  Saving model ...
Validation loss decreased (0.477609 --> 0.477203).  Saving model ...
Validation loss decreased (0.477203 --> 0.476711).  Saving model ...
Validation loss decreased (0.476711 --> 0.476174).  Saving model ...
Validation loss decreased (0.476174 --> 0.475670).  Saving model ...
Validation loss decreased (0.475670 --> 0.475190).  Saving model ...
Validation loss decreased (0.475190 --> 0.474673).  Saving model ...
Validation loss decreased (0.474673 --> 0.474230).  Saving model ...
Validation loss decreased (0.474230 --> 0.473870).  Saving model ...
Validation loss decreased (0.473870 --> 0.473421).  Saving model ...
Validation loss decreased (0.473421 --> 0.472944).  Saving model ...
Validation loss decreased (0.472944 --> 0.472439).  Saving model ...
Validation loss decreased (0.472439 --> 0.472080).  Saving model ...
Validation loss decreased (0.472080 --> 0.471771).  Saving model ...
Validation loss decreased (0.471771 --> 0.471492).  Saving model ...
Validation loss decreased (0.471492 --> 0.471172).  Saving model ...
Validation loss decreased (0.471172 --> 0.470849).  Saving model ...
Validation loss decreased (0.470849 --> 0.470494).  Saving model ...
Validation loss decreased (0.470494 --> 0.470058).  Saving model ...
Validation loss decreased (0.470058 --> 0.469629).  Saving model ...
Validation loss decreased (0.469629 --> 0.469333).  Saving model ...
Validation loss decreased (0.469333 --> 0.469175).  Saving model ...
Validation loss decreased (0.469175 --> 0.468878).  Saving model ...
Validation loss decreased (0.468878 --> 0.468598).  Saving model ...
Validation loss decreased (0.468598 --> 0.468343).  Saving model ...
epoch 401, loss 0.3665, train acc 78.50%, f1 0.7850, precision 0.7850, recall 0.7850, auc 0.7850
Validation loss decreased (0.468343 --> 0.468161).  Saving model ...
Validation loss decreased (0.468161 --> 0.467942).  Saving model ...
Validation loss decreased (0.467942 --> 0.467852).  Saving model ...
Validation loss decreased (0.467852 --> 0.467780).  Saving model ...
Validation loss decreased (0.467780 --> 0.467598).  Saving model ...
Validation loss decreased (0.467598 --> 0.467363).  Saving model ...
Validation loss decreased (0.467363 --> 0.467282).  Saving model ...
Validation loss decreased (0.467282 --> 0.467111).  Saving model ...
Validation loss decreased (0.467111 --> 0.466906).  Saving model ...
Validation loss decreased (0.466906 --> 0.466841).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
Validation loss decreased (0.466841 --> 0.466824).  Saving model ...
Validation loss decreased (0.466824 --> 0.466702).  Saving model ...
Validation loss decreased (0.466702 --> 0.466470).  Saving model ...
Validation loss decreased (0.466470 --> 0.466367).  Saving model ...
Validation loss decreased (0.466367 --> 0.466249).  Saving model ...
Validation loss decreased (0.466249 --> 0.466147).  Saving model ...
Validation loss decreased (0.466147 --> 0.466022).  Saving model ...
Validation loss decreased (0.466022 --> 0.465915).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.465915 --> 0.465899).  Saving model ...
Validation loss decreased (0.465899 --> 0.465847).  Saving model ...
Validation loss decreased (0.465847 --> 0.465816).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.465816 --> 0.465769).  Saving model ...
Validation loss decreased (0.465769 --> 0.465626).  Saving model ...
Validation loss decreased (0.465626 --> 0.465442).  Saving model ...
Validation loss decreased (0.465442 --> 0.465231).  Saving model ...
Validation loss decreased (0.465231 --> 0.464938).  Saving model ...
Validation loss decreased (0.464938 --> 0.464692).  Saving model ...
Validation loss decreased (0.464692 --> 0.464481).  Saving model ...
Validation loss decreased (0.464481 --> 0.464288).  Saving model ...
Validation loss decreased (0.464288 --> 0.464067).  Saving model ...
Validation loss decreased (0.464067 --> 0.463757).  Saving model ...
Validation loss decreased (0.463757 --> 0.463480).  Saving model ...
Validation loss decreased (0.463480 --> 0.463241).  Saving model ...
Validation loss decreased (0.463241 --> 0.463075).  Saving model ...
Validation loss decreased (0.463075 --> 0.462899).  Saving model ...
Validation loss decreased (0.462899 --> 0.462790).  Saving model ...
Validation loss decreased (0.462790 --> 0.462700).  Saving model ...
Validation loss decreased (0.462700 --> 0.462555).  Saving model ...
Validation loss decreased (0.462555 --> 0.462399).  Saving model ...
Validation loss decreased (0.462399 --> 0.462170).  Saving model ...
Validation loss decreased (0.462170 --> 0.461962).  Saving model ...
Validation loss decreased (0.461962 --> 0.461768).  Saving model ...
Validation loss decreased (0.461768 --> 0.461638).  Saving model ...
Validation loss decreased (0.461638 --> 0.461358).  Saving model ...
Validation loss decreased (0.461358 --> 0.460854).  Saving model ...
Validation loss decreased (0.460854 --> 0.460370).  Saving model ...
Validation loss decreased (0.460370 --> 0.459970).  Saving model ...
Validation loss decreased (0.459970 --> 0.459670).  Saving model ...
Validation loss decreased (0.459670 --> 0.459482).  Saving model ...
Validation loss decreased (0.459482 --> 0.459083).  Saving model ...
Validation loss decreased (0.459083 --> 0.458786).  Saving model ...
Validation loss decreased (0.458786 --> 0.458587).  Saving model ...
Validation loss decreased (0.458587 --> 0.458534).  Saving model ...
Validation loss decreased (0.458534 --> 0.458411).  Saving model ...
Validation loss decreased (0.458411 --> 0.458309).  Saving model ...
Validation loss decreased (0.458309 --> 0.458228).  Saving model ...
Validation loss decreased (0.458228 --> 0.458144).  Saving model ...
Validation loss decreased (0.458144 --> 0.458030).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.458030 --> 0.458012).  Saving model ...
Validation loss decreased (0.458012 --> 0.457912).  Saving model ...
Validation loss decreased (0.457912 --> 0.457772).  Saving model ...
Validation loss decreased (0.457772 --> 0.457626).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.457626 --> 0.457445).  Saving model ...
Validation loss decreased (0.457445 --> 0.457215).  Saving model ...
Validation loss decreased (0.457215 --> 0.457028).  Saving model ...
Validation loss decreased (0.457028 --> 0.456866).  Saving model ...
Validation loss decreased (0.456866 --> 0.456754).  Saving model ...
Validation loss decreased (0.456754 --> 0.456727).  Saving model ...
Validation loss decreased (0.456727 --> 0.456570).  Saving model ...
Validation loss decreased (0.456570 --> 0.456411).  Saving model ...
Validation loss decreased (0.456411 --> 0.456327).  Saving model ...
Validation loss decreased (0.456327 --> 0.456122).  Saving model ...
Validation loss decreased (0.456122 --> 0.456058).  Saving model ...
Validation loss decreased (0.456058 --> 0.455829).  Saving model ...
Validation loss decreased (0.455829 --> 0.455601).  Saving model ...
Validation loss decreased (0.455601 --> 0.455449).  Saving model ...
Validation loss decreased (0.455449 --> 0.455228).  Saving model ...
Validation loss decreased (0.455228 --> 0.454986).  Saving model ...
Validation loss decreased (0.454986 --> 0.454780).  Saving model ...
Validation loss decreased (0.454780 --> 0.454604).  Saving model ...
Validation loss decreased (0.454604 --> 0.454521).  Saving model ...
Validation loss decreased (0.454521 --> 0.454438).  Saving model ...
Validation loss decreased (0.454438 --> 0.454388).  Saving model ...
Validation loss decreased (0.454388 --> 0.454385).  Saving model ...
Validation loss decreased (0.454385 --> 0.454335).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.454335 --> 0.454312).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
epoch 501, loss 0.2931, train acc 79.50%, f1 0.7950, precision 0.7950, recall 0.7950, auc 0.7950
Validation loss decreased (0.454312 --> 0.454308).  Saving model ...
Validation loss decreased (0.454308 --> 0.454275).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 522, loss 0.3870, train acc 79.50%, f1 0.7950, precision 0.7950, recall 0.7950, auc 0.7950



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_Mirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_5
./test_pima/result_MLP_minus_Mirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5911320754716981

the Fscore is 0.5604395604395604

the precision is 0.3953488372093023

the recall is 0.9622641509433962

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_5
----------------------



epoch 1, loss 0.6933, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.6084, train acc 78.24%, f1 0.7929, precision 0.7564, recall 0.8331, auc 0.7824
epoch 201, loss 0.5359, train acc 81.04%, f1 0.8117, precision 0.8064, recall 0.8170, auc 0.8104
epoch 301, loss 0.3611, train acc 82.41%, f1 0.8239, precision 0.8250, recall 0.8228, auc 0.8241
epoch 401, loss 0.4471, train acc 83.35%, f1 0.8330, precision 0.8358, recall 0.8302, auc 0.8335
epoch 501, loss 0.3075, train acc 83.84%, f1 0.8377, precision 0.8410, recall 0.8344, auc 0.8384
epoch 601, loss 0.3276, train acc 84.02%, f1 0.8395, precision 0.8430, recall 0.8361, auc 0.8402
epoch 701, loss 0.4096, train acc 84.11%, f1 0.8404, precision 0.8440, recall 0.8367, auc 0.8411
epoch 801, loss 0.2310, train acc 84.14%, f1 0.8409, precision 0.8438, recall 0.8379, auc 0.8414
epoch 901, loss 0.4635, train acc 84.20%, f1 0.8413, precision 0.8449, recall 0.8378, auc 0.8420
epoch 1001, loss 0.2816, train acc 84.23%, f1 0.8417, precision 0.8446, recall 0.8388, auc 0.8423
epoch 1101, loss 0.4077, train acc 84.23%, f1 0.8419, precision 0.8442, recall 0.8397, auc 0.8423
epoch 1201, loss 0.3597, train acc 84.24%, f1 0.8420, precision 0.8443, recall 0.8396, auc 0.8424
epoch 1301, loss 0.4892, train acc 84.22%, f1 0.8419, precision 0.8434, recall 0.8405, auc 0.8422
epoch 1401, loss 0.3295, train acc 84.25%, f1 0.8422, precision 0.8438, recall 0.8407, auc 0.8425
epoch 1501, loss 0.3553, train acc 84.28%, f1 0.8426, precision 0.8438, recall 0.8413, auc 0.8428
epoch 1601, loss 0.3899, train acc 84.26%, f1 0.8424, precision 0.8434, recall 0.8414, auc 0.8426
epoch 1701, loss 0.3608, train acc 84.28%, f1 0.8426, precision 0.8436, recall 0.8416, auc 0.8428
epoch 1801, loss 0.4449, train acc 84.22%, f1 0.8420, precision 0.8427, recall 0.8413, auc 0.8422
epoch 1901, loss 0.3830, train acc 84.24%, f1 0.8423, precision 0.8431, recall 0.8414, auc 0.8424
epoch 2001, loss 0.3640, train acc 84.26%, f1 0.8425, precision 0.8430, recall 0.8419, auc 0.8426
epoch 2101, loss 0.4519, train acc 84.27%, f1 0.8426, precision 0.8431, recall 0.8420, auc 0.8427
epoch 2201, loss 0.2510, train acc 84.28%, f1 0.8427, precision 0.8429, recall 0.8425, auc 0.8428
epoch 2301, loss 0.2927, train acc 84.26%, f1 0.8426, precision 0.8429, recall 0.8422, auc 0.8426
epoch 2401, loss 0.3363, train acc 84.17%, f1 0.8416, precision 0.8419, recall 0.8414, auc 0.8417
epoch 2501, loss 0.3622, train acc 84.27%, f1 0.8425, precision 0.8434, recall 0.8417, auc 0.8427
epoch 2601, loss 0.2824, train acc 84.23%, f1 0.8422, precision 0.8425, recall 0.8419, auc 0.8423
epoch 2701, loss 0.3303, train acc 84.21%, f1 0.8420, precision 0.8427, recall 0.8413, auc 0.8421
epoch 2801, loss 0.4123, train acc 84.26%, f1 0.8426, precision 0.8426, recall 0.8425, auc 0.8426
epoch 2901, loss 0.4085, train acc 84.25%, f1 0.8425, precision 0.8426, recall 0.8424, auc 0.8425
epoch 3001, loss 0.4063, train acc 84.31%, f1 0.8431, precision 0.8433, recall 0.8429, auc 0.8431
epoch 3101, loss 0.4807, train acc 84.28%, f1 0.8427, precision 0.8429, recall 0.8425, auc 0.8428
epoch 3201, loss 0.4054, train acc 84.28%, f1 0.8426, precision 0.8434, recall 0.8418, auc 0.8428
epoch 3301, loss 0.3307, train acc 84.34%, f1 0.8434, precision 0.8434, recall 0.8433, auc 0.8434
epoch 3401, loss 0.2952, train acc 84.38%, f1 0.8437, precision 0.8444, recall 0.8430, auc 0.8438
epoch 3501, loss 0.4364, train acc 84.30%, f1 0.8429, precision 0.8431, recall 0.8428, auc 0.8430
epoch 3601, loss 0.3570, train acc 84.33%, f1 0.8432, precision 0.8433, recall 0.8431, auc 0.8432
epoch 3701, loss 0.3041, train acc 84.24%, f1 0.8423, precision 0.8429, recall 0.8418, auc 0.8424
epoch 3801, loss 0.3092, train acc 84.31%, f1 0.8430, precision 0.8435, recall 0.8424, auc 0.8431
epoch 3901, loss 0.4193, train acc 84.31%, f1 0.8430, precision 0.8435, recall 0.8424, auc 0.8431
epoch 4001, loss 0.3252, train acc 84.34%, f1 0.8433, precision 0.8438, recall 0.8428, auc 0.8434
epoch 4101, loss 0.2475, train acc 84.34%, f1 0.8433, precision 0.8436, recall 0.8431, auc 0.8434
epoch 4201, loss 0.3150, train acc 84.24%, f1 0.8423, precision 0.8430, recall 0.8416, auc 0.8424
epoch 4301, loss 0.3572, train acc 84.35%, f1 0.8435, precision 0.8435, recall 0.8435, auc 0.8435
epoch 4401, loss 0.2317, train acc 84.36%, f1 0.8436, precision 0.8436, recall 0.8436, auc 0.8436
epoch 4501, loss 0.3499, train acc 84.38%, f1 0.8438, precision 0.8439, recall 0.8437, auc 0.8438
epoch 4601, loss 0.3491, train acc 84.38%, f1 0.8438, precision 0.8438, recall 0.8438, auc 0.8438
epoch 4701, loss 0.3110, train acc 84.30%, f1 0.8429, precision 0.8435, recall 0.8423, auc 0.8430
epoch 4801, loss 0.4303, train acc 84.39%, f1 0.8438, precision 0.8441, recall 0.8435, auc 0.8439
epoch 4901, loss 0.3954, train acc 84.39%, f1 0.8439, precision 0.8439, recall 0.8439, auc 0.8439
epoch 5001, loss 0.4762, train acc 84.44%, f1 0.8444, precision 0.8443, recall 0.8445, auc 0.8444
epoch 5101, loss 0.2776, train acc 84.44%, f1 0.8444, precision 0.8445, recall 0.8444, auc 0.8444
epoch 5201, loss 0.3109, train acc 84.47%, f1 0.8447, precision 0.8450, recall 0.8444, auc 0.8447
epoch 5301, loss 0.3450, train acc 84.48%, f1 0.8447, precision 0.8451, recall 0.8443, auc 0.8448
epoch 5401, loss 0.4773, train acc 84.43%, f1 0.8443, precision 0.8443, recall 0.8442, auc 0.8443
epoch 5501, loss 0.3046, train acc 84.50%, f1 0.8450, precision 0.8452, recall 0.8448, auc 0.8450
epoch 5601, loss 0.3597, train acc 84.47%, f1 0.8447, precision 0.8449, recall 0.8445, auc 0.8448
epoch 5701, loss 0.3137, train acc 84.51%, f1 0.8451, precision 0.8451, recall 0.8452, auc 0.8451
epoch 5801, loss 0.4264, train acc 84.50%, f1 0.8450, precision 0.8451, recall 0.8450, auc 0.8450
epoch 5901, loss 0.3156, train acc 84.56%, f1 0.8456, precision 0.8456, recall 0.8455, auc 0.8456
epoch 6001, loss 0.3234, train acc 84.63%, f1 0.8463, precision 0.8464, recall 0.8462, auc 0.8463
epoch 6101, loss 0.2529, train acc 84.67%, f1 0.8468, precision 0.8463, recall 0.8474, auc 0.8467
epoch 6201, loss 0.3487, train acc 84.67%, f1 0.8467, precision 0.8467, recall 0.8468, auc 0.8467
epoch 6301, loss 0.2893, train acc 84.67%, f1 0.8467, precision 0.8469, recall 0.8465, auc 0.8467
epoch 6401, loss 0.2851, train acc 84.72%, f1 0.8472, precision 0.8472, recall 0.8471, auc 0.8472
epoch 6501, loss 0.3814, train acc 84.69%, f1 0.8469, precision 0.8469, recall 0.8470, auc 0.8469
epoch 6601, loss 0.3794, train acc 84.68%, f1 0.8468, precision 0.8469, recall 0.8467, auc 0.8468
epoch 6701, loss 0.2360, train acc 84.79%, f1 0.8479, precision 0.8482, recall 0.8476, auc 0.8479
epoch 6801, loss 0.4861, train acc 84.80%, f1 0.8480, precision 0.8480, recall 0.8479, auc 0.8480
epoch 6901, loss 0.3075, train acc 84.83%, f1 0.8483, precision 0.8484, recall 0.8483, auc 0.8483
epoch 7001, loss 0.2911, train acc 84.86%, f1 0.8486, precision 0.8485, recall 0.8488, auc 0.8486
epoch 7101, loss 0.4461, train acc 84.84%, f1 0.8483, precision 0.8485, recall 0.8482, auc 0.8484
epoch 7201, loss 0.3857, train acc 84.88%, f1 0.8488, precision 0.8489, recall 0.8486, auc 0.8488
epoch 7301, loss 0.3657, train acc 84.90%, f1 0.8490, precision 0.8490, recall 0.8490, auc 0.8490
epoch 7401, loss 0.2624, train acc 84.97%, f1 0.8497, precision 0.8497, recall 0.8498, auc 0.8497
epoch 7501, loss 0.3517, train acc 84.98%, f1 0.8498, precision 0.8497, recall 0.8499, auc 0.8498
epoch 7601, loss 0.5153, train acc 84.99%, f1 0.8499, precision 0.8500, recall 0.8498, auc 0.8499
epoch 7701, loss 0.4367, train acc 85.02%, f1 0.8502, precision 0.8501, recall 0.8502, auc 0.8502
epoch 7801, loss 0.2867, train acc 85.05%, f1 0.8505, precision 0.8508, recall 0.8502, auc 0.8505
epoch 7901, loss 0.3998, train acc 85.04%, f1 0.8504, precision 0.8504, recall 0.8504, auc 0.8504
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_Mirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_5
./test_pima/result_MLP_minus_Mirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.655

the Fscore is 0.6057142857142858

the precision is 0.4344262295081967

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_5
----------------------



epoch 1, loss 0.6933, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6120, train acc 77.95%, f1 0.7662, precision 0.8153, recall 0.7226, auc 0.7795
epoch 201, loss 0.4590, train acc 80.90%, f1 0.8078, precision 0.8128, recall 0.8029, auc 0.8090
epoch 301, loss 0.3740, train acc 82.44%, f1 0.8248, precision 0.8230, recall 0.8267, auc 0.8244
epoch 401, loss 0.4245, train acc 83.40%, f1 0.8343, precision 0.8331, recall 0.8355, auc 0.8340
epoch 501, loss 0.3586, train acc 83.84%, f1 0.8390, precision 0.8356, recall 0.8425, auc 0.8384
epoch 601, loss 0.3159, train acc 84.03%, f1 0.8410, precision 0.8372, recall 0.8447, auc 0.8402
epoch 701, loss 0.3134, train acc 84.17%, f1 0.8423, precision 0.8391, recall 0.8455, auc 0.8417
epoch 801, loss 0.4049, train acc 84.18%, f1 0.8426, precision 0.8387, recall 0.8464, auc 0.8418
epoch 901, loss 0.3914, train acc 84.22%, f1 0.8428, precision 0.8395, recall 0.8461, auc 0.8422
epoch 1001, loss 0.4275, train acc 84.21%, f1 0.8427, precision 0.8397, recall 0.8456, auc 0.8421
epoch 1101, loss 0.4310, train acc 84.25%, f1 0.8431, precision 0.8401, recall 0.8461, auc 0.8425
epoch 1201, loss 0.5058, train acc 84.26%, f1 0.8430, precision 0.8412, recall 0.8448, auc 0.8426
epoch 1301, loss 0.3857, train acc 84.26%, f1 0.8431, precision 0.8404, recall 0.8457, auc 0.8426
epoch 1401, loss 0.3018, train acc 84.27%, f1 0.8430, precision 0.8414, recall 0.8447, auc 0.8427
epoch 1501, loss 0.3830, train acc 84.25%, f1 0.8427, precision 0.8415, recall 0.8440, auc 0.8425
epoch 1601, loss 0.3041, train acc 84.28%, f1 0.8430, precision 0.8421, recall 0.8438, auc 0.8428
epoch 1701, loss 0.4006, train acc 84.31%, f1 0.8434, precision 0.8418, recall 0.8449, auc 0.8431
epoch 1801, loss 0.3854, train acc 84.30%, f1 0.8432, precision 0.8422, recall 0.8442, auc 0.8430
epoch 1901, loss 0.4662, train acc 84.28%, f1 0.8430, precision 0.8422, recall 0.8438, auc 0.8428
epoch 2001, loss 0.4150, train acc 84.21%, f1 0.8421, precision 0.8419, recall 0.8424, auc 0.8421
epoch 2101, loss 0.3744, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8423, auc 0.8423
epoch 2201, loss 0.3651, train acc 84.25%, f1 0.8426, precision 0.8419, recall 0.8433, auc 0.8425
epoch 2301, loss 0.3139, train acc 84.25%, f1 0.8425, precision 0.8423, recall 0.8428, auc 0.8425
epoch 2401, loss 0.3711, train acc 84.27%, f1 0.8428, precision 0.8424, recall 0.8432, auc 0.8427
epoch 2501, loss 0.4002, train acc 84.26%, f1 0.8426, precision 0.8425, recall 0.8427, auc 0.8426
epoch 2601, loss 0.4176, train acc 84.20%, f1 0.8421, precision 0.8417, recall 0.8424, auc 0.8420
epoch 2701, loss 0.3608, train acc 84.22%, f1 0.8424, precision 0.8416, recall 0.8431, auc 0.8422
epoch 2801, loss 0.3990, train acc 84.29%, f1 0.8430, precision 0.8423, recall 0.8438, auc 0.8429
epoch 2901, loss 0.3591, train acc 84.25%, f1 0.8426, precision 0.8422, recall 0.8430, auc 0.8425
epoch 3001, loss 0.2806, train acc 84.24%, f1 0.8425, precision 0.8422, recall 0.8427, auc 0.8424
epoch 3101, loss 0.2848, train acc 84.25%, f1 0.8426, precision 0.8420, recall 0.8431, auc 0.8425
epoch 3201, loss 0.3563, train acc 84.25%, f1 0.8426, precision 0.8421, recall 0.8431, auc 0.8425
epoch 3301, loss 0.4922, train acc 84.23%, f1 0.8423, precision 0.8423, recall 0.8424, auc 0.8423
epoch 3401, loss 0.3444, train acc 84.23%, f1 0.8424, precision 0.8420, recall 0.8428, auc 0.8423
epoch 3501, loss 0.3985, train acc 84.27%, f1 0.8427, precision 0.8425, recall 0.8429, auc 0.8427
epoch 3601, loss 0.4000, train acc 84.28%, f1 0.8429, precision 0.8426, recall 0.8431, auc 0.8428
epoch 3701, loss 0.3621, train acc 84.26%, f1 0.8427, precision 0.8423, recall 0.8430, auc 0.8426
epoch 3801, loss 0.2684, train acc 84.28%, f1 0.8428, precision 0.8426, recall 0.8431, auc 0.8428
epoch 3901, loss 0.3630, train acc 84.28%, f1 0.8429, precision 0.8426, recall 0.8432, auc 0.8428
epoch 4001, loss 0.3415, train acc 84.31%, f1 0.8432, precision 0.8426, recall 0.8438, auc 0.8431
epoch 4101, loss 0.2852, train acc 84.35%, f1 0.8436, precision 0.8431, recall 0.8441, auc 0.8435
epoch 4201, loss 0.2631, train acc 84.31%, f1 0.8432, precision 0.8429, recall 0.8434, auc 0.8431
epoch 4301, loss 0.2807, train acc 84.34%, f1 0.8435, precision 0.8431, recall 0.8439, auc 0.8434
epoch 4401, loss 0.3050, train acc 84.36%, f1 0.8437, precision 0.8432, recall 0.8442, auc 0.8436
epoch 4501, loss 0.3218, train acc 84.40%, f1 0.8440, precision 0.8440, recall 0.8441, auc 0.8440
epoch 4601, loss 0.2788, train acc 84.38%, f1 0.8439, precision 0.8434, recall 0.8443, auc 0.8438
epoch 4701, loss 0.2907, train acc 84.43%, f1 0.8444, precision 0.8442, recall 0.8446, auc 0.8443
epoch 4801, loss 0.3976, train acc 84.35%, f1 0.8436, precision 0.8432, recall 0.8440, auc 0.8435
epoch 4901, loss 0.2753, train acc 84.43%, f1 0.8443, precision 0.8441, recall 0.8445, auc 0.8443
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_Mirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_5
./test_pima/result_MLP_minus_Mirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.615

the Fscore is 0.5792349726775957

the precision is 0.4076923076923077

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_5
----------------------



epoch 1, loss 0.6930, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6181, train acc 78.27%, f1 0.7720, precision 0.8120, recall 0.7358, auc 0.7827
epoch 201, loss 0.5333, train acc 81.12%, f1 0.8101, precision 0.8149, recall 0.8054, auc 0.8112
epoch 301, loss 0.3978, train acc 82.42%, f1 0.8243, precision 0.8241, recall 0.8244, auc 0.8242
epoch 401, loss 0.4333, train acc 83.32%, f1 0.8335, precision 0.8320, recall 0.8351, auc 0.8332
epoch 501, loss 0.4023, train acc 83.80%, f1 0.8386, precision 0.8357, recall 0.8415, auc 0.8380
epoch 601, loss 0.3456, train acc 83.99%, f1 0.8404, precision 0.8376, recall 0.8433, auc 0.8399
epoch 701, loss 0.4814, train acc 84.12%, f1 0.8419, precision 0.8384, recall 0.8455, auc 0.8412
epoch 801, loss 0.3232, train acc 84.20%, f1 0.8426, precision 0.8393, recall 0.8458, auc 0.8420
epoch 901, loss 0.3033, train acc 84.26%, f1 0.8432, precision 0.8404, recall 0.8459, auc 0.8426
epoch 1001, loss 0.3640, train acc 84.25%, f1 0.8429, precision 0.8408, recall 0.8450, auc 0.8425
epoch 1101, loss 0.4593, train acc 84.22%, f1 0.8426, precision 0.8407, recall 0.8445, auc 0.8422
epoch 1201, loss 0.5929, train acc 84.21%, f1 0.8427, precision 0.8399, recall 0.8455, auc 0.8421
epoch 1301, loss 0.4135, train acc 84.24%, f1 0.8427, precision 0.8408, recall 0.8446, auc 0.8424
epoch 1401, loss 0.3812, train acc 84.24%, f1 0.8428, precision 0.8408, recall 0.8448, auc 0.8424
epoch 1501, loss 0.3759, train acc 84.24%, f1 0.8426, precision 0.8414, recall 0.8438, auc 0.8424
epoch 1601, loss 0.4310, train acc 84.22%, f1 0.8424, precision 0.8415, recall 0.8433, auc 0.8422
epoch 1701, loss 0.2714, train acc 84.25%, f1 0.8427, precision 0.8416, recall 0.8437, auc 0.8425
epoch 1801, loss 0.2544, train acc 84.24%, f1 0.8423, precision 0.8425, recall 0.8422, auc 0.8424
epoch 1901, loss 0.4835, train acc 84.21%, f1 0.8422, precision 0.8418, recall 0.8425, auc 0.8421
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_Mirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_5
./test_pima/result_MLP_minus_Mirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5661320754716981

the Fscore is 0.5454545454545454

the precision is 0.3805970149253731

the recall is 0.9622641509433962

Done
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_5
----------------------



epoch 1, loss 0.6933, train acc 45.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693502).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
Validation loss decreased (0.693502 --> 0.693394).  Saving model ...
Validation loss decreased (0.693394 --> 0.693230).  Saving model ...
Validation loss decreased (0.693230 --> 0.693055).  Saving model ...
Validation loss decreased (0.693055 --> 0.692844).  Saving model ...
Validation loss decreased (0.692844 --> 0.692671).  Saving model ...
Validation loss decreased (0.692671 --> 0.692526).  Saving model ...
Validation loss decreased (0.692526 --> 0.692374).  Saving model ...
Validation loss decreased (0.692374 --> 0.692212).  Saving model ...
Validation loss decreased (0.692212 --> 0.692010).  Saving model ...
Validation loss decreased (0.692010 --> 0.691784).  Saving model ...
Validation loss decreased (0.691784 --> 0.691586).  Saving model ...
Validation loss decreased (0.691586 --> 0.691335).  Saving model ...
Validation loss decreased (0.691335 --> 0.691086).  Saving model ...
Validation loss decreased (0.691086 --> 0.690845).  Saving model ...
Validation loss decreased (0.690845 --> 0.690602).  Saving model ...
Validation loss decreased (0.690602 --> 0.690363).  Saving model ...
Validation loss decreased (0.690363 --> 0.690080).  Saving model ...
Validation loss decreased (0.690080 --> 0.689778).  Saving model ...
Validation loss decreased (0.689778 --> 0.689431).  Saving model ...
Validation loss decreased (0.689431 --> 0.689086).  Saving model ...
Validation loss decreased (0.689086 --> 0.688753).  Saving model ...
Validation loss decreased (0.688753 --> 0.688393).  Saving model ...
Validation loss decreased (0.688393 --> 0.688024).  Saving model ...
Validation loss decreased (0.688024 --> 0.687658).  Saving model ...
Validation loss decreased (0.687658 --> 0.687269).  Saving model ...
Validation loss decreased (0.687269 --> 0.686851).  Saving model ...
Validation loss decreased (0.686851 --> 0.686460).  Saving model ...
Validation loss decreased (0.686460 --> 0.686029).  Saving model ...
Validation loss decreased (0.686029 --> 0.685590).  Saving model ...
Validation loss decreased (0.685590 --> 0.685111).  Saving model ...
Validation loss decreased (0.685111 --> 0.684605).  Saving model ...
Validation loss decreased (0.684605 --> 0.684066).  Saving model ...
Validation loss decreased (0.684066 --> 0.683492).  Saving model ...
Validation loss decreased (0.683492 --> 0.682892).  Saving model ...
Validation loss decreased (0.682892 --> 0.682257).  Saving model ...
Validation loss decreased (0.682257 --> 0.681606).  Saving model ...
Validation loss decreased (0.681606 --> 0.680929).  Saving model ...
Validation loss decreased (0.680929 --> 0.680232).  Saving model ...
Validation loss decreased (0.680232 --> 0.679511).  Saving model ...
Validation loss decreased (0.679511 --> 0.678767).  Saving model ...
Validation loss decreased (0.678767 --> 0.678008).  Saving model ...
Validation loss decreased (0.678008 --> 0.677234).  Saving model ...
Validation loss decreased (0.677234 --> 0.676423).  Saving model ...
Validation loss decreased (0.676423 --> 0.675640).  Saving model ...
Validation loss decreased (0.675640 --> 0.674833).  Saving model ...
Validation loss decreased (0.674833 --> 0.673994).  Saving model ...
Validation loss decreased (0.673994 --> 0.673132).  Saving model ...
Validation loss decreased (0.673132 --> 0.672250).  Saving model ...
Validation loss decreased (0.672250 --> 0.671362).  Saving model ...
Validation loss decreased (0.671362 --> 0.670462).  Saving model ...
Validation loss decreased (0.670462 --> 0.669547).  Saving model ...
Validation loss decreased (0.669547 --> 0.668614).  Saving model ...
Validation loss decreased (0.668614 --> 0.667682).  Saving model ...
Validation loss decreased (0.667682 --> 0.666750).  Saving model ...
Validation loss decreased (0.666750 --> 0.665822).  Saving model ...
Validation loss decreased (0.665822 --> 0.664869).  Saving model ...
Validation loss decreased (0.664869 --> 0.663901).  Saving model ...
Validation loss decreased (0.663901 --> 0.662918).  Saving model ...
Validation loss decreased (0.662918 --> 0.661915).  Saving model ...
Validation loss decreased (0.661915 --> 0.660900).  Saving model ...
Validation loss decreased (0.660900 --> 0.659894).  Saving model ...
Validation loss decreased (0.659894 --> 0.658895).  Saving model ...
Validation loss decreased (0.658895 --> 0.657877).  Saving model ...
Validation loss decreased (0.657877 --> 0.656844).  Saving model ...
Validation loss decreased (0.656844 --> 0.655830).  Saving model ...
Validation loss decreased (0.655830 --> 0.654821).  Saving model ...
Validation loss decreased (0.654821 --> 0.653801).  Saving model ...
Validation loss decreased (0.653801 --> 0.652771).  Saving model ...
Validation loss decreased (0.652771 --> 0.651727).  Saving model ...
Validation loss decreased (0.651727 --> 0.650647).  Saving model ...
Validation loss decreased (0.650647 --> 0.649557).  Saving model ...
Validation loss decreased (0.649557 --> 0.648456).  Saving model ...
Validation loss decreased (0.648456 --> 0.647348).  Saving model ...
Validation loss decreased (0.647348 --> 0.646265).  Saving model ...
Validation loss decreased (0.646265 --> 0.645174).  Saving model ...
Validation loss decreased (0.645174 --> 0.644063).  Saving model ...
Validation loss decreased (0.644063 --> 0.642932).  Saving model ...
Validation loss decreased (0.642932 --> 0.641797).  Saving model ...
Validation loss decreased (0.641797 --> 0.640646).  Saving model ...
Validation loss decreased (0.640646 --> 0.639509).  Saving model ...
Validation loss decreased (0.639509 --> 0.638344).  Saving model ...
Validation loss decreased (0.638344 --> 0.637172).  Saving model ...
Validation loss decreased (0.637172 --> 0.635993).  Saving model ...
Validation loss decreased (0.635993 --> 0.634814).  Saving model ...
epoch 101, loss 0.6306, train acc 66.50%, f1 0.6171, precision 0.8182, recall 0.4954, auc 0.6818
Validation loss decreased (0.634814 --> 0.633648).  Saving model ...
Validation loss decreased (0.633648 --> 0.632486).  Saving model ...
Validation loss decreased (0.632486 --> 0.631308).  Saving model ...
Validation loss decreased (0.631308 --> 0.630139).  Saving model ...
Validation loss decreased (0.630139 --> 0.628977).  Saving model ...
Validation loss decreased (0.628977 --> 0.627803).  Saving model ...
Validation loss decreased (0.627803 --> 0.626630).  Saving model ...
Validation loss decreased (0.626630 --> 0.625463).  Saving model ...
Validation loss decreased (0.625463 --> 0.624303).  Saving model ...
Validation loss decreased (0.624303 --> 0.623160).  Saving model ...
Validation loss decreased (0.623160 --> 0.622014).  Saving model ...
Validation loss decreased (0.622014 --> 0.620860).  Saving model ...
Validation loss decreased (0.620860 --> 0.619706).  Saving model ...
Validation loss decreased (0.619706 --> 0.618568).  Saving model ...
Validation loss decreased (0.618568 --> 0.617444).  Saving model ...
Validation loss decreased (0.617444 --> 0.616327).  Saving model ...
Validation loss decreased (0.616327 --> 0.615209).  Saving model ...
Validation loss decreased (0.615209 --> 0.614109).  Saving model ...
Validation loss decreased (0.614109 --> 0.613022).  Saving model ...
Validation loss decreased (0.613022 --> 0.611953).  Saving model ...
Validation loss decreased (0.611953 --> 0.610897).  Saving model ...
Validation loss decreased (0.610897 --> 0.609849).  Saving model ...
Validation loss decreased (0.609849 --> 0.608801).  Saving model ...
Validation loss decreased (0.608801 --> 0.607783).  Saving model ...
Validation loss decreased (0.607783 --> 0.606757).  Saving model ...
Validation loss decreased (0.606757 --> 0.605726).  Saving model ...
Validation loss decreased (0.605726 --> 0.604697).  Saving model ...
Validation loss decreased (0.604697 --> 0.603653).  Saving model ...
Validation loss decreased (0.603653 --> 0.602623).  Saving model ...
Validation loss decreased (0.602623 --> 0.601588).  Saving model ...
Validation loss decreased (0.601588 --> 0.600565).  Saving model ...
Validation loss decreased (0.600565 --> 0.599525).  Saving model ...
Validation loss decreased (0.599525 --> 0.598498).  Saving model ...
Validation loss decreased (0.598498 --> 0.597478).  Saving model ...
Validation loss decreased (0.597478 --> 0.596476).  Saving model ...
Validation loss decreased (0.596476 --> 0.595497).  Saving model ...
Validation loss decreased (0.595497 --> 0.594540).  Saving model ...
Validation loss decreased (0.594540 --> 0.593578).  Saving model ...
Validation loss decreased (0.593578 --> 0.592611).  Saving model ...
Validation loss decreased (0.592611 --> 0.591633).  Saving model ...
Validation loss decreased (0.591633 --> 0.590678).  Saving model ...
Validation loss decreased (0.590678 --> 0.589704).  Saving model ...
Validation loss decreased (0.589704 --> 0.588724).  Saving model ...
Validation loss decreased (0.588724 --> 0.587754).  Saving model ...
Validation loss decreased (0.587754 --> 0.586794).  Saving model ...
Validation loss decreased (0.586794 --> 0.585836).  Saving model ...
Validation loss decreased (0.585836 --> 0.584870).  Saving model ...
Validation loss decreased (0.584870 --> 0.583927).  Saving model ...
Validation loss decreased (0.583927 --> 0.582987).  Saving model ...
Validation loss decreased (0.582987 --> 0.582057).  Saving model ...
Validation loss decreased (0.582057 --> 0.581154).  Saving model ...
Validation loss decreased (0.581154 --> 0.580276).  Saving model ...
Validation loss decreased (0.580276 --> 0.579391).  Saving model ...
Validation loss decreased (0.579391 --> 0.578499).  Saving model ...
Validation loss decreased (0.578499 --> 0.577610).  Saving model ...
Validation loss decreased (0.577610 --> 0.576740).  Saving model ...
Validation loss decreased (0.576740 --> 0.575884).  Saving model ...
Validation loss decreased (0.575884 --> 0.575016).  Saving model ...
Validation loss decreased (0.575016 --> 0.574141).  Saving model ...
Validation loss decreased (0.574141 --> 0.573249).  Saving model ...
Validation loss decreased (0.573249 --> 0.572389).  Saving model ...
Validation loss decreased (0.572389 --> 0.571515).  Saving model ...
Validation loss decreased (0.571515 --> 0.570651).  Saving model ...
Validation loss decreased (0.570651 --> 0.569806).  Saving model ...
Validation loss decreased (0.569806 --> 0.568953).  Saving model ...
Validation loss decreased (0.568953 --> 0.568107).  Saving model ...
Validation loss decreased (0.568107 --> 0.567262).  Saving model ...
Validation loss decreased (0.567262 --> 0.566412).  Saving model ...
Validation loss decreased (0.566412 --> 0.565551).  Saving model ...
Validation loss decreased (0.565551 --> 0.564714).  Saving model ...
Validation loss decreased (0.564714 --> 0.563862).  Saving model ...
Validation loss decreased (0.563862 --> 0.563011).  Saving model ...
Validation loss decreased (0.563011 --> 0.562159).  Saving model ...
Validation loss decreased (0.562159 --> 0.561316).  Saving model ...
Validation loss decreased (0.561316 --> 0.560484).  Saving model ...
Validation loss decreased (0.560484 --> 0.559669).  Saving model ...
Validation loss decreased (0.559669 --> 0.558856).  Saving model ...
Validation loss decreased (0.558856 --> 0.558087).  Saving model ...
Validation loss decreased (0.558087 --> 0.557303).  Saving model ...
Validation loss decreased (0.557303 --> 0.556494).  Saving model ...
Validation loss decreased (0.556494 --> 0.555717).  Saving model ...
Validation loss decreased (0.555717 --> 0.554920).  Saving model ...
Validation loss decreased (0.554920 --> 0.554157).  Saving model ...
Validation loss decreased (0.554157 --> 0.553374).  Saving model ...
Validation loss decreased (0.553374 --> 0.552592).  Saving model ...
Validation loss decreased (0.552592 --> 0.551799).  Saving model ...
Validation loss decreased (0.551799 --> 0.551030).  Saving model ...
Validation loss decreased (0.551030 --> 0.550240).  Saving model ...
Validation loss decreased (0.550240 --> 0.549464).  Saving model ...
Validation loss decreased (0.549464 --> 0.548712).  Saving model ...
Validation loss decreased (0.548712 --> 0.547974).  Saving model ...
Validation loss decreased (0.547974 --> 0.547267).  Saving model ...
Validation loss decreased (0.547267 --> 0.546594).  Saving model ...
Validation loss decreased (0.546594 --> 0.545913).  Saving model ...
Validation loss decreased (0.545913 --> 0.545233).  Saving model ...
Validation loss decreased (0.545233 --> 0.544556).  Saving model ...
Validation loss decreased (0.544556 --> 0.543900).  Saving model ...
Validation loss decreased (0.543900 --> 0.543213).  Saving model ...
Validation loss decreased (0.543213 --> 0.542512).  Saving model ...
Validation loss decreased (0.542512 --> 0.541807).  Saving model ...
epoch 201, loss 0.4919, train acc 75.50%, f1 0.7610, precision 0.8125, recall 0.7156, auc 0.7589
Validation loss decreased (0.541807 --> 0.541084).  Saving model ...
Validation loss decreased (0.541084 --> 0.540363).  Saving model ...
Validation loss decreased (0.540363 --> 0.539636).  Saving model ...
Validation loss decreased (0.539636 --> 0.538915).  Saving model ...
Validation loss decreased (0.538915 --> 0.538212).  Saving model ...
Validation loss decreased (0.538212 --> 0.537516).  Saving model ...
Validation loss decreased (0.537516 --> 0.536861).  Saving model ...
Validation loss decreased (0.536861 --> 0.536224).  Saving model ...
Validation loss decreased (0.536224 --> 0.535569).  Saving model ...
Validation loss decreased (0.535569 --> 0.534930).  Saving model ...
Validation loss decreased (0.534930 --> 0.534287).  Saving model ...
Validation loss decreased (0.534287 --> 0.533644).  Saving model ...
Validation loss decreased (0.533644 --> 0.533023).  Saving model ...
Validation loss decreased (0.533023 --> 0.532421).  Saving model ...
Validation loss decreased (0.532421 --> 0.531810).  Saving model ...
Validation loss decreased (0.531810 --> 0.531172).  Saving model ...
Validation loss decreased (0.531172 --> 0.530568).  Saving model ...
Validation loss decreased (0.530568 --> 0.530000).  Saving model ...
Validation loss decreased (0.530000 --> 0.529437).  Saving model ...
Validation loss decreased (0.529437 --> 0.528878).  Saving model ...
Validation loss decreased (0.528878 --> 0.528307).  Saving model ...
Validation loss decreased (0.528307 --> 0.527775).  Saving model ...
Validation loss decreased (0.527775 --> 0.527266).  Saving model ...
Validation loss decreased (0.527266 --> 0.526686).  Saving model ...
Validation loss decreased (0.526686 --> 0.526056).  Saving model ...
Validation loss decreased (0.526056 --> 0.525451).  Saving model ...
Validation loss decreased (0.525451 --> 0.524842).  Saving model ...
Validation loss decreased (0.524842 --> 0.524255).  Saving model ...
Validation loss decreased (0.524255 --> 0.523678).  Saving model ...
Validation loss decreased (0.523678 --> 0.523143).  Saving model ...
Validation loss decreased (0.523143 --> 0.522613).  Saving model ...
Validation loss decreased (0.522613 --> 0.522110).  Saving model ...
Validation loss decreased (0.522110 --> 0.521603).  Saving model ...
Validation loss decreased (0.521603 --> 0.521103).  Saving model ...
Validation loss decreased (0.521103 --> 0.520543).  Saving model ...
Validation loss decreased (0.520543 --> 0.519990).  Saving model ...
Validation loss decreased (0.519990 --> 0.519451).  Saving model ...
Validation loss decreased (0.519451 --> 0.518876).  Saving model ...
Validation loss decreased (0.518876 --> 0.518289).  Saving model ...
Validation loss decreased (0.518289 --> 0.517755).  Saving model ...
Validation loss decreased (0.517755 --> 0.517225).  Saving model ...
Validation loss decreased (0.517225 --> 0.516665).  Saving model ...
Validation loss decreased (0.516665 --> 0.516079).  Saving model ...
Validation loss decreased (0.516079 --> 0.515543).  Saving model ...
Validation loss decreased (0.515543 --> 0.515001).  Saving model ...
Validation loss decreased (0.515001 --> 0.514446).  Saving model ...
Validation loss decreased (0.514446 --> 0.513911).  Saving model ...
Validation loss decreased (0.513911 --> 0.513364).  Saving model ...
Validation loss decreased (0.513364 --> 0.512853).  Saving model ...
Validation loss decreased (0.512853 --> 0.512345).  Saving model ...
Validation loss decreased (0.512345 --> 0.511818).  Saving model ...
Validation loss decreased (0.511818 --> 0.511316).  Saving model ...
Validation loss decreased (0.511316 --> 0.510822).  Saving model ...
Validation loss decreased (0.510822 --> 0.510318).  Saving model ...
Validation loss decreased (0.510318 --> 0.509781).  Saving model ...
Validation loss decreased (0.509781 --> 0.509164).  Saving model ...
Validation loss decreased (0.509164 --> 0.508557).  Saving model ...
Validation loss decreased (0.508557 --> 0.507955).  Saving model ...
Validation loss decreased (0.507955 --> 0.507363).  Saving model ...
Validation loss decreased (0.507363 --> 0.506792).  Saving model ...
Validation loss decreased (0.506792 --> 0.506182).  Saving model ...
Validation loss decreased (0.506182 --> 0.505619).  Saving model ...
Validation loss decreased (0.505619 --> 0.504978).  Saving model ...
Validation loss decreased (0.504978 --> 0.504335).  Saving model ...
Validation loss decreased (0.504335 --> 0.503729).  Saving model ...
Validation loss decreased (0.503729 --> 0.503119).  Saving model ...
Validation loss decreased (0.503119 --> 0.502541).  Saving model ...
Validation loss decreased (0.502541 --> 0.502002).  Saving model ...
Validation loss decreased (0.502002 --> 0.501512).  Saving model ...
Validation loss decreased (0.501512 --> 0.501001).  Saving model ...
Validation loss decreased (0.501001 --> 0.500491).  Saving model ...
Validation loss decreased (0.500491 --> 0.499932).  Saving model ...
Validation loss decreased (0.499932 --> 0.499404).  Saving model ...
Validation loss decreased (0.499404 --> 0.498882).  Saving model ...
Validation loss decreased (0.498882 --> 0.498331).  Saving model ...
Validation loss decreased (0.498331 --> 0.497843).  Saving model ...
Validation loss decreased (0.497843 --> 0.497390).  Saving model ...
Validation loss decreased (0.497390 --> 0.496991).  Saving model ...
Validation loss decreased (0.496991 --> 0.496586).  Saving model ...
Validation loss decreased (0.496586 --> 0.496225).  Saving model ...
Validation loss decreased (0.496225 --> 0.495839).  Saving model ...
Validation loss decreased (0.495839 --> 0.495367).  Saving model ...
Validation loss decreased (0.495367 --> 0.494907).  Saving model ...
Validation loss decreased (0.494907 --> 0.494444).  Saving model ...
Validation loss decreased (0.494444 --> 0.494025).  Saving model ...
Validation loss decreased (0.494025 --> 0.493632).  Saving model ...
Validation loss decreased (0.493632 --> 0.493178).  Saving model ...
Validation loss decreased (0.493178 --> 0.492703).  Saving model ...
Validation loss decreased (0.492703 --> 0.492175).  Saving model ...
Validation loss decreased (0.492175 --> 0.491693).  Saving model ...
Validation loss decreased (0.491693 --> 0.491210).  Saving model ...
Validation loss decreased (0.491210 --> 0.490695).  Saving model ...
Validation loss decreased (0.490695 --> 0.490228).  Saving model ...
Validation loss decreased (0.490228 --> 0.489709).  Saving model ...
Validation loss decreased (0.489709 --> 0.489179).  Saving model ...
Validation loss decreased (0.489179 --> 0.488635).  Saving model ...
Validation loss decreased (0.488635 --> 0.488088).  Saving model ...
Validation loss decreased (0.488088 --> 0.487555).  Saving model ...
Validation loss decreased (0.487555 --> 0.486994).  Saving model ...
Validation loss decreased (0.486994 --> 0.486469).  Saving model ...
epoch 301, loss 0.3444, train acc 75.50%, f1 0.7678, precision 0.7941, recall 0.7431, auc 0.7562
Validation loss decreased (0.486469 --> 0.485961).  Saving model ...
Validation loss decreased (0.485961 --> 0.485532).  Saving model ...
Validation loss decreased (0.485532 --> 0.485129).  Saving model ...
Validation loss decreased (0.485129 --> 0.484693).  Saving model ...
Validation loss decreased (0.484693 --> 0.484254).  Saving model ...
Validation loss decreased (0.484254 --> 0.483808).  Saving model ...
Validation loss decreased (0.483808 --> 0.483372).  Saving model ...
Validation loss decreased (0.483372 --> 0.482933).  Saving model ...
Validation loss decreased (0.482933 --> 0.482514).  Saving model ...
Validation loss decreased (0.482514 --> 0.482116).  Saving model ...
Validation loss decreased (0.482116 --> 0.481699).  Saving model ...
Validation loss decreased (0.481699 --> 0.481295).  Saving model ...
Validation loss decreased (0.481295 --> 0.480906).  Saving model ...
Validation loss decreased (0.480906 --> 0.480520).  Saving model ...
Validation loss decreased (0.480520 --> 0.480075).  Saving model ...
Validation loss decreased (0.480075 --> 0.479608).  Saving model ...
Validation loss decreased (0.479608 --> 0.479142).  Saving model ...
Validation loss decreased (0.479142 --> 0.478682).  Saving model ...
Validation loss decreased (0.478682 --> 0.478271).  Saving model ...
Validation loss decreased (0.478271 --> 0.477796).  Saving model ...
Validation loss decreased (0.477796 --> 0.477348).  Saving model ...
Validation loss decreased (0.477348 --> 0.476890).  Saving model ...
Validation loss decreased (0.476890 --> 0.476431).  Saving model ...
Validation loss decreased (0.476431 --> 0.476093).  Saving model ...
Validation loss decreased (0.476093 --> 0.475670).  Saving model ...
Validation loss decreased (0.475670 --> 0.475301).  Saving model ...
Validation loss decreased (0.475301 --> 0.474977).  Saving model ...
Validation loss decreased (0.474977 --> 0.474622).  Saving model ...
Validation loss decreased (0.474622 --> 0.474291).  Saving model ...
Validation loss decreased (0.474291 --> 0.473940).  Saving model ...
Validation loss decreased (0.473940 --> 0.473553).  Saving model ...
Validation loss decreased (0.473553 --> 0.473145).  Saving model ...
Validation loss decreased (0.473145 --> 0.472747).  Saving model ...
Validation loss decreased (0.472747 --> 0.472328).  Saving model ...
Validation loss decreased (0.472328 --> 0.471973).  Saving model ...
Validation loss decreased (0.471973 --> 0.471549).  Saving model ...
Validation loss decreased (0.471549 --> 0.471156).  Saving model ...
Validation loss decreased (0.471156 --> 0.470681).  Saving model ...
Validation loss decreased (0.470681 --> 0.470178).  Saving model ...
Validation loss decreased (0.470178 --> 0.469666).  Saving model ...
Validation loss decreased (0.469666 --> 0.469138).  Saving model ...
Validation loss decreased (0.469138 --> 0.468702).  Saving model ...
Validation loss decreased (0.468702 --> 0.468304).  Saving model ...
Validation loss decreased (0.468304 --> 0.467876).  Saving model ...
Validation loss decreased (0.467876 --> 0.467464).  Saving model ...
Validation loss decreased (0.467464 --> 0.467076).  Saving model ...
Validation loss decreased (0.467076 --> 0.466654).  Saving model ...
Validation loss decreased (0.466654 --> 0.466261).  Saving model ...
Validation loss decreased (0.466261 --> 0.465860).  Saving model ...
Validation loss decreased (0.465860 --> 0.465482).  Saving model ...
Validation loss decreased (0.465482 --> 0.465111).  Saving model ...
Validation loss decreased (0.465111 --> 0.464817).  Saving model ...
Validation loss decreased (0.464817 --> 0.464549).  Saving model ...
Validation loss decreased (0.464549 --> 0.464234).  Saving model ...
Validation loss decreased (0.464234 --> 0.463838).  Saving model ...
Validation loss decreased (0.463838 --> 0.463416).  Saving model ...
Validation loss decreased (0.463416 --> 0.462980).  Saving model ...
Validation loss decreased (0.462980 --> 0.462561).  Saving model ...
Validation loss decreased (0.462561 --> 0.462102).  Saving model ...
Validation loss decreased (0.462102 --> 0.461709).  Saving model ...
Validation loss decreased (0.461709 --> 0.461318).  Saving model ...
Validation loss decreased (0.461318 --> 0.460927).  Saving model ...
Validation loss decreased (0.460927 --> 0.460530).  Saving model ...
Validation loss decreased (0.460530 --> 0.460081).  Saving model ...
Validation loss decreased (0.460081 --> 0.459734).  Saving model ...
Validation loss decreased (0.459734 --> 0.459308).  Saving model ...
Validation loss decreased (0.459308 --> 0.458845).  Saving model ...
Validation loss decreased (0.458845 --> 0.458394).  Saving model ...
Validation loss decreased (0.458394 --> 0.457890).  Saving model ...
Validation loss decreased (0.457890 --> 0.457360).  Saving model ...
Validation loss decreased (0.457360 --> 0.456875).  Saving model ...
Validation loss decreased (0.456875 --> 0.456361).  Saving model ...
Validation loss decreased (0.456361 --> 0.455811).  Saving model ...
Validation loss decreased (0.455811 --> 0.455312).  Saving model ...
Validation loss decreased (0.455312 --> 0.454875).  Saving model ...
Validation loss decreased (0.454875 --> 0.454364).  Saving model ...
Validation loss decreased (0.454364 --> 0.453851).  Saving model ...
Validation loss decreased (0.453851 --> 0.453429).  Saving model ...
Validation loss decreased (0.453429 --> 0.453025).  Saving model ...
Validation loss decreased (0.453025 --> 0.452661).  Saving model ...
Validation loss decreased (0.452661 --> 0.452334).  Saving model ...
Validation loss decreased (0.452334 --> 0.451988).  Saving model ...
Validation loss decreased (0.451988 --> 0.451614).  Saving model ...
Validation loss decreased (0.451614 --> 0.451207).  Saving model ...
Validation loss decreased (0.451207 --> 0.450738).  Saving model ...
Validation loss decreased (0.450738 --> 0.450341).  Saving model ...
Validation loss decreased (0.450341 --> 0.449905).  Saving model ...
Validation loss decreased (0.449905 --> 0.449513).  Saving model ...
Validation loss decreased (0.449513 --> 0.449112).  Saving model ...
Validation loss decreased (0.449112 --> 0.448702).  Saving model ...
Validation loss decreased (0.448702 --> 0.448305).  Saving model ...
Validation loss decreased (0.448305 --> 0.447940).  Saving model ...
Validation loss decreased (0.447940 --> 0.447454).  Saving model ...
Validation loss decreased (0.447454 --> 0.446984).  Saving model ...
Validation loss decreased (0.446984 --> 0.446566).  Saving model ...
Validation loss decreased (0.446566 --> 0.446152).  Saving model ...
Validation loss decreased (0.446152 --> 0.445771).  Saving model ...
Validation loss decreased (0.445771 --> 0.445346).  Saving model ...
Validation loss decreased (0.445346 --> 0.444915).  Saving model ...
Validation loss decreased (0.444915 --> 0.444502).  Saving model ...
epoch 401, loss 0.4248, train acc 78.50%, f1 0.8018, precision 0.8056, recall 0.7982, auc 0.7837
Validation loss decreased (0.444502 --> 0.444087).  Saving model ...
Validation loss decreased (0.444087 --> 0.443711).  Saving model ...
Validation loss decreased (0.443711 --> 0.443422).  Saving model ...
Validation loss decreased (0.443422 --> 0.443153).  Saving model ...
Validation loss decreased (0.443153 --> 0.442887).  Saving model ...
Validation loss decreased (0.442887 --> 0.442628).  Saving model ...
Validation loss decreased (0.442628 --> 0.442337).  Saving model ...
Validation loss decreased (0.442337 --> 0.442041).  Saving model ...
Validation loss decreased (0.442041 --> 0.441807).  Saving model ...
Validation loss decreased (0.441807 --> 0.441529).  Saving model ...
Validation loss decreased (0.441529 --> 0.441255).  Saving model ...
Validation loss decreased (0.441255 --> 0.440954).  Saving model ...
Validation loss decreased (0.440954 --> 0.440691).  Saving model ...
Validation loss decreased (0.440691 --> 0.440489).  Saving model ...
Validation loss decreased (0.440489 --> 0.440307).  Saving model ...
Validation loss decreased (0.440307 --> 0.440225).  Saving model ...
Validation loss decreased (0.440225 --> 0.440112).  Saving model ...
Validation loss decreased (0.440112 --> 0.439977).  Saving model ...
Validation loss decreased (0.439977 --> 0.439783).  Saving model ...
Validation loss decreased (0.439783 --> 0.439559).  Saving model ...
Validation loss decreased (0.439559 --> 0.439285).  Saving model ...
Validation loss decreased (0.439285 --> 0.439062).  Saving model ...
Validation loss decreased (0.439062 --> 0.438882).  Saving model ...
Validation loss decreased (0.438882 --> 0.438664).  Saving model ...
Validation loss decreased (0.438664 --> 0.438521).  Saving model ...
Validation loss decreased (0.438521 --> 0.438423).  Saving model ...
Validation loss decreased (0.438423 --> 0.438370).  Saving model ...
Validation loss decreased (0.438370 --> 0.438237).  Saving model ...
Validation loss decreased (0.438237 --> 0.438063).  Saving model ...
Validation loss decreased (0.438063 --> 0.437896).  Saving model ...
Validation loss decreased (0.437896 --> 0.437713).  Saving model ...
Validation loss decreased (0.437713 --> 0.437580).  Saving model ...
Validation loss decreased (0.437580 --> 0.437517).  Saving model ...
Validation loss decreased (0.437517 --> 0.437429).  Saving model ...
Validation loss decreased (0.437429 --> 0.437173).  Saving model ...
Validation loss decreased (0.437173 --> 0.436975).  Saving model ...
Validation loss decreased (0.436975 --> 0.436728).  Saving model ...
Validation loss decreased (0.436728 --> 0.436397).  Saving model ...
Validation loss decreased (0.436397 --> 0.436096).  Saving model ...
Validation loss decreased (0.436096 --> 0.435777).  Saving model ...
Validation loss decreased (0.435777 --> 0.435501).  Saving model ...
Validation loss decreased (0.435501 --> 0.435328).  Saving model ...
Validation loss decreased (0.435328 --> 0.435143).  Saving model ...
Validation loss decreased (0.435143 --> 0.434919).  Saving model ...
Validation loss decreased (0.434919 --> 0.434684).  Saving model ...
Validation loss decreased (0.434684 --> 0.434519).  Saving model ...
Validation loss decreased (0.434519 --> 0.434273).  Saving model ...
Validation loss decreased (0.434273 --> 0.433969).  Saving model ...
Validation loss decreased (0.433969 --> 0.433656).  Saving model ...
Validation loss decreased (0.433656 --> 0.433401).  Saving model ...
Validation loss decreased (0.433401 --> 0.433151).  Saving model ...
Validation loss decreased (0.433151 --> 0.432847).  Saving model ...
Validation loss decreased (0.432847 --> 0.432533).  Saving model ...
Validation loss decreased (0.432533 --> 0.432249).  Saving model ...
Validation loss decreased (0.432249 --> 0.432014).  Saving model ...
Validation loss decreased (0.432014 --> 0.431840).  Saving model ...
Validation loss decreased (0.431840 --> 0.431687).  Saving model ...
Validation loss decreased (0.431687 --> 0.431581).  Saving model ...
Validation loss decreased (0.431581 --> 0.431505).  Saving model ...
Validation loss decreased (0.431505 --> 0.431480).  Saving model ...
Validation loss decreased (0.431480 --> 0.431394).  Saving model ...
Validation loss decreased (0.431394 --> 0.431310).  Saving model ...
Validation loss decreased (0.431310 --> 0.431187).  Saving model ...
Validation loss decreased (0.431187 --> 0.430996).  Saving model ...
Validation loss decreased (0.430996 --> 0.430849).  Saving model ...
Validation loss decreased (0.430849 --> 0.430752).  Saving model ...
Validation loss decreased (0.430752 --> 0.430707).  Saving model ...
Validation loss decreased (0.430707 --> 0.430567).  Saving model ...
Validation loss decreased (0.430567 --> 0.430502).  Saving model ...
Validation loss decreased (0.430502 --> 0.430387).  Saving model ...
Validation loss decreased (0.430387 --> 0.430209).  Saving model ...
Validation loss decreased (0.430209 --> 0.430016).  Saving model ...
Validation loss decreased (0.430016 --> 0.429836).  Saving model ...
Validation loss decreased (0.429836 --> 0.429704).  Saving model ...
Validation loss decreased (0.429704 --> 0.429537).  Saving model ...
Validation loss decreased (0.429537 --> 0.429373).  Saving model ...
Validation loss decreased (0.429373 --> 0.429237).  Saving model ...
Validation loss decreased (0.429237 --> 0.429145).  Saving model ...
Validation loss decreased (0.429145 --> 0.429035).  Saving model ...
Validation loss decreased (0.429035 --> 0.428885).  Saving model ...
Validation loss decreased (0.428885 --> 0.428698).  Saving model ...
Validation loss decreased (0.428698 --> 0.428492).  Saving model ...
Validation loss decreased (0.428492 --> 0.428214).  Saving model ...
Validation loss decreased (0.428214 --> 0.427972).  Saving model ...
Validation loss decreased (0.427972 --> 0.427724).  Saving model ...
Validation loss decreased (0.427724 --> 0.427471).  Saving model ...
Validation loss decreased (0.427471 --> 0.427181).  Saving model ...
Validation loss decreased (0.427181 --> 0.426875).  Saving model ...
Validation loss decreased (0.426875 --> 0.426553).  Saving model ...
Validation loss decreased (0.426553 --> 0.426288).  Saving model ...
Validation loss decreased (0.426288 --> 0.425989).  Saving model ...
Validation loss decreased (0.425989 --> 0.425731).  Saving model ...
Validation loss decreased (0.425731 --> 0.425525).  Saving model ...
Validation loss decreased (0.425525 --> 0.425361).  Saving model ...
Validation loss decreased (0.425361 --> 0.425252).  Saving model ...
Validation loss decreased (0.425252 --> 0.425182).  Saving model ...
Validation loss decreased (0.425182 --> 0.425122).  Saving model ...
Validation loss decreased (0.425122 --> 0.425009).  Saving model ...
Validation loss decreased (0.425009 --> 0.424791).  Saving model ...
Validation loss decreased (0.424791 --> 0.424489).  Saving model ...
epoch 501, loss 0.4874, train acc 79.00%, f1 0.8073, precision 0.8073, recall 0.8073, auc 0.7883
Validation loss decreased (0.424489 --> 0.424156).  Saving model ...
Validation loss decreased (0.424156 --> 0.423801).  Saving model ...
Validation loss decreased (0.423801 --> 0.423427).  Saving model ...
Validation loss decreased (0.423427 --> 0.423042).  Saving model ...
Validation loss decreased (0.423042 --> 0.422650).  Saving model ...
Validation loss decreased (0.422650 --> 0.422310).  Saving model ...
Validation loss decreased (0.422310 --> 0.422014).  Saving model ...
Validation loss decreased (0.422014 --> 0.421652).  Saving model ...
Validation loss decreased (0.421652 --> 0.421282).  Saving model ...
Validation loss decreased (0.421282 --> 0.420950).  Saving model ...
Validation loss decreased (0.420950 --> 0.420600).  Saving model ...
Validation loss decreased (0.420600 --> 0.420258).  Saving model ...
Validation loss decreased (0.420258 --> 0.420029).  Saving model ...
Validation loss decreased (0.420029 --> 0.419778).  Saving model ...
Validation loss decreased (0.419778 --> 0.419490).  Saving model ...
Validation loss decreased (0.419490 --> 0.419276).  Saving model ...
Validation loss decreased (0.419276 --> 0.419035).  Saving model ...
Validation loss decreased (0.419035 --> 0.418820).  Saving model ...
Validation loss decreased (0.418820 --> 0.418613).  Saving model ...
Validation loss decreased (0.418613 --> 0.418504).  Saving model ...
Validation loss decreased (0.418504 --> 0.418301).  Saving model ...
Validation loss decreased (0.418301 --> 0.418115).  Saving model ...
Validation loss decreased (0.418115 --> 0.417895).  Saving model ...
Validation loss decreased (0.417895 --> 0.417668).  Saving model ...
Validation loss decreased (0.417668 --> 0.417334).  Saving model ...
Validation loss decreased (0.417334 --> 0.417015).  Saving model ...
Validation loss decreased (0.417015 --> 0.416689).  Saving model ...
Validation loss decreased (0.416689 --> 0.416432).  Saving model ...
Validation loss decreased (0.416432 --> 0.416133).  Saving model ...
Validation loss decreased (0.416133 --> 0.415816).  Saving model ...
Validation loss decreased (0.415816 --> 0.415576).  Saving model ...
Validation loss decreased (0.415576 --> 0.415285).  Saving model ...
Validation loss decreased (0.415285 --> 0.415031).  Saving model ...
Validation loss decreased (0.415031 --> 0.414805).  Saving model ...
Validation loss decreased (0.414805 --> 0.414544).  Saving model ...
Validation loss decreased (0.414544 --> 0.414269).  Saving model ...
Validation loss decreased (0.414269 --> 0.413948).  Saving model ...
Validation loss decreased (0.413948 --> 0.413716).  Saving model ...
Validation loss decreased (0.413716 --> 0.413450).  Saving model ...
Validation loss decreased (0.413450 --> 0.413113).  Saving model ...
Validation loss decreased (0.413113 --> 0.412751).  Saving model ...
Validation loss decreased (0.412751 --> 0.412382).  Saving model ...
Validation loss decreased (0.412382 --> 0.411967).  Saving model ...
Validation loss decreased (0.411967 --> 0.411484).  Saving model ...
Validation loss decreased (0.411484 --> 0.411062).  Saving model ...
Validation loss decreased (0.411062 --> 0.410585).  Saving model ...
Validation loss decreased (0.410585 --> 0.410184).  Saving model ...
Validation loss decreased (0.410184 --> 0.409750).  Saving model ...
Validation loss decreased (0.409750 --> 0.409369).  Saving model ...
Validation loss decreased (0.409369 --> 0.409010).  Saving model ...
Validation loss decreased (0.409010 --> 0.408653).  Saving model ...
Validation loss decreased (0.408653 --> 0.408318).  Saving model ...
Validation loss decreased (0.408318 --> 0.408059).  Saving model ...
Validation loss decreased (0.408059 --> 0.407762).  Saving model ...
Validation loss decreased (0.407762 --> 0.407509).  Saving model ...
Validation loss decreased (0.407509 --> 0.407202).  Saving model ...
Validation loss decreased (0.407202 --> 0.406920).  Saving model ...
Validation loss decreased (0.406920 --> 0.406654).  Saving model ...
Validation loss decreased (0.406654 --> 0.406465).  Saving model ...
Validation loss decreased (0.406465 --> 0.406310).  Saving model ...
Validation loss decreased (0.406310 --> 0.406205).  Saving model ...
Validation loss decreased (0.406205 --> 0.406063).  Saving model ...
Validation loss decreased (0.406063 --> 0.405966).  Saving model ...
Validation loss decreased (0.405966 --> 0.405929).  Saving model ...
Validation loss decreased (0.405929 --> 0.405919).  Saving model ...
Validation loss decreased (0.405919 --> 0.405825).  Saving model ...
Validation loss decreased (0.405825 --> 0.405658).  Saving model ...
Validation loss decreased (0.405658 --> 0.405600).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.405600 --> 0.405571).  Saving model ...
Validation loss decreased (0.405571 --> 0.405522).  Saving model ...
Validation loss decreased (0.405522 --> 0.405460).  Saving model ...
Validation loss decreased (0.405460 --> 0.405346).  Saving model ...
Validation loss decreased (0.405346 --> 0.405137).  Saving model ...
Validation loss decreased (0.405137 --> 0.404924).  Saving model ...
Validation loss decreased (0.404924 --> 0.404759).  Saving model ...
Validation loss decreased (0.404759 --> 0.404662).  Saving model ...
Validation loss decreased (0.404662 --> 0.404629).  Saving model ...
Validation loss decreased (0.404629 --> 0.404581).  Saving model ...
Validation loss decreased (0.404581 --> 0.404506).  Saving model ...
Validation loss decreased (0.404506 --> 0.404429).  Saving model ...
Validation loss decreased (0.404429 --> 0.404315).  Saving model ...
Validation loss decreased (0.404315 --> 0.404264).  Saving model ...
Validation loss decreased (0.404264 --> 0.404166).  Saving model ...
Validation loss decreased (0.404166 --> 0.404072).  Saving model ...
Validation loss decreased (0.404072 --> 0.403933).  Saving model ...
Validation loss decreased (0.403933 --> 0.403857).  Saving model ...
Validation loss decreased (0.403857 --> 0.403727).  Saving model ...
Validation loss decreased (0.403727 --> 0.403666).  Saving model ...
Validation loss decreased (0.403666 --> 0.403522).  Saving model ...
Validation loss decreased (0.403522 --> 0.403287).  Saving model ...
Validation loss decreased (0.403287 --> 0.403007).  Saving model ...
Validation loss decreased (0.403007 --> 0.402866).  Saving model ...
Validation loss decreased (0.402866 --> 0.402736).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.402736 --> 0.402581).  Saving model ...
Validation loss decreased (0.402581 --> 0.402474).  Saving model ...
Validation loss decreased (0.402474 --> 0.402316).  Saving model ...
Validation loss decreased (0.402316 --> 0.402148).  Saving model ...
Validation loss decreased (0.402148 --> 0.401871).  Saving model ...
Validation loss decreased (0.401871 --> 0.401581).  Saving model ...
epoch 601, loss 0.3614, train acc 80.50%, f1 0.8235, precision 0.8125, recall 0.8349, auc 0.8020
Validation loss decreased (0.401581 --> 0.401328).  Saving model ...
Validation loss decreased (0.401328 --> 0.401178).  Saving model ...
Validation loss decreased (0.401178 --> 0.401062).  Saving model ...
Validation loss decreased (0.401062 --> 0.400967).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 624, loss 0.3408, train acc 81.00%, f1 0.8288, precision 0.8142, recall 0.8440, auc 0.8066



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_notMirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_5
./test_pima/result_MLP_minus_notMirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.61

the Fscore is 0.5760869565217391

the precision is 0.40458015267175573

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_5
----------------------



epoch 1, loss 0.6931, train acc 62.48%, f1 0.5843, precision 0.6553, recall 0.5272, auc 0.6249
epoch 101, loss 0.6168, train acc 77.67%, f1 0.7842, precision 0.7591, recall 0.8110, auc 0.7767
epoch 201, loss 0.4827, train acc 80.43%, f1 0.8046, precision 0.8034, recall 0.8059, auc 0.8043
epoch 301, loss 0.4544, train acc 82.41%, f1 0.8241, precision 0.8246, recall 0.8236, auc 0.8241
epoch 401, loss 0.3010, train acc 83.38%, f1 0.8337, precision 0.8342, recall 0.8333, auc 0.8338
epoch 501, loss 0.4055, train acc 83.88%, f1 0.8384, precision 0.8406, recall 0.8363, auc 0.8388
epoch 601, loss 0.4825, train acc 84.03%, f1 0.8395, precision 0.8440, recall 0.8351, auc 0.8403
epoch 701, loss 0.3051, train acc 84.18%, f1 0.8418, precision 0.8423, recall 0.8414, auc 0.8418
epoch 801, loss 0.2668, train acc 84.16%, f1 0.8412, precision 0.8437, recall 0.8388, auc 0.8416
epoch 901, loss 0.3198, train acc 84.26%, f1 0.8428, precision 0.8424, recall 0.8431, auc 0.8426
epoch 1001, loss 0.3227, train acc 84.21%, f1 0.8416, precision 0.8446, recall 0.8386, auc 0.8421
epoch 1101, loss 0.2988, train acc 84.24%, f1 0.8423, precision 0.8432, recall 0.8413, auc 0.8424
epoch 1201, loss 0.2722, train acc 84.25%, f1 0.8418, precision 0.8459, recall 0.8377, auc 0.8425
epoch 1301, loss 0.4186, train acc 84.31%, f1 0.8428, precision 0.8449, recall 0.8407, auc 0.8431
epoch 1401, loss 0.4425, train acc 84.27%, f1 0.8424, precision 0.8443, recall 0.8406, auc 0.8427
epoch 1501, loss 0.2879, train acc 84.25%, f1 0.8426, precision 0.8428, recall 0.8424, auc 0.8425
epoch 1601, loss 0.4485, train acc 84.25%, f1 0.8423, precision 0.8437, recall 0.8409, auc 0.8425
epoch 1701, loss 0.2690, train acc 84.23%, f1 0.8420, precision 0.8437, recall 0.8403, auc 0.8423
epoch 1801, loss 0.3247, train acc 84.27%, f1 0.8427, precision 0.8431, recall 0.8422, auc 0.8427
epoch 1901, loss 0.4197, train acc 84.21%, f1 0.8420, precision 0.8429, recall 0.8411, auc 0.8421
epoch 2001, loss 0.4960, train acc 84.22%, f1 0.8425, precision 0.8416, recall 0.8434, auc 0.8422
epoch 2101, loss 0.4458, train acc 84.23%, f1 0.8420, precision 0.8443, recall 0.8396, auc 0.8423
epoch 2201, loss 0.3425, train acc 84.22%, f1 0.8421, precision 0.8432, recall 0.8409, auc 0.8422
epoch 2301, loss 0.3651, train acc 84.26%, f1 0.8423, precision 0.8445, recall 0.8401, auc 0.8426
epoch 2401, loss 0.4521, train acc 84.21%, f1 0.8416, precision 0.8449, recall 0.8382, auc 0.8421
epoch 2501, loss 0.3858, train acc 84.25%, f1 0.8423, precision 0.8436, recall 0.8410, auc 0.8425
epoch 2601, loss 0.3872, train acc 84.27%, f1 0.8429, precision 0.8422, recall 0.8436, auc 0.8427
epoch 2701, loss 0.3731, train acc 84.25%, f1 0.8427, precision 0.8418, recall 0.8435, auc 0.8425
epoch 2801, loss 0.3771, train acc 84.25%, f1 0.8425, precision 0.8431, recall 0.8419, auc 0.8425
epoch 2901, loss 0.2280, train acc 84.22%, f1 0.8419, precision 0.8437, recall 0.8400, auc 0.8422
epoch 3001, loss 0.4558, train acc 84.24%, f1 0.8422, precision 0.8437, recall 0.8406, auc 0.8424
epoch 3101, loss 0.3152, train acc 84.26%, f1 0.8424, precision 0.8434, recall 0.8415, auc 0.8426
epoch 3201, loss 0.3996, train acc 84.29%, f1 0.8430, precision 0.8427, recall 0.8433, auc 0.8429
epoch 3301, loss 0.3401, train acc 84.23%, f1 0.8421, precision 0.8435, recall 0.8407, auc 0.8423
epoch 3401, loss 0.3255, train acc 84.30%, f1 0.8427, precision 0.8448, recall 0.8406, auc 0.8430
epoch 3501, loss 0.3679, train acc 84.28%, f1 0.8428, precision 0.8435, recall 0.8420, auc 0.8428
epoch 3601, loss 0.2344, train acc 84.22%, f1 0.8417, precision 0.8449, recall 0.8385, auc 0.8422
epoch 3701, loss 0.2649, train acc 84.21%, f1 0.8419, precision 0.8431, recall 0.8407, auc 0.8421
epoch 3801, loss 0.5334, train acc 84.23%, f1 0.8422, precision 0.8429, recall 0.8415, auc 0.8423
epoch 3901, loss 0.3207, train acc 84.23%, f1 0.8419, precision 0.8445, recall 0.8394, auc 0.8423
epoch 4001, loss 0.2274, train acc 84.32%, f1 0.8430, precision 0.8443, recall 0.8417, auc 0.8432
epoch 4101, loss 0.3704, train acc 84.38%, f1 0.8438, precision 0.8443, recall 0.8432, auc 0.8438
epoch 4201, loss 0.2384, train acc 84.37%, f1 0.8437, precision 0.8442, recall 0.8432, auc 0.8437
epoch 4301, loss 0.4197, train acc 84.32%, f1 0.8431, precision 0.8440, recall 0.8423, auc 0.8432
epoch 4401, loss 0.4455, train acc 84.39%, f1 0.8442, precision 0.8430, recall 0.8453, auc 0.8439
epoch 4501, loss 0.3669, train acc 84.42%, f1 0.8442, precision 0.8450, recall 0.8434, auc 0.8442
epoch 4601, loss 0.3147, train acc 84.37%, f1 0.8440, precision 0.8427, recall 0.8453, auc 0.8437
epoch 4701, loss 0.3114, train acc 84.43%, f1 0.8444, precision 0.8444, recall 0.8443, auc 0.8443
epoch 4801, loss 0.3759, train acc 84.45%, f1 0.8445, precision 0.8448, recall 0.8443, auc 0.8445
epoch 4901, loss 0.4284, train acc 84.44%, f1 0.8447, precision 0.8434, recall 0.8460, auc 0.8444
epoch 5001, loss 0.3137, train acc 84.45%, f1 0.8450, precision 0.8428, recall 0.8472, auc 0.8445
epoch 5101, loss 0.3008, train acc 84.52%, f1 0.8451, precision 0.8458, recall 0.8444, auc 0.8452
epoch 5201, loss 0.3058, train acc 84.54%, f1 0.8453, precision 0.8462, recall 0.8444, auc 0.8454
epoch 5301, loss 0.3011, train acc 84.51%, f1 0.8448, precision 0.8465, recall 0.8431, auc 0.8451
epoch 5401, loss 0.3882, train acc 84.53%, f1 0.8457, precision 0.8440, recall 0.8475, auc 0.8453
epoch 5501, loss 0.3346, train acc 84.52%, f1 0.8452, precision 0.8454, recall 0.8450, auc 0.8452
epoch 5601, loss 0.3737, train acc 84.55%, f1 0.8457, precision 0.8447, recall 0.8468, auc 0.8455
epoch 5701, loss 0.2835, train acc 84.58%, f1 0.8459, precision 0.8461, recall 0.8456, auc 0.8458
epoch 5801, loss 0.4004, train acc 84.60%, f1 0.8462, precision 0.8454, recall 0.8470, auc 0.8460
epoch 5901, loss 0.3647, train acc 84.65%, f1 0.8464, precision 0.8472, recall 0.8456, auc 0.8465
epoch 6001, loss 0.2535, train acc 84.62%, f1 0.8465, precision 0.8452, recall 0.8478, auc 0.8462
epoch 6101, loss 0.3628, train acc 84.71%, f1 0.8468, precision 0.8490, recall 0.8445, auc 0.8471
epoch 6201, loss 0.3340, train acc 84.73%, f1 0.8473, precision 0.8480, recall 0.8466, auc 0.8473
epoch 6301, loss 0.2336, train acc 84.76%, f1 0.8474, precision 0.8489, recall 0.8459, auc 0.8476
epoch 6401, loss 0.3415, train acc 84.78%, f1 0.8478, precision 0.8480, recall 0.8477, auc 0.8478
epoch 6501, loss 0.2866, train acc 84.78%, f1 0.8479, precision 0.8476, recall 0.8482, auc 0.8478
epoch 6601, loss 0.3430, train acc 84.82%, f1 0.8482, precision 0.8484, recall 0.8480, auc 0.8482
epoch 6701, loss 0.4627, train acc 84.83%, f1 0.8486, precision 0.8473, recall 0.8499, auc 0.8483
epoch 6801, loss 0.3627, train acc 84.87%, f1 0.8486, precision 0.8492, recall 0.8480, auc 0.8487
epoch 6901, loss 0.3005, train acc 84.87%, f1 0.8487, precision 0.8490, recall 0.8485, auc 0.8487
epoch 7001, loss 0.3629, train acc 84.88%, f1 0.8491, precision 0.8479, recall 0.8502, auc 0.8488
epoch 7101, loss 0.3985, train acc 84.92%, f1 0.8488, precision 0.8515, recall 0.8461, auc 0.8492
epoch 7201, loss 0.3202, train acc 84.94%, f1 0.8494, precision 0.8497, recall 0.8490, auc 0.8494
epoch 7301, loss 0.3923, train acc 84.96%, f1 0.8496, precision 0.8498, recall 0.8494, auc 0.8496
epoch 7401, loss 0.3057, train acc 85.02%, f1 0.8503, precision 0.8501, recall 0.8505, auc 0.8502
epoch 7501, loss 0.2935, train acc 85.02%, f1 0.8504, precision 0.8499, recall 0.8508, auc 0.8502
epoch 7601, loss 0.3594, train acc 85.03%, f1 0.8499, precision 0.8522, recall 0.8476, auc 0.8503
epoch 7701, loss 0.4338, train acc 85.08%, f1 0.8508, precision 0.8507, recall 0.8509, auc 0.8508
epoch 7801, loss 0.4073, train acc 85.07%, f1 0.8506, precision 0.8511, recall 0.8502, auc 0.8507
epoch 7901, loss 0.3681, train acc 85.12%, f1 0.8516, precision 0.8498, recall 0.8533, auc 0.8512
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_notMirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_5
./test_pima/result_MLP_minus_notMirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6455660377358491

the Fscore is 0.5977011494252873

the precision is 0.4297520661157025

the recall is 0.9811320754716981

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_5
----------------------



epoch 1, loss 0.6930, train acc 49.99%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6192, train acc 72.52%, f1 0.7742, precision 0.6571, recall 0.9419, auc 0.7252
epoch 201, loss 0.5201, train acc 80.22%, f1 0.8145, precision 0.7669, recall 0.8683, auc 0.8022
epoch 301, loss 0.3984, train acc 82.40%, f1 0.8280, precision 0.8099, recall 0.8468, auc 0.8240
epoch 401, loss 0.3487, train acc 83.35%, f1 0.8333, precision 0.8342, recall 0.8324, auc 0.8335
epoch 501, loss 0.3906, train acc 83.75%, f1 0.8371, precision 0.8395, recall 0.8347, auc 0.8375
epoch 601, loss 0.3562, train acc 83.99%, f1 0.8381, precision 0.8476, recall 0.8288, auc 0.8399
epoch 701, loss 0.3440, train acc 84.05%, f1 0.8387, precision 0.8481, recall 0.8296, auc 0.8405
epoch 801, loss 0.3677, train acc 84.10%, f1 0.8391, precision 0.8495, recall 0.8290, auc 0.8410
epoch 901, loss 0.3270, train acc 84.09%, f1 0.8381, precision 0.8534, recall 0.8233, auc 0.8409
epoch 1001, loss 0.3726, train acc 84.16%, f1 0.8394, precision 0.8514, recall 0.8278, auc 0.8416
epoch 1101, loss 0.3837, train acc 84.25%, f1 0.8406, precision 0.8508, recall 0.8307, auc 0.8425
epoch 1201, loss 0.4288, train acc 84.27%, f1 0.8412, precision 0.8492, recall 0.8334, auc 0.8427
epoch 1301, loss 0.3630, train acc 84.24%, f1 0.8403, precision 0.8515, recall 0.8294, auc 0.8424
epoch 1401, loss 0.4560, train acc 84.25%, f1 0.8410, precision 0.8490, recall 0.8331, auc 0.8425
epoch 1501, loss 0.3452, train acc 84.24%, f1 0.8408, precision 0.8495, recall 0.8323, auc 0.8424
epoch 1601, loss 0.3788, train acc 84.23%, f1 0.8408, precision 0.8489, recall 0.8328, auc 0.8423
epoch 1701, loss 0.4309, train acc 84.25%, f1 0.8411, precision 0.8489, recall 0.8335, auc 0.8425
epoch 1801, loss 0.4531, train acc 84.23%, f1 0.8409, precision 0.8487, recall 0.8332, auc 0.8423
epoch 1901, loss 0.3844, train acc 84.20%, f1 0.8408, precision 0.8478, recall 0.8338, auc 0.8420
epoch 2001, loss 0.3980, train acc 84.20%, f1 0.8410, precision 0.8464, recall 0.8356, auc 0.8420
epoch 2101, loss 0.2975, train acc 84.20%, f1 0.8407, precision 0.8481, recall 0.8334, auc 0.8420
epoch 2201, loss 0.3046, train acc 84.22%, f1 0.8413, precision 0.8460, recall 0.8367, auc 0.8422
epoch 2301, loss 0.4201, train acc 84.22%, f1 0.8413, precision 0.8463, recall 0.8362, auc 0.8422
epoch 2401, loss 0.2281, train acc 84.28%, f1 0.8422, precision 0.8454, recall 0.8391, auc 0.8428
epoch 2501, loss 0.4805, train acc 84.30%, f1 0.8422, precision 0.8467, recall 0.8378, auc 0.8430
epoch 2601, loss 0.3254, train acc 84.27%, f1 0.8423, precision 0.8445, recall 0.8400, auc 0.8427
epoch 2701, loss 0.3627, train acc 84.23%, f1 0.8418, precision 0.8449, recall 0.8387, auc 0.8423
epoch 2801, loss 0.5511, train acc 84.24%, f1 0.8418, precision 0.8453, recall 0.8383, auc 0.8424
epoch 2901, loss 0.2590, train acc 84.26%, f1 0.8419, precision 0.8454, recall 0.8385, auc 0.8426
epoch 3001, loss 0.3150, train acc 84.23%, f1 0.8416, precision 0.8455, recall 0.8378, auc 0.8423
epoch 3101, loss 0.3834, train acc 84.23%, f1 0.8419, precision 0.8440, recall 0.8399, auc 0.8423
epoch 3201, loss 0.3392, train acc 84.24%, f1 0.8421, precision 0.8440, recall 0.8402, auc 0.8424
epoch 3301, loss 0.3319, train acc 84.25%, f1 0.8416, precision 0.8467, recall 0.8366, auc 0.8425
epoch 3401, loss 0.3701, train acc 84.30%, f1 0.8430, precision 0.8434, recall 0.8426, auc 0.8430
epoch 3501, loss 0.3032, train acc 84.28%, f1 0.8428, precision 0.8426, recall 0.8431, auc 0.8428
epoch 3601, loss 0.2886, train acc 84.22%, f1 0.8419, precision 0.8436, recall 0.8402, auc 0.8422
epoch 3701, loss 0.3238, train acc 84.27%, f1 0.8426, precision 0.8433, recall 0.8419, auc 0.8427
epoch 3801, loss 0.3751, train acc 84.28%, f1 0.8429, precision 0.8429, recall 0.8428, auc 0.8428
epoch 3901, loss 0.4910, train acc 84.30%, f1 0.8430, precision 0.8431, recall 0.8429, auc 0.8430
epoch 4001, loss 0.3075, train acc 84.30%, f1 0.8422, precision 0.8466, recall 0.8378, auc 0.8430
epoch 4101, loss 0.4315, train acc 84.29%, f1 0.8424, precision 0.8450, recall 0.8399, auc 0.8429
epoch 4201, loss 0.2578, train acc 84.27%, f1 0.8424, precision 0.8442, recall 0.8405, auc 0.8427
epoch 4301, loss 0.5116, train acc 84.28%, f1 0.8426, precision 0.8437, recall 0.8416, auc 0.8428
epoch 4401, loss 0.3402, train acc 84.33%, f1 0.8436, precision 0.8418, recall 0.8455, auc 0.8433
epoch 4501, loss 0.2752, train acc 84.38%, f1 0.8433, precision 0.8463, recall 0.8403, auc 0.8438
epoch 4601, loss 0.4159, train acc 84.35%, f1 0.8439, precision 0.8417, recall 0.8462, auc 0.8435
epoch 4701, loss 0.4019, train acc 84.35%, f1 0.8429, precision 0.8464, recall 0.8393, auc 0.8435
epoch 4801, loss 0.3140, train acc 84.39%, f1 0.8439, precision 0.8442, recall 0.8436, auc 0.8439
epoch 4901, loss 0.2672, train acc 84.47%, f1 0.8449, precision 0.8441, recall 0.8457, auc 0.8447
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_notMirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_5
./test_pima/result_MLP_minus_notMirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.62

the Fscore is 0.5824175824175825

the precision is 0.4108527131782946

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_5
----------------------



epoch 1, loss 0.6932, train acc 49.97%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5873, train acc 77.75%, f1 0.7584, precision 0.8305, recall 0.6978, auc 0.7776
epoch 201, loss 0.5504, train acc 80.97%, f1 0.8070, precision 0.8190, recall 0.7953, auc 0.8097
epoch 301, loss 0.4114, train acc 82.38%, f1 0.8238, precision 0.8239, recall 0.8238, auc 0.8238
epoch 401, loss 0.3726, train acc 83.36%, f1 0.8347, precision 0.8298, recall 0.8396, auc 0.8336
epoch 501, loss 0.3556, train acc 83.80%, f1 0.8391, precision 0.8339, recall 0.8443, auc 0.8380
epoch 601, loss 0.3516, train acc 84.02%, f1 0.8412, precision 0.8364, recall 0.8461, auc 0.8402
epoch 701, loss 0.3327, train acc 84.10%, f1 0.8419, precision 0.8376, recall 0.8462, auc 0.8410
epoch 801, loss 0.4479, train acc 84.16%, f1 0.8427, precision 0.8376, recall 0.8478, auc 0.8416
epoch 901, loss 0.3330, train acc 84.13%, f1 0.8424, precision 0.8369, recall 0.8481, auc 0.8413
epoch 1001, loss 0.4802, train acc 84.18%, f1 0.8428, precision 0.8379, recall 0.8477, auc 0.8418
epoch 1101, loss 0.3808, train acc 84.21%, f1 0.8432, precision 0.8381, recall 0.8483, auc 0.8421
epoch 1201, loss 0.5451, train acc 84.19%, f1 0.8430, precision 0.8377, recall 0.8485, auc 0.8419
epoch 1301, loss 0.3853, train acc 84.20%, f1 0.8432, precision 0.8374, recall 0.8490, auc 0.8420
epoch 1401, loss 0.2953, train acc 84.26%, f1 0.8435, precision 0.8390, recall 0.8481, auc 0.8426
epoch 1501, loss 0.4464, train acc 84.22%, f1 0.8431, precision 0.8387, recall 0.8476, auc 0.8422
epoch 1601, loss 0.4368, train acc 84.23%, f1 0.8427, precision 0.8408, recall 0.8446, auc 0.8423
epoch 1701, loss 0.4745, train acc 84.19%, f1 0.8426, precision 0.8394, recall 0.8459, auc 0.8419
epoch 1801, loss 0.2906, train acc 84.16%, f1 0.8426, precision 0.8375, recall 0.8479, auc 0.8416
epoch 1901, loss 0.3101, train acc 84.24%, f1 0.8428, precision 0.8413, recall 0.8444, auc 0.8424
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_minus_notMirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_5
./test_pima/result_MLP_minus_notMirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.635

the Fscore is 0.5921787709497206

the precision is 0.42063492063492064

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_5
----------------------



epoch 1, loss 0.6928, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.691438).  Saving model ...
Validation loss decreased (0.691438 --> 0.690092).  Saving model ...
Validation loss decreased (0.690092 --> 0.688766).  Saving model ...
Validation loss decreased (0.688766 --> 0.687461).  Saving model ...
Validation loss decreased (0.687461 --> 0.686176).  Saving model ...
Validation loss decreased (0.686176 --> 0.684912).  Saving model ...
Validation loss decreased (0.684912 --> 0.683668).  Saving model ...
Validation loss decreased (0.683668 --> 0.682444).  Saving model ...
Validation loss decreased (0.682444 --> 0.681240).  Saving model ...
Validation loss decreased (0.681240 --> 0.680056).  Saving model ...
Validation loss decreased (0.680056 --> 0.678891).  Saving model ...
Validation loss decreased (0.678891 --> 0.677746).  Saving model ...
Validation loss decreased (0.677746 --> 0.676619).  Saving model ...
Validation loss decreased (0.676619 --> 0.675511).  Saving model ...
Validation loss decreased (0.675511 --> 0.674421).  Saving model ...
Validation loss decreased (0.674421 --> 0.673349).  Saving model ...
Validation loss decreased (0.673349 --> 0.672295).  Saving model ...
Validation loss decreased (0.672295 --> 0.671259).  Saving model ...
Validation loss decreased (0.671259 --> 0.670240).  Saving model ...
Validation loss decreased (0.670240 --> 0.669238).  Saving model ...
Validation loss decreased (0.669238 --> 0.668253).  Saving model ...
Validation loss decreased (0.668253 --> 0.667285).  Saving model ...
Validation loss decreased (0.667285 --> 0.666333).  Saving model ...
Validation loss decreased (0.666333 --> 0.665397).  Saving model ...
Validation loss decreased (0.665397 --> 0.664477).  Saving model ...
Validation loss decreased (0.664477 --> 0.663573).  Saving model ...
Validation loss decreased (0.663573 --> 0.662683).  Saving model ...
Validation loss decreased (0.662683 --> 0.661809).  Saving model ...
Validation loss decreased (0.661809 --> 0.660949).  Saving model ...
Validation loss decreased (0.660949 --> 0.660104).  Saving model ...
Validation loss decreased (0.660104 --> 0.659273).  Saving model ...
Validation loss decreased (0.659273 --> 0.658456).  Saving model ...
Validation loss decreased (0.658456 --> 0.657653).  Saving model ...
Validation loss decreased (0.657653 --> 0.656863).  Saving model ...
Validation loss decreased (0.656863 --> 0.656086).  Saving model ...
Validation loss decreased (0.656086 --> 0.655323).  Saving model ...
Validation loss decreased (0.655323 --> 0.654572).  Saving model ...
Validation loss decreased (0.654572 --> 0.653833).  Saving model ...
Validation loss decreased (0.653833 --> 0.653107).  Saving model ...
Validation loss decreased (0.653107 --> 0.652393).  Saving model ...
Validation loss decreased (0.652393 --> 0.651690).  Saving model ...
Validation loss decreased (0.651690 --> 0.650999).  Saving model ...
Validation loss decreased (0.650999 --> 0.650320).  Saving model ...
Validation loss decreased (0.650320 --> 0.649651).  Saving model ...
Validation loss decreased (0.649651 --> 0.648994).  Saving model ...
Validation loss decreased (0.648994 --> 0.648347).  Saving model ...
Validation loss decreased (0.648347 --> 0.647711).  Saving model ...
Validation loss decreased (0.647711 --> 0.647085).  Saving model ...
Validation loss decreased (0.647085 --> 0.646469).  Saving model ...
Validation loss decreased (0.646469 --> 0.645863).  Saving model ...
Validation loss decreased (0.645863 --> 0.645267).  Saving model ...
Validation loss decreased (0.645267 --> 0.644681).  Saving model ...
Validation loss decreased (0.644681 --> 0.644103).  Saving model ...
Validation loss decreased (0.644103 --> 0.643535).  Saving model ...
Validation loss decreased (0.643535 --> 0.642976).  Saving model ...
Validation loss decreased (0.642976 --> 0.642426).  Saving model ...
Validation loss decreased (0.642426 --> 0.641884).  Saving model ...
Validation loss decreased (0.641884 --> 0.641350).  Saving model ...
Validation loss decreased (0.641350 --> 0.640825).  Saving model ...
Validation loss decreased (0.640825 --> 0.640308).  Saving model ...
Validation loss decreased (0.640308 --> 0.639799).  Saving model ...
Validation loss decreased (0.639799 --> 0.639297).  Saving model ...
Validation loss decreased (0.639297 --> 0.638803).  Saving model ...
Validation loss decreased (0.638803 --> 0.638316).  Saving model ...
Validation loss decreased (0.638316 --> 0.637836).  Saving model ...
Validation loss decreased (0.637836 --> 0.637364).  Saving model ...
Validation loss decreased (0.637364 --> 0.636898).  Saving model ...
Validation loss decreased (0.636898 --> 0.636439).  Saving model ...
Validation loss decreased (0.636439 --> 0.635986).  Saving model ...
Validation loss decreased (0.635986 --> 0.635540).  Saving model ...
Validation loss decreased (0.635540 --> 0.635100).  Saving model ...
Validation loss decreased (0.635100 --> 0.634665).  Saving model ...
Validation loss decreased (0.634665 --> 0.634237).  Saving model ...
Validation loss decreased (0.634237 --> 0.633815).  Saving model ...
Validation loss decreased (0.633815 --> 0.633397).  Saving model ...
Validation loss decreased (0.633397 --> 0.632986).  Saving model ...
Validation loss decreased (0.632986 --> 0.632579).  Saving model ...
Validation loss decreased (0.632579 --> 0.632178).  Saving model ...
Validation loss decreased (0.632178 --> 0.631782).  Saving model ...
Validation loss decreased (0.631782 --> 0.631391).  Saving model ...
Validation loss decreased (0.631391 --> 0.631004).  Saving model ...
Validation loss decreased (0.631004 --> 0.630622).  Saving model ...
Validation loss decreased (0.630622 --> 0.630244).  Saving model ...
Validation loss decreased (0.630244 --> 0.629870).  Saving model ...
Validation loss decreased (0.629870 --> 0.629501).  Saving model ...
Validation loss decreased (0.629501 --> 0.629136).  Saving model ...
Validation loss decreased (0.629136 --> 0.628774).  Saving model ...
Validation loss decreased (0.628774 --> 0.628417).  Saving model ...
Validation loss decreased (0.628417 --> 0.628063).  Saving model ...
Validation loss decreased (0.628063 --> 0.627712).  Saving model ...
Validation loss decreased (0.627712 --> 0.627366).  Saving model ...
Validation loss decreased (0.627366 --> 0.627022).  Saving model ...
Validation loss decreased (0.627022 --> 0.626682).  Saving model ...
Validation loss decreased (0.626682 --> 0.626344).  Saving model ...
Validation loss decreased (0.626344 --> 0.626010).  Saving model ...
Validation loss decreased (0.626010 --> 0.625679).  Saving model ...
Validation loss decreased (0.625679 --> 0.625350).  Saving model ...
Validation loss decreased (0.625350 --> 0.625025).  Saving model ...
Validation loss decreased (0.625025 --> 0.624701).  Saving model ...
Validation loss decreased (0.624701 --> 0.624381).  Saving model ...
epoch 101, loss 0.6244, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.624381 --> 0.624063).  Saving model ...
Validation loss decreased (0.624063 --> 0.623747).  Saving model ...
Validation loss decreased (0.623747 --> 0.623434).  Saving model ...
Validation loss decreased (0.623434 --> 0.623122).  Saving model ...
Validation loss decreased (0.623122 --> 0.622813).  Saving model ...
Validation loss decreased (0.622813 --> 0.622506).  Saving model ...
Validation loss decreased (0.622506 --> 0.622201).  Saving model ...
Validation loss decreased (0.622201 --> 0.621898).  Saving model ...
Validation loss decreased (0.621898 --> 0.621597).  Saving model ...
Validation loss decreased (0.621597 --> 0.621297).  Saving model ...
Validation loss decreased (0.621297 --> 0.621000).  Saving model ...
Validation loss decreased (0.621000 --> 0.620704).  Saving model ...
Validation loss decreased (0.620704 --> 0.620409).  Saving model ...
Validation loss decreased (0.620409 --> 0.620116).  Saving model ...
Validation loss decreased (0.620116 --> 0.619825).  Saving model ...
Validation loss decreased (0.619825 --> 0.619535).  Saving model ...
Validation loss decreased (0.619535 --> 0.619246).  Saving model ...
Validation loss decreased (0.619246 --> 0.618959).  Saving model ...
Validation loss decreased (0.618959 --> 0.618673).  Saving model ...
Validation loss decreased (0.618673 --> 0.618389).  Saving model ...
Validation loss decreased (0.618389 --> 0.618105).  Saving model ...
Validation loss decreased (0.618105 --> 0.617823).  Saving model ...
Validation loss decreased (0.617823 --> 0.617542).  Saving model ...
Validation loss decreased (0.617542 --> 0.617263).  Saving model ...
Validation loss decreased (0.617263 --> 0.616984).  Saving model ...
Validation loss decreased (0.616984 --> 0.616706).  Saving model ...
Validation loss decreased (0.616706 --> 0.616429).  Saving model ...
Validation loss decreased (0.616429 --> 0.616154).  Saving model ...
Validation loss decreased (0.616154 --> 0.615879).  Saving model ...
Validation loss decreased (0.615879 --> 0.615605).  Saving model ...
Validation loss decreased (0.615605 --> 0.615332).  Saving model ...
Validation loss decreased (0.615332 --> 0.615060).  Saving model ...
Validation loss decreased (0.615060 --> 0.614789).  Saving model ...
Validation loss decreased (0.614789 --> 0.614519).  Saving model ...
Validation loss decreased (0.614519 --> 0.614249).  Saving model ...
Validation loss decreased (0.614249 --> 0.613980).  Saving model ...
Validation loss decreased (0.613980 --> 0.613712).  Saving model ...
Validation loss decreased (0.613712 --> 0.613445).  Saving model ...
Validation loss decreased (0.613445 --> 0.613179).  Saving model ...
Validation loss decreased (0.613179 --> 0.612913).  Saving model ...
Validation loss decreased (0.612913 --> 0.612648).  Saving model ...
Validation loss decreased (0.612648 --> 0.612383).  Saving model ...
Validation loss decreased (0.612383 --> 0.612119).  Saving model ...
Validation loss decreased (0.612119 --> 0.611856).  Saving model ...
Validation loss decreased (0.611856 --> 0.611593).  Saving model ...
Validation loss decreased (0.611593 --> 0.611331).  Saving model ...
Validation loss decreased (0.611331 --> 0.611070).  Saving model ...
Validation loss decreased (0.611070 --> 0.610809).  Saving model ...
Validation loss decreased (0.610809 --> 0.610548).  Saving model ...
Validation loss decreased (0.610548 --> 0.610288).  Saving model ...
Validation loss decreased (0.610288 --> 0.610029).  Saving model ...
Validation loss decreased (0.610029 --> 0.609770).  Saving model ...
Validation loss decreased (0.609770 --> 0.609512).  Saving model ...
Validation loss decreased (0.609512 --> 0.609254).  Saving model ...
Validation loss decreased (0.609254 --> 0.608996).  Saving model ...
Validation loss decreased (0.608996 --> 0.608739).  Saving model ...
Validation loss decreased (0.608739 --> 0.608483).  Saving model ...
Validation loss decreased (0.608483 --> 0.608226).  Saving model ...
Validation loss decreased (0.608226 --> 0.607970).  Saving model ...
Validation loss decreased (0.607970 --> 0.607715).  Saving model ...
Validation loss decreased (0.607715 --> 0.607460).  Saving model ...
Validation loss decreased (0.607460 --> 0.607205).  Saving model ...
Validation loss decreased (0.607205 --> 0.606951).  Saving model ...
Validation loss decreased (0.606951 --> 0.606697).  Saving model ...
Validation loss decreased (0.606697 --> 0.606443).  Saving model ...
Validation loss decreased (0.606443 --> 0.606189).  Saving model ...
Validation loss decreased (0.606189 --> 0.605936).  Saving model ...
Validation loss decreased (0.605936 --> 0.605683).  Saving model ...
Validation loss decreased (0.605683 --> 0.605431).  Saving model ...
Validation loss decreased (0.605431 --> 0.605178).  Saving model ...
Validation loss decreased (0.605178 --> 0.604926).  Saving model ...
Validation loss decreased (0.604926 --> 0.604674).  Saving model ...
Validation loss decreased (0.604674 --> 0.604423).  Saving model ...
Validation loss decreased (0.604423 --> 0.604171).  Saving model ...
Validation loss decreased (0.604171 --> 0.603920).  Saving model ...
Validation loss decreased (0.603920 --> 0.603669).  Saving model ...
Validation loss decreased (0.603669 --> 0.603418).  Saving model ...
Validation loss decreased (0.603418 --> 0.603168).  Saving model ...
Validation loss decreased (0.603168 --> 0.602917).  Saving model ...
Validation loss decreased (0.602917 --> 0.602667).  Saving model ...
Validation loss decreased (0.602667 --> 0.602416).  Saving model ...
Validation loss decreased (0.602416 --> 0.602166).  Saving model ...
Validation loss decreased (0.602166 --> 0.601916).  Saving model ...
Validation loss decreased (0.601916 --> 0.601666).  Saving model ...
Validation loss decreased (0.601666 --> 0.601417).  Saving model ...
Validation loss decreased (0.601417 --> 0.601167).  Saving model ...
Validation loss decreased (0.601167 --> 0.600917).  Saving model ...
Validation loss decreased (0.600917 --> 0.600668).  Saving model ...
Validation loss decreased (0.600668 --> 0.600419).  Saving model ...
Validation loss decreased (0.600419 --> 0.600169).  Saving model ...
Validation loss decreased (0.600169 --> 0.599920).  Saving model ...
Validation loss decreased (0.599920 --> 0.599670).  Saving model ...
Validation loss decreased (0.599670 --> 0.599421).  Saving model ...
Validation loss decreased (0.599421 --> 0.599172).  Saving model ...
Validation loss decreased (0.599172 --> 0.598923).  Saving model ...
Validation loss decreased (0.598923 --> 0.598674).  Saving model ...
Validation loss decreased (0.598674 --> 0.598424).  Saving model ...
Validation loss decreased (0.598424 --> 0.598175).  Saving model ...
Validation loss decreased (0.598175 --> 0.597926).  Saving model ...
Validation loss decreased (0.597926 --> 0.597677).  Saving model ...
epoch 201, loss 0.5977, train acc 64.96%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.597677 --> 0.597428).  Saving model ...
Validation loss decreased (0.597428 --> 0.597178).  Saving model ...
Validation loss decreased (0.597178 --> 0.596929).  Saving model ...
Validation loss decreased (0.596929 --> 0.596680).  Saving model ...
Validation loss decreased (0.596680 --> 0.596430).  Saving model ...
Validation loss decreased (0.596430 --> 0.596181).  Saving model ...
Validation loss decreased (0.596181 --> 0.595932).  Saving model ...
Validation loss decreased (0.595932 --> 0.595682).  Saving model ...
Validation loss decreased (0.595682 --> 0.595433).  Saving model ...
Validation loss decreased (0.595433 --> 0.595183).  Saving model ...
Validation loss decreased (0.595183 --> 0.594933).  Saving model ...
Validation loss decreased (0.594933 --> 0.594684).  Saving model ...
Validation loss decreased (0.594684 --> 0.594434).  Saving model ...
Validation loss decreased (0.594434 --> 0.594184).  Saving model ...
Validation loss decreased (0.594184 --> 0.593934).  Saving model ...
Validation loss decreased (0.593934 --> 0.593684).  Saving model ...
Validation loss decreased (0.593684 --> 0.593434).  Saving model ...
Validation loss decreased (0.593434 --> 0.593184).  Saving model ...
Validation loss decreased (0.593184 --> 0.592933).  Saving model ...
Validation loss decreased (0.592933 --> 0.592683).  Saving model ...
Validation loss decreased (0.592683 --> 0.592433).  Saving model ...
Validation loss decreased (0.592433 --> 0.592182).  Saving model ...
Validation loss decreased (0.592182 --> 0.591931).  Saving model ...
Validation loss decreased (0.591931 --> 0.591681).  Saving model ...
Validation loss decreased (0.591681 --> 0.591430).  Saving model ...
Validation loss decreased (0.591430 --> 0.591179).  Saving model ...
Validation loss decreased (0.591179 --> 0.590928).  Saving model ...
Validation loss decreased (0.590928 --> 0.590677).  Saving model ...
Validation loss decreased (0.590677 --> 0.590426).  Saving model ...
Validation loss decreased (0.590426 --> 0.590175).  Saving model ...
Validation loss decreased (0.590175 --> 0.589924).  Saving model ...
Validation loss decreased (0.589924 --> 0.589673).  Saving model ...
Validation loss decreased (0.589673 --> 0.589421).  Saving model ...
Validation loss decreased (0.589421 --> 0.589170).  Saving model ...
Validation loss decreased (0.589170 --> 0.588918).  Saving model ...
Validation loss decreased (0.588918 --> 0.588667).  Saving model ...
Validation loss decreased (0.588667 --> 0.588415).  Saving model ...
Validation loss decreased (0.588415 --> 0.588163).  Saving model ...
Validation loss decreased (0.588163 --> 0.587912).  Saving model ...
Validation loss decreased (0.587912 --> 0.587660).  Saving model ...
Validation loss decreased (0.587660 --> 0.587408).  Saving model ...
Validation loss decreased (0.587408 --> 0.587156).  Saving model ...
Validation loss decreased (0.587156 --> 0.586904).  Saving model ...
Validation loss decreased (0.586904 --> 0.586652).  Saving model ...
Validation loss decreased (0.586652 --> 0.586400).  Saving model ...
Validation loss decreased (0.586400 --> 0.586148).  Saving model ...
Validation loss decreased (0.586148 --> 0.585896).  Saving model ...
Validation loss decreased (0.585896 --> 0.585644).  Saving model ...
Validation loss decreased (0.585644 --> 0.585392).  Saving model ...
Validation loss decreased (0.585392 --> 0.585140).  Saving model ...
Validation loss decreased (0.585140 --> 0.584888).  Saving model ...
Validation loss decreased (0.584888 --> 0.584635).  Saving model ...
Validation loss decreased (0.584635 --> 0.584383).  Saving model ...
Validation loss decreased (0.584383 --> 0.584131).  Saving model ...
Validation loss decreased (0.584131 --> 0.583879).  Saving model ...
Validation loss decreased (0.583879 --> 0.583627).  Saving model ...
Validation loss decreased (0.583627 --> 0.583375).  Saving model ...
Validation loss decreased (0.583375 --> 0.583123).  Saving model ...
Validation loss decreased (0.583123 --> 0.582871).  Saving model ...
Validation loss decreased (0.582871 --> 0.582619).  Saving model ...
Validation loss decreased (0.582619 --> 0.582367).  Saving model ...
Validation loss decreased (0.582367 --> 0.582116).  Saving model ...
Validation loss decreased (0.582116 --> 0.581864).  Saving model ...
Validation loss decreased (0.581864 --> 0.581612).  Saving model ...
Validation loss decreased (0.581612 --> 0.581361).  Saving model ...
Validation loss decreased (0.581361 --> 0.581109).  Saving model ...
Validation loss decreased (0.581109 --> 0.580858).  Saving model ...
Validation loss decreased (0.580858 --> 0.580606).  Saving model ...
Validation loss decreased (0.580606 --> 0.580355).  Saving model ...
Validation loss decreased (0.580355 --> 0.580104).  Saving model ...
Validation loss decreased (0.580104 --> 0.579853).  Saving model ...
Validation loss decreased (0.579853 --> 0.579602).  Saving model ...
Validation loss decreased (0.579602 --> 0.579351).  Saving model ...
Validation loss decreased (0.579351 --> 0.579100).  Saving model ...
Validation loss decreased (0.579100 --> 0.578850).  Saving model ...
Validation loss decreased (0.578850 --> 0.578599).  Saving model ...
Validation loss decreased (0.578599 --> 0.578349).  Saving model ...
Validation loss decreased (0.578349 --> 0.578099).  Saving model ...
Validation loss decreased (0.578099 --> 0.577849).  Saving model ...
Validation loss decreased (0.577849 --> 0.577600).  Saving model ...
Validation loss decreased (0.577600 --> 0.577350).  Saving model ...
Validation loss decreased (0.577350 --> 0.577101).  Saving model ...
Validation loss decreased (0.577101 --> 0.576851).  Saving model ...
Validation loss decreased (0.576851 --> 0.576602).  Saving model ...
Validation loss decreased (0.576602 --> 0.576353).  Saving model ...
Validation loss decreased (0.576353 --> 0.576105).  Saving model ...
Validation loss decreased (0.576105 --> 0.575856).  Saving model ...
Validation loss decreased (0.575856 --> 0.575608).  Saving model ...
Validation loss decreased (0.575608 --> 0.575360).  Saving model ...
Validation loss decreased (0.575360 --> 0.575112).  Saving model ...
Validation loss decreased (0.575112 --> 0.574865).  Saving model ...
Validation loss decreased (0.574865 --> 0.574617).  Saving model ...
Validation loss decreased (0.574617 --> 0.574370).  Saving model ...
Validation loss decreased (0.574370 --> 0.574123).  Saving model ...
Validation loss decreased (0.574123 --> 0.573877).  Saving model ...
Validation loss decreased (0.573877 --> 0.573630).  Saving model ...
Validation loss decreased (0.573630 --> 0.573384).  Saving model ...
Validation loss decreased (0.573384 --> 0.573138).  Saving model ...
Validation loss decreased (0.573138 --> 0.572893).  Saving model ...
Validation loss decreased (0.572893 --> 0.572647).  Saving model ...
epoch 301, loss 0.5726, train acc 64.79%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4987
Validation loss decreased (0.572647 --> 0.572402).  Saving model ...
Validation loss decreased (0.572402 --> 0.572158).  Saving model ...
Validation loss decreased (0.572158 --> 0.571913).  Saving model ...
Validation loss decreased (0.571913 --> 0.571669).  Saving model ...
Validation loss decreased (0.571669 --> 0.571425).  Saving model ...
Validation loss decreased (0.571425 --> 0.571182).  Saving model ...
Validation loss decreased (0.571182 --> 0.570938).  Saving model ...
Validation loss decreased (0.570938 --> 0.570695).  Saving model ...
Validation loss decreased (0.570695 --> 0.570453).  Saving model ...
Validation loss decreased (0.570453 --> 0.570211).  Saving model ...
Validation loss decreased (0.570211 --> 0.569969).  Saving model ...
Validation loss decreased (0.569969 --> 0.569727).  Saving model ...
Validation loss decreased (0.569727 --> 0.569485).  Saving model ...
Validation loss decreased (0.569485 --> 0.569245).  Saving model ...
Validation loss decreased (0.569245 --> 0.569004).  Saving model ...
Validation loss decreased (0.569004 --> 0.568764).  Saving model ...
Validation loss decreased (0.568764 --> 0.568524).  Saving model ...
Validation loss decreased (0.568524 --> 0.568284).  Saving model ...
Validation loss decreased (0.568284 --> 0.568045).  Saving model ...
Validation loss decreased (0.568045 --> 0.567806).  Saving model ...
Validation loss decreased (0.567806 --> 0.567567).  Saving model ...
Validation loss decreased (0.567567 --> 0.567329).  Saving model ...
Validation loss decreased (0.567329 --> 0.567091).  Saving model ...
Validation loss decreased (0.567091 --> 0.566854).  Saving model ...
Validation loss decreased (0.566854 --> 0.566617).  Saving model ...
Validation loss decreased (0.566617 --> 0.566380).  Saving model ...
Validation loss decreased (0.566380 --> 0.566144).  Saving model ...
Validation loss decreased (0.566144 --> 0.565908).  Saving model ...
Validation loss decreased (0.565908 --> 0.565673).  Saving model ...
Validation loss decreased (0.565673 --> 0.565437).  Saving model ...
Validation loss decreased (0.565437 --> 0.565203).  Saving model ...
Validation loss decreased (0.565203 --> 0.564968).  Saving model ...
Validation loss decreased (0.564968 --> 0.564734).  Saving model ...
Validation loss decreased (0.564734 --> 0.564501).  Saving model ...
Validation loss decreased (0.564501 --> 0.564268).  Saving model ...
Validation loss decreased (0.564268 --> 0.564035).  Saving model ...
Validation loss decreased (0.564035 --> 0.563802).  Saving model ...
Validation loss decreased (0.563802 --> 0.563570).  Saving model ...
Validation loss decreased (0.563570 --> 0.563339).  Saving model ...
Validation loss decreased (0.563339 --> 0.563108).  Saving model ...
Validation loss decreased (0.563108 --> 0.562877).  Saving model ...
Validation loss decreased (0.562877 --> 0.562647).  Saving model ...
Validation loss decreased (0.562647 --> 0.562417).  Saving model ...
Validation loss decreased (0.562417 --> 0.562187).  Saving model ...
Validation loss decreased (0.562187 --> 0.561958).  Saving model ...
Validation loss decreased (0.561958 --> 0.561730).  Saving model ...
Validation loss decreased (0.561730 --> 0.561502).  Saving model ...
Validation loss decreased (0.561502 --> 0.561274).  Saving model ...
Validation loss decreased (0.561274 --> 0.561046).  Saving model ...
Validation loss decreased (0.561046 --> 0.560820).  Saving model ...
Validation loss decreased (0.560820 --> 0.560593).  Saving model ...
Validation loss decreased (0.560593 --> 0.560367).  Saving model ...
Validation loss decreased (0.560367 --> 0.560141).  Saving model ...
Validation loss decreased (0.560141 --> 0.559916).  Saving model ...
Validation loss decreased (0.559916 --> 0.559691).  Saving model ...
Validation loss decreased (0.559691 --> 0.559467).  Saving model ...
Validation loss decreased (0.559467 --> 0.559243).  Saving model ...
Validation loss decreased (0.559243 --> 0.559020).  Saving model ...
Validation loss decreased (0.559020 --> 0.558797).  Saving model ...
Validation loss decreased (0.558797 --> 0.558574).  Saving model ...
Validation loss decreased (0.558574 --> 0.558352).  Saving model ...
Validation loss decreased (0.558352 --> 0.558131).  Saving model ...
Validation loss decreased (0.558131 --> 0.557909).  Saving model ...
Validation loss decreased (0.557909 --> 0.557689).  Saving model ...
Validation loss decreased (0.557689 --> 0.557468).  Saving model ...
Validation loss decreased (0.557468 --> 0.557248).  Saving model ...
Validation loss decreased (0.557248 --> 0.557029).  Saving model ...
Validation loss decreased (0.557029 --> 0.556810).  Saving model ...
Validation loss decreased (0.556810 --> 0.556591).  Saving model ...
Validation loss decreased (0.556591 --> 0.556373).  Saving model ...
Validation loss decreased (0.556373 --> 0.556156).  Saving model ...
Validation loss decreased (0.556156 --> 0.555938).  Saving model ...
Validation loss decreased (0.555938 --> 0.555722).  Saving model ...
Validation loss decreased (0.555722 --> 0.555505).  Saving model ...
Validation loss decreased (0.555505 --> 0.555290).  Saving model ...
Validation loss decreased (0.555290 --> 0.555074).  Saving model ...
Validation loss decreased (0.555074 --> 0.554859).  Saving model ...
Validation loss decreased (0.554859 --> 0.554645).  Saving model ...
Validation loss decreased (0.554645 --> 0.554431).  Saving model ...
Validation loss decreased (0.554431 --> 0.554217).  Saving model ...
Validation loss decreased (0.554217 --> 0.554004).  Saving model ...
Validation loss decreased (0.554004 --> 0.553792).  Saving model ...
Validation loss decreased (0.553792 --> 0.553580).  Saving model ...
Validation loss decreased (0.553580 --> 0.553368).  Saving model ...
Validation loss decreased (0.553368 --> 0.553157).  Saving model ...
Validation loss decreased (0.553157 --> 0.552946).  Saving model ...
Validation loss decreased (0.552946 --> 0.552735).  Saving model ...
Validation loss decreased (0.552735 --> 0.552526).  Saving model ...
Validation loss decreased (0.552526 --> 0.552316).  Saving model ...
Validation loss decreased (0.552316 --> 0.552107).  Saving model ...
Validation loss decreased (0.552107 --> 0.551899).  Saving model ...
Validation loss decreased (0.551899 --> 0.551691).  Saving model ...
Validation loss decreased (0.551691 --> 0.551483).  Saving model ...
Validation loss decreased (0.551483 --> 0.551276).  Saving model ...
Validation loss decreased (0.551276 --> 0.551069).  Saving model ...
Validation loss decreased (0.551069 --> 0.550863).  Saving model ...
Validation loss decreased (0.550863 --> 0.550657).  Saving model ...
Validation loss decreased (0.550657 --> 0.550452).  Saving model ...
Validation loss decreased (0.550452 --> 0.550247).  Saving model ...
Validation loss decreased (0.550247 --> 0.550043).  Saving model ...
epoch 401, loss 0.5500, train acc 67.69%, f1 0.1674, precision 0.8636, recall 0.0927, auc 0.5424
Validation loss decreased (0.550043 --> 0.549839).  Saving model ...
Validation loss decreased (0.549839 --> 0.549635).  Saving model ...
Validation loss decreased (0.549635 --> 0.549432).  Saving model ...
Validation loss decreased (0.549432 --> 0.549230).  Saving model ...
Validation loss decreased (0.549230 --> 0.549028).  Saving model ...
Validation loss decreased (0.549028 --> 0.548826).  Saving model ...
Validation loss decreased (0.548826 --> 0.548625).  Saving model ...
Validation loss decreased (0.548625 --> 0.548424).  Saving model ...
Validation loss decreased (0.548424 --> 0.548224).  Saving model ...
Validation loss decreased (0.548224 --> 0.548024).  Saving model ...
Validation loss decreased (0.548024 --> 0.547825).  Saving model ...
Validation loss decreased (0.547825 --> 0.547626).  Saving model ...
Validation loss decreased (0.547626 --> 0.547428).  Saving model ...
Validation loss decreased (0.547428 --> 0.547230).  Saving model ...
Validation loss decreased (0.547230 --> 0.547032).  Saving model ...
Validation loss decreased (0.547032 --> 0.546835).  Saving model ...
Validation loss decreased (0.546835 --> 0.546639).  Saving model ...
Validation loss decreased (0.546639 --> 0.546442).  Saving model ...
Validation loss decreased (0.546442 --> 0.546247).  Saving model ...
Validation loss decreased (0.546247 --> 0.546052).  Saving model ...
Validation loss decreased (0.546052 --> 0.545857).  Saving model ...
Validation loss decreased (0.545857 --> 0.545662).  Saving model ...
Validation loss decreased (0.545662 --> 0.545469).  Saving model ...
Validation loss decreased (0.545469 --> 0.545275).  Saving model ...
Validation loss decreased (0.545275 --> 0.545082).  Saving model ...
Validation loss decreased (0.545082 --> 0.544890).  Saving model ...
Validation loss decreased (0.544890 --> 0.544698).  Saving model ...
Validation loss decreased (0.544698 --> 0.544506).  Saving model ...
Validation loss decreased (0.544506 --> 0.544315).  Saving model ...
Validation loss decreased (0.544315 --> 0.544124).  Saving model ...
Validation loss decreased (0.544124 --> 0.543934).  Saving model ...
Validation loss decreased (0.543934 --> 0.543744).  Saving model ...
Validation loss decreased (0.543744 --> 0.543555).  Saving model ...
Validation loss decreased (0.543555 --> 0.543366).  Saving model ...
Validation loss decreased (0.543366 --> 0.543178).  Saving model ...
Validation loss decreased (0.543178 --> 0.542990).  Saving model ...
Validation loss decreased (0.542990 --> 0.542802).  Saving model ...
Validation loss decreased (0.542802 --> 0.542615).  Saving model ...
Validation loss decreased (0.542615 --> 0.542429).  Saving model ...
Validation loss decreased (0.542429 --> 0.542242).  Saving model ...
Validation loss decreased (0.542242 --> 0.542057).  Saving model ...
Validation loss decreased (0.542057 --> 0.541871).  Saving model ...
Validation loss decreased (0.541871 --> 0.541687).  Saving model ...
Validation loss decreased (0.541687 --> 0.541502).  Saving model ...
Validation loss decreased (0.541502 --> 0.541318).  Saving model ...
Validation loss decreased (0.541318 --> 0.541135).  Saving model ...
Validation loss decreased (0.541135 --> 0.540952).  Saving model ...
Validation loss decreased (0.540952 --> 0.540769).  Saving model ...
Validation loss decreased (0.540769 --> 0.540587).  Saving model ...
Validation loss decreased (0.540587 --> 0.540405).  Saving model ...
Validation loss decreased (0.540405 --> 0.540224).  Saving model ...
Validation loss decreased (0.540224 --> 0.540043).  Saving model ...
Validation loss decreased (0.540043 --> 0.539863).  Saving model ...
Validation loss decreased (0.539863 --> 0.539683).  Saving model ...
Validation loss decreased (0.539683 --> 0.539503).  Saving model ...
Validation loss decreased (0.539503 --> 0.539324).  Saving model ...
Validation loss decreased (0.539324 --> 0.539146).  Saving model ...
Validation loss decreased (0.539146 --> 0.538968).  Saving model ...
Validation loss decreased (0.538968 --> 0.538790).  Saving model ...
Validation loss decreased (0.538790 --> 0.538612).  Saving model ...
Validation loss decreased (0.538612 --> 0.538436).  Saving model ...
Validation loss decreased (0.538436 --> 0.538259).  Saving model ...
Validation loss decreased (0.538259 --> 0.538083).  Saving model ...
Validation loss decreased (0.538083 --> 0.537908).  Saving model ...
Validation loss decreased (0.537908 --> 0.537733).  Saving model ...
Validation loss decreased (0.537733 --> 0.537558).  Saving model ...
Validation loss decreased (0.537558 --> 0.537384).  Saving model ...
Validation loss decreased (0.537384 --> 0.537210).  Saving model ...
Validation loss decreased (0.537210 --> 0.537037).  Saving model ...
Validation loss decreased (0.537037 --> 0.536864).  Saving model ...
Validation loss decreased (0.536864 --> 0.536691).  Saving model ...
Validation loss decreased (0.536691 --> 0.536519).  Saving model ...
Validation loss decreased (0.536519 --> 0.536347).  Saving model ...
Validation loss decreased (0.536347 --> 0.536176).  Saving model ...
Validation loss decreased (0.536176 --> 0.536005).  Saving model ...
Validation loss decreased (0.536005 --> 0.535835).  Saving model ...
Validation loss decreased (0.535835 --> 0.535665).  Saving model ...
Validation loss decreased (0.535665 --> 0.535496).  Saving model ...
Validation loss decreased (0.535496 --> 0.535326).  Saving model ...
Validation loss decreased (0.535326 --> 0.535158).  Saving model ...
Validation loss decreased (0.535158 --> 0.534989).  Saving model ...
Validation loss decreased (0.534989 --> 0.534822).  Saving model ...
Validation loss decreased (0.534822 --> 0.534654).  Saving model ...
Validation loss decreased (0.534654 --> 0.534487).  Saving model ...
Validation loss decreased (0.534487 --> 0.534321).  Saving model ...
Validation loss decreased (0.534321 --> 0.534155).  Saving model ...
Validation loss decreased (0.534155 --> 0.533989).  Saving model ...
Validation loss decreased (0.533989 --> 0.533824).  Saving model ...
Validation loss decreased (0.533824 --> 0.533659).  Saving model ...
Validation loss decreased (0.533659 --> 0.533495).  Saving model ...
Validation loss decreased (0.533495 --> 0.533330).  Saving model ...
Validation loss decreased (0.533330 --> 0.533167).  Saving model ...
Validation loss decreased (0.533167 --> 0.533004).  Saving model ...
Validation loss decreased (0.533004 --> 0.532841).  Saving model ...
Validation loss decreased (0.532841 --> 0.532679).  Saving model ...
Validation loss decreased (0.532679 --> 0.532517).  Saving model ...
Validation loss decreased (0.532517 --> 0.532355).  Saving model ...
Validation loss decreased (0.532355 --> 0.532194).  Saving model ...
Validation loss decreased (0.532194 --> 0.532033).  Saving model ...
Validation loss decreased (0.532033 --> 0.531873).  Saving model ...
epoch 501, loss 0.5319, train acc 71.11%, f1 0.3525, precision 0.8214, recall 0.2244, auc 0.5990
Validation loss decreased (0.531873 --> 0.531713).  Saving model ...
Validation loss decreased (0.531713 --> 0.531554).  Saving model ...
Validation loss decreased (0.531554 --> 0.531395).  Saving model ...
Validation loss decreased (0.531395 --> 0.531236).  Saving model ...
Validation loss decreased (0.531236 --> 0.531078).  Saving model ...
Validation loss decreased (0.531078 --> 0.530920).  Saving model ...
Validation loss decreased (0.530920 --> 0.530763).  Saving model ...
Validation loss decreased (0.530763 --> 0.530606).  Saving model ...
Validation loss decreased (0.530606 --> 0.530449).  Saving model ...
Validation loss decreased (0.530449 --> 0.530293).  Saving model ...
Validation loss decreased (0.530293 --> 0.530137).  Saving model ...
Validation loss decreased (0.530137 --> 0.529982).  Saving model ...
Validation loss decreased (0.529982 --> 0.529827).  Saving model ...
Validation loss decreased (0.529827 --> 0.529673).  Saving model ...
Validation loss decreased (0.529673 --> 0.529518).  Saving model ...
Validation loss decreased (0.529518 --> 0.529365).  Saving model ...
Validation loss decreased (0.529365 --> 0.529211).  Saving model ...
Validation loss decreased (0.529211 --> 0.529058).  Saving model ...
Validation loss decreased (0.529058 --> 0.528906).  Saving model ...
Validation loss decreased (0.528906 --> 0.528754).  Saving model ...
Validation loss decreased (0.528754 --> 0.528602).  Saving model ...
Validation loss decreased (0.528602 --> 0.528450).  Saving model ...
Validation loss decreased (0.528450 --> 0.528300).  Saving model ...
Validation loss decreased (0.528300 --> 0.528149).  Saving model ...
Validation loss decreased (0.528149 --> 0.527999).  Saving model ...
Validation loss decreased (0.527999 --> 0.527849).  Saving model ...
Validation loss decreased (0.527849 --> 0.527700).  Saving model ...
Validation loss decreased (0.527700 --> 0.527551).  Saving model ...
Validation loss decreased (0.527551 --> 0.527402).  Saving model ...
Validation loss decreased (0.527402 --> 0.527254).  Saving model ...
Validation loss decreased (0.527254 --> 0.527106).  Saving model ...
Validation loss decreased (0.527106 --> 0.526959).  Saving model ...
Validation loss decreased (0.526959 --> 0.526812).  Saving model ...
Validation loss decreased (0.526812 --> 0.526665).  Saving model ...
Validation loss decreased (0.526665 --> 0.526519).  Saving model ...
Validation loss decreased (0.526519 --> 0.526373).  Saving model ...
Validation loss decreased (0.526373 --> 0.526228).  Saving model ...
Validation loss decreased (0.526228 --> 0.526083).  Saving model ...
Validation loss decreased (0.526083 --> 0.525938).  Saving model ...
Validation loss decreased (0.525938 --> 0.525794).  Saving model ...
Validation loss decreased (0.525794 --> 0.525650).  Saving model ...
Validation loss decreased (0.525650 --> 0.525506).  Saving model ...
Validation loss decreased (0.525506 --> 0.525363).  Saving model ...
Validation loss decreased (0.525363 --> 0.525220).  Saving model ...
Validation loss decreased (0.525220 --> 0.525078).  Saving model ...
Validation loss decreased (0.525078 --> 0.524936).  Saving model ...
Validation loss decreased (0.524936 --> 0.524794).  Saving model ...
Validation loss decreased (0.524794 --> 0.524653).  Saving model ...
Validation loss decreased (0.524653 --> 0.524512).  Saving model ...
Validation loss decreased (0.524512 --> 0.524372).  Saving model ...
Validation loss decreased (0.524372 --> 0.524232).  Saving model ...
Validation loss decreased (0.524232 --> 0.524092).  Saving model ...
Validation loss decreased (0.524092 --> 0.523953).  Saving model ...
Validation loss decreased (0.523953 --> 0.523814).  Saving model ...
Validation loss decreased (0.523814 --> 0.523675).  Saving model ...
Validation loss decreased (0.523675 --> 0.523537).  Saving model ...
Validation loss decreased (0.523537 --> 0.523399).  Saving model ...
Validation loss decreased (0.523399 --> 0.523261).  Saving model ...
Validation loss decreased (0.523261 --> 0.523124).  Saving model ...
Validation loss decreased (0.523124 --> 0.522988).  Saving model ...
Validation loss decreased (0.522988 --> 0.522851).  Saving model ...
Validation loss decreased (0.522851 --> 0.522715).  Saving model ...
Validation loss decreased (0.522715 --> 0.522580).  Saving model ...
Validation loss decreased (0.522580 --> 0.522444).  Saving model ...
Validation loss decreased (0.522444 --> 0.522310).  Saving model ...
Validation loss decreased (0.522310 --> 0.522175).  Saving model ...
Validation loss decreased (0.522175 --> 0.522041).  Saving model ...
Validation loss decreased (0.522041 --> 0.521907).  Saving model ...
Validation loss decreased (0.521907 --> 0.521774).  Saving model ...
Validation loss decreased (0.521774 --> 0.521641).  Saving model ...
Validation loss decreased (0.521641 --> 0.521508).  Saving model ...
Validation loss decreased (0.521508 --> 0.521376).  Saving model ...
Validation loss decreased (0.521376 --> 0.521244).  Saving model ...
Validation loss decreased (0.521244 --> 0.521112).  Saving model ...
Validation loss decreased (0.521112 --> 0.520981).  Saving model ...
Validation loss decreased (0.520981 --> 0.520850).  Saving model ...
Validation loss decreased (0.520850 --> 0.520720).  Saving model ...
Validation loss decreased (0.520720 --> 0.520589).  Saving model ...
Validation loss decreased (0.520589 --> 0.520460).  Saving model ...
Validation loss decreased (0.520460 --> 0.520330).  Saving model ...
Validation loss decreased (0.520330 --> 0.520201).  Saving model ...
Validation loss decreased (0.520201 --> 0.520072).  Saving model ...
Validation loss decreased (0.520072 --> 0.519944).  Saving model ...
Validation loss decreased (0.519944 --> 0.519816).  Saving model ...
Validation loss decreased (0.519816 --> 0.519688).  Saving model ...
Validation loss decreased (0.519688 --> 0.519561).  Saving model ...
Validation loss decreased (0.519561 --> 0.519434).  Saving model ...
Validation loss decreased (0.519434 --> 0.519307).  Saving model ...
Validation loss decreased (0.519307 --> 0.519181).  Saving model ...
Validation loss decreased (0.519181 --> 0.519055).  Saving model ...
Validation loss decreased (0.519055 --> 0.518930).  Saving model ...
Validation loss decreased (0.518930 --> 0.518804).  Saving model ...
Validation loss decreased (0.518804 --> 0.518680).  Saving model ...
Validation loss decreased (0.518680 --> 0.518555).  Saving model ...
Validation loss decreased (0.518555 --> 0.518431).  Saving model ...
Validation loss decreased (0.518431 --> 0.518307).  Saving model ...
Validation loss decreased (0.518307 --> 0.518184).  Saving model ...
Validation loss decreased (0.518184 --> 0.518061).  Saving model ...
Validation loss decreased (0.518061 --> 0.517938).  Saving model ...
Validation loss decreased (0.517938 --> 0.517815).  Saving model ...
epoch 601, loss 0.5178, train acc 74.70%, f1 0.4932, precision 0.8276, recall 0.3512, auc 0.6559
Validation loss decreased (0.517815 --> 0.517693).  Saving model ...
Validation loss decreased (0.517693 --> 0.517572).  Saving model ...
Validation loss decreased (0.517572 --> 0.517450).  Saving model ...
Validation loss decreased (0.517450 --> 0.517329).  Saving model ...
Validation loss decreased (0.517329 --> 0.517208).  Saving model ...
Validation loss decreased (0.517208 --> 0.517088).  Saving model ...
Validation loss decreased (0.517088 --> 0.516968).  Saving model ...
Validation loss decreased (0.516968 --> 0.516848).  Saving model ...
Validation loss decreased (0.516848 --> 0.516729).  Saving model ...
Validation loss decreased (0.516729 --> 0.516610).  Saving model ...
Validation loss decreased (0.516610 --> 0.516491).  Saving model ...
Validation loss decreased (0.516491 --> 0.516373).  Saving model ...
Validation loss decreased (0.516373 --> 0.516255).  Saving model ...
Validation loss decreased (0.516255 --> 0.516137).  Saving model ...
Validation loss decreased (0.516137 --> 0.516020).  Saving model ...
Validation loss decreased (0.516020 --> 0.515903).  Saving model ...
Validation loss decreased (0.515903 --> 0.515786).  Saving model ...
Validation loss decreased (0.515786 --> 0.515670).  Saving model ...
Validation loss decreased (0.515670 --> 0.515553).  Saving model ...
Validation loss decreased (0.515553 --> 0.515438).  Saving model ...
Validation loss decreased (0.515438 --> 0.515322).  Saving model ...
Validation loss decreased (0.515322 --> 0.515207).  Saving model ...
Validation loss decreased (0.515207 --> 0.515093).  Saving model ...
Validation loss decreased (0.515093 --> 0.514978).  Saving model ...
Validation loss decreased (0.514978 --> 0.514864).  Saving model ...
Validation loss decreased (0.514864 --> 0.514750).  Saving model ...
Validation loss decreased (0.514750 --> 0.514637).  Saving model ...
Validation loss decreased (0.514637 --> 0.514524).  Saving model ...
Validation loss decreased (0.514524 --> 0.514411).  Saving model ...
Validation loss decreased (0.514411 --> 0.514299).  Saving model ...
Validation loss decreased (0.514299 --> 0.514186).  Saving model ...
Validation loss decreased (0.514186 --> 0.514075).  Saving model ...
Validation loss decreased (0.514075 --> 0.513963).  Saving model ...
Validation loss decreased (0.513963 --> 0.513852).  Saving model ...
Validation loss decreased (0.513852 --> 0.513741).  Saving model ...
Validation loss decreased (0.513741 --> 0.513631).  Saving model ...
Validation loss decreased (0.513631 --> 0.513520).  Saving model ...
Validation loss decreased (0.513520 --> 0.513411).  Saving model ...
Validation loss decreased (0.513411 --> 0.513301).  Saving model ...
Validation loss decreased (0.513301 --> 0.513192).  Saving model ...
Validation loss decreased (0.513192 --> 0.513083).  Saving model ...
Validation loss decreased (0.513083 --> 0.512974).  Saving model ...
Validation loss decreased (0.512974 --> 0.512866).  Saving model ...
Validation loss decreased (0.512866 --> 0.512758).  Saving model ...
Validation loss decreased (0.512758 --> 0.512650).  Saving model ...
Validation loss decreased (0.512650 --> 0.512543).  Saving model ...
Validation loss decreased (0.512543 --> 0.512435).  Saving model ...
Validation loss decreased (0.512435 --> 0.512329).  Saving model ...
Validation loss decreased (0.512329 --> 0.512222).  Saving model ...
Validation loss decreased (0.512222 --> 0.512116).  Saving model ...
Validation loss decreased (0.512116 --> 0.512010).  Saving model ...
Validation loss decreased (0.512010 --> 0.511905).  Saving model ...
Validation loss decreased (0.511905 --> 0.511800).  Saving model ...
Validation loss decreased (0.511800 --> 0.511695).  Saving model ...
Validation loss decreased (0.511695 --> 0.511590).  Saving model ...
Validation loss decreased (0.511590 --> 0.511486).  Saving model ...
Validation loss decreased (0.511486 --> 0.511382).  Saving model ...
Validation loss decreased (0.511382 --> 0.511278).  Saving model ...
Validation loss decreased (0.511278 --> 0.511174).  Saving model ...
Validation loss decreased (0.511174 --> 0.511071).  Saving model ...
Validation loss decreased (0.511071 --> 0.510969).  Saving model ...
Validation loss decreased (0.510969 --> 0.510866).  Saving model ...
Validation loss decreased (0.510866 --> 0.510764).  Saving model ...
Validation loss decreased (0.510764 --> 0.510662).  Saving model ...
Validation loss decreased (0.510662 --> 0.510560).  Saving model ...
Validation loss decreased (0.510560 --> 0.510459).  Saving model ...
Validation loss decreased (0.510459 --> 0.510358).  Saving model ...
Validation loss decreased (0.510358 --> 0.510257).  Saving model ...
Validation loss decreased (0.510257 --> 0.510157).  Saving model ...
Validation loss decreased (0.510157 --> 0.510057).  Saving model ...
Validation loss decreased (0.510057 --> 0.509957).  Saving model ...
Validation loss decreased (0.509957 --> 0.509857).  Saving model ...
Validation loss decreased (0.509857 --> 0.509758).  Saving model ...
Validation loss decreased (0.509758 --> 0.509659).  Saving model ...
Validation loss decreased (0.509659 --> 0.509560).  Saving model ...
Validation loss decreased (0.509560 --> 0.509462).  Saving model ...
Validation loss decreased (0.509462 --> 0.509364).  Saving model ...
Validation loss decreased (0.509364 --> 0.509266).  Saving model ...
Validation loss decreased (0.509266 --> 0.509169).  Saving model ...
Validation loss decreased (0.509169 --> 0.509071).  Saving model ...
Validation loss decreased (0.509071 --> 0.508974).  Saving model ...
Validation loss decreased (0.508974 --> 0.508878).  Saving model ...
Validation loss decreased (0.508878 --> 0.508781).  Saving model ...
Validation loss decreased (0.508781 --> 0.508685).  Saving model ...
Validation loss decreased (0.508685 --> 0.508590).  Saving model ...
Validation loss decreased (0.508590 --> 0.508494).  Saving model ...
Validation loss decreased (0.508494 --> 0.508399).  Saving model ...
Validation loss decreased (0.508399 --> 0.508304).  Saving model ...
Validation loss decreased (0.508304 --> 0.508209).  Saving model ...
Validation loss decreased (0.508209 --> 0.508115).  Saving model ...
Validation loss decreased (0.508115 --> 0.508021).  Saving model ...
Validation loss decreased (0.508021 --> 0.507927).  Saving model ...
Validation loss decreased (0.507927 --> 0.507833).  Saving model ...
Validation loss decreased (0.507833 --> 0.507740).  Saving model ...
Validation loss decreased (0.507740 --> 0.507647).  Saving model ...
Validation loss decreased (0.507647 --> 0.507554).  Saving model ...
Validation loss decreased (0.507554 --> 0.507462).  Saving model ...
Validation loss decreased (0.507462 --> 0.507370).  Saving model ...
Validation loss decreased (0.507370 --> 0.507278).  Saving model ...
Validation loss decreased (0.507278 --> 0.507186).  Saving model ...
epoch 701, loss 0.5072, train acc 75.56%, f1 0.5545, precision 0.7672, recall 0.4341, auc 0.6815
Validation loss decreased (0.507186 --> 0.507095).  Saving model ...
Validation loss decreased (0.507095 --> 0.507004).  Saving model ...
Validation loss decreased (0.507004 --> 0.506913).  Saving model ...
Validation loss decreased (0.506913 --> 0.506822).  Saving model ...
Validation loss decreased (0.506822 --> 0.506732).  Saving model ...
Validation loss decreased (0.506732 --> 0.506642).  Saving model ...
Validation loss decreased (0.506642 --> 0.506552).  Saving model ...
Validation loss decreased (0.506552 --> 0.506463).  Saving model ...
Validation loss decreased (0.506463 --> 0.506374).  Saving model ...
Validation loss decreased (0.506374 --> 0.506285).  Saving model ...
Validation loss decreased (0.506285 --> 0.506196).  Saving model ...
Validation loss decreased (0.506196 --> 0.506108).  Saving model ...
Validation loss decreased (0.506108 --> 0.506020).  Saving model ...
Validation loss decreased (0.506020 --> 0.505932).  Saving model ...
Validation loss decreased (0.505932 --> 0.505844).  Saving model ...
Validation loss decreased (0.505844 --> 0.505757).  Saving model ...
Validation loss decreased (0.505757 --> 0.505670).  Saving model ...
Validation loss decreased (0.505670 --> 0.505583).  Saving model ...
Validation loss decreased (0.505583 --> 0.505496).  Saving model ...
Validation loss decreased (0.505496 --> 0.505410).  Saving model ...
Validation loss decreased (0.505410 --> 0.505324).  Saving model ...
Validation loss decreased (0.505324 --> 0.505238).  Saving model ...
Validation loss decreased (0.505238 --> 0.505153).  Saving model ...
Validation loss decreased (0.505153 --> 0.505067).  Saving model ...
Validation loss decreased (0.505067 --> 0.504982).  Saving model ...
Validation loss decreased (0.504982 --> 0.504898).  Saving model ...
Validation loss decreased (0.504898 --> 0.504813).  Saving model ...
Validation loss decreased (0.504813 --> 0.504729).  Saving model ...
Validation loss decreased (0.504729 --> 0.504645).  Saving model ...
Validation loss decreased (0.504645 --> 0.504561).  Saving model ...
Validation loss decreased (0.504561 --> 0.504478).  Saving model ...
Validation loss decreased (0.504478 --> 0.504394).  Saving model ...
Validation loss decreased (0.504394 --> 0.504312).  Saving model ...
Validation loss decreased (0.504312 --> 0.504229).  Saving model ...
Validation loss decreased (0.504229 --> 0.504146).  Saving model ...
Validation loss decreased (0.504146 --> 0.504064).  Saving model ...
Validation loss decreased (0.504064 --> 0.503982).  Saving model ...
Validation loss decreased (0.503982 --> 0.503900).  Saving model ...
Validation loss decreased (0.503900 --> 0.503819).  Saving model ...
Validation loss decreased (0.503819 --> 0.503738).  Saving model ...
Validation loss decreased (0.503738 --> 0.503657).  Saving model ...
Validation loss decreased (0.503657 --> 0.503576).  Saving model ...
Validation loss decreased (0.503576 --> 0.503495).  Saving model ...
Validation loss decreased (0.503495 --> 0.503415).  Saving model ...
Validation loss decreased (0.503415 --> 0.503335).  Saving model ...
Validation loss decreased (0.503335 --> 0.503255).  Saving model ...
Validation loss decreased (0.503255 --> 0.503176).  Saving model ...
Validation loss decreased (0.503176 --> 0.503096).  Saving model ...
Validation loss decreased (0.503096 --> 0.503017).  Saving model ...
Validation loss decreased (0.503017 --> 0.502938).  Saving model ...
Validation loss decreased (0.502938 --> 0.502860).  Saving model ...
Validation loss decreased (0.502860 --> 0.502782).  Saving model ...
Validation loss decreased (0.502782 --> 0.502703).  Saving model ...
Validation loss decreased (0.502703 --> 0.502626).  Saving model ...
Validation loss decreased (0.502626 --> 0.502548).  Saving model ...
Validation loss decreased (0.502548 --> 0.502471).  Saving model ...
Validation loss decreased (0.502471 --> 0.502393).  Saving model ...
Validation loss decreased (0.502393 --> 0.502316).  Saving model ...
Validation loss decreased (0.502316 --> 0.502240).  Saving model ...
Validation loss decreased (0.502240 --> 0.502163).  Saving model ...
Validation loss decreased (0.502163 --> 0.502087).  Saving model ...
Validation loss decreased (0.502087 --> 0.502011).  Saving model ...
Validation loss decreased (0.502011 --> 0.501935).  Saving model ...
Validation loss decreased (0.501935 --> 0.501860).  Saving model ...
Validation loss decreased (0.501860 --> 0.501784).  Saving model ...
Validation loss decreased (0.501784 --> 0.501709).  Saving model ...
Validation loss decreased (0.501709 --> 0.501634).  Saving model ...
Validation loss decreased (0.501634 --> 0.501560).  Saving model ...
Validation loss decreased (0.501560 --> 0.501485).  Saving model ...
Validation loss decreased (0.501485 --> 0.501411).  Saving model ...
Validation loss decreased (0.501411 --> 0.501337).  Saving model ...
Validation loss decreased (0.501337 --> 0.501264).  Saving model ...
Validation loss decreased (0.501264 --> 0.501190).  Saving model ...
Validation loss decreased (0.501190 --> 0.501117).  Saving model ...
Validation loss decreased (0.501117 --> 0.501044).  Saving model ...
Validation loss decreased (0.501044 --> 0.500971).  Saving model ...
Validation loss decreased (0.500971 --> 0.500898).  Saving model ...
Validation loss decreased (0.500898 --> 0.500826).  Saving model ...
Validation loss decreased (0.500826 --> 0.500754).  Saving model ...
Validation loss decreased (0.500754 --> 0.500682).  Saving model ...
Validation loss decreased (0.500682 --> 0.500610).  Saving model ...
Validation loss decreased (0.500610 --> 0.500539).  Saving model ...
Validation loss decreased (0.500539 --> 0.500467).  Saving model ...
Validation loss decreased (0.500467 --> 0.500396).  Saving model ...
Validation loss decreased (0.500396 --> 0.500325).  Saving model ...
Validation loss decreased (0.500325 --> 0.500255).  Saving model ...
Validation loss decreased (0.500255 --> 0.500184).  Saving model ...
Validation loss decreased (0.500184 --> 0.500114).  Saving model ...
Validation loss decreased (0.500114 --> 0.500044).  Saving model ...
Validation loss decreased (0.500044 --> 0.499974).  Saving model ...
Validation loss decreased (0.499974 --> 0.499905).  Saving model ...
Validation loss decreased (0.499905 --> 0.499835).  Saving model ...
Validation loss decreased (0.499835 --> 0.499766).  Saving model ...
Validation loss decreased (0.499766 --> 0.499697).  Saving model ...
Validation loss decreased (0.499697 --> 0.499628).  Saving model ...
Validation loss decreased (0.499628 --> 0.499560).  Saving model ...
Validation loss decreased (0.499560 --> 0.499491).  Saving model ...
Validation loss decreased (0.499491 --> 0.499423).  Saving model ...
Validation loss decreased (0.499423 --> 0.499355).  Saving model ...
Validation loss decreased (0.499355 --> 0.499288).  Saving model ...
epoch 801, loss 0.4993, train acc 75.90%, f1 0.5960, precision 0.7222, recall 0.5073, auc 0.7010
Validation loss decreased (0.499288 --> 0.499220).  Saving model ...
Validation loss decreased (0.499220 --> 0.499153).  Saving model ...
Validation loss decreased (0.499153 --> 0.499086).  Saving model ...
Validation loss decreased (0.499086 --> 0.499019).  Saving model ...
Validation loss decreased (0.499019 --> 0.498952).  Saving model ...
Validation loss decreased (0.498952 --> 0.498886).  Saving model ...
Validation loss decreased (0.498886 --> 0.498820).  Saving model ...
Validation loss decreased (0.498820 --> 0.498753).  Saving model ...
Validation loss decreased (0.498753 --> 0.498688).  Saving model ...
Validation loss decreased (0.498688 --> 0.498622).  Saving model ...
Validation loss decreased (0.498622 --> 0.498556).  Saving model ...
Validation loss decreased (0.498556 --> 0.498491).  Saving model ...
Validation loss decreased (0.498491 --> 0.498426).  Saving model ...
Validation loss decreased (0.498426 --> 0.498361).  Saving model ...
Validation loss decreased (0.498361 --> 0.498297).  Saving model ...
Validation loss decreased (0.498297 --> 0.498232).  Saving model ...
Validation loss decreased (0.498232 --> 0.498168).  Saving model ...
Validation loss decreased (0.498168 --> 0.498104).  Saving model ...
Validation loss decreased (0.498104 --> 0.498040).  Saving model ...
Validation loss decreased (0.498040 --> 0.497976).  Saving model ...
Validation loss decreased (0.497976 --> 0.497912).  Saving model ...
Validation loss decreased (0.497912 --> 0.497849).  Saving model ...
Validation loss decreased (0.497849 --> 0.497786).  Saving model ...
Validation loss decreased (0.497786 --> 0.497723).  Saving model ...
Validation loss decreased (0.497723 --> 0.497660).  Saving model ...
Validation loss decreased (0.497660 --> 0.497598).  Saving model ...
Validation loss decreased (0.497598 --> 0.497535).  Saving model ...
Validation loss decreased (0.497535 --> 0.497473).  Saving model ...
Validation loss decreased (0.497473 --> 0.497411).  Saving model ...
Validation loss decreased (0.497411 --> 0.497349).  Saving model ...
Validation loss decreased (0.497349 --> 0.497288).  Saving model ...
Validation loss decreased (0.497288 --> 0.497226).  Saving model ...
Validation loss decreased (0.497226 --> 0.497165).  Saving model ...
Validation loss decreased (0.497165 --> 0.497104).  Saving model ...
Validation loss decreased (0.497104 --> 0.497043).  Saving model ...
Validation loss decreased (0.497043 --> 0.496982).  Saving model ...
Validation loss decreased (0.496982 --> 0.496922).  Saving model ...
Validation loss decreased (0.496922 --> 0.496862).  Saving model ...
Validation loss decreased (0.496862 --> 0.496801).  Saving model ...
Validation loss decreased (0.496801 --> 0.496741).  Saving model ...
Validation loss decreased (0.496741 --> 0.496682).  Saving model ...
Validation loss decreased (0.496682 --> 0.496622).  Saving model ...
Validation loss decreased (0.496622 --> 0.496563).  Saving model ...
Validation loss decreased (0.496563 --> 0.496503).  Saving model ...
Validation loss decreased (0.496503 --> 0.496444).  Saving model ...
Validation loss decreased (0.496444 --> 0.496385).  Saving model ...
Validation loss decreased (0.496385 --> 0.496327).  Saving model ...
Validation loss decreased (0.496327 --> 0.496268).  Saving model ...
Validation loss decreased (0.496268 --> 0.496210).  Saving model ...
Validation loss decreased (0.496210 --> 0.496152).  Saving model ...
Validation loss decreased (0.496152 --> 0.496093).  Saving model ...
Validation loss decreased (0.496093 --> 0.496036).  Saving model ...
Validation loss decreased (0.496036 --> 0.495978).  Saving model ...
Validation loss decreased (0.495978 --> 0.495920).  Saving model ...
Validation loss decreased (0.495920 --> 0.495863).  Saving model ...
Validation loss decreased (0.495863 --> 0.495806).  Saving model ...
Validation loss decreased (0.495806 --> 0.495749).  Saving model ...
Validation loss decreased (0.495749 --> 0.495692).  Saving model ...
Validation loss decreased (0.495692 --> 0.495636).  Saving model ...
Validation loss decreased (0.495636 --> 0.495579).  Saving model ...
Validation loss decreased (0.495579 --> 0.495523).  Saving model ...
Validation loss decreased (0.495523 --> 0.495467).  Saving model ...
Validation loss decreased (0.495467 --> 0.495411).  Saving model ...
Validation loss decreased (0.495411 --> 0.495355).  Saving model ...
Validation loss decreased (0.495355 --> 0.495299).  Saving model ...
Validation loss decreased (0.495299 --> 0.495244).  Saving model ...
Validation loss decreased (0.495244 --> 0.495188).  Saving model ...
Validation loss decreased (0.495188 --> 0.495133).  Saving model ...
Validation loss decreased (0.495133 --> 0.495078).  Saving model ...
Validation loss decreased (0.495078 --> 0.495023).  Saving model ...
Validation loss decreased (0.495023 --> 0.494969).  Saving model ...
Validation loss decreased (0.494969 --> 0.494914).  Saving model ...
Validation loss decreased (0.494914 --> 0.494860).  Saving model ...
Validation loss decreased (0.494860 --> 0.494806).  Saving model ...
Validation loss decreased (0.494806 --> 0.494752).  Saving model ...
Validation loss decreased (0.494752 --> 0.494698).  Saving model ...
Validation loss decreased (0.494698 --> 0.494644).  Saving model ...
Validation loss decreased (0.494644 --> 0.494590).  Saving model ...
Validation loss decreased (0.494590 --> 0.494537).  Saving model ...
Validation loss decreased (0.494537 --> 0.494484).  Saving model ...
Validation loss decreased (0.494484 --> 0.494431).  Saving model ...
Validation loss decreased (0.494431 --> 0.494378).  Saving model ...
Validation loss decreased (0.494378 --> 0.494325).  Saving model ...
Validation loss decreased (0.494325 --> 0.494272).  Saving model ...
Validation loss decreased (0.494272 --> 0.494220).  Saving model ...
Validation loss decreased (0.494220 --> 0.494167).  Saving model ...
Validation loss decreased (0.494167 --> 0.494115).  Saving model ...
Validation loss decreased (0.494115 --> 0.494063).  Saving model ...
Validation loss decreased (0.494063 --> 0.494011).  Saving model ...
Validation loss decreased (0.494011 --> 0.493960).  Saving model ...
Validation loss decreased (0.493960 --> 0.493908).  Saving model ...
Validation loss decreased (0.493908 --> 0.493857).  Saving model ...
Validation loss decreased (0.493857 --> 0.493806).  Saving model ...
Validation loss decreased (0.493806 --> 0.493754).  Saving model ...
Validation loss decreased (0.493754 --> 0.493703).  Saving model ...
Validation loss decreased (0.493703 --> 0.493653).  Saving model ...
Validation loss decreased (0.493653 --> 0.493602).  Saving model ...
Validation loss decreased (0.493602 --> 0.493551).  Saving model ...
Validation loss decreased (0.493551 --> 0.493501).  Saving model ...
Validation loss decreased (0.493501 --> 0.493451).  Saving model ...
epoch 901, loss 0.4935, train acc 76.41%, f1 0.6188, precision 0.7134, recall 0.5463, auc 0.7140
Validation loss decreased (0.493451 --> 0.493401).  Saving model ...
Validation loss decreased (0.493401 --> 0.493351).  Saving model ...
Validation loss decreased (0.493351 --> 0.493301).  Saving model ...
Validation loss decreased (0.493301 --> 0.493251).  Saving model ...
Validation loss decreased (0.493251 --> 0.493202).  Saving model ...
Validation loss decreased (0.493202 --> 0.493152).  Saving model ...
Validation loss decreased (0.493152 --> 0.493103).  Saving model ...
Validation loss decreased (0.493103 --> 0.493054).  Saving model ...
Validation loss decreased (0.493054 --> 0.493005).  Saving model ...
Validation loss decreased (0.493005 --> 0.492956).  Saving model ...
Validation loss decreased (0.492956 --> 0.492907).  Saving model ...
Validation loss decreased (0.492907 --> 0.492859).  Saving model ...
Validation loss decreased (0.492859 --> 0.492810).  Saving model ...
Validation loss decreased (0.492810 --> 0.492762).  Saving model ...
Validation loss decreased (0.492762 --> 0.492714).  Saving model ...
Validation loss decreased (0.492714 --> 0.492666).  Saving model ...
Validation loss decreased (0.492666 --> 0.492618).  Saving model ...
Validation loss decreased (0.492618 --> 0.492570).  Saving model ...
Validation loss decreased (0.492570 --> 0.492523).  Saving model ...
Validation loss decreased (0.492523 --> 0.492475).  Saving model ...
Validation loss decreased (0.492475 --> 0.492428).  Saving model ...
Validation loss decreased (0.492428 --> 0.492381).  Saving model ...
Validation loss decreased (0.492381 --> 0.492334).  Saving model ...
Validation loss decreased (0.492334 --> 0.492287).  Saving model ...
Validation loss decreased (0.492287 --> 0.492240).  Saving model ...
Validation loss decreased (0.492240 --> 0.492193).  Saving model ...
Validation loss decreased (0.492193 --> 0.492147).  Saving model ...
Validation loss decreased (0.492147 --> 0.492100).  Saving model ...
Validation loss decreased (0.492100 --> 0.492054).  Saving model ...
Validation loss decreased (0.492054 --> 0.492008).  Saving model ...
Validation loss decreased (0.492008 --> 0.491962).  Saving model ...
Validation loss decreased (0.491962 --> 0.491916).  Saving model ...
Validation loss decreased (0.491916 --> 0.491870).  Saving model ...
Validation loss decreased (0.491870 --> 0.491824).  Saving model ...
Validation loss decreased (0.491824 --> 0.491779).  Saving model ...
Validation loss decreased (0.491779 --> 0.491733).  Saving model ...
Validation loss decreased (0.491733 --> 0.491688).  Saving model ...
Validation loss decreased (0.491688 --> 0.491643).  Saving model ...
Validation loss decreased (0.491643 --> 0.491598).  Saving model ...
Validation loss decreased (0.491598 --> 0.491553).  Saving model ...
Validation loss decreased (0.491553 --> 0.491508).  Saving model ...
Validation loss decreased (0.491508 --> 0.491463).  Saving model ...
Validation loss decreased (0.491463 --> 0.491419).  Saving model ...
Validation loss decreased (0.491419 --> 0.491374).  Saving model ...
Validation loss decreased (0.491374 --> 0.491330).  Saving model ...
Validation loss decreased (0.491330 --> 0.491285).  Saving model ...
Validation loss decreased (0.491285 --> 0.491241).  Saving model ...
Validation loss decreased (0.491241 --> 0.491197).  Saving model ...
Validation loss decreased (0.491197 --> 0.491153).  Saving model ...
Validation loss decreased (0.491153 --> 0.491110).  Saving model ...
Validation loss decreased (0.491110 --> 0.491066).  Saving model ...
Validation loss decreased (0.491066 --> 0.491022).  Saving model ...
Validation loss decreased (0.491022 --> 0.490979).  Saving model ...
Validation loss decreased (0.490979 --> 0.490936).  Saving model ...
Validation loss decreased (0.490936 --> 0.490892).  Saving model ...
Validation loss decreased (0.490892 --> 0.490849).  Saving model ...
Validation loss decreased (0.490849 --> 0.490806).  Saving model ...
Validation loss decreased (0.490806 --> 0.490763).  Saving model ...
Validation loss decreased (0.490763 --> 0.490721).  Saving model ...
Validation loss decreased (0.490721 --> 0.490678).  Saving model ...
Validation loss decreased (0.490678 --> 0.490635).  Saving model ...
Validation loss decreased (0.490635 --> 0.490593).  Saving model ...
Validation loss decreased (0.490593 --> 0.490551).  Saving model ...
Validation loss decreased (0.490551 --> 0.490508).  Saving model ...
Validation loss decreased (0.490508 --> 0.490466).  Saving model ...
Validation loss decreased (0.490466 --> 0.490424).  Saving model ...
Validation loss decreased (0.490424 --> 0.490382).  Saving model ...
Validation loss decreased (0.490382 --> 0.490340).  Saving model ...
Validation loss decreased (0.490340 --> 0.490299).  Saving model ...
Validation loss decreased (0.490299 --> 0.490257).  Saving model ...
Validation loss decreased (0.490257 --> 0.490215).  Saving model ...
Validation loss decreased (0.490215 --> 0.490174).  Saving model ...
Validation loss decreased (0.490174 --> 0.490133).  Saving model ...
Validation loss decreased (0.490133 --> 0.490091).  Saving model ...
Validation loss decreased (0.490091 --> 0.490050).  Saving model ...
Validation loss decreased (0.490050 --> 0.490009).  Saving model ...
Validation loss decreased (0.490009 --> 0.489968).  Saving model ...
Validation loss decreased (0.489968 --> 0.489927).  Saving model ...
Validation loss decreased (0.489927 --> 0.489887).  Saving model ...
Validation loss decreased (0.489887 --> 0.489846).  Saving model ...
Validation loss decreased (0.489846 --> 0.489806).  Saving model ...
Validation loss decreased (0.489806 --> 0.489765).  Saving model ...
Validation loss decreased (0.489765 --> 0.489725).  Saving model ...
Validation loss decreased (0.489725 --> 0.489684).  Saving model ...
Validation loss decreased (0.489684 --> 0.489644).  Saving model ...
Validation loss decreased (0.489644 --> 0.489604).  Saving model ...
Validation loss decreased (0.489604 --> 0.489564).  Saving model ...
Validation loss decreased (0.489564 --> 0.489524).  Saving model ...
Validation loss decreased (0.489524 --> 0.489484).  Saving model ...
Validation loss decreased (0.489484 --> 0.489445).  Saving model ...
Validation loss decreased (0.489445 --> 0.489405).  Saving model ...
Validation loss decreased (0.489405 --> 0.489365).  Saving model ...
Validation loss decreased (0.489365 --> 0.489326).  Saving model ...
Validation loss decreased (0.489326 --> 0.489287).  Saving model ...
Validation loss decreased (0.489287 --> 0.489247).  Saving model ...
Validation loss decreased (0.489247 --> 0.489208).  Saving model ...
Validation loss decreased (0.489208 --> 0.489169).  Saving model ...
Validation loss decreased (0.489169 --> 0.489130).  Saving model ...
Validation loss decreased (0.489130 --> 0.489091).  Saving model ...
Validation loss decreased (0.489091 --> 0.489052).  Saving model ...
epoch 1001, loss 0.4891, train acc 76.75%, f1 0.6304, precision 0.7117, recall 0.5659, auc 0.7211
Validation loss decreased (0.489052 --> 0.489013).  Saving model ...
Validation loss decreased (0.489013 --> 0.488974).  Saving model ...
Validation loss decreased (0.488974 --> 0.488936).  Saving model ...
Validation loss decreased (0.488936 --> 0.488897).  Saving model ...
Validation loss decreased (0.488897 --> 0.488859).  Saving model ...
Validation loss decreased (0.488859 --> 0.488820).  Saving model ...
Validation loss decreased (0.488820 --> 0.488782).  Saving model ...
Validation loss decreased (0.488782 --> 0.488744).  Saving model ...
Validation loss decreased (0.488744 --> 0.488706).  Saving model ...
Validation loss decreased (0.488706 --> 0.488667).  Saving model ...
Validation loss decreased (0.488667 --> 0.488629).  Saving model ...
Validation loss decreased (0.488629 --> 0.488591).  Saving model ...
Validation loss decreased (0.488591 --> 0.488553).  Saving model ...
Validation loss decreased (0.488553 --> 0.488516).  Saving model ...
Validation loss decreased (0.488516 --> 0.488478).  Saving model ...
Validation loss decreased (0.488478 --> 0.488440).  Saving model ...
Validation loss decreased (0.488440 --> 0.488402).  Saving model ...
Validation loss decreased (0.488402 --> 0.488365).  Saving model ...
Validation loss decreased (0.488365 --> 0.488327).  Saving model ...
Validation loss decreased (0.488327 --> 0.488290).  Saving model ...
Validation loss decreased (0.488290 --> 0.488253).  Saving model ...
Validation loss decreased (0.488253 --> 0.488215).  Saving model ...
Validation loss decreased (0.488215 --> 0.488178).  Saving model ...
Validation loss decreased (0.488178 --> 0.488141).  Saving model ...
Validation loss decreased (0.488141 --> 0.488104).  Saving model ...
Validation loss decreased (0.488104 --> 0.488067).  Saving model ...
Validation loss decreased (0.488067 --> 0.488030).  Saving model ...
Validation loss decreased (0.488030 --> 0.487993).  Saving model ...
Validation loss decreased (0.487993 --> 0.487956).  Saving model ...
Validation loss decreased (0.487956 --> 0.487919).  Saving model ...
Validation loss decreased (0.487919 --> 0.487882).  Saving model ...
Validation loss decreased (0.487882 --> 0.487846).  Saving model ...
Validation loss decreased (0.487846 --> 0.487809).  Saving model ...
Validation loss decreased (0.487809 --> 0.487772).  Saving model ...
Validation loss decreased (0.487772 --> 0.487736).  Saving model ...
Validation loss decreased (0.487736 --> 0.487699).  Saving model ...
Validation loss decreased (0.487699 --> 0.487663).  Saving model ...
Validation loss decreased (0.487663 --> 0.487626).  Saving model ...
Validation loss decreased (0.487626 --> 0.487590).  Saving model ...
Validation loss decreased (0.487590 --> 0.487554).  Saving model ...
Validation loss decreased (0.487554 --> 0.487518).  Saving model ...
Validation loss decreased (0.487518 --> 0.487481).  Saving model ...
Validation loss decreased (0.487481 --> 0.487445).  Saving model ...
Validation loss decreased (0.487445 --> 0.487409).  Saving model ...
Validation loss decreased (0.487409 --> 0.487373).  Saving model ...
Validation loss decreased (0.487373 --> 0.487337).  Saving model ...
Validation loss decreased (0.487337 --> 0.487301).  Saving model ...
Validation loss decreased (0.487301 --> 0.487265).  Saving model ...
Validation loss decreased (0.487265 --> 0.487229).  Saving model ...
Validation loss decreased (0.487229 --> 0.487193).  Saving model ...
Validation loss decreased (0.487193 --> 0.487157).  Saving model ...
Validation loss decreased (0.487157 --> 0.487122).  Saving model ...
Validation loss decreased (0.487122 --> 0.487086).  Saving model ...
Validation loss decreased (0.487086 --> 0.487050).  Saving model ...
Validation loss decreased (0.487050 --> 0.487014).  Saving model ...
Validation loss decreased (0.487014 --> 0.486979).  Saving model ...
Validation loss decreased (0.486979 --> 0.486943).  Saving model ...
Validation loss decreased (0.486943 --> 0.486907).  Saving model ...
Validation loss decreased (0.486907 --> 0.486872).  Saving model ...
Validation loss decreased (0.486872 --> 0.486836).  Saving model ...
Validation loss decreased (0.486836 --> 0.486801).  Saving model ...
Validation loss decreased (0.486801 --> 0.486765).  Saving model ...
Validation loss decreased (0.486765 --> 0.486730).  Saving model ...
Validation loss decreased (0.486730 --> 0.486694).  Saving model ...
Validation loss decreased (0.486694 --> 0.486659).  Saving model ...
Validation loss decreased (0.486659 --> 0.486623).  Saving model ...
Validation loss decreased (0.486623 --> 0.486588).  Saving model ...
Validation loss decreased (0.486588 --> 0.486553).  Saving model ...
Validation loss decreased (0.486553 --> 0.486517).  Saving model ...
Validation loss decreased (0.486517 --> 0.486482).  Saving model ...
Validation loss decreased (0.486482 --> 0.486447).  Saving model ...
Validation loss decreased (0.486447 --> 0.486411).  Saving model ...
Validation loss decreased (0.486411 --> 0.486376).  Saving model ...
Validation loss decreased (0.486376 --> 0.486341).  Saving model ...
Validation loss decreased (0.486341 --> 0.486305).  Saving model ...
Validation loss decreased (0.486305 --> 0.486270).  Saving model ...
Validation loss decreased (0.486270 --> 0.486235).  Saving model ...
Validation loss decreased (0.486235 --> 0.486200).  Saving model ...
Validation loss decreased (0.486200 --> 0.486164).  Saving model ...
Validation loss decreased (0.486164 --> 0.486129).  Saving model ...
Validation loss decreased (0.486129 --> 0.486094).  Saving model ...
Validation loss decreased (0.486094 --> 0.486059).  Saving model ...
Validation loss decreased (0.486059 --> 0.486024).  Saving model ...
Validation loss decreased (0.486024 --> 0.485988).  Saving model ...
Validation loss decreased (0.485988 --> 0.485953).  Saving model ...
Validation loss decreased (0.485953 --> 0.485918).  Saving model ...
Validation loss decreased (0.485918 --> 0.485883).  Saving model ...
Validation loss decreased (0.485883 --> 0.485847).  Saving model ...
Validation loss decreased (0.485847 --> 0.485812).  Saving model ...
Validation loss decreased (0.485812 --> 0.485777).  Saving model ...
Validation loss decreased (0.485777 --> 0.485742).  Saving model ...
Validation loss decreased (0.485742 --> 0.485706).  Saving model ...
Validation loss decreased (0.485706 --> 0.485671).  Saving model ...
Validation loss decreased (0.485671 --> 0.485636).  Saving model ...
Validation loss decreased (0.485636 --> 0.485600).  Saving model ...
Validation loss decreased (0.485600 --> 0.485565).  Saving model ...
Validation loss decreased (0.485565 --> 0.485530).  Saving model ...
Validation loss decreased (0.485530 --> 0.485494).  Saving model ...
Validation loss decreased (0.485494 --> 0.485459).  Saving model ...
Validation loss decreased (0.485459 --> 0.485424).  Saving model ...
epoch 1101, loss 0.4854, train acc 77.26%, f1 0.6434, precision 0.7143, recall 0.5854, auc 0.7295
Validation loss decreased (0.485424 --> 0.485388).  Saving model ...
Validation loss decreased (0.485388 --> 0.485353).  Saving model ...
Validation loss decreased (0.485353 --> 0.485317).  Saving model ...
Validation loss decreased (0.485317 --> 0.485282).  Saving model ...
Validation loss decreased (0.485282 --> 0.485246).  Saving model ...
Validation loss decreased (0.485246 --> 0.485211).  Saving model ...
Validation loss decreased (0.485211 --> 0.485175).  Saving model ...
Validation loss decreased (0.485175 --> 0.485140).  Saving model ...
Validation loss decreased (0.485140 --> 0.485104).  Saving model ...
Validation loss decreased (0.485104 --> 0.485068).  Saving model ...
Validation loss decreased (0.485068 --> 0.485032).  Saving model ...
Validation loss decreased (0.485032 --> 0.484997).  Saving model ...
Validation loss decreased (0.484997 --> 0.484961).  Saving model ...
Validation loss decreased (0.484961 --> 0.484925).  Saving model ...
Validation loss decreased (0.484925 --> 0.484889).  Saving model ...
Validation loss decreased (0.484889 --> 0.484854).  Saving model ...
Validation loss decreased (0.484854 --> 0.484818).  Saving model ...
Validation loss decreased (0.484818 --> 0.484782).  Saving model ...
Validation loss decreased (0.484782 --> 0.484746).  Saving model ...
Validation loss decreased (0.484746 --> 0.484710).  Saving model ...
Validation loss decreased (0.484710 --> 0.484674).  Saving model ...
Validation loss decreased (0.484674 --> 0.484637).  Saving model ...
Validation loss decreased (0.484637 --> 0.484601).  Saving model ...
Validation loss decreased (0.484601 --> 0.484565).  Saving model ...
Validation loss decreased (0.484565 --> 0.484529).  Saving model ...
Validation loss decreased (0.484529 --> 0.484492).  Saving model ...
Validation loss decreased (0.484492 --> 0.484456).  Saving model ...
Validation loss decreased (0.484456 --> 0.484420).  Saving model ...
Validation loss decreased (0.484420 --> 0.484383).  Saving model ...
Validation loss decreased (0.484383 --> 0.484347).  Saving model ...
Validation loss decreased (0.484347 --> 0.484310).  Saving model ...
Validation loss decreased (0.484310 --> 0.484273).  Saving model ...
Validation loss decreased (0.484273 --> 0.484237).  Saving model ...
Validation loss decreased (0.484237 --> 0.484200).  Saving model ...
Validation loss decreased (0.484200 --> 0.484163).  Saving model ...
Validation loss decreased (0.484163 --> 0.484126).  Saving model ...
Validation loss decreased (0.484126 --> 0.484089).  Saving model ...
Validation loss decreased (0.484089 --> 0.484053).  Saving model ...
Validation loss decreased (0.484053 --> 0.484015).  Saving model ...
Validation loss decreased (0.484015 --> 0.483978).  Saving model ...
Validation loss decreased (0.483978 --> 0.483941).  Saving model ...
Validation loss decreased (0.483941 --> 0.483904).  Saving model ...
Validation loss decreased (0.483904 --> 0.483867).  Saving model ...
Validation loss decreased (0.483867 --> 0.483829).  Saving model ...
Validation loss decreased (0.483829 --> 0.483792).  Saving model ...
Validation loss decreased (0.483792 --> 0.483754).  Saving model ...
Validation loss decreased (0.483754 --> 0.483717).  Saving model ...
Validation loss decreased (0.483717 --> 0.483679).  Saving model ...
Validation loss decreased (0.483679 --> 0.483642).  Saving model ...
Validation loss decreased (0.483642 --> 0.483604).  Saving model ...
Validation loss decreased (0.483604 --> 0.483566).  Saving model ...
Validation loss decreased (0.483566 --> 0.483528).  Saving model ...
Validation loss decreased (0.483528 --> 0.483490).  Saving model ...
Validation loss decreased (0.483490 --> 0.483452).  Saving model ...
Validation loss decreased (0.483452 --> 0.483414).  Saving model ...
Validation loss decreased (0.483414 --> 0.483376).  Saving model ...
Validation loss decreased (0.483376 --> 0.483338).  Saving model ...
Validation loss decreased (0.483338 --> 0.483299).  Saving model ...
Validation loss decreased (0.483299 --> 0.483261).  Saving model ...
Validation loss decreased (0.483261 --> 0.483222).  Saving model ...
Validation loss decreased (0.483222 --> 0.483184).  Saving model ...
Validation loss decreased (0.483184 --> 0.483145).  Saving model ...
Validation loss decreased (0.483145 --> 0.483107).  Saving model ...
Validation loss decreased (0.483107 --> 0.483068).  Saving model ...
Validation loss decreased (0.483068 --> 0.483029).  Saving model ...
Validation loss decreased (0.483029 --> 0.482990).  Saving model ...
Validation loss decreased (0.482990 --> 0.482951).  Saving model ...
Validation loss decreased (0.482951 --> 0.482912).  Saving model ...
Validation loss decreased (0.482912 --> 0.482873).  Saving model ...
Validation loss decreased (0.482873 --> 0.482834).  Saving model ...
Validation loss decreased (0.482834 --> 0.482794).  Saving model ...
Validation loss decreased (0.482794 --> 0.482755).  Saving model ...
Validation loss decreased (0.482755 --> 0.482716).  Saving model ...
Validation loss decreased (0.482716 --> 0.482676).  Saving model ...
Validation loss decreased (0.482676 --> 0.482637).  Saving model ...
Validation loss decreased (0.482637 --> 0.482597).  Saving model ...
Validation loss decreased (0.482597 --> 0.482557).  Saving model ...
Validation loss decreased (0.482557 --> 0.482518).  Saving model ...
Validation loss decreased (0.482518 --> 0.482478).  Saving model ...
Validation loss decreased (0.482478 --> 0.482438).  Saving model ...
Validation loss decreased (0.482438 --> 0.482398).  Saving model ...
Validation loss decreased (0.482398 --> 0.482358).  Saving model ...
Validation loss decreased (0.482358 --> 0.482317).  Saving model ...
Validation loss decreased (0.482317 --> 0.482277).  Saving model ...
Validation loss decreased (0.482277 --> 0.482237).  Saving model ...
Validation loss decreased (0.482237 --> 0.482196).  Saving model ...
Validation loss decreased (0.482196 --> 0.482156).  Saving model ...
Validation loss decreased (0.482156 --> 0.482115).  Saving model ...
Validation loss decreased (0.482115 --> 0.482075).  Saving model ...
Validation loss decreased (0.482075 --> 0.482034).  Saving model ...
Validation loss decreased (0.482034 --> 0.481993).  Saving model ...
Validation loss decreased (0.481993 --> 0.481952).  Saving model ...
Validation loss decreased (0.481952 --> 0.481911).  Saving model ...
Validation loss decreased (0.481911 --> 0.481870).  Saving model ...
Validation loss decreased (0.481870 --> 0.481829).  Saving model ...
Validation loss decreased (0.481829 --> 0.481788).  Saving model ...
Validation loss decreased (0.481788 --> 0.481747).  Saving model ...
Validation loss decreased (0.481747 --> 0.481706).  Saving model ...
Validation loss decreased (0.481706 --> 0.481664).  Saving model ...
Validation loss decreased (0.481664 --> 0.481623).  Saving model ...
epoch 1201, loss 0.4816, train acc 77.78%, f1 0.6561, precision 0.7168, recall 0.6049, auc 0.7380
Validation loss decreased (0.481623 --> 0.481581).  Saving model ...
Validation loss decreased (0.481581 --> 0.481540).  Saving model ...
Validation loss decreased (0.481540 --> 0.481498).  Saving model ...
Validation loss decreased (0.481498 --> 0.481456).  Saving model ...
Validation loss decreased (0.481456 --> 0.481414).  Saving model ...
Validation loss decreased (0.481414 --> 0.481372).  Saving model ...
Validation loss decreased (0.481372 --> 0.481330).  Saving model ...
Validation loss decreased (0.481330 --> 0.481288).  Saving model ...
Validation loss decreased (0.481288 --> 0.481246).  Saving model ...
Validation loss decreased (0.481246 --> 0.481204).  Saving model ...
Validation loss decreased (0.481204 --> 0.481162).  Saving model ...
Validation loss decreased (0.481162 --> 0.481119).  Saving model ...
Validation loss decreased (0.481119 --> 0.481077).  Saving model ...
Validation loss decreased (0.481077 --> 0.481035).  Saving model ...
Validation loss decreased (0.481035 --> 0.480992).  Saving model ...
Validation loss decreased (0.480992 --> 0.480949).  Saving model ...
Validation loss decreased (0.480949 --> 0.480907).  Saving model ...
Validation loss decreased (0.480907 --> 0.480864).  Saving model ...
Validation loss decreased (0.480864 --> 0.480821).  Saving model ...
Validation loss decreased (0.480821 --> 0.480778).  Saving model ...
Validation loss decreased (0.480778 --> 0.480735).  Saving model ...
Validation loss decreased (0.480735 --> 0.480692).  Saving model ...
Validation loss decreased (0.480692 --> 0.480649).  Saving model ...
Validation loss decreased (0.480649 --> 0.480606).  Saving model ...
Validation loss decreased (0.480606 --> 0.480563).  Saving model ...
Validation loss decreased (0.480563 --> 0.480519).  Saving model ...
Validation loss decreased (0.480519 --> 0.480476).  Saving model ...
Validation loss decreased (0.480476 --> 0.480432).  Saving model ...
Validation loss decreased (0.480432 --> 0.480389).  Saving model ...
Validation loss decreased (0.480389 --> 0.480345).  Saving model ...
Validation loss decreased (0.480345 --> 0.480302).  Saving model ...
Validation loss decreased (0.480302 --> 0.480258).  Saving model ...
Validation loss decreased (0.480258 --> 0.480214).  Saving model ...
Validation loss decreased (0.480214 --> 0.480170).  Saving model ...
Validation loss decreased (0.480170 --> 0.480126).  Saving model ...
Validation loss decreased (0.480126 --> 0.480082).  Saving model ...
Validation loss decreased (0.480082 --> 0.480038).  Saving model ...
Validation loss decreased (0.480038 --> 0.479994).  Saving model ...
Validation loss decreased (0.479994 --> 0.479950).  Saving model ...
Validation loss decreased (0.479950 --> 0.479906).  Saving model ...
Validation loss decreased (0.479906 --> 0.479861).  Saving model ...
Validation loss decreased (0.479861 --> 0.479817).  Saving model ...
Validation loss decreased (0.479817 --> 0.479772).  Saving model ...
Validation loss decreased (0.479772 --> 0.479728).  Saving model ...
Validation loss decreased (0.479728 --> 0.479683).  Saving model ...
Validation loss decreased (0.479683 --> 0.479639).  Saving model ...
Validation loss decreased (0.479639 --> 0.479594).  Saving model ...
Validation loss decreased (0.479594 --> 0.479549).  Saving model ...
Validation loss decreased (0.479549 --> 0.479504).  Saving model ...
Validation loss decreased (0.479504 --> 0.479459).  Saving model ...
Validation loss decreased (0.479459 --> 0.479414).  Saving model ...
Validation loss decreased (0.479414 --> 0.479369).  Saving model ...
Validation loss decreased (0.479369 --> 0.479324).  Saving model ...
Validation loss decreased (0.479324 --> 0.479279).  Saving model ...
Validation loss decreased (0.479279 --> 0.479234).  Saving model ...
Validation loss decreased (0.479234 --> 0.479188).  Saving model ...
Validation loss decreased (0.479188 --> 0.479143).  Saving model ...
Validation loss decreased (0.479143 --> 0.479098).  Saving model ...
Validation loss decreased (0.479098 --> 0.479052).  Saving model ...
Validation loss decreased (0.479052 --> 0.479007).  Saving model ...
Validation loss decreased (0.479007 --> 0.478961).  Saving model ...
Validation loss decreased (0.478961 --> 0.478915).  Saving model ...
Validation loss decreased (0.478915 --> 0.478870).  Saving model ...
Validation loss decreased (0.478870 --> 0.478824).  Saving model ...
Validation loss decreased (0.478824 --> 0.478778).  Saving model ...
Validation loss decreased (0.478778 --> 0.478732).  Saving model ...
Validation loss decreased (0.478732 --> 0.478686).  Saving model ...
Validation loss decreased (0.478686 --> 0.478640).  Saving model ...
Validation loss decreased (0.478640 --> 0.478594).  Saving model ...
Validation loss decreased (0.478594 --> 0.478548).  Saving model ...
Validation loss decreased (0.478548 --> 0.478502).  Saving model ...
Validation loss decreased (0.478502 --> 0.478456).  Saving model ...
Validation loss decreased (0.478456 --> 0.478409).  Saving model ...
Validation loss decreased (0.478409 --> 0.478363).  Saving model ...
Validation loss decreased (0.478363 --> 0.478316).  Saving model ...
Validation loss decreased (0.478316 --> 0.478270).  Saving model ...
Validation loss decreased (0.478270 --> 0.478223).  Saving model ...
Validation loss decreased (0.478223 --> 0.478177).  Saving model ...
Validation loss decreased (0.478177 --> 0.478130).  Saving model ...
Validation loss decreased (0.478130 --> 0.478084).  Saving model ...
Validation loss decreased (0.478084 --> 0.478037).  Saving model ...
Validation loss decreased (0.478037 --> 0.477990).  Saving model ...
Validation loss decreased (0.477990 --> 0.477943).  Saving model ...
Validation loss decreased (0.477943 --> 0.477896).  Saving model ...
Validation loss decreased (0.477896 --> 0.477849).  Saving model ...
Validation loss decreased (0.477849 --> 0.477802).  Saving model ...
Validation loss decreased (0.477802 --> 0.477755).  Saving model ...
Validation loss decreased (0.477755 --> 0.477708).  Saving model ...
Validation loss decreased (0.477708 --> 0.477661).  Saving model ...
Validation loss decreased (0.477661 --> 0.477614).  Saving model ...
Validation loss decreased (0.477614 --> 0.477566).  Saving model ...
Validation loss decreased (0.477566 --> 0.477519).  Saving model ...
Validation loss decreased (0.477519 --> 0.477472).  Saving model ...
Validation loss decreased (0.477472 --> 0.477424).  Saving model ...
Validation loss decreased (0.477424 --> 0.477377).  Saving model ...
Validation loss decreased (0.477377 --> 0.477329).  Saving model ...
Validation loss decreased (0.477329 --> 0.477282).  Saving model ...
Validation loss decreased (0.477282 --> 0.477234).  Saving model ...
Validation loss decreased (0.477234 --> 0.477186).  Saving model ...
Validation loss decreased (0.477186 --> 0.477139).  Saving model ...
epoch 1301, loss 0.4771, train acc 78.12%, f1 0.6596, precision 0.7251, recall 0.6049, auc 0.7406
Validation loss decreased (0.477139 --> 0.477091).  Saving model ...
Validation loss decreased (0.477091 --> 0.477043).  Saving model ...
Validation loss decreased (0.477043 --> 0.476995).  Saving model ...
Validation loss decreased (0.476995 --> 0.476947).  Saving model ...
Validation loss decreased (0.476947 --> 0.476899).  Saving model ...
Validation loss decreased (0.476899 --> 0.476851).  Saving model ...
Validation loss decreased (0.476851 --> 0.476803).  Saving model ...
Validation loss decreased (0.476803 --> 0.476755).  Saving model ...
Validation loss decreased (0.476755 --> 0.476707).  Saving model ...
Validation loss decreased (0.476707 --> 0.476659).  Saving model ...
Validation loss decreased (0.476659 --> 0.476611).  Saving model ...
Validation loss decreased (0.476611 --> 0.476563).  Saving model ...
Validation loss decreased (0.476563 --> 0.476514).  Saving model ...
Validation loss decreased (0.476514 --> 0.476466).  Saving model ...
Validation loss decreased (0.476466 --> 0.476418).  Saving model ...
Validation loss decreased (0.476418 --> 0.476369).  Saving model ...
Validation loss decreased (0.476369 --> 0.476321).  Saving model ...
Validation loss decreased (0.476321 --> 0.476272).  Saving model ...
Validation loss decreased (0.476272 --> 0.476224).  Saving model ...
Validation loss decreased (0.476224 --> 0.476175).  Saving model ...
Validation loss decreased (0.476175 --> 0.476126).  Saving model ...
Validation loss decreased (0.476126 --> 0.476078).  Saving model ...
Validation loss decreased (0.476078 --> 0.476029).  Saving model ...
Validation loss decreased (0.476029 --> 0.475980).  Saving model ...
Validation loss decreased (0.475980 --> 0.475931).  Saving model ...
Validation loss decreased (0.475931 --> 0.475883).  Saving model ...
Validation loss decreased (0.475883 --> 0.475834).  Saving model ...
Validation loss decreased (0.475834 --> 0.475785).  Saving model ...
Validation loss decreased (0.475785 --> 0.475736).  Saving model ...
Validation loss decreased (0.475736 --> 0.475687).  Saving model ...
Validation loss decreased (0.475687 --> 0.475638).  Saving model ...
Validation loss decreased (0.475638 --> 0.475589).  Saving model ...
Validation loss decreased (0.475589 --> 0.475540).  Saving model ...
Validation loss decreased (0.475540 --> 0.475491).  Saving model ...
Validation loss decreased (0.475491 --> 0.475442).  Saving model ...
Validation loss decreased (0.475442 --> 0.475393).  Saving model ...
Validation loss decreased (0.475393 --> 0.475343).  Saving model ...
Validation loss decreased (0.475343 --> 0.475294).  Saving model ...
Validation loss decreased (0.475294 --> 0.475245).  Saving model ...
Validation loss decreased (0.475245 --> 0.475196).  Saving model ...
Validation loss decreased (0.475196 --> 0.475146).  Saving model ...
Validation loss decreased (0.475146 --> 0.475097).  Saving model ...
Validation loss decreased (0.475097 --> 0.475047).  Saving model ...
Validation loss decreased (0.475047 --> 0.474998).  Saving model ...
Validation loss decreased (0.474998 --> 0.474949).  Saving model ...
Validation loss decreased (0.474949 --> 0.474899).  Saving model ...
Validation loss decreased (0.474899 --> 0.474850).  Saving model ...
Validation loss decreased (0.474850 --> 0.474800).  Saving model ...
Validation loss decreased (0.474800 --> 0.474750).  Saving model ...
Validation loss decreased (0.474750 --> 0.474701).  Saving model ...
Validation loss decreased (0.474701 --> 0.474651).  Saving model ...
Validation loss decreased (0.474651 --> 0.474602).  Saving model ...
Validation loss decreased (0.474602 --> 0.474552).  Saving model ...
Validation loss decreased (0.474552 --> 0.474502).  Saving model ...
Validation loss decreased (0.474502 --> 0.474452).  Saving model ...
Validation loss decreased (0.474452 --> 0.474403).  Saving model ...
Validation loss decreased (0.474403 --> 0.474353).  Saving model ...
Validation loss decreased (0.474353 --> 0.474303).  Saving model ...
Validation loss decreased (0.474303 --> 0.474253).  Saving model ...
Validation loss decreased (0.474253 --> 0.474204).  Saving model ...
Validation loss decreased (0.474204 --> 0.474154).  Saving model ...
Validation loss decreased (0.474154 --> 0.474104).  Saving model ...
Validation loss decreased (0.474104 --> 0.474054).  Saving model ...
Validation loss decreased (0.474054 --> 0.474004).  Saving model ...
Validation loss decreased (0.474004 --> 0.473954).  Saving model ...
Validation loss decreased (0.473954 --> 0.473904).  Saving model ...
Validation loss decreased (0.473904 --> 0.473854).  Saving model ...
Validation loss decreased (0.473854 --> 0.473804).  Saving model ...
Validation loss decreased (0.473804 --> 0.473754).  Saving model ...
Validation loss decreased (0.473754 --> 0.473704).  Saving model ...
Validation loss decreased (0.473704 --> 0.473654).  Saving model ...
Validation loss decreased (0.473654 --> 0.473604).  Saving model ...
Validation loss decreased (0.473604 --> 0.473554).  Saving model ...
Validation loss decreased (0.473554 --> 0.473503).  Saving model ...
Validation loss decreased (0.473503 --> 0.473453).  Saving model ...
Validation loss decreased (0.473453 --> 0.473403).  Saving model ...
Validation loss decreased (0.473403 --> 0.473353).  Saving model ...
Validation loss decreased (0.473353 --> 0.473303).  Saving model ...
Validation loss decreased (0.473303 --> 0.473252).  Saving model ...
Validation loss decreased (0.473252 --> 0.473202).  Saving model ...
Validation loss decreased (0.473202 --> 0.473152).  Saving model ...
Validation loss decreased (0.473152 --> 0.473102).  Saving model ...
Validation loss decreased (0.473102 --> 0.473051).  Saving model ...
Validation loss decreased (0.473051 --> 0.473001).  Saving model ...
Validation loss decreased (0.473001 --> 0.472951).  Saving model ...
Validation loss decreased (0.472951 --> 0.472901).  Saving model ...
Validation loss decreased (0.472901 --> 0.472850).  Saving model ...
Validation loss decreased (0.472850 --> 0.472800).  Saving model ...
Validation loss decreased (0.472800 --> 0.472749).  Saving model ...
Validation loss decreased (0.472749 --> 0.472699).  Saving model ...
Validation loss decreased (0.472699 --> 0.472649).  Saving model ...
Validation loss decreased (0.472649 --> 0.472598).  Saving model ...
Validation loss decreased (0.472598 --> 0.472548).  Saving model ...
Validation loss decreased (0.472548 --> 0.472497).  Saving model ...
Validation loss decreased (0.472497 --> 0.472447).  Saving model ...
Validation loss decreased (0.472447 --> 0.472396).  Saving model ...
Validation loss decreased (0.472396 --> 0.472346).  Saving model ...
Validation loss decreased (0.472346 --> 0.472295).  Saving model ...
Validation loss decreased (0.472295 --> 0.472245).  Saving model ...
Validation loss decreased (0.472245 --> 0.472194).  Saving model ...
epoch 1401, loss 0.4722, train acc 78.12%, f1 0.6559, precision 0.7305, recall 0.5951, auc 0.7384
Validation loss decreased (0.472194 --> 0.472144).  Saving model ...
Validation loss decreased (0.472144 --> 0.472093).  Saving model ...
Validation loss decreased (0.472093 --> 0.472043).  Saving model ...
Validation loss decreased (0.472043 --> 0.471992).  Saving model ...
Validation loss decreased (0.471992 --> 0.471942).  Saving model ...
Validation loss decreased (0.471942 --> 0.471891).  Saving model ...
Validation loss decreased (0.471891 --> 0.471841).  Saving model ...
Validation loss decreased (0.471841 --> 0.471790).  Saving model ...
Validation loss decreased (0.471790 --> 0.471739).  Saving model ...
Validation loss decreased (0.471739 --> 0.471689).  Saving model ...
Validation loss decreased (0.471689 --> 0.471638).  Saving model ...
Validation loss decreased (0.471638 --> 0.471588).  Saving model ...
Validation loss decreased (0.471588 --> 0.471537).  Saving model ...
Validation loss decreased (0.471537 --> 0.471486).  Saving model ...
Validation loss decreased (0.471486 --> 0.471436).  Saving model ...
Validation loss decreased (0.471436 --> 0.471385).  Saving model ...
Validation loss decreased (0.471385 --> 0.471335).  Saving model ...
Validation loss decreased (0.471335 --> 0.471284).  Saving model ...
Validation loss decreased (0.471284 --> 0.471233).  Saving model ...
Validation loss decreased (0.471233 --> 0.471183).  Saving model ...
Validation loss decreased (0.471183 --> 0.471132).  Saving model ...
Validation loss decreased (0.471132 --> 0.471081).  Saving model ...
Validation loss decreased (0.471081 --> 0.471031).  Saving model ...
Validation loss decreased (0.471031 --> 0.470980).  Saving model ...
Validation loss decreased (0.470980 --> 0.470929).  Saving model ...
Validation loss decreased (0.470929 --> 0.470879).  Saving model ...
Validation loss decreased (0.470879 --> 0.470828).  Saving model ...
Validation loss decreased (0.470828 --> 0.470777).  Saving model ...
Validation loss decreased (0.470777 --> 0.470726).  Saving model ...
Validation loss decreased (0.470726 --> 0.470676).  Saving model ...
Validation loss decreased (0.470676 --> 0.470625).  Saving model ...
Validation loss decreased (0.470625 --> 0.470574).  Saving model ...
Validation loss decreased (0.470574 --> 0.470524).  Saving model ...
Validation loss decreased (0.470524 --> 0.470473).  Saving model ...
Validation loss decreased (0.470473 --> 0.470422).  Saving model ...
Validation loss decreased (0.470422 --> 0.470372).  Saving model ...
Validation loss decreased (0.470372 --> 0.470321).  Saving model ...
Validation loss decreased (0.470321 --> 0.470270).  Saving model ...
Validation loss decreased (0.470270 --> 0.470220).  Saving model ...
Validation loss decreased (0.470220 --> 0.470169).  Saving model ...
Validation loss decreased (0.470169 --> 0.470118).  Saving model ...
Validation loss decreased (0.470118 --> 0.470068).  Saving model ...
Validation loss decreased (0.470068 --> 0.470017).  Saving model ...
Validation loss decreased (0.470017 --> 0.469966).  Saving model ...
Validation loss decreased (0.469966 --> 0.469916).  Saving model ...
Validation loss decreased (0.469916 --> 0.469865).  Saving model ...
Validation loss decreased (0.469865 --> 0.469814).  Saving model ...
Validation loss decreased (0.469814 --> 0.469764).  Saving model ...
Validation loss decreased (0.469764 --> 0.469713).  Saving model ...
Validation loss decreased (0.469713 --> 0.469662).  Saving model ...
Validation loss decreased (0.469662 --> 0.469612).  Saving model ...
Validation loss decreased (0.469612 --> 0.469561).  Saving model ...
Validation loss decreased (0.469561 --> 0.469510).  Saving model ...
Validation loss decreased (0.469510 --> 0.469460).  Saving model ...
Validation loss decreased (0.469460 --> 0.469409).  Saving model ...
Validation loss decreased (0.469409 --> 0.469359).  Saving model ...
Validation loss decreased (0.469359 --> 0.469308).  Saving model ...
Validation loss decreased (0.469308 --> 0.469257).  Saving model ...
Validation loss decreased (0.469257 --> 0.469207).  Saving model ...
Validation loss decreased (0.469207 --> 0.469156).  Saving model ...
Validation loss decreased (0.469156 --> 0.469106).  Saving model ...
Validation loss decreased (0.469106 --> 0.469055).  Saving model ...
Validation loss decreased (0.469055 --> 0.469005).  Saving model ...
Validation loss decreased (0.469005 --> 0.468954).  Saving model ...
Validation loss decreased (0.468954 --> 0.468904).  Saving model ...
Validation loss decreased (0.468904 --> 0.468853).  Saving model ...
Validation loss decreased (0.468853 --> 0.468803).  Saving model ...
Validation loss decreased (0.468803 --> 0.468752).  Saving model ...
Validation loss decreased (0.468752 --> 0.468702).  Saving model ...
Validation loss decreased (0.468702 --> 0.468652).  Saving model ...
Validation loss decreased (0.468652 --> 0.468601).  Saving model ...
Validation loss decreased (0.468601 --> 0.468551).  Saving model ...
Validation loss decreased (0.468551 --> 0.468500).  Saving model ...
Validation loss decreased (0.468500 --> 0.468450).  Saving model ...
Validation loss decreased (0.468450 --> 0.468400).  Saving model ...
Validation loss decreased (0.468400 --> 0.468349).  Saving model ...
Validation loss decreased (0.468349 --> 0.468299).  Saving model ...
Validation loss decreased (0.468299 --> 0.468249).  Saving model ...
Validation loss decreased (0.468249 --> 0.468199).  Saving model ...
Validation loss decreased (0.468199 --> 0.468148).  Saving model ...
Validation loss decreased (0.468148 --> 0.468098).  Saving model ...
Validation loss decreased (0.468098 --> 0.468048).  Saving model ...
Validation loss decreased (0.468048 --> 0.467998).  Saving model ...
Validation loss decreased (0.467998 --> 0.467948).  Saving model ...
Validation loss decreased (0.467948 --> 0.467898).  Saving model ...
Validation loss decreased (0.467898 --> 0.467848).  Saving model ...
Validation loss decreased (0.467848 --> 0.467798).  Saving model ...
Validation loss decreased (0.467798 --> 0.467747).  Saving model ...
Validation loss decreased (0.467747 --> 0.467697).  Saving model ...
Validation loss decreased (0.467697 --> 0.467647).  Saving model ...
Validation loss decreased (0.467647 --> 0.467597).  Saving model ...
Validation loss decreased (0.467597 --> 0.467548).  Saving model ...
Validation loss decreased (0.467548 --> 0.467498).  Saving model ...
Validation loss decreased (0.467498 --> 0.467448).  Saving model ...
Validation loss decreased (0.467448 --> 0.467398).  Saving model ...
Validation loss decreased (0.467398 --> 0.467348).  Saving model ...
Validation loss decreased (0.467348 --> 0.467298).  Saving model ...
Validation loss decreased (0.467298 --> 0.467248).  Saving model ...
Validation loss decreased (0.467248 --> 0.467199).  Saving model ...
Validation loss decreased (0.467199 --> 0.467149).  Saving model ...
epoch 1501, loss 0.4671, train acc 78.29%, f1 0.6577, precision 0.7349, recall 0.5951, auc 0.7397
Validation loss decreased (0.467149 --> 0.467099).  Saving model ...
Validation loss decreased (0.467099 --> 0.467050).  Saving model ...
Validation loss decreased (0.467050 --> 0.467000).  Saving model ...
Validation loss decreased (0.467000 --> 0.466951).  Saving model ...
Validation loss decreased (0.466951 --> 0.466901).  Saving model ...
Validation loss decreased (0.466901 --> 0.466851).  Saving model ...
Validation loss decreased (0.466851 --> 0.466802).  Saving model ...
Validation loss decreased (0.466802 --> 0.466752).  Saving model ...
Validation loss decreased (0.466752 --> 0.466703).  Saving model ...
Validation loss decreased (0.466703 --> 0.466654).  Saving model ...
Validation loss decreased (0.466654 --> 0.466604).  Saving model ...
Validation loss decreased (0.466604 --> 0.466555).  Saving model ...
Validation loss decreased (0.466555 --> 0.466506).  Saving model ...
Validation loss decreased (0.466506 --> 0.466456).  Saving model ...
Validation loss decreased (0.466456 --> 0.466407).  Saving model ...
Validation loss decreased (0.466407 --> 0.466358).  Saving model ...
Validation loss decreased (0.466358 --> 0.466309).  Saving model ...
Validation loss decreased (0.466309 --> 0.466260).  Saving model ...
Validation loss decreased (0.466260 --> 0.466211).  Saving model ...
Validation loss decreased (0.466211 --> 0.466162).  Saving model ...
Validation loss decreased (0.466162 --> 0.466113).  Saving model ...
Validation loss decreased (0.466113 --> 0.466064).  Saving model ...
Validation loss decreased (0.466064 --> 0.466015).  Saving model ...
Validation loss decreased (0.466015 --> 0.465966).  Saving model ...
Validation loss decreased (0.465966 --> 0.465917).  Saving model ...
Validation loss decreased (0.465917 --> 0.465868).  Saving model ...
Validation loss decreased (0.465868 --> 0.465819).  Saving model ...
Validation loss decreased (0.465819 --> 0.465771).  Saving model ...
Validation loss decreased (0.465771 --> 0.465722).  Saving model ...
Validation loss decreased (0.465722 --> 0.465673).  Saving model ...
Validation loss decreased (0.465673 --> 0.465625).  Saving model ...
Validation loss decreased (0.465625 --> 0.465576).  Saving model ...
Validation loss decreased (0.465576 --> 0.465528).  Saving model ...
Validation loss decreased (0.465528 --> 0.465479).  Saving model ...
Validation loss decreased (0.465479 --> 0.465430).  Saving model ...
Validation loss decreased (0.465430 --> 0.465382).  Saving model ...
Validation loss decreased (0.465382 --> 0.465334).  Saving model ...
Validation loss decreased (0.465334 --> 0.465285).  Saving model ...
Validation loss decreased (0.465285 --> 0.465237).  Saving model ...
Validation loss decreased (0.465237 --> 0.465189).  Saving model ...
Validation loss decreased (0.465189 --> 0.465141).  Saving model ...
Validation loss decreased (0.465141 --> 0.465092).  Saving model ...
Validation loss decreased (0.465092 --> 0.465044).  Saving model ...
Validation loss decreased (0.465044 --> 0.464996).  Saving model ...
Validation loss decreased (0.464996 --> 0.464948).  Saving model ...
Validation loss decreased (0.464948 --> 0.464900).  Saving model ...
Validation loss decreased (0.464900 --> 0.464852).  Saving model ...
Validation loss decreased (0.464852 --> 0.464804).  Saving model ...
Validation loss decreased (0.464804 --> 0.464756).  Saving model ...
Validation loss decreased (0.464756 --> 0.464708).  Saving model ...
Validation loss decreased (0.464708 --> 0.464661).  Saving model ...
Validation loss decreased (0.464661 --> 0.464613).  Saving model ...
Validation loss decreased (0.464613 --> 0.464565).  Saving model ...
Validation loss decreased (0.464565 --> 0.464517).  Saving model ...
Validation loss decreased (0.464517 --> 0.464470).  Saving model ...
Validation loss decreased (0.464470 --> 0.464422).  Saving model ...
Validation loss decreased (0.464422 --> 0.464375).  Saving model ...
Validation loss decreased (0.464375 --> 0.464327).  Saving model ...
Validation loss decreased (0.464327 --> 0.464280).  Saving model ...
Validation loss decreased (0.464280 --> 0.464232).  Saving model ...
Validation loss decreased (0.464232 --> 0.464185).  Saving model ...
Validation loss decreased (0.464185 --> 0.464137).  Saving model ...
Validation loss decreased (0.464137 --> 0.464090).  Saving model ...
Validation loss decreased (0.464090 --> 0.464043).  Saving model ...
Validation loss decreased (0.464043 --> 0.463996).  Saving model ...
Validation loss decreased (0.463996 --> 0.463948).  Saving model ...
Validation loss decreased (0.463948 --> 0.463901).  Saving model ...
Validation loss decreased (0.463901 --> 0.463854).  Saving model ...
Validation loss decreased (0.463854 --> 0.463807).  Saving model ...
Validation loss decreased (0.463807 --> 0.463760).  Saving model ...
Validation loss decreased (0.463760 --> 0.463713).  Saving model ...
Validation loss decreased (0.463713 --> 0.463666).  Saving model ...
Validation loss decreased (0.463666 --> 0.463620).  Saving model ...
Validation loss decreased (0.463620 --> 0.463573).  Saving model ...
Validation loss decreased (0.463573 --> 0.463526).  Saving model ...
Validation loss decreased (0.463526 --> 0.463479).  Saving model ...
Validation loss decreased (0.463479 --> 0.463432).  Saving model ...
Validation loss decreased (0.463432 --> 0.463386).  Saving model ...
Validation loss decreased (0.463386 --> 0.463339).  Saving model ...
Validation loss decreased (0.463339 --> 0.463293).  Saving model ...
Validation loss decreased (0.463293 --> 0.463246).  Saving model ...
Validation loss decreased (0.463246 --> 0.463200).  Saving model ...
Validation loss decreased (0.463200 --> 0.463153).  Saving model ...
Validation loss decreased (0.463153 --> 0.463107).  Saving model ...
Validation loss decreased (0.463107 --> 0.463061).  Saving model ...
Validation loss decreased (0.463061 --> 0.463014).  Saving model ...
Validation loss decreased (0.463014 --> 0.462968).  Saving model ...
Validation loss decreased (0.462968 --> 0.462922).  Saving model ...
Validation loss decreased (0.462922 --> 0.462876).  Saving model ...
Validation loss decreased (0.462876 --> 0.462829).  Saving model ...
Validation loss decreased (0.462829 --> 0.462783).  Saving model ...
Validation loss decreased (0.462783 --> 0.462737).  Saving model ...
Validation loss decreased (0.462737 --> 0.462691).  Saving model ...
Validation loss decreased (0.462691 --> 0.462646).  Saving model ...
Validation loss decreased (0.462646 --> 0.462600).  Saving model ...
Validation loss decreased (0.462600 --> 0.462554).  Saving model ...
Validation loss decreased (0.462554 --> 0.462508).  Saving model ...
Validation loss decreased (0.462508 --> 0.462462).  Saving model ...
Validation loss decreased (0.462462 --> 0.462417).  Saving model ...
Validation loss decreased (0.462417 --> 0.462371).  Saving model ...
epoch 1601, loss 0.4624, train acc 78.97%, f1 0.6702, precision 0.7440, recall 0.6098, auc 0.7483
Validation loss decreased (0.462371 --> 0.462325).  Saving model ...
Validation loss decreased (0.462325 --> 0.462280).  Saving model ...
Validation loss decreased (0.462280 --> 0.462234).  Saving model ...
Validation loss decreased (0.462234 --> 0.462189).  Saving model ...
Validation loss decreased (0.462189 --> 0.462143).  Saving model ...
Validation loss decreased (0.462143 --> 0.462098).  Saving model ...
Validation loss decreased (0.462098 --> 0.462053).  Saving model ...
Validation loss decreased (0.462053 --> 0.462007).  Saving model ...
Validation loss decreased (0.462007 --> 0.461962).  Saving model ...
Validation loss decreased (0.461962 --> 0.461917).  Saving model ...
Validation loss decreased (0.461917 --> 0.461872).  Saving model ...
Validation loss decreased (0.461872 --> 0.461826).  Saving model ...
Validation loss decreased (0.461826 --> 0.461781).  Saving model ...
Validation loss decreased (0.461781 --> 0.461736).  Saving model ...
Validation loss decreased (0.461736 --> 0.461691).  Saving model ...
Validation loss decreased (0.461691 --> 0.461646).  Saving model ...
Validation loss decreased (0.461646 --> 0.461602).  Saving model ...
Validation loss decreased (0.461602 --> 0.461557).  Saving model ...
Validation loss decreased (0.461557 --> 0.461512).  Saving model ...
Validation loss decreased (0.461512 --> 0.461467).  Saving model ...
Validation loss decreased (0.461467 --> 0.461423).  Saving model ...
Validation loss decreased (0.461423 --> 0.461378).  Saving model ...
Validation loss decreased (0.461378 --> 0.461333).  Saving model ...
Validation loss decreased (0.461333 --> 0.461289).  Saving model ...
Validation loss decreased (0.461289 --> 0.461244).  Saving model ...
Validation loss decreased (0.461244 --> 0.461200).  Saving model ...
Validation loss decreased (0.461200 --> 0.461155).  Saving model ...
Validation loss decreased (0.461155 --> 0.461111).  Saving model ...
Validation loss decreased (0.461111 --> 0.461067).  Saving model ...
Validation loss decreased (0.461067 --> 0.461022).  Saving model ...
Validation loss decreased (0.461022 --> 0.460978).  Saving model ...
Validation loss decreased (0.460978 --> 0.460934).  Saving model ...
Validation loss decreased (0.460934 --> 0.460890).  Saving model ...
Validation loss decreased (0.460890 --> 0.460846).  Saving model ...
Validation loss decreased (0.460846 --> 0.460802).  Saving model ...
Validation loss decreased (0.460802 --> 0.460758).  Saving model ...
Validation loss decreased (0.460758 --> 0.460714).  Saving model ...
Validation loss decreased (0.460714 --> 0.460670).  Saving model ...
Validation loss decreased (0.460670 --> 0.460626).  Saving model ...
Validation loss decreased (0.460626 --> 0.460582).  Saving model ...
Validation loss decreased (0.460582 --> 0.460538).  Saving model ...
Validation loss decreased (0.460538 --> 0.460495).  Saving model ...
Validation loss decreased (0.460495 --> 0.460451).  Saving model ...
Validation loss decreased (0.460451 --> 0.460408).  Saving model ...
Validation loss decreased (0.460408 --> 0.460364).  Saving model ...
Validation loss decreased (0.460364 --> 0.460321).  Saving model ...
Validation loss decreased (0.460321 --> 0.460277).  Saving model ...
Validation loss decreased (0.460277 --> 0.460234).  Saving model ...
Validation loss decreased (0.460234 --> 0.460190).  Saving model ...
Validation loss decreased (0.460190 --> 0.460147).  Saving model ...
Validation loss decreased (0.460147 --> 0.460104).  Saving model ...
Validation loss decreased (0.460104 --> 0.460061).  Saving model ...
Validation loss decreased (0.460061 --> 0.460017).  Saving model ...
Validation loss decreased (0.460017 --> 0.459974).  Saving model ...
Validation loss decreased (0.459974 --> 0.459931).  Saving model ...
Validation loss decreased (0.459931 --> 0.459888).  Saving model ...
Validation loss decreased (0.459888 --> 0.459845).  Saving model ...
Validation loss decreased (0.459845 --> 0.459802).  Saving model ...
Validation loss decreased (0.459802 --> 0.459760).  Saving model ...
Validation loss decreased (0.459760 --> 0.459717).  Saving model ...
Validation loss decreased (0.459717 --> 0.459674).  Saving model ...
Validation loss decreased (0.459674 --> 0.459631).  Saving model ...
Validation loss decreased (0.459631 --> 0.459589).  Saving model ...
Validation loss decreased (0.459589 --> 0.459546).  Saving model ...
Validation loss decreased (0.459546 --> 0.459504).  Saving model ...
Validation loss decreased (0.459504 --> 0.459461).  Saving model ...
Validation loss decreased (0.459461 --> 0.459419).  Saving model ...
Validation loss decreased (0.459419 --> 0.459376).  Saving model ...
Validation loss decreased (0.459376 --> 0.459334).  Saving model ...
Validation loss decreased (0.459334 --> 0.459292).  Saving model ...
Validation loss decreased (0.459292 --> 0.459249).  Saving model ...
Validation loss decreased (0.459249 --> 0.459207).  Saving model ...
Validation loss decreased (0.459207 --> 0.459165).  Saving model ...
Validation loss decreased (0.459165 --> 0.459123).  Saving model ...
Validation loss decreased (0.459123 --> 0.459081).  Saving model ...
Validation loss decreased (0.459081 --> 0.459039).  Saving model ...
Validation loss decreased (0.459039 --> 0.458997).  Saving model ...
Validation loss decreased (0.458997 --> 0.458955).  Saving model ...
Validation loss decreased (0.458955 --> 0.458913).  Saving model ...
Validation loss decreased (0.458913 --> 0.458871).  Saving model ...
Validation loss decreased (0.458871 --> 0.458830).  Saving model ...
Validation loss decreased (0.458830 --> 0.458788).  Saving model ...
Validation loss decreased (0.458788 --> 0.458747).  Saving model ...
Validation loss decreased (0.458747 --> 0.458705).  Saving model ...
Validation loss decreased (0.458705 --> 0.458663).  Saving model ...
Validation loss decreased (0.458663 --> 0.458622).  Saving model ...
Validation loss decreased (0.458622 --> 0.458581).  Saving model ...
Validation loss decreased (0.458581 --> 0.458539).  Saving model ...
Validation loss decreased (0.458539 --> 0.458498).  Saving model ...
Validation loss decreased (0.458498 --> 0.458457).  Saving model ...
Validation loss decreased (0.458457 --> 0.458416).  Saving model ...
Validation loss decreased (0.458416 --> 0.458375).  Saving model ...
Validation loss decreased (0.458375 --> 0.458333).  Saving model ...
Validation loss decreased (0.458333 --> 0.458292).  Saving model ...
Validation loss decreased (0.458292 --> 0.458252).  Saving model ...
Validation loss decreased (0.458252 --> 0.458211).  Saving model ...
Validation loss decreased (0.458211 --> 0.458170).  Saving model ...
Validation loss decreased (0.458170 --> 0.458129).  Saving model ...
Validation loss decreased (0.458129 --> 0.458088).  Saving model ...
Validation loss decreased (0.458088 --> 0.458048).  Saving model ...
epoch 1701, loss 0.4580, train acc 79.15%, f1 0.6738, precision 0.7456, recall 0.6146, auc 0.7507
Validation loss decreased (0.458048 --> 0.458007).  Saving model ...
Validation loss decreased (0.458007 --> 0.457966).  Saving model ...
Validation loss decreased (0.457966 --> 0.457926).  Saving model ...
Validation loss decreased (0.457926 --> 0.457885).  Saving model ...
Validation loss decreased (0.457885 --> 0.457845).  Saving model ...
Validation loss decreased (0.457845 --> 0.457805).  Saving model ...
Validation loss decreased (0.457805 --> 0.457764).  Saving model ...
Validation loss decreased (0.457764 --> 0.457724).  Saving model ...
Validation loss decreased (0.457724 --> 0.457684).  Saving model ...
Validation loss decreased (0.457684 --> 0.457644).  Saving model ...
Validation loss decreased (0.457644 --> 0.457604).  Saving model ...
Validation loss decreased (0.457604 --> 0.457564).  Saving model ...
Validation loss decreased (0.457564 --> 0.457524).  Saving model ...
Validation loss decreased (0.457524 --> 0.457484).  Saving model ...
Validation loss decreased (0.457484 --> 0.457444).  Saving model ...
Validation loss decreased (0.457444 --> 0.457404).  Saving model ...
Validation loss decreased (0.457404 --> 0.457365).  Saving model ...
Validation loss decreased (0.457365 --> 0.457325).  Saving model ...
Validation loss decreased (0.457325 --> 0.457285).  Saving model ...
Validation loss decreased (0.457285 --> 0.457246).  Saving model ...
Validation loss decreased (0.457246 --> 0.457206).  Saving model ...
Validation loss decreased (0.457206 --> 0.457167).  Saving model ...
Validation loss decreased (0.457167 --> 0.457128).  Saving model ...
Validation loss decreased (0.457128 --> 0.457088).  Saving model ...
Validation loss decreased (0.457088 --> 0.457049).  Saving model ...
Validation loss decreased (0.457049 --> 0.457010).  Saving model ...
Validation loss decreased (0.457010 --> 0.456971).  Saving model ...
Validation loss decreased (0.456971 --> 0.456932).  Saving model ...
Validation loss decreased (0.456932 --> 0.456892).  Saving model ...
Validation loss decreased (0.456892 --> 0.456854).  Saving model ...
Validation loss decreased (0.456854 --> 0.456815).  Saving model ...
Validation loss decreased (0.456815 --> 0.456776).  Saving model ...
Validation loss decreased (0.456776 --> 0.456737).  Saving model ...
Validation loss decreased (0.456737 --> 0.456698).  Saving model ...
Validation loss decreased (0.456698 --> 0.456659).  Saving model ...
Validation loss decreased (0.456659 --> 0.456621).  Saving model ...
Validation loss decreased (0.456621 --> 0.456582).  Saving model ...
Validation loss decreased (0.456582 --> 0.456544).  Saving model ...
Validation loss decreased (0.456544 --> 0.456505).  Saving model ...
Validation loss decreased (0.456505 --> 0.456467).  Saving model ...
Validation loss decreased (0.456467 --> 0.456429).  Saving model ...
Validation loss decreased (0.456429 --> 0.456390).  Saving model ...
Validation loss decreased (0.456390 --> 0.456352).  Saving model ...
Validation loss decreased (0.456352 --> 0.456314).  Saving model ...
Validation loss decreased (0.456314 --> 0.456276).  Saving model ...
Validation loss decreased (0.456276 --> 0.456238).  Saving model ...
Validation loss decreased (0.456238 --> 0.456200).  Saving model ...
Validation loss decreased (0.456200 --> 0.456162).  Saving model ...
Validation loss decreased (0.456162 --> 0.456124).  Saving model ...
Validation loss decreased (0.456124 --> 0.456086).  Saving model ...
Validation loss decreased (0.456086 --> 0.456048).  Saving model ...
Validation loss decreased (0.456048 --> 0.456011).  Saving model ...
Validation loss decreased (0.456011 --> 0.455973).  Saving model ...
Validation loss decreased (0.455973 --> 0.455935).  Saving model ...
Validation loss decreased (0.455935 --> 0.455898).  Saving model ...
Validation loss decreased (0.455898 --> 0.455860).  Saving model ...
Validation loss decreased (0.455860 --> 0.455823).  Saving model ...
Validation loss decreased (0.455823 --> 0.455786).  Saving model ...
Validation loss decreased (0.455786 --> 0.455748).  Saving model ...
Validation loss decreased (0.455748 --> 0.455711).  Saving model ...
Validation loss decreased (0.455711 --> 0.455674).  Saving model ...
Validation loss decreased (0.455674 --> 0.455637).  Saving model ...
Validation loss decreased (0.455637 --> 0.455600).  Saving model ...
Validation loss decreased (0.455600 --> 0.455563).  Saving model ...
Validation loss decreased (0.455563 --> 0.455526).  Saving model ...
Validation loss decreased (0.455526 --> 0.455489).  Saving model ...
Validation loss decreased (0.455489 --> 0.455452).  Saving model ...
Validation loss decreased (0.455452 --> 0.455415).  Saving model ...
Validation loss decreased (0.455415 --> 0.455378).  Saving model ...
Validation loss decreased (0.455378 --> 0.455342).  Saving model ...
Validation loss decreased (0.455342 --> 0.455305).  Saving model ...
Validation loss decreased (0.455305 --> 0.455269).  Saving model ...
Validation loss decreased (0.455269 --> 0.455232).  Saving model ...
Validation loss decreased (0.455232 --> 0.455196).  Saving model ...
Validation loss decreased (0.455196 --> 0.455159).  Saving model ...
Validation loss decreased (0.455159 --> 0.455123).  Saving model ...
Validation loss decreased (0.455123 --> 0.455087).  Saving model ...
Validation loss decreased (0.455087 --> 0.455050).  Saving model ...
Validation loss decreased (0.455050 --> 0.455014).  Saving model ...
Validation loss decreased (0.455014 --> 0.454978).  Saving model ...
Validation loss decreased (0.454978 --> 0.454942).  Saving model ...
Validation loss decreased (0.454942 --> 0.454906).  Saving model ...
Validation loss decreased (0.454906 --> 0.454870).  Saving model ...
Validation loss decreased (0.454870 --> 0.454834).  Saving model ...
Validation loss decreased (0.454834 --> 0.454799).  Saving model ...
Validation loss decreased (0.454799 --> 0.454763).  Saving model ...
Validation loss decreased (0.454763 --> 0.454727).  Saving model ...
Validation loss decreased (0.454727 --> 0.454691).  Saving model ...
Validation loss decreased (0.454691 --> 0.454656).  Saving model ...
Validation loss decreased (0.454656 --> 0.454620).  Saving model ...
Validation loss decreased (0.454620 --> 0.454585).  Saving model ...
Validation loss decreased (0.454585 --> 0.454549).  Saving model ...
Validation loss decreased (0.454549 --> 0.454514).  Saving model ...
Validation loss decreased (0.454514 --> 0.454479).  Saving model ...
Validation loss decreased (0.454479 --> 0.454444).  Saving model ...
Validation loss decreased (0.454444 --> 0.454408).  Saving model ...
Validation loss decreased (0.454408 --> 0.454373).  Saving model ...
Validation loss decreased (0.454373 --> 0.454338).  Saving model ...
Validation loss decreased (0.454338 --> 0.454303).  Saving model ...
Validation loss decreased (0.454303 --> 0.454268).  Saving model ...
epoch 1801, loss 0.4543, train acc 79.66%, f1 0.6844, precision 0.7500, recall 0.6293, auc 0.7581
Validation loss decreased (0.454268 --> 0.454233).  Saving model ...
Validation loss decreased (0.454233 --> 0.454198).  Saving model ...
Validation loss decreased (0.454198 --> 0.454164).  Saving model ...
Validation loss decreased (0.454164 --> 0.454129).  Saving model ...
Validation loss decreased (0.454129 --> 0.454094).  Saving model ...
Validation loss decreased (0.454094 --> 0.454060).  Saving model ...
Validation loss decreased (0.454060 --> 0.454025).  Saving model ...
Validation loss decreased (0.454025 --> 0.453990).  Saving model ...
Validation loss decreased (0.453990 --> 0.453956).  Saving model ...
Validation loss decreased (0.453956 --> 0.453922).  Saving model ...
Validation loss decreased (0.453922 --> 0.453887).  Saving model ...
Validation loss decreased (0.453887 --> 0.453853).  Saving model ...
Validation loss decreased (0.453853 --> 0.453819).  Saving model ...
Validation loss decreased (0.453819 --> 0.453784).  Saving model ...
Validation loss decreased (0.453784 --> 0.453750).  Saving model ...
Validation loss decreased (0.453750 --> 0.453716).  Saving model ...
Validation loss decreased (0.453716 --> 0.453682).  Saving model ...
Validation loss decreased (0.453682 --> 0.453648).  Saving model ...
Validation loss decreased (0.453648 --> 0.453614).  Saving model ...
Validation loss decreased (0.453614 --> 0.453581).  Saving model ...
Validation loss decreased (0.453581 --> 0.453547).  Saving model ...
Validation loss decreased (0.453547 --> 0.453513).  Saving model ...
Validation loss decreased (0.453513 --> 0.453479).  Saving model ...
Validation loss decreased (0.453479 --> 0.453446).  Saving model ...
Validation loss decreased (0.453446 --> 0.453412).  Saving model ...
Validation loss decreased (0.453412 --> 0.453379).  Saving model ...
Validation loss decreased (0.453379 --> 0.453345).  Saving model ...
Validation loss decreased (0.453345 --> 0.453312).  Saving model ...
Validation loss decreased (0.453312 --> 0.453278).  Saving model ...
Validation loss decreased (0.453278 --> 0.453245).  Saving model ...
Validation loss decreased (0.453245 --> 0.453212).  Saving model ...
Validation loss decreased (0.453212 --> 0.453179).  Saving model ...
Validation loss decreased (0.453179 --> 0.453145).  Saving model ...
Validation loss decreased (0.453145 --> 0.453112).  Saving model ...
Validation loss decreased (0.453112 --> 0.453079).  Saving model ...
Validation loss decreased (0.453079 --> 0.453046).  Saving model ...
Validation loss decreased (0.453046 --> 0.453013).  Saving model ...
Validation loss decreased (0.453013 --> 0.452980).  Saving model ...
Validation loss decreased (0.452980 --> 0.452948).  Saving model ...
Validation loss decreased (0.452948 --> 0.452915).  Saving model ...
Validation loss decreased (0.452915 --> 0.452882).  Saving model ...
Validation loss decreased (0.452882 --> 0.452849).  Saving model ...
Validation loss decreased (0.452849 --> 0.452817).  Saving model ...
Validation loss decreased (0.452817 --> 0.452784).  Saving model ...
Validation loss decreased (0.452784 --> 0.452752).  Saving model ...
Validation loss decreased (0.452752 --> 0.452719).  Saving model ...
Validation loss decreased (0.452719 --> 0.452687).  Saving model ...
Validation loss decreased (0.452687 --> 0.452654).  Saving model ...
Validation loss decreased (0.452654 --> 0.452622).  Saving model ...
Validation loss decreased (0.452622 --> 0.452590).  Saving model ...
Validation loss decreased (0.452590 --> 0.452558).  Saving model ...
Validation loss decreased (0.452558 --> 0.452526).  Saving model ...
Validation loss decreased (0.452526 --> 0.452493).  Saving model ...
Validation loss decreased (0.452493 --> 0.452461).  Saving model ...
Validation loss decreased (0.452461 --> 0.452429).  Saving model ...
Validation loss decreased (0.452429 --> 0.452397).  Saving model ...
Validation loss decreased (0.452397 --> 0.452366).  Saving model ...
Validation loss decreased (0.452366 --> 0.452334).  Saving model ...
Validation loss decreased (0.452334 --> 0.452302).  Saving model ...
Validation loss decreased (0.452302 --> 0.452270).  Saving model ...
Validation loss decreased (0.452270 --> 0.452239).  Saving model ...
Validation loss decreased (0.452239 --> 0.452207).  Saving model ...
Validation loss decreased (0.452207 --> 0.452175).  Saving model ...
Validation loss decreased (0.452175 --> 0.452144).  Saving model ...
Validation loss decreased (0.452144 --> 0.452112).  Saving model ...
Validation loss decreased (0.452112 --> 0.452081).  Saving model ...
Validation loss decreased (0.452081 --> 0.452050).  Saving model ...
Validation loss decreased (0.452050 --> 0.452018).  Saving model ...
Validation loss decreased (0.452018 --> 0.451987).  Saving model ...
Validation loss decreased (0.451987 --> 0.451956).  Saving model ...
Validation loss decreased (0.451956 --> 0.451925).  Saving model ...
Validation loss decreased (0.451925 --> 0.451894).  Saving model ...
Validation loss decreased (0.451894 --> 0.451862).  Saving model ...
Validation loss decreased (0.451862 --> 0.451831).  Saving model ...
Validation loss decreased (0.451831 --> 0.451800).  Saving model ...
Validation loss decreased (0.451800 --> 0.451770).  Saving model ...
Validation loss decreased (0.451770 --> 0.451739).  Saving model ...
Validation loss decreased (0.451739 --> 0.451708).  Saving model ...
Validation loss decreased (0.451708 --> 0.451677).  Saving model ...
Validation loss decreased (0.451677 --> 0.451646).  Saving model ...
Validation loss decreased (0.451646 --> 0.451616).  Saving model ...
Validation loss decreased (0.451616 --> 0.451585).  Saving model ...
Validation loss decreased (0.451585 --> 0.451555).  Saving model ...
Validation loss decreased (0.451555 --> 0.451524).  Saving model ...
Validation loss decreased (0.451524 --> 0.451494).  Saving model ...
Validation loss decreased (0.451494 --> 0.451463).  Saving model ...
Validation loss decreased (0.451463 --> 0.451433).  Saving model ...
Validation loss decreased (0.451433 --> 0.451403).  Saving model ...
Validation loss decreased (0.451403 --> 0.451372).  Saving model ...
Validation loss decreased (0.451372 --> 0.451342).  Saving model ...
Validation loss decreased (0.451342 --> 0.451312).  Saving model ...
Validation loss decreased (0.451312 --> 0.451282).  Saving model ...
Validation loss decreased (0.451282 --> 0.451252).  Saving model ...
Validation loss decreased (0.451252 --> 0.451222).  Saving model ...
Validation loss decreased (0.451222 --> 0.451192).  Saving model ...
Validation loss decreased (0.451192 --> 0.451162).  Saving model ...
Validation loss decreased (0.451162 --> 0.451132).  Saving model ...
Validation loss decreased (0.451132 --> 0.451102).  Saving model ...
Validation loss decreased (0.451102 --> 0.451072).  Saving model ...
Validation loss decreased (0.451072 --> 0.451042).  Saving model ...
epoch 1901, loss 0.4510, train acc 79.49%, f1 0.6825, precision 0.7457, recall 0.6293, auc 0.7567
Validation loss decreased (0.451042 --> 0.451013).  Saving model ...
Validation loss decreased (0.451013 --> 0.450983).  Saving model ...
Validation loss decreased (0.450983 --> 0.450954).  Saving model ...
Validation loss decreased (0.450954 --> 0.450924).  Saving model ...
Validation loss decreased (0.450924 --> 0.450895).  Saving model ...
Validation loss decreased (0.450895 --> 0.450865).  Saving model ...
Validation loss decreased (0.450865 --> 0.450836).  Saving model ...
Validation loss decreased (0.450836 --> 0.450806).  Saving model ...
Validation loss decreased (0.450806 --> 0.450777).  Saving model ...
Validation loss decreased (0.450777 --> 0.450748).  Saving model ...
Validation loss decreased (0.450748 --> 0.450718).  Saving model ...
Validation loss decreased (0.450718 --> 0.450689).  Saving model ...
Validation loss decreased (0.450689 --> 0.450660).  Saving model ...
Validation loss decreased (0.450660 --> 0.450631).  Saving model ...
Validation loss decreased (0.450631 --> 0.450602).  Saving model ...
Validation loss decreased (0.450602 --> 0.450573).  Saving model ...
Validation loss decreased (0.450573 --> 0.450544).  Saving model ...
Validation loss decreased (0.450544 --> 0.450515).  Saving model ...
Validation loss decreased (0.450515 --> 0.450486).  Saving model ...
Validation loss decreased (0.450486 --> 0.450458).  Saving model ...
Validation loss decreased (0.450458 --> 0.450429).  Saving model ...
Validation loss decreased (0.450429 --> 0.450400).  Saving model ...
Validation loss decreased (0.450400 --> 0.450372).  Saving model ...
Validation loss decreased (0.450372 --> 0.450343).  Saving model ...
Validation loss decreased (0.450343 --> 0.450314).  Saving model ...
Validation loss decreased (0.450314 --> 0.450286).  Saving model ...
Validation loss decreased (0.450286 --> 0.450257).  Saving model ...
Validation loss decreased (0.450257 --> 0.450229).  Saving model ...
Validation loss decreased (0.450229 --> 0.450201).  Saving model ...
Validation loss decreased (0.450201 --> 0.450172).  Saving model ...
Validation loss decreased (0.450172 --> 0.450144).  Saving model ...
Validation loss decreased (0.450144 --> 0.450116).  Saving model ...
Validation loss decreased (0.450116 --> 0.450087).  Saving model ...
Validation loss decreased (0.450087 --> 0.450059).  Saving model ...
Validation loss decreased (0.450059 --> 0.450031).  Saving model ...
Validation loss decreased (0.450031 --> 0.450003).  Saving model ...
Validation loss decreased (0.450003 --> 0.449975).  Saving model ...
Validation loss decreased (0.449975 --> 0.449947).  Saving model ...
Validation loss decreased (0.449947 --> 0.449919).  Saving model ...
Validation loss decreased (0.449919 --> 0.449891).  Saving model ...
Validation loss decreased (0.449891 --> 0.449863).  Saving model ...
Validation loss decreased (0.449863 --> 0.449836).  Saving model ...
Validation loss decreased (0.449836 --> 0.449808).  Saving model ...
Validation loss decreased (0.449808 --> 0.449780).  Saving model ...
Validation loss decreased (0.449780 --> 0.449752).  Saving model ...
Validation loss decreased (0.449752 --> 0.449725).  Saving model ...
Validation loss decreased (0.449725 --> 0.449697).  Saving model ...
Validation loss decreased (0.449697 --> 0.449670).  Saving model ...
Validation loss decreased (0.449670 --> 0.449642).  Saving model ...
Validation loss decreased (0.449642 --> 0.449615).  Saving model ...
Validation loss decreased (0.449615 --> 0.449587).  Saving model ...
Validation loss decreased (0.449587 --> 0.449560).  Saving model ...
Validation loss decreased (0.449560 --> 0.449533).  Saving model ...
Validation loss decreased (0.449533 --> 0.449505).  Saving model ...
Validation loss decreased (0.449505 --> 0.449478).  Saving model ...
Validation loss decreased (0.449478 --> 0.449451).  Saving model ...
Validation loss decreased (0.449451 --> 0.449424).  Saving model ...
Validation loss decreased (0.449424 --> 0.449397).  Saving model ...
Validation loss decreased (0.449397 --> 0.449370).  Saving model ...
Validation loss decreased (0.449370 --> 0.449342).  Saving model ...
Validation loss decreased (0.449342 --> 0.449316).  Saving model ...
Validation loss decreased (0.449316 --> 0.449289).  Saving model ...
Validation loss decreased (0.449289 --> 0.449262).  Saving model ...
Validation loss decreased (0.449262 --> 0.449235).  Saving model ...
Validation loss decreased (0.449235 --> 0.449208).  Saving model ...
Validation loss decreased (0.449208 --> 0.449181).  Saving model ...
Validation loss decreased (0.449181 --> 0.449154).  Saving model ...
Validation loss decreased (0.449154 --> 0.449128).  Saving model ...
Validation loss decreased (0.449128 --> 0.449101).  Saving model ...
Validation loss decreased (0.449101 --> 0.449074).  Saving model ...
Validation loss decreased (0.449074 --> 0.449048).  Saving model ...
Validation loss decreased (0.449048 --> 0.449021).  Saving model ...
Validation loss decreased (0.449021 --> 0.448995).  Saving model ...
Validation loss decreased (0.448995 --> 0.448968).  Saving model ...
Validation loss decreased (0.448968 --> 0.448942).  Saving model ...
Validation loss decreased (0.448942 --> 0.448916).  Saving model ...
Validation loss decreased (0.448916 --> 0.448889).  Saving model ...
Validation loss decreased (0.448889 --> 0.448863).  Saving model ...
Validation loss decreased (0.448863 --> 0.448837).  Saving model ...
Validation loss decreased (0.448837 --> 0.448811).  Saving model ...
Validation loss decreased (0.448811 --> 0.448784).  Saving model ...
Validation loss decreased (0.448784 --> 0.448758).  Saving model ...
Validation loss decreased (0.448758 --> 0.448732).  Saving model ...
Validation loss decreased (0.448732 --> 0.448706).  Saving model ...
Validation loss decreased (0.448706 --> 0.448680).  Saving model ...
Validation loss decreased (0.448680 --> 0.448654).  Saving model ...
Validation loss decreased (0.448654 --> 0.448628).  Saving model ...
Validation loss decreased (0.448628 --> 0.448602).  Saving model ...
Validation loss decreased (0.448602 --> 0.448576).  Saving model ...
Validation loss decreased (0.448576 --> 0.448551).  Saving model ...
Validation loss decreased (0.448551 --> 0.448525).  Saving model ...
Validation loss decreased (0.448525 --> 0.448499).  Saving model ...
Validation loss decreased (0.448499 --> 0.448473).  Saving model ...
Validation loss decreased (0.448473 --> 0.448448).  Saving model ...
Validation loss decreased (0.448448 --> 0.448422).  Saving model ...
Validation loss decreased (0.448422 --> 0.448397).  Saving model ...
Validation loss decreased (0.448397 --> 0.448371).  Saving model ...
Validation loss decreased (0.448371 --> 0.448346).  Saving model ...
Validation loss decreased (0.448346 --> 0.448320).  Saving model ...
Validation loss decreased (0.448320 --> 0.448295).  Saving model ...
epoch 2001, loss 0.4483, train acc 79.49%, f1 0.6825, precision 0.7457, recall 0.6293, auc 0.7567
Validation loss decreased (0.448295 --> 0.448269).  Saving model ...
Validation loss decreased (0.448269 --> 0.448244).  Saving model ...
Validation loss decreased (0.448244 --> 0.448219).  Saving model ...
Validation loss decreased (0.448219 --> 0.448193).  Saving model ...
Validation loss decreased (0.448193 --> 0.448168).  Saving model ...
Validation loss decreased (0.448168 --> 0.448143).  Saving model ...
Validation loss decreased (0.448143 --> 0.448118).  Saving model ...
Validation loss decreased (0.448118 --> 0.448093).  Saving model ...
Validation loss decreased (0.448093 --> 0.448068).  Saving model ...
Validation loss decreased (0.448068 --> 0.448042).  Saving model ...
Validation loss decreased (0.448042 --> 0.448018).  Saving model ...
Validation loss decreased (0.448018 --> 0.447993).  Saving model ...
Validation loss decreased (0.447993 --> 0.447968).  Saving model ...
Validation loss decreased (0.447968 --> 0.447943).  Saving model ...
Validation loss decreased (0.447943 --> 0.447918).  Saving model ...
Validation loss decreased (0.447918 --> 0.447893).  Saving model ...
Validation loss decreased (0.447893 --> 0.447868).  Saving model ...
Validation loss decreased (0.447868 --> 0.447843).  Saving model ...
Validation loss decreased (0.447843 --> 0.447819).  Saving model ...
Validation loss decreased (0.447819 --> 0.447794).  Saving model ...
Validation loss decreased (0.447794 --> 0.447769).  Saving model ...
Validation loss decreased (0.447769 --> 0.447745).  Saving model ...
Validation loss decreased (0.447745 --> 0.447720).  Saving model ...
Validation loss decreased (0.447720 --> 0.447696).  Saving model ...
Validation loss decreased (0.447696 --> 0.447671).  Saving model ...
Validation loss decreased (0.447671 --> 0.447647).  Saving model ...
Validation loss decreased (0.447647 --> 0.447622).  Saving model ...
Validation loss decreased (0.447622 --> 0.447598).  Saving model ...
Validation loss decreased (0.447598 --> 0.447574).  Saving model ...
Validation loss decreased (0.447574 --> 0.447549).  Saving model ...
Validation loss decreased (0.447549 --> 0.447525).  Saving model ...
Validation loss decreased (0.447525 --> 0.447501).  Saving model ...
Validation loss decreased (0.447501 --> 0.447476).  Saving model ...
Validation loss decreased (0.447476 --> 0.447452).  Saving model ...
Validation loss decreased (0.447452 --> 0.447428).  Saving model ...
Validation loss decreased (0.447428 --> 0.447404).  Saving model ...
Validation loss decreased (0.447404 --> 0.447380).  Saving model ...
Validation loss decreased (0.447380 --> 0.447356).  Saving model ...
Validation loss decreased (0.447356 --> 0.447332).  Saving model ...
Validation loss decreased (0.447332 --> 0.447308).  Saving model ...
Validation loss decreased (0.447308 --> 0.447284).  Saving model ...
Validation loss decreased (0.447284 --> 0.447260).  Saving model ...
Validation loss decreased (0.447260 --> 0.447236).  Saving model ...
Validation loss decreased (0.447236 --> 0.447212).  Saving model ...
Validation loss decreased (0.447212 --> 0.447189).  Saving model ...
Validation loss decreased (0.447189 --> 0.447165).  Saving model ...
Validation loss decreased (0.447165 --> 0.447141).  Saving model ...
Validation loss decreased (0.447141 --> 0.447117).  Saving model ...
Validation loss decreased (0.447117 --> 0.447094).  Saving model ...
Validation loss decreased (0.447094 --> 0.447070).  Saving model ...
Validation loss decreased (0.447070 --> 0.447046).  Saving model ...
Validation loss decreased (0.447046 --> 0.447023).  Saving model ...
Validation loss decreased (0.447023 --> 0.446999).  Saving model ...
Validation loss decreased (0.446999 --> 0.446976).  Saving model ...
Validation loss decreased (0.446976 --> 0.446952).  Saving model ...
Validation loss decreased (0.446952 --> 0.446929).  Saving model ...
Validation loss decreased (0.446929 --> 0.446905).  Saving model ...
Validation loss decreased (0.446905 --> 0.446882).  Saving model ...
Validation loss decreased (0.446882 --> 0.446859).  Saving model ...
Validation loss decreased (0.446859 --> 0.446835).  Saving model ...
Validation loss decreased (0.446835 --> 0.446812).  Saving model ...
Validation loss decreased (0.446812 --> 0.446789).  Saving model ...
Validation loss decreased (0.446789 --> 0.446766).  Saving model ...
Validation loss decreased (0.446766 --> 0.446743).  Saving model ...
Validation loss decreased (0.446743 --> 0.446719).  Saving model ...
Validation loss decreased (0.446719 --> 0.446696).  Saving model ...
Validation loss decreased (0.446696 --> 0.446673).  Saving model ...
Validation loss decreased (0.446673 --> 0.446650).  Saving model ...
Validation loss decreased (0.446650 --> 0.446627).  Saving model ...
Validation loss decreased (0.446627 --> 0.446604).  Saving model ...
Validation loss decreased (0.446604 --> 0.446581).  Saving model ...
Validation loss decreased (0.446581 --> 0.446558).  Saving model ...
Validation loss decreased (0.446558 --> 0.446535).  Saving model ...
Validation loss decreased (0.446535 --> 0.446512).  Saving model ...
Validation loss decreased (0.446512 --> 0.446489).  Saving model ...
Validation loss decreased (0.446489 --> 0.446467).  Saving model ...
Validation loss decreased (0.446467 --> 0.446444).  Saving model ...
Validation loss decreased (0.446444 --> 0.446421).  Saving model ...
Validation loss decreased (0.446421 --> 0.446398).  Saving model ...
Validation loss decreased (0.446398 --> 0.446376).  Saving model ...
Validation loss decreased (0.446376 --> 0.446353).  Saving model ...
Validation loss decreased (0.446353 --> 0.446330).  Saving model ...
Validation loss decreased (0.446330 --> 0.446308).  Saving model ...
Validation loss decreased (0.446308 --> 0.446285).  Saving model ...
Validation loss decreased (0.446285 --> 0.446263).  Saving model ...
Validation loss decreased (0.446263 --> 0.446240).  Saving model ...
Validation loss decreased (0.446240 --> 0.446218).  Saving model ...
Validation loss decreased (0.446218 --> 0.446195).  Saving model ...
Validation loss decreased (0.446195 --> 0.446173).  Saving model ...
Validation loss decreased (0.446173 --> 0.446151).  Saving model ...
Validation loss decreased (0.446151 --> 0.446128).  Saving model ...
Validation loss decreased (0.446128 --> 0.446106).  Saving model ...
Validation loss decreased (0.446106 --> 0.446084).  Saving model ...
Validation loss decreased (0.446084 --> 0.446061).  Saving model ...
Validation loss decreased (0.446061 --> 0.446039).  Saving model ...
Validation loss decreased (0.446039 --> 0.446017).  Saving model ...
Validation loss decreased (0.446017 --> 0.445995).  Saving model ...
Validation loss decreased (0.445995 --> 0.445973).  Saving model ...
Validation loss decreased (0.445973 --> 0.445950).  Saving model ...
Validation loss decreased (0.445950 --> 0.445928).  Saving model ...
epoch 2101, loss 0.4459, train acc 79.49%, f1 0.6842, precision 0.7429, recall 0.6341, auc 0.7579
Validation loss decreased (0.445928 --> 0.445906).  Saving model ...
Validation loss decreased (0.445906 --> 0.445884).  Saving model ...
Validation loss decreased (0.445884 --> 0.445862).  Saving model ...
Validation loss decreased (0.445862 --> 0.445840).  Saving model ...
Validation loss decreased (0.445840 --> 0.445818).  Saving model ...
Validation loss decreased (0.445818 --> 0.445796).  Saving model ...
Validation loss decreased (0.445796 --> 0.445774).  Saving model ...
Validation loss decreased (0.445774 --> 0.445753).  Saving model ...
Validation loss decreased (0.445753 --> 0.445731).  Saving model ...
Validation loss decreased (0.445731 --> 0.445709).  Saving model ...
Validation loss decreased (0.445709 --> 0.445687).  Saving model ...
Validation loss decreased (0.445687 --> 0.445665).  Saving model ...
Validation loss decreased (0.445665 --> 0.445644).  Saving model ...
Validation loss decreased (0.445644 --> 0.445622).  Saving model ...
Validation loss decreased (0.445622 --> 0.445600).  Saving model ...
Validation loss decreased (0.445600 --> 0.445579).  Saving model ...
Validation loss decreased (0.445579 --> 0.445557).  Saving model ...
Validation loss decreased (0.445557 --> 0.445535).  Saving model ...
Validation loss decreased (0.445535 --> 0.445514).  Saving model ...
Validation loss decreased (0.445514 --> 0.445492).  Saving model ...
Validation loss decreased (0.445492 --> 0.445471).  Saving model ...
Validation loss decreased (0.445471 --> 0.445449).  Saving model ...
Validation loss decreased (0.445449 --> 0.445428).  Saving model ...
Validation loss decreased (0.445428 --> 0.445406).  Saving model ...
Validation loss decreased (0.445406 --> 0.445385).  Saving model ...
Validation loss decreased (0.445385 --> 0.445364).  Saving model ...
Validation loss decreased (0.445364 --> 0.445342).  Saving model ...
Validation loss decreased (0.445342 --> 0.445321).  Saving model ...
Validation loss decreased (0.445321 --> 0.445300).  Saving model ...
Validation loss decreased (0.445300 --> 0.445278).  Saving model ...
Validation loss decreased (0.445278 --> 0.445257).  Saving model ...
Validation loss decreased (0.445257 --> 0.445236).  Saving model ...
Validation loss decreased (0.445236 --> 0.445215).  Saving model ...
Validation loss decreased (0.445215 --> 0.445193).  Saving model ...
Validation loss decreased (0.445193 --> 0.445172).  Saving model ...
Validation loss decreased (0.445172 --> 0.445151).  Saving model ...
Validation loss decreased (0.445151 --> 0.445130).  Saving model ...
Validation loss decreased (0.445130 --> 0.445109).  Saving model ...
Validation loss decreased (0.445109 --> 0.445088).  Saving model ...
Validation loss decreased (0.445088 --> 0.445067).  Saving model ...
Validation loss decreased (0.445067 --> 0.445046).  Saving model ...
Validation loss decreased (0.445046 --> 0.445025).  Saving model ...
Validation loss decreased (0.445025 --> 0.445004).  Saving model ...
Validation loss decreased (0.445004 --> 0.444983).  Saving model ...
Validation loss decreased (0.444983 --> 0.444962).  Saving model ...
Validation loss decreased (0.444962 --> 0.444941).  Saving model ...
Validation loss decreased (0.444941 --> 0.444921).  Saving model ...
Validation loss decreased (0.444921 --> 0.444900).  Saving model ...
Validation loss decreased (0.444900 --> 0.444879).  Saving model ...
Validation loss decreased (0.444879 --> 0.444858).  Saving model ...
Validation loss decreased (0.444858 --> 0.444837).  Saving model ...
Validation loss decreased (0.444837 --> 0.444817).  Saving model ...
Validation loss decreased (0.444817 --> 0.444796).  Saving model ...
Validation loss decreased (0.444796 --> 0.444775).  Saving model ...
Validation loss decreased (0.444775 --> 0.444755).  Saving model ...
Validation loss decreased (0.444755 --> 0.444734).  Saving model ...
Validation loss decreased (0.444734 --> 0.444713).  Saving model ...
Validation loss decreased (0.444713 --> 0.444693).  Saving model ...
Validation loss decreased (0.444693 --> 0.444672).  Saving model ...
Validation loss decreased (0.444672 --> 0.444652).  Saving model ...
Validation loss decreased (0.444652 --> 0.444631).  Saving model ...
Validation loss decreased (0.444631 --> 0.444611).  Saving model ...
Validation loss decreased (0.444611 --> 0.444590).  Saving model ...
Validation loss decreased (0.444590 --> 0.444570).  Saving model ...
Validation loss decreased (0.444570 --> 0.444550).  Saving model ...
Validation loss decreased (0.444550 --> 0.444529).  Saving model ...
Validation loss decreased (0.444529 --> 0.444509).  Saving model ...
Validation loss decreased (0.444509 --> 0.444488).  Saving model ...
Validation loss decreased (0.444488 --> 0.444468).  Saving model ...
Validation loss decreased (0.444468 --> 0.444448).  Saving model ...
Validation loss decreased (0.444448 --> 0.444428).  Saving model ...
Validation loss decreased (0.444428 --> 0.444407).  Saving model ...
Validation loss decreased (0.444407 --> 0.444387).  Saving model ...
Validation loss decreased (0.444387 --> 0.444367).  Saving model ...
Validation loss decreased (0.444367 --> 0.444347).  Saving model ...
Validation loss decreased (0.444347 --> 0.444327).  Saving model ...
Validation loss decreased (0.444327 --> 0.444307).  Saving model ...
Validation loss decreased (0.444307 --> 0.444286).  Saving model ...
Validation loss decreased (0.444286 --> 0.444266).  Saving model ...
Validation loss decreased (0.444266 --> 0.444246).  Saving model ...
Validation loss decreased (0.444246 --> 0.444226).  Saving model ...
Validation loss decreased (0.444226 --> 0.444206).  Saving model ...
Validation loss decreased (0.444206 --> 0.444186).  Saving model ...
Validation loss decreased (0.444186 --> 0.444166).  Saving model ...
Validation loss decreased (0.444166 --> 0.444146).  Saving model ...
Validation loss decreased (0.444146 --> 0.444126).  Saving model ...
Validation loss decreased (0.444126 --> 0.444107).  Saving model ...
Validation loss decreased (0.444107 --> 0.444087).  Saving model ...
Validation loss decreased (0.444087 --> 0.444067).  Saving model ...
Validation loss decreased (0.444067 --> 0.444047).  Saving model ...
Validation loss decreased (0.444047 --> 0.444027).  Saving model ...
Validation loss decreased (0.444027 --> 0.444007).  Saving model ...
Validation loss decreased (0.444007 --> 0.443988).  Saving model ...
Validation loss decreased (0.443988 --> 0.443968).  Saving model ...
Validation loss decreased (0.443968 --> 0.443948).  Saving model ...
Validation loss decreased (0.443948 --> 0.443929).  Saving model ...
Validation loss decreased (0.443929 --> 0.443909).  Saving model ...
Validation loss decreased (0.443909 --> 0.443889).  Saving model ...
Validation loss decreased (0.443889 --> 0.443870).  Saving model ...
Validation loss decreased (0.443870 --> 0.443850).  Saving model ...
epoch 2201, loss 0.4439, train acc 79.32%, f1 0.6841, precision 0.7360, recall 0.6390, auc 0.7577
Validation loss decreased (0.443850 --> 0.443831).  Saving model ...
Validation loss decreased (0.443831 --> 0.443811).  Saving model ...
Validation loss decreased (0.443811 --> 0.443792).  Saving model ...
Validation loss decreased (0.443792 --> 0.443772).  Saving model ...
Validation loss decreased (0.443772 --> 0.443753).  Saving model ...
Validation loss decreased (0.443753 --> 0.443733).  Saving model ...
Validation loss decreased (0.443733 --> 0.443714).  Saving model ...
Validation loss decreased (0.443714 --> 0.443694).  Saving model ...
Validation loss decreased (0.443694 --> 0.443675).  Saving model ...
Validation loss decreased (0.443675 --> 0.443655).  Saving model ...
Validation loss decreased (0.443655 --> 0.443636).  Saving model ...
Validation loss decreased (0.443636 --> 0.443617).  Saving model ...
Validation loss decreased (0.443617 --> 0.443598).  Saving model ...
Validation loss decreased (0.443598 --> 0.443578).  Saving model ...
Validation loss decreased (0.443578 --> 0.443559).  Saving model ...
Validation loss decreased (0.443559 --> 0.443540).  Saving model ...
Validation loss decreased (0.443540 --> 0.443521).  Saving model ...
Validation loss decreased (0.443521 --> 0.443501).  Saving model ...
Validation loss decreased (0.443501 --> 0.443482).  Saving model ...
Validation loss decreased (0.443482 --> 0.443463).  Saving model ...
Validation loss decreased (0.443463 --> 0.443444).  Saving model ...
Validation loss decreased (0.443444 --> 0.443425).  Saving model ...
Validation loss decreased (0.443425 --> 0.443406).  Saving model ...
Validation loss decreased (0.443406 --> 0.443387).  Saving model ...
Validation loss decreased (0.443387 --> 0.443368).  Saving model ...
Validation loss decreased (0.443368 --> 0.443349).  Saving model ...
Validation loss decreased (0.443349 --> 0.443330).  Saving model ...
Validation loss decreased (0.443330 --> 0.443311).  Saving model ...
Validation loss decreased (0.443311 --> 0.443292).  Saving model ...
Validation loss decreased (0.443292 --> 0.443273).  Saving model ...
Validation loss decreased (0.443273 --> 0.443254).  Saving model ...
Validation loss decreased (0.443254 --> 0.443235).  Saving model ...
Validation loss decreased (0.443235 --> 0.443216).  Saving model ...
Validation loss decreased (0.443216 --> 0.443198).  Saving model ...
Validation loss decreased (0.443198 --> 0.443179).  Saving model ...
Validation loss decreased (0.443179 --> 0.443160).  Saving model ...
Validation loss decreased (0.443160 --> 0.443141).  Saving model ...
Validation loss decreased (0.443141 --> 0.443123).  Saving model ...
Validation loss decreased (0.443123 --> 0.443104).  Saving model ...
Validation loss decreased (0.443104 --> 0.443085).  Saving model ...
Validation loss decreased (0.443085 --> 0.443067).  Saving model ...
Validation loss decreased (0.443067 --> 0.443048).  Saving model ...
Validation loss decreased (0.443048 --> 0.443029).  Saving model ...
Validation loss decreased (0.443029 --> 0.443011).  Saving model ...
Validation loss decreased (0.443011 --> 0.442992).  Saving model ...
Validation loss decreased (0.442992 --> 0.442974).  Saving model ...
Validation loss decreased (0.442974 --> 0.442955).  Saving model ...
Validation loss decreased (0.442955 --> 0.442937).  Saving model ...
Validation loss decreased (0.442937 --> 0.442918).  Saving model ...
Validation loss decreased (0.442918 --> 0.442900).  Saving model ...
Validation loss decreased (0.442900 --> 0.442881).  Saving model ...
Validation loss decreased (0.442881 --> 0.442863).  Saving model ...
Validation loss decreased (0.442863 --> 0.442845).  Saving model ...
Validation loss decreased (0.442845 --> 0.442826).  Saving model ...
Validation loss decreased (0.442826 --> 0.442808).  Saving model ...
Validation loss decreased (0.442808 --> 0.442790).  Saving model ...
Validation loss decreased (0.442790 --> 0.442771).  Saving model ...
Validation loss decreased (0.442771 --> 0.442753).  Saving model ...
Validation loss decreased (0.442753 --> 0.442735).  Saving model ...
Validation loss decreased (0.442735 --> 0.442717).  Saving model ...
Validation loss decreased (0.442717 --> 0.442699).  Saving model ...
Validation loss decreased (0.442699 --> 0.442680).  Saving model ...
Validation loss decreased (0.442680 --> 0.442662).  Saving model ...
Validation loss decreased (0.442662 --> 0.442644).  Saving model ...
Validation loss decreased (0.442644 --> 0.442626).  Saving model ...
Validation loss decreased (0.442626 --> 0.442608).  Saving model ...
Validation loss decreased (0.442608 --> 0.442590).  Saving model ...
Validation loss decreased (0.442590 --> 0.442572).  Saving model ...
Validation loss decreased (0.442572 --> 0.442554).  Saving model ...
Validation loss decreased (0.442554 --> 0.442536).  Saving model ...
Validation loss decreased (0.442536 --> 0.442518).  Saving model ...
Validation loss decreased (0.442518 --> 0.442500).  Saving model ...
Validation loss decreased (0.442500 --> 0.442482).  Saving model ...
Validation loss decreased (0.442482 --> 0.442464).  Saving model ...
Validation loss decreased (0.442464 --> 0.442446).  Saving model ...
Validation loss decreased (0.442446 --> 0.442429).  Saving model ...
Validation loss decreased (0.442429 --> 0.442411).  Saving model ...
Validation loss decreased (0.442411 --> 0.442393).  Saving model ...
Validation loss decreased (0.442393 --> 0.442375).  Saving model ...
Validation loss decreased (0.442375 --> 0.442357).  Saving model ...
Validation loss decreased (0.442357 --> 0.442340).  Saving model ...
Validation loss decreased (0.442340 --> 0.442322).  Saving model ...
Validation loss decreased (0.442322 --> 0.442304).  Saving model ...
Validation loss decreased (0.442304 --> 0.442287).  Saving model ...
Validation loss decreased (0.442287 --> 0.442269).  Saving model ...
Validation loss decreased (0.442269 --> 0.442252).  Saving model ...
Validation loss decreased (0.442252 --> 0.442234).  Saving model ...
Validation loss decreased (0.442234 --> 0.442216).  Saving model ...
Validation loss decreased (0.442216 --> 0.442199).  Saving model ...
Validation loss decreased (0.442199 --> 0.442181).  Saving model ...
Validation loss decreased (0.442181 --> 0.442164).  Saving model ...
Validation loss decreased (0.442164 --> 0.442146).  Saving model ...
Validation loss decreased (0.442146 --> 0.442129).  Saving model ...
Validation loss decreased (0.442129 --> 0.442111).  Saving model ...
Validation loss decreased (0.442111 --> 0.442094).  Saving model ...
Validation loss decreased (0.442094 --> 0.442077).  Saving model ...
Validation loss decreased (0.442077 --> 0.442059).  Saving model ...
Validation loss decreased (0.442059 --> 0.442042).  Saving model ...
Validation loss decreased (0.442042 --> 0.442025).  Saving model ...
Validation loss decreased (0.442025 --> 0.442007).  Saving model ...
epoch 2301, loss 0.4420, train acc 79.49%, f1 0.6875, precision 0.7374, recall 0.6439, auc 0.7601
Validation loss decreased (0.442007 --> 0.441990).  Saving model ...
Validation loss decreased (0.441990 --> 0.441973).  Saving model ...
Validation loss decreased (0.441973 --> 0.441956).  Saving model ...
Validation loss decreased (0.441956 --> 0.441939).  Saving model ...
Validation loss decreased (0.441939 --> 0.441921).  Saving model ...
Validation loss decreased (0.441921 --> 0.441904).  Saving model ...
Validation loss decreased (0.441904 --> 0.441887).  Saving model ...
Validation loss decreased (0.441887 --> 0.441870).  Saving model ...
Validation loss decreased (0.441870 --> 0.441853).  Saving model ...
Validation loss decreased (0.441853 --> 0.441836).  Saving model ...
Validation loss decreased (0.441836 --> 0.441819).  Saving model ...
Validation loss decreased (0.441819 --> 0.441802).  Saving model ...
Validation loss decreased (0.441802 --> 0.441785).  Saving model ...
Validation loss decreased (0.441785 --> 0.441768).  Saving model ...
Validation loss decreased (0.441768 --> 0.441751).  Saving model ...
Validation loss decreased (0.441751 --> 0.441734).  Saving model ...
Validation loss decreased (0.441734 --> 0.441717).  Saving model ...
Validation loss decreased (0.441717 --> 0.441700).  Saving model ...
Validation loss decreased (0.441700 --> 0.441683).  Saving model ...
Validation loss decreased (0.441683 --> 0.441666).  Saving model ...
Validation loss decreased (0.441666 --> 0.441649).  Saving model ...
Validation loss decreased (0.441649 --> 0.441633).  Saving model ...
Validation loss decreased (0.441633 --> 0.441616).  Saving model ...
Validation loss decreased (0.441616 --> 0.441599).  Saving model ...
Validation loss decreased (0.441599 --> 0.441582).  Saving model ...
Validation loss decreased (0.441582 --> 0.441566).  Saving model ...
Validation loss decreased (0.441566 --> 0.441549).  Saving model ...
Validation loss decreased (0.441549 --> 0.441532).  Saving model ...
Validation loss decreased (0.441532 --> 0.441516).  Saving model ...
Validation loss decreased (0.441516 --> 0.441499).  Saving model ...
Validation loss decreased (0.441499 --> 0.441482).  Saving model ...
Validation loss decreased (0.441482 --> 0.441466).  Saving model ...
Validation loss decreased (0.441466 --> 0.441449).  Saving model ...
Validation loss decreased (0.441449 --> 0.441433).  Saving model ...
Validation loss decreased (0.441433 --> 0.441416).  Saving model ...
Validation loss decreased (0.441416 --> 0.441400).  Saving model ...
Validation loss decreased (0.441400 --> 0.441383).  Saving model ...
Validation loss decreased (0.441383 --> 0.441367).  Saving model ...
Validation loss decreased (0.441367 --> 0.441350).  Saving model ...
Validation loss decreased (0.441350 --> 0.441334).  Saving model ...
Validation loss decreased (0.441334 --> 0.441317).  Saving model ...
Validation loss decreased (0.441317 --> 0.441301).  Saving model ...
Validation loss decreased (0.441301 --> 0.441285).  Saving model ...
Validation loss decreased (0.441285 --> 0.441268).  Saving model ...
Validation loss decreased (0.441268 --> 0.441252).  Saving model ...
Validation loss decreased (0.441252 --> 0.441235).  Saving model ...
Validation loss decreased (0.441235 --> 0.441219).  Saving model ...
Validation loss decreased (0.441219 --> 0.441203).  Saving model ...
Validation loss decreased (0.441203 --> 0.441187).  Saving model ...
Validation loss decreased (0.441187 --> 0.441170).  Saving model ...
Validation loss decreased (0.441170 --> 0.441154).  Saving model ...
Validation loss decreased (0.441154 --> 0.441138).  Saving model ...
Validation loss decreased (0.441138 --> 0.441122).  Saving model ...
Validation loss decreased (0.441122 --> 0.441106).  Saving model ...
Validation loss decreased (0.441106 --> 0.441089).  Saving model ...
Validation loss decreased (0.441089 --> 0.441073).  Saving model ...
Validation loss decreased (0.441073 --> 0.441057).  Saving model ...
Validation loss decreased (0.441057 --> 0.441041).  Saving model ...
Validation loss decreased (0.441041 --> 0.441025).  Saving model ...
Validation loss decreased (0.441025 --> 0.441009).  Saving model ...
Validation loss decreased (0.441009 --> 0.440993).  Saving model ...
Validation loss decreased (0.440993 --> 0.440977).  Saving model ...
Validation loss decreased (0.440977 --> 0.440961).  Saving model ...
Validation loss decreased (0.440961 --> 0.440945).  Saving model ...
Validation loss decreased (0.440945 --> 0.440929).  Saving model ...
Validation loss decreased (0.440929 --> 0.440913).  Saving model ...
Validation loss decreased (0.440913 --> 0.440897).  Saving model ...
Validation loss decreased (0.440897 --> 0.440881).  Saving model ...
Validation loss decreased (0.440881 --> 0.440866).  Saving model ...
Validation loss decreased (0.440866 --> 0.440850).  Saving model ...
Validation loss decreased (0.440850 --> 0.440834).  Saving model ...
Validation loss decreased (0.440834 --> 0.440818).  Saving model ...
Validation loss decreased (0.440818 --> 0.440802).  Saving model ...
Validation loss decreased (0.440802 --> 0.440787).  Saving model ...
Validation loss decreased (0.440787 --> 0.440771).  Saving model ...
Validation loss decreased (0.440771 --> 0.440755).  Saving model ...
Validation loss decreased (0.440755 --> 0.440739).  Saving model ...
Validation loss decreased (0.440739 --> 0.440724).  Saving model ...
Validation loss decreased (0.440724 --> 0.440708).  Saving model ...
Validation loss decreased (0.440708 --> 0.440692).  Saving model ...
Validation loss decreased (0.440692 --> 0.440677).  Saving model ...
Validation loss decreased (0.440677 --> 0.440661).  Saving model ...
Validation loss decreased (0.440661 --> 0.440645).  Saving model ...
Validation loss decreased (0.440645 --> 0.440630).  Saving model ...
Validation loss decreased (0.440630 --> 0.440614).  Saving model ...
Validation loss decreased (0.440614 --> 0.440599).  Saving model ...
Validation loss decreased (0.440599 --> 0.440583).  Saving model ...
Validation loss decreased (0.440583 --> 0.440568).  Saving model ...
Validation loss decreased (0.440568 --> 0.440552).  Saving model ...
Validation loss decreased (0.440552 --> 0.440537).  Saving model ...
Validation loss decreased (0.440537 --> 0.440521).  Saving model ...
Validation loss decreased (0.440521 --> 0.440506).  Saving model ...
Validation loss decreased (0.440506 --> 0.440490).  Saving model ...
Validation loss decreased (0.440490 --> 0.440475).  Saving model ...
Validation loss decreased (0.440475 --> 0.440459).  Saving model ...
Validation loss decreased (0.440459 --> 0.440444).  Saving model ...
Validation loss decreased (0.440444 --> 0.440429).  Saving model ...
Validation loss decreased (0.440429 --> 0.440413).  Saving model ...
Validation loss decreased (0.440413 --> 0.440398).  Saving model ...
Validation loss decreased (0.440398 --> 0.440383).  Saving model ...
epoch 2401, loss 0.4404, train acc 79.32%, f1 0.6857, precision 0.7333, recall 0.6439, auc 0.7588
Validation loss decreased (0.440383 --> 0.440367).  Saving model ...
Validation loss decreased (0.440367 --> 0.440352).  Saving model ...
Validation loss decreased (0.440352 --> 0.440337).  Saving model ...
Validation loss decreased (0.440337 --> 0.440322).  Saving model ...
Validation loss decreased (0.440322 --> 0.440306).  Saving model ...
Validation loss decreased (0.440306 --> 0.440291).  Saving model ...
Validation loss decreased (0.440291 --> 0.440276).  Saving model ...
Validation loss decreased (0.440276 --> 0.440261).  Saving model ...
Validation loss decreased (0.440261 --> 0.440246).  Saving model ...
Validation loss decreased (0.440246 --> 0.440230).  Saving model ...
Validation loss decreased (0.440230 --> 0.440215).  Saving model ...
Validation loss decreased (0.440215 --> 0.440200).  Saving model ...
Validation loss decreased (0.440200 --> 0.440185).  Saving model ...
Validation loss decreased (0.440185 --> 0.440170).  Saving model ...
Validation loss decreased (0.440170 --> 0.440155).  Saving model ...
Validation loss decreased (0.440155 --> 0.440140).  Saving model ...
Validation loss decreased (0.440140 --> 0.440125).  Saving model ...
Validation loss decreased (0.440125 --> 0.440110).  Saving model ...
Validation loss decreased (0.440110 --> 0.440095).  Saving model ...
Validation loss decreased (0.440095 --> 0.440080).  Saving model ...
Validation loss decreased (0.440080 --> 0.440065).  Saving model ...
Validation loss decreased (0.440065 --> 0.440050).  Saving model ...
Validation loss decreased (0.440050 --> 0.440035).  Saving model ...
Validation loss decreased (0.440035 --> 0.440020).  Saving model ...
Validation loss decreased (0.440020 --> 0.440005).  Saving model ...
Validation loss decreased (0.440005 --> 0.439990).  Saving model ...
Validation loss decreased (0.439990 --> 0.439975).  Saving model ...
Validation loss decreased (0.439975 --> 0.439961).  Saving model ...
Validation loss decreased (0.439961 --> 0.439946).  Saving model ...
Validation loss decreased (0.439946 --> 0.439931).  Saving model ...
Validation loss decreased (0.439931 --> 0.439916).  Saving model ...
Validation loss decreased (0.439916 --> 0.439901).  Saving model ...
Validation loss decreased (0.439901 --> 0.439886).  Saving model ...
Validation loss decreased (0.439886 --> 0.439872).  Saving model ...
Validation loss decreased (0.439872 --> 0.439857).  Saving model ...
Validation loss decreased (0.439857 --> 0.439842).  Saving model ...
Validation loss decreased (0.439842 --> 0.439827).  Saving model ...
Validation loss decreased (0.439827 --> 0.439813).  Saving model ...
Validation loss decreased (0.439813 --> 0.439798).  Saving model ...
Validation loss decreased (0.439798 --> 0.439783).  Saving model ...
Validation loss decreased (0.439783 --> 0.439769).  Saving model ...
Validation loss decreased (0.439769 --> 0.439754).  Saving model ...
Validation loss decreased (0.439754 --> 0.439739).  Saving model ...
Validation loss decreased (0.439739 --> 0.439725).  Saving model ...
Validation loss decreased (0.439725 --> 0.439710).  Saving model ...
Validation loss decreased (0.439710 --> 0.439695).  Saving model ...
Validation loss decreased (0.439695 --> 0.439681).  Saving model ...
Validation loss decreased (0.439681 --> 0.439666).  Saving model ...
Validation loss decreased (0.439666 --> 0.439652).  Saving model ...
Validation loss decreased (0.439652 --> 0.439637).  Saving model ...
Validation loss decreased (0.439637 --> 0.439622).  Saving model ...
Validation loss decreased (0.439622 --> 0.439608).  Saving model ...
Validation loss decreased (0.439608 --> 0.439593).  Saving model ...
Validation loss decreased (0.439593 --> 0.439579).  Saving model ...
Validation loss decreased (0.439579 --> 0.439564).  Saving model ...
Validation loss decreased (0.439564 --> 0.439550).  Saving model ...
Validation loss decreased (0.439550 --> 0.439535).  Saving model ...
Validation loss decreased (0.439535 --> 0.439521).  Saving model ...
Validation loss decreased (0.439521 --> 0.439507).  Saving model ...
Validation loss decreased (0.439507 --> 0.439492).  Saving model ...
Validation loss decreased (0.439492 --> 0.439478).  Saving model ...
Validation loss decreased (0.439478 --> 0.439463).  Saving model ...
Validation loss decreased (0.439463 --> 0.439449).  Saving model ...
Validation loss decreased (0.439449 --> 0.439434).  Saving model ...
Validation loss decreased (0.439434 --> 0.439420).  Saving model ...
Validation loss decreased (0.439420 --> 0.439406).  Saving model ...
Validation loss decreased (0.439406 --> 0.439391).  Saving model ...
Validation loss decreased (0.439391 --> 0.439377).  Saving model ...
Validation loss decreased (0.439377 --> 0.439363).  Saving model ...
Validation loss decreased (0.439363 --> 0.439348).  Saving model ...
Validation loss decreased (0.439348 --> 0.439334).  Saving model ...
Validation loss decreased (0.439334 --> 0.439320).  Saving model ...
Validation loss decreased (0.439320 --> 0.439306).  Saving model ...
Validation loss decreased (0.439306 --> 0.439291).  Saving model ...
Validation loss decreased (0.439291 --> 0.439277).  Saving model ...
Validation loss decreased (0.439277 --> 0.439263).  Saving model ...
Validation loss decreased (0.439263 --> 0.439249).  Saving model ...
Validation loss decreased (0.439249 --> 0.439234).  Saving model ...
Validation loss decreased (0.439234 --> 0.439220).  Saving model ...
Validation loss decreased (0.439220 --> 0.439206).  Saving model ...
Validation loss decreased (0.439206 --> 0.439192).  Saving model ...
Validation loss decreased (0.439192 --> 0.439178).  Saving model ...
Validation loss decreased (0.439178 --> 0.439163).  Saving model ...
Validation loss decreased (0.439163 --> 0.439149).  Saving model ...
Validation loss decreased (0.439149 --> 0.439135).  Saving model ...
Validation loss decreased (0.439135 --> 0.439121).  Saving model ...
Validation loss decreased (0.439121 --> 0.439107).  Saving model ...
Validation loss decreased (0.439107 --> 0.439093).  Saving model ...
Validation loss decreased (0.439093 --> 0.439079).  Saving model ...
Validation loss decreased (0.439079 --> 0.439064).  Saving model ...
Validation loss decreased (0.439064 --> 0.439050).  Saving model ...
Validation loss decreased (0.439050 --> 0.439036).  Saving model ...
Validation loss decreased (0.439036 --> 0.439022).  Saving model ...
Validation loss decreased (0.439022 --> 0.439008).  Saving model ...
Validation loss decreased (0.439008 --> 0.438994).  Saving model ...
Validation loss decreased (0.438994 --> 0.438980).  Saving model ...
Validation loss decreased (0.438980 --> 0.438966).  Saving model ...
Validation loss decreased (0.438966 --> 0.438952).  Saving model ...
Validation loss decreased (0.438952 --> 0.438938).  Saving model ...
Validation loss decreased (0.438938 --> 0.438924).  Saving model ...
epoch 2501, loss 0.4389, train acc 79.49%, f1 0.6891, precision 0.7348, recall 0.6488, auc 0.7612
Validation loss decreased (0.438924 --> 0.438910).  Saving model ...
Validation loss decreased (0.438910 --> 0.438896).  Saving model ...
Validation loss decreased (0.438896 --> 0.438882).  Saving model ...
Validation loss decreased (0.438882 --> 0.438868).  Saving model ...
Validation loss decreased (0.438868 --> 0.438854).  Saving model ...
Validation loss decreased (0.438854 --> 0.438840).  Saving model ...
Validation loss decreased (0.438840 --> 0.438826).  Saving model ...
Validation loss decreased (0.438826 --> 0.438812).  Saving model ...
Validation loss decreased (0.438812 --> 0.438798).  Saving model ...
Validation loss decreased (0.438798 --> 0.438784).  Saving model ...
Validation loss decreased (0.438784 --> 0.438770).  Saving model ...
Validation loss decreased (0.438770 --> 0.438756).  Saving model ...
Validation loss decreased (0.438756 --> 0.438742).  Saving model ...
Validation loss decreased (0.438742 --> 0.438728).  Saving model ...
Validation loss decreased (0.438728 --> 0.438714).  Saving model ...
Validation loss decreased (0.438714 --> 0.438701).  Saving model ...
Validation loss decreased (0.438701 --> 0.438687).  Saving model ...
Validation loss decreased (0.438687 --> 0.438673).  Saving model ...
Validation loss decreased (0.438673 --> 0.438659).  Saving model ...
Validation loss decreased (0.438659 --> 0.438645).  Saving model ...
Validation loss decreased (0.438645 --> 0.438631).  Saving model ...
Validation loss decreased (0.438631 --> 0.438617).  Saving model ...
Validation loss decreased (0.438617 --> 0.438603).  Saving model ...
Validation loss decreased (0.438603 --> 0.438590).  Saving model ...
Validation loss decreased (0.438590 --> 0.438576).  Saving model ...
Validation loss decreased (0.438576 --> 0.438562).  Saving model ...
Validation loss decreased (0.438562 --> 0.438548).  Saving model ...
Validation loss decreased (0.438548 --> 0.438534).  Saving model ...
Validation loss decreased (0.438534 --> 0.438520).  Saving model ...
Validation loss decreased (0.438520 --> 0.438507).  Saving model ...
Validation loss decreased (0.438507 --> 0.438493).  Saving model ...
Validation loss decreased (0.438493 --> 0.438479).  Saving model ...
Validation loss decreased (0.438479 --> 0.438465).  Saving model ...
Validation loss decreased (0.438465 --> 0.438451).  Saving model ...
Validation loss decreased (0.438451 --> 0.438438).  Saving model ...
Validation loss decreased (0.438438 --> 0.438424).  Saving model ...
Validation loss decreased (0.438424 --> 0.438410).  Saving model ...
Validation loss decreased (0.438410 --> 0.438396).  Saving model ...
Validation loss decreased (0.438396 --> 0.438382).  Saving model ...
Validation loss decreased (0.438382 --> 0.438369).  Saving model ...
Validation loss decreased (0.438369 --> 0.438355).  Saving model ...
Validation loss decreased (0.438355 --> 0.438341).  Saving model ...
Validation loss decreased (0.438341 --> 0.438327).  Saving model ...
Validation loss decreased (0.438327 --> 0.438314).  Saving model ...
Validation loss decreased (0.438314 --> 0.438300).  Saving model ...
Validation loss decreased (0.438300 --> 0.438286).  Saving model ...
Validation loss decreased (0.438286 --> 0.438272).  Saving model ...
Validation loss decreased (0.438272 --> 0.438258).  Saving model ...
Validation loss decreased (0.438258 --> 0.438245).  Saving model ...
Validation loss decreased (0.438245 --> 0.438231).  Saving model ...
Validation loss decreased (0.438231 --> 0.438217).  Saving model ...
Validation loss decreased (0.438217 --> 0.438204).  Saving model ...
Validation loss decreased (0.438204 --> 0.438190).  Saving model ...
Validation loss decreased (0.438190 --> 0.438176).  Saving model ...
Validation loss decreased (0.438176 --> 0.438162).  Saving model ...
Validation loss decreased (0.438162 --> 0.438149).  Saving model ...
Validation loss decreased (0.438149 --> 0.438135).  Saving model ...
Validation loss decreased (0.438135 --> 0.438121).  Saving model ...
Validation loss decreased (0.438121 --> 0.438107).  Saving model ...
Validation loss decreased (0.438107 --> 0.438094).  Saving model ...
Validation loss decreased (0.438094 --> 0.438080).  Saving model ...
Validation loss decreased (0.438080 --> 0.438066).  Saving model ...
Validation loss decreased (0.438066 --> 0.438052).  Saving model ...
Validation loss decreased (0.438052 --> 0.438039).  Saving model ...
Validation loss decreased (0.438039 --> 0.438025).  Saving model ...
Validation loss decreased (0.438025 --> 0.438011).  Saving model ...
Validation loss decreased (0.438011 --> 0.437998).  Saving model ...
Validation loss decreased (0.437998 --> 0.437984).  Saving model ...
Validation loss decreased (0.437984 --> 0.437970).  Saving model ...
Validation loss decreased (0.437970 --> 0.437956).  Saving model ...
Validation loss decreased (0.437956 --> 0.437943).  Saving model ...
Validation loss decreased (0.437943 --> 0.437929).  Saving model ...
Validation loss decreased (0.437929 --> 0.437915).  Saving model ...
Validation loss decreased (0.437915 --> 0.437901).  Saving model ...
Validation loss decreased (0.437901 --> 0.437888).  Saving model ...
Validation loss decreased (0.437888 --> 0.437874).  Saving model ...
Validation loss decreased (0.437874 --> 0.437860).  Saving model ...
Validation loss decreased (0.437860 --> 0.437846).  Saving model ...
Validation loss decreased (0.437846 --> 0.437833).  Saving model ...
Validation loss decreased (0.437833 --> 0.437819).  Saving model ...
Validation loss decreased (0.437819 --> 0.437805).  Saving model ...
Validation loss decreased (0.437805 --> 0.437791).  Saving model ...
Validation loss decreased (0.437791 --> 0.437778).  Saving model ...
Validation loss decreased (0.437778 --> 0.437764).  Saving model ...
Validation loss decreased (0.437764 --> 0.437750).  Saving model ...
Validation loss decreased (0.437750 --> 0.437736).  Saving model ...
Validation loss decreased (0.437736 --> 0.437723).  Saving model ...
Validation loss decreased (0.437723 --> 0.437709).  Saving model ...
Validation loss decreased (0.437709 --> 0.437695).  Saving model ...
Validation loss decreased (0.437695 --> 0.437681).  Saving model ...
Validation loss decreased (0.437681 --> 0.437668).  Saving model ...
Validation loss decreased (0.437668 --> 0.437654).  Saving model ...
Validation loss decreased (0.437654 --> 0.437640).  Saving model ...
Validation loss decreased (0.437640 --> 0.437626).  Saving model ...
Validation loss decreased (0.437626 --> 0.437613).  Saving model ...
Validation loss decreased (0.437613 --> 0.437599).  Saving model ...
Validation loss decreased (0.437599 --> 0.437585).  Saving model ...
Validation loss decreased (0.437585 --> 0.437571).  Saving model ...
Validation loss decreased (0.437571 --> 0.437557).  Saving model ...
Validation loss decreased (0.437557 --> 0.437544).  Saving model ...
epoch 2601, loss 0.4375, train acc 79.66%, f1 0.6909, precision 0.7389, recall 0.6488, auc 0.7625
Validation loss decreased (0.437544 --> 0.437530).  Saving model ...
Validation loss decreased (0.437530 --> 0.437516).  Saving model ...
Validation loss decreased (0.437516 --> 0.437502).  Saving model ...
Validation loss decreased (0.437502 --> 0.437488).  Saving model ...
Validation loss decreased (0.437488 --> 0.437475).  Saving model ...
Validation loss decreased (0.437475 --> 0.437461).  Saving model ...
Validation loss decreased (0.437461 --> 0.437447).  Saving model ...
Validation loss decreased (0.437447 --> 0.437433).  Saving model ...
Validation loss decreased (0.437433 --> 0.437419).  Saving model ...
Validation loss decreased (0.437419 --> 0.437405).  Saving model ...
Validation loss decreased (0.437405 --> 0.437391).  Saving model ...
Validation loss decreased (0.437391 --> 0.437378).  Saving model ...
Validation loss decreased (0.437378 --> 0.437364).  Saving model ...
Validation loss decreased (0.437364 --> 0.437350).  Saving model ...
Validation loss decreased (0.437350 --> 0.437336).  Saving model ...
Validation loss decreased (0.437336 --> 0.437322).  Saving model ...
Validation loss decreased (0.437322 --> 0.437308).  Saving model ...
Validation loss decreased (0.437308 --> 0.437294).  Saving model ...
Validation loss decreased (0.437294 --> 0.437280).  Saving model ...
Validation loss decreased (0.437280 --> 0.437267).  Saving model ...
Validation loss decreased (0.437267 --> 0.437253).  Saving model ...
Validation loss decreased (0.437253 --> 0.437239).  Saving model ...
Validation loss decreased (0.437239 --> 0.437225).  Saving model ...
Validation loss decreased (0.437225 --> 0.437211).  Saving model ...
Validation loss decreased (0.437211 --> 0.437197).  Saving model ...
Validation loss decreased (0.437197 --> 0.437183).  Saving model ...
Validation loss decreased (0.437183 --> 0.437169).  Saving model ...
Validation loss decreased (0.437169 --> 0.437155).  Saving model ...
Validation loss decreased (0.437155 --> 0.437141).  Saving model ...
Validation loss decreased (0.437141 --> 0.437127).  Saving model ...
Validation loss decreased (0.437127 --> 0.437113).  Saving model ...
Validation loss decreased (0.437113 --> 0.437099).  Saving model ...
Validation loss decreased (0.437099 --> 0.437085).  Saving model ...
Validation loss decreased (0.437085 --> 0.437071).  Saving model ...
Validation loss decreased (0.437071 --> 0.437057).  Saving model ...
Validation loss decreased (0.437057 --> 0.437043).  Saving model ...
Validation loss decreased (0.437043 --> 0.437029).  Saving model ...
Validation loss decreased (0.437029 --> 0.437015).  Saving model ...
Validation loss decreased (0.437015 --> 0.437001).  Saving model ...
Validation loss decreased (0.437001 --> 0.436987).  Saving model ...
Validation loss decreased (0.436987 --> 0.436973).  Saving model ...
Validation loss decreased (0.436973 --> 0.436959).  Saving model ...
Validation loss decreased (0.436959 --> 0.436944).  Saving model ...
Validation loss decreased (0.436944 --> 0.436930).  Saving model ...
Validation loss decreased (0.436930 --> 0.436916).  Saving model ...
Validation loss decreased (0.436916 --> 0.436902).  Saving model ...
Validation loss decreased (0.436902 --> 0.436888).  Saving model ...
Validation loss decreased (0.436888 --> 0.436874).  Saving model ...
Validation loss decreased (0.436874 --> 0.436860).  Saving model ...
Validation loss decreased (0.436860 --> 0.436845).  Saving model ...
Validation loss decreased (0.436845 --> 0.436831).  Saving model ...
Validation loss decreased (0.436831 --> 0.436817).  Saving model ...
Validation loss decreased (0.436817 --> 0.436803).  Saving model ...
Validation loss decreased (0.436803 --> 0.436789).  Saving model ...
Validation loss decreased (0.436789 --> 0.436775).  Saving model ...
Validation loss decreased (0.436775 --> 0.436760).  Saving model ...
Validation loss decreased (0.436760 --> 0.436746).  Saving model ...
Validation loss decreased (0.436746 --> 0.436732).  Saving model ...
Validation loss decreased (0.436732 --> 0.436718).  Saving model ...
Validation loss decreased (0.436718 --> 0.436703).  Saving model ...
Validation loss decreased (0.436703 --> 0.436689).  Saving model ...
Validation loss decreased (0.436689 --> 0.436675).  Saving model ...
Validation loss decreased (0.436675 --> 0.436660).  Saving model ...
Validation loss decreased (0.436660 --> 0.436646).  Saving model ...
Validation loss decreased (0.436646 --> 0.436632).  Saving model ...
Validation loss decreased (0.436632 --> 0.436617).  Saving model ...
Validation loss decreased (0.436617 --> 0.436603).  Saving model ...
Validation loss decreased (0.436603 --> 0.436589).  Saving model ...
Validation loss decreased (0.436589 --> 0.436574).  Saving model ...
Validation loss decreased (0.436574 --> 0.436560).  Saving model ...
Validation loss decreased (0.436560 --> 0.436546).  Saving model ...
Validation loss decreased (0.436546 --> 0.436531).  Saving model ...
Validation loss decreased (0.436531 --> 0.436517).  Saving model ...
Validation loss decreased (0.436517 --> 0.436502).  Saving model ...
Validation loss decreased (0.436502 --> 0.436488).  Saving model ...
Validation loss decreased (0.436488 --> 0.436474).  Saving model ...
Validation loss decreased (0.436474 --> 0.436459).  Saving model ...
Validation loss decreased (0.436459 --> 0.436445).  Saving model ...
Validation loss decreased (0.436445 --> 0.436430).  Saving model ...
Validation loss decreased (0.436430 --> 0.436416).  Saving model ...
Validation loss decreased (0.436416 --> 0.436401).  Saving model ...
Validation loss decreased (0.436401 --> 0.436387).  Saving model ...
Validation loss decreased (0.436387 --> 0.436372).  Saving model ...
Validation loss decreased (0.436372 --> 0.436358).  Saving model ...
Validation loss decreased (0.436358 --> 0.436343).  Saving model ...
Validation loss decreased (0.436343 --> 0.436328).  Saving model ...
Validation loss decreased (0.436328 --> 0.436314).  Saving model ...
Validation loss decreased (0.436314 --> 0.436299).  Saving model ...
Validation loss decreased (0.436299 --> 0.436285).  Saving model ...
Validation loss decreased (0.436285 --> 0.436270).  Saving model ...
Validation loss decreased (0.436270 --> 0.436255).  Saving model ...
Validation loss decreased (0.436255 --> 0.436241).  Saving model ...
Validation loss decreased (0.436241 --> 0.436226).  Saving model ...
Validation loss decreased (0.436226 --> 0.436211).  Saving model ...
Validation loss decreased (0.436211 --> 0.436197).  Saving model ...
Validation loss decreased (0.436197 --> 0.436182).  Saving model ...
Validation loss decreased (0.436182 --> 0.436167).  Saving model ...
Validation loss decreased (0.436167 --> 0.436153).  Saving model ...
Validation loss decreased (0.436153 --> 0.436138).  Saving model ...
Validation loss decreased (0.436138 --> 0.436123).  Saving model ...
epoch 2701, loss 0.4361, train acc 79.83%, f1 0.6927, precision 0.7430, recall 0.6488, auc 0.7639
Validation loss decreased (0.436123 --> 0.436108).  Saving model ...
Validation loss decreased (0.436108 --> 0.436094).  Saving model ...
Validation loss decreased (0.436094 --> 0.436079).  Saving model ...
Validation loss decreased (0.436079 --> 0.436064).  Saving model ...
Validation loss decreased (0.436064 --> 0.436049).  Saving model ...
Validation loss decreased (0.436049 --> 0.436035).  Saving model ...
Validation loss decreased (0.436035 --> 0.436020).  Saving model ...
Validation loss decreased (0.436020 --> 0.436005).  Saving model ...
Validation loss decreased (0.436005 --> 0.435990).  Saving model ...
Validation loss decreased (0.435990 --> 0.435975).  Saving model ...
Validation loss decreased (0.435975 --> 0.435960).  Saving model ...
Validation loss decreased (0.435960 --> 0.435945).  Saving model ...
Validation loss decreased (0.435945 --> 0.435930).  Saving model ...
Validation loss decreased (0.435930 --> 0.435916).  Saving model ...
Validation loss decreased (0.435916 --> 0.435901).  Saving model ...
Validation loss decreased (0.435901 --> 0.435886).  Saving model ...
Validation loss decreased (0.435886 --> 0.435871).  Saving model ...
Validation loss decreased (0.435871 --> 0.435856).  Saving model ...
Validation loss decreased (0.435856 --> 0.435841).  Saving model ...
Validation loss decreased (0.435841 --> 0.435826).  Saving model ...
Validation loss decreased (0.435826 --> 0.435811).  Saving model ...
Validation loss decreased (0.435811 --> 0.435796).  Saving model ...
Validation loss decreased (0.435796 --> 0.435781).  Saving model ...
Validation loss decreased (0.435781 --> 0.435766).  Saving model ...
Validation loss decreased (0.435766 --> 0.435751).  Saving model ...
Validation loss decreased (0.435751 --> 0.435736).  Saving model ...
Validation loss decreased (0.435736 --> 0.435721).  Saving model ...
Validation loss decreased (0.435721 --> 0.435706).  Saving model ...
Validation loss decreased (0.435706 --> 0.435690).  Saving model ...
Validation loss decreased (0.435690 --> 0.435675).  Saving model ...
Validation loss decreased (0.435675 --> 0.435660).  Saving model ...
Validation loss decreased (0.435660 --> 0.435645).  Saving model ...
Validation loss decreased (0.435645 --> 0.435630).  Saving model ...
Validation loss decreased (0.435630 --> 0.435615).  Saving model ...
Validation loss decreased (0.435615 --> 0.435600).  Saving model ...
Validation loss decreased (0.435600 --> 0.435584).  Saving model ...
Validation loss decreased (0.435584 --> 0.435569).  Saving model ...
Validation loss decreased (0.435569 --> 0.435554).  Saving model ...
Validation loss decreased (0.435554 --> 0.435539).  Saving model ...
Validation loss decreased (0.435539 --> 0.435524).  Saving model ...
Validation loss decreased (0.435524 --> 0.435508).  Saving model ...
Validation loss decreased (0.435508 --> 0.435493).  Saving model ...
Validation loss decreased (0.435493 --> 0.435478).  Saving model ...
Validation loss decreased (0.435478 --> 0.435463).  Saving model ...
Validation loss decreased (0.435463 --> 0.435447).  Saving model ...
Validation loss decreased (0.435447 --> 0.435432).  Saving model ...
Validation loss decreased (0.435432 --> 0.435417).  Saving model ...
Validation loss decreased (0.435417 --> 0.435402).  Saving model ...
Validation loss decreased (0.435402 --> 0.435386).  Saving model ...
Validation loss decreased (0.435386 --> 0.435371).  Saving model ...
Validation loss decreased (0.435371 --> 0.435356).  Saving model ...
Validation loss decreased (0.435356 --> 0.435340).  Saving model ...
Validation loss decreased (0.435340 --> 0.435325).  Saving model ...
Validation loss decreased (0.435325 --> 0.435309).  Saving model ...
Validation loss decreased (0.435309 --> 0.435294).  Saving model ...
Validation loss decreased (0.435294 --> 0.435279).  Saving model ...
Validation loss decreased (0.435279 --> 0.435263).  Saving model ...
Validation loss decreased (0.435263 --> 0.435248).  Saving model ...
Validation loss decreased (0.435248 --> 0.435233).  Saving model ...
Validation loss decreased (0.435233 --> 0.435217).  Saving model ...
Validation loss decreased (0.435217 --> 0.435202).  Saving model ...
Validation loss decreased (0.435202 --> 0.435186).  Saving model ...
Validation loss decreased (0.435186 --> 0.435171).  Saving model ...
Validation loss decreased (0.435171 --> 0.435155).  Saving model ...
Validation loss decreased (0.435155 --> 0.435140).  Saving model ...
Validation loss decreased (0.435140 --> 0.435124).  Saving model ...
Validation loss decreased (0.435124 --> 0.435109).  Saving model ...
Validation loss decreased (0.435109 --> 0.435093).  Saving model ...
Validation loss decreased (0.435093 --> 0.435078).  Saving model ...
Validation loss decreased (0.435078 --> 0.435062).  Saving model ...
Validation loss decreased (0.435062 --> 0.435047).  Saving model ...
Validation loss decreased (0.435047 --> 0.435031).  Saving model ...
Validation loss decreased (0.435031 --> 0.435016).  Saving model ...
Validation loss decreased (0.435016 --> 0.435000).  Saving model ...
Validation loss decreased (0.435000 --> 0.434985).  Saving model ...
Validation loss decreased (0.434985 --> 0.434969).  Saving model ...
Validation loss decreased (0.434969 --> 0.434954).  Saving model ...
Validation loss decreased (0.434954 --> 0.434938).  Saving model ...
Validation loss decreased (0.434938 --> 0.434922).  Saving model ...
Validation loss decreased (0.434922 --> 0.434907).  Saving model ...
Validation loss decreased (0.434907 --> 0.434891).  Saving model ...
Validation loss decreased (0.434891 --> 0.434876).  Saving model ...
Validation loss decreased (0.434876 --> 0.434860).  Saving model ...
Validation loss decreased (0.434860 --> 0.434844).  Saving model ...
Validation loss decreased (0.434844 --> 0.434829).  Saving model ...
Validation loss decreased (0.434829 --> 0.434813).  Saving model ...
Validation loss decreased (0.434813 --> 0.434797).  Saving model ...
Validation loss decreased (0.434797 --> 0.434782).  Saving model ...
Validation loss decreased (0.434782 --> 0.434766).  Saving model ...
Validation loss decreased (0.434766 --> 0.434750).  Saving model ...
Validation loss decreased (0.434750 --> 0.434735).  Saving model ...
Validation loss decreased (0.434735 --> 0.434719).  Saving model ...
Validation loss decreased (0.434719 --> 0.434703).  Saving model ...
Validation loss decreased (0.434703 --> 0.434688).  Saving model ...
Validation loss decreased (0.434688 --> 0.434672).  Saving model ...
Validation loss decreased (0.434672 --> 0.434656).  Saving model ...
Validation loss decreased (0.434656 --> 0.434641).  Saving model ...
Validation loss decreased (0.434641 --> 0.434625).  Saving model ...
Validation loss decreased (0.434625 --> 0.434609).  Saving model ...
Validation loss decreased (0.434609 --> 0.434593).  Saving model ...
epoch 2801, loss 0.4346, train acc 79.49%, f1 0.6875, precision 0.7374, recall 0.6439, auc 0.7601
Validation loss decreased (0.434593 --> 0.434578).  Saving model ...
Validation loss decreased (0.434578 --> 0.434562).  Saving model ...
Validation loss decreased (0.434562 --> 0.434546).  Saving model ...
Validation loss decreased (0.434546 --> 0.434530).  Saving model ...
Validation loss decreased (0.434530 --> 0.434515).  Saving model ...
Validation loss decreased (0.434515 --> 0.434499).  Saving model ...
Validation loss decreased (0.434499 --> 0.434483).  Saving model ...
Validation loss decreased (0.434483 --> 0.434467).  Saving model ...
Validation loss decreased (0.434467 --> 0.434452).  Saving model ...
Validation loss decreased (0.434452 --> 0.434436).  Saving model ...
Validation loss decreased (0.434436 --> 0.434420).  Saving model ...
Validation loss decreased (0.434420 --> 0.434404).  Saving model ...
Validation loss decreased (0.434404 --> 0.434389).  Saving model ...
Validation loss decreased (0.434389 --> 0.434373).  Saving model ...
Validation loss decreased (0.434373 --> 0.434357).  Saving model ...
Validation loss decreased (0.434357 --> 0.434341).  Saving model ...
Validation loss decreased (0.434341 --> 0.434325).  Saving model ...
Validation loss decreased (0.434325 --> 0.434310).  Saving model ...
Validation loss decreased (0.434310 --> 0.434294).  Saving model ...
Validation loss decreased (0.434294 --> 0.434278).  Saving model ...
Validation loss decreased (0.434278 --> 0.434262).  Saving model ...
Validation loss decreased (0.434262 --> 0.434246).  Saving model ...
Validation loss decreased (0.434246 --> 0.434231).  Saving model ...
Validation loss decreased (0.434231 --> 0.434215).  Saving model ...
Validation loss decreased (0.434215 --> 0.434199).  Saving model ...
Validation loss decreased (0.434199 --> 0.434183).  Saving model ...
Validation loss decreased (0.434183 --> 0.434167).  Saving model ...
Validation loss decreased (0.434167 --> 0.434152).  Saving model ...
Validation loss decreased (0.434152 --> 0.434136).  Saving model ...
Validation loss decreased (0.434136 --> 0.434120).  Saving model ...
Validation loss decreased (0.434120 --> 0.434104).  Saving model ...
Validation loss decreased (0.434104 --> 0.434088).  Saving model ...
Validation loss decreased (0.434088 --> 0.434072).  Saving model ...
Validation loss decreased (0.434072 --> 0.434057).  Saving model ...
Validation loss decreased (0.434057 --> 0.434041).  Saving model ...
Validation loss decreased (0.434041 --> 0.434025).  Saving model ...
Validation loss decreased (0.434025 --> 0.434009).  Saving model ...
Validation loss decreased (0.434009 --> 0.433993).  Saving model ...
Validation loss decreased (0.433993 --> 0.433977).  Saving model ...
Validation loss decreased (0.433977 --> 0.433962).  Saving model ...
Validation loss decreased (0.433962 --> 0.433946).  Saving model ...
Validation loss decreased (0.433946 --> 0.433930).  Saving model ...
Validation loss decreased (0.433930 --> 0.433914).  Saving model ...
Validation loss decreased (0.433914 --> 0.433898).  Saving model ...
Validation loss decreased (0.433898 --> 0.433882).  Saving model ...
Validation loss decreased (0.433882 --> 0.433867).  Saving model ...
Validation loss decreased (0.433867 --> 0.433851).  Saving model ...
Validation loss decreased (0.433851 --> 0.433835).  Saving model ...
Validation loss decreased (0.433835 --> 0.433819).  Saving model ...
Validation loss decreased (0.433819 --> 0.433803).  Saving model ...
Validation loss decreased (0.433803 --> 0.433787).  Saving model ...
Validation loss decreased (0.433787 --> 0.433772).  Saving model ...
Validation loss decreased (0.433772 --> 0.433756).  Saving model ...
Validation loss decreased (0.433756 --> 0.433740).  Saving model ...
Validation loss decreased (0.433740 --> 0.433724).  Saving model ...
Validation loss decreased (0.433724 --> 0.433708).  Saving model ...
Validation loss decreased (0.433708 --> 0.433692).  Saving model ...
Validation loss decreased (0.433692 --> 0.433677).  Saving model ...
Validation loss decreased (0.433677 --> 0.433661).  Saving model ...
Validation loss decreased (0.433661 --> 0.433645).  Saving model ...
Validation loss decreased (0.433645 --> 0.433629).  Saving model ...
Validation loss decreased (0.433629 --> 0.433613).  Saving model ...
Validation loss decreased (0.433613 --> 0.433597).  Saving model ...
Validation loss decreased (0.433597 --> 0.433582).  Saving model ...
Validation loss decreased (0.433582 --> 0.433566).  Saving model ...
Validation loss decreased (0.433566 --> 0.433550).  Saving model ...
Validation loss decreased (0.433550 --> 0.433534).  Saving model ...
Validation loss decreased (0.433534 --> 0.433518).  Saving model ...
Validation loss decreased (0.433518 --> 0.433502).  Saving model ...
Validation loss decreased (0.433502 --> 0.433487).  Saving model ...
Validation loss decreased (0.433487 --> 0.433471).  Saving model ...
Validation loss decreased (0.433471 --> 0.433455).  Saving model ...
Validation loss decreased (0.433455 --> 0.433439).  Saving model ...
Validation loss decreased (0.433439 --> 0.433423).  Saving model ...
Validation loss decreased (0.433423 --> 0.433407).  Saving model ...
Validation loss decreased (0.433407 --> 0.433392).  Saving model ...
Validation loss decreased (0.433392 --> 0.433376).  Saving model ...
Validation loss decreased (0.433376 --> 0.433360).  Saving model ...
Validation loss decreased (0.433360 --> 0.433344).  Saving model ...
Validation loss decreased (0.433344 --> 0.433328).  Saving model ...
Validation loss decreased (0.433328 --> 0.433313).  Saving model ...
Validation loss decreased (0.433313 --> 0.433297).  Saving model ...
Validation loss decreased (0.433297 --> 0.433281).  Saving model ...
Validation loss decreased (0.433281 --> 0.433265).  Saving model ...
Validation loss decreased (0.433265 --> 0.433249).  Saving model ...
Validation loss decreased (0.433249 --> 0.433234).  Saving model ...
Validation loss decreased (0.433234 --> 0.433218).  Saving model ...
Validation loss decreased (0.433218 --> 0.433202).  Saving model ...
Validation loss decreased (0.433202 --> 0.433186).  Saving model ...
Validation loss decreased (0.433186 --> 0.433170).  Saving model ...
Validation loss decreased (0.433170 --> 0.433155).  Saving model ...
Validation loss decreased (0.433155 --> 0.433139).  Saving model ...
Validation loss decreased (0.433139 --> 0.433123).  Saving model ...
Validation loss decreased (0.433123 --> 0.433107).  Saving model ...
Validation loss decreased (0.433107 --> 0.433092).  Saving model ...
Validation loss decreased (0.433092 --> 0.433076).  Saving model ...
Validation loss decreased (0.433076 --> 0.433060).  Saving model ...
Validation loss decreased (0.433060 --> 0.433044).  Saving model ...
Validation loss decreased (0.433044 --> 0.433029).  Saving model ...
Validation loss decreased (0.433029 --> 0.433013).  Saving model ...
epoch 2901, loss 0.4330, train acc 79.49%, f1 0.6875, precision 0.7374, recall 0.6439, auc 0.7601
Validation loss decreased (0.433013 --> 0.432997).  Saving model ...
Validation loss decreased (0.432997 --> 0.432981).  Saving model ...
Validation loss decreased (0.432981 --> 0.432966).  Saving model ...
Validation loss decreased (0.432966 --> 0.432950).  Saving model ...
Validation loss decreased (0.432950 --> 0.432934).  Saving model ...
Validation loss decreased (0.432934 --> 0.432918).  Saving model ...
Validation loss decreased (0.432918 --> 0.432903).  Saving model ...
Validation loss decreased (0.432903 --> 0.432887).  Saving model ...
Validation loss decreased (0.432887 --> 0.432871).  Saving model ...
Validation loss decreased (0.432871 --> 0.432855).  Saving model ...
Validation loss decreased (0.432855 --> 0.432840).  Saving model ...
Validation loss decreased (0.432840 --> 0.432824).  Saving model ...
Validation loss decreased (0.432824 --> 0.432808).  Saving model ...
Validation loss decreased (0.432808 --> 0.432792).  Saving model ...
Validation loss decreased (0.432792 --> 0.432777).  Saving model ...
Validation loss decreased (0.432777 --> 0.432761).  Saving model ...
Validation loss decreased (0.432761 --> 0.432745).  Saving model ...
Validation loss decreased (0.432745 --> 0.432730).  Saving model ...
Validation loss decreased (0.432730 --> 0.432714).  Saving model ...
Validation loss decreased (0.432714 --> 0.432698).  Saving model ...
Validation loss decreased (0.432698 --> 0.432683).  Saving model ...
Validation loss decreased (0.432683 --> 0.432667).  Saving model ...
Validation loss decreased (0.432667 --> 0.432651).  Saving model ...
Validation loss decreased (0.432651 --> 0.432635).  Saving model ...
Validation loss decreased (0.432635 --> 0.432620).  Saving model ...
Validation loss decreased (0.432620 --> 0.432604).  Saving model ...
Validation loss decreased (0.432604 --> 0.432588).  Saving model ...
Validation loss decreased (0.432588 --> 0.432573).  Saving model ...
Validation loss decreased (0.432573 --> 0.432557).  Saving model ...
Validation loss decreased (0.432557 --> 0.432541).  Saving model ...
Validation loss decreased (0.432541 --> 0.432526).  Saving model ...
Validation loss decreased (0.432526 --> 0.432510).  Saving model ...
Validation loss decreased (0.432510 --> 0.432494).  Saving model ...
Validation loss decreased (0.432494 --> 0.432479).  Saving model ...
Validation loss decreased (0.432479 --> 0.432463).  Saving model ...
Validation loss decreased (0.432463 --> 0.432447).  Saving model ...
Validation loss decreased (0.432447 --> 0.432432).  Saving model ...
Validation loss decreased (0.432432 --> 0.432416).  Saving model ...
Validation loss decreased (0.432416 --> 0.432401).  Saving model ...
Validation loss decreased (0.432401 --> 0.432385).  Saving model ...
Validation loss decreased (0.432385 --> 0.432369).  Saving model ...
Validation loss decreased (0.432369 --> 0.432354).  Saving model ...
Validation loss decreased (0.432354 --> 0.432338).  Saving model ...
Validation loss decreased (0.432338 --> 0.432322).  Saving model ...
Validation loss decreased (0.432322 --> 0.432307).  Saving model ...
Validation loss decreased (0.432307 --> 0.432291).  Saving model ...
Validation loss decreased (0.432291 --> 0.432276).  Saving model ...
Validation loss decreased (0.432276 --> 0.432260).  Saving model ...
Validation loss decreased (0.432260 --> 0.432244).  Saving model ...
Validation loss decreased (0.432244 --> 0.432229).  Saving model ...
Validation loss decreased (0.432229 --> 0.432213).  Saving model ...
Validation loss decreased (0.432213 --> 0.432198).  Saving model ...
Validation loss decreased (0.432198 --> 0.432182).  Saving model ...
Validation loss decreased (0.432182 --> 0.432166).  Saving model ...
Validation loss decreased (0.432166 --> 0.432151).  Saving model ...
Validation loss decreased (0.432151 --> 0.432135).  Saving model ...
Validation loss decreased (0.432135 --> 0.432120).  Saving model ...
Validation loss decreased (0.432120 --> 0.432104).  Saving model ...
Validation loss decreased (0.432104 --> 0.432088).  Saving model ...
Validation loss decreased (0.432088 --> 0.432073).  Saving model ...
Validation loss decreased (0.432073 --> 0.432057).  Saving model ...
Validation loss decreased (0.432057 --> 0.432042).  Saving model ...
Validation loss decreased (0.432042 --> 0.432026).  Saving model ...
Validation loss decreased (0.432026 --> 0.432011).  Saving model ...
Validation loss decreased (0.432011 --> 0.431995).  Saving model ...
Validation loss decreased (0.431995 --> 0.431980).  Saving model ...
Validation loss decreased (0.431980 --> 0.431964).  Saving model ...
Validation loss decreased (0.431964 --> 0.431948).  Saving model ...
Validation loss decreased (0.431948 --> 0.431933).  Saving model ...
Validation loss decreased (0.431933 --> 0.431917).  Saving model ...
Validation loss decreased (0.431917 --> 0.431902).  Saving model ...
Validation loss decreased (0.431902 --> 0.431886).  Saving model ...
Validation loss decreased (0.431886 --> 0.431871).  Saving model ...
Validation loss decreased (0.431871 --> 0.431855).  Saving model ...
Validation loss decreased (0.431855 --> 0.431840).  Saving model ...
Validation loss decreased (0.431840 --> 0.431824).  Saving model ...
Validation loss decreased (0.431824 --> 0.431809).  Saving model ...
Validation loss decreased (0.431809 --> 0.431793).  Saving model ...
Validation loss decreased (0.431793 --> 0.431777).  Saving model ...
Validation loss decreased (0.431777 --> 0.431762).  Saving model ...
Validation loss decreased (0.431762 --> 0.431746).  Saving model ...
Validation loss decreased (0.431746 --> 0.431731).  Saving model ...
Validation loss decreased (0.431731 --> 0.431715).  Saving model ...
Validation loss decreased (0.431715 --> 0.431700).  Saving model ...
Validation loss decreased (0.431700 --> 0.431684).  Saving model ...
Validation loss decreased (0.431684 --> 0.431669).  Saving model ...
Validation loss decreased (0.431669 --> 0.431653).  Saving model ...
Validation loss decreased (0.431653 --> 0.431638).  Saving model ...
Validation loss decreased (0.431638 --> 0.431622).  Saving model ...
Validation loss decreased (0.431622 --> 0.431607).  Saving model ...
Validation loss decreased (0.431607 --> 0.431591).  Saving model ...
Validation loss decreased (0.431591 --> 0.431576).  Saving model ...
Validation loss decreased (0.431576 --> 0.431560).  Saving model ...
Validation loss decreased (0.431560 --> 0.431545).  Saving model ...
Validation loss decreased (0.431545 --> 0.431529).  Saving model ...
Validation loss decreased (0.431529 --> 0.431514).  Saving model ...
Validation loss decreased (0.431514 --> 0.431498).  Saving model ...
Validation loss decreased (0.431498 --> 0.431483).  Saving model ...
Validation loss decreased (0.431483 --> 0.431467).  Saving model ...
Validation loss decreased (0.431467 --> 0.431452).  Saving model ...
epoch 3001, loss 0.4315, train acc 79.83%, f1 0.6927, precision 0.7430, recall 0.6488, auc 0.7639
Validation loss decreased (0.431452 --> 0.431436).  Saving model ...
Validation loss decreased (0.431436 --> 0.431421).  Saving model ...
Validation loss decreased (0.431421 --> 0.431405).  Saving model ...
Validation loss decreased (0.431405 --> 0.431390).  Saving model ...
Validation loss decreased (0.431390 --> 0.431374).  Saving model ...
Validation loss decreased (0.431374 --> 0.431359).  Saving model ...
Validation loss decreased (0.431359 --> 0.431344).  Saving model ...
Validation loss decreased (0.431344 --> 0.431328).  Saving model ...
Validation loss decreased (0.431328 --> 0.431313).  Saving model ...
Validation loss decreased (0.431313 --> 0.431297).  Saving model ...
Validation loss decreased (0.431297 --> 0.431282).  Saving model ...
Validation loss decreased (0.431282 --> 0.431266).  Saving model ...
Validation loss decreased (0.431266 --> 0.431251).  Saving model ...
Validation loss decreased (0.431251 --> 0.431235).  Saving model ...
Validation loss decreased (0.431235 --> 0.431220).  Saving model ...
Validation loss decreased (0.431220 --> 0.431204).  Saving model ...
Validation loss decreased (0.431204 --> 0.431189).  Saving model ...
Validation loss decreased (0.431189 --> 0.431173).  Saving model ...
Validation loss decreased (0.431173 --> 0.431158).  Saving model ...
Validation loss decreased (0.431158 --> 0.431143).  Saving model ...
Validation loss decreased (0.431143 --> 0.431127).  Saving model ...
Validation loss decreased (0.431127 --> 0.431112).  Saving model ...
Validation loss decreased (0.431112 --> 0.431096).  Saving model ...
Validation loss decreased (0.431096 --> 0.431081).  Saving model ...
Validation loss decreased (0.431081 --> 0.431065).  Saving model ...
Validation loss decreased (0.431065 --> 0.431050).  Saving model ...
Validation loss decreased (0.431050 --> 0.431034).  Saving model ...
Validation loss decreased (0.431034 --> 0.431019).  Saving model ...
Validation loss decreased (0.431019 --> 0.431004).  Saving model ...
Validation loss decreased (0.431004 --> 0.430988).  Saving model ...
Validation loss decreased (0.430988 --> 0.430973).  Saving model ...
Validation loss decreased (0.430973 --> 0.430957).  Saving model ...
Validation loss decreased (0.430957 --> 0.430942).  Saving model ...
Validation loss decreased (0.430942 --> 0.430926).  Saving model ...
Validation loss decreased (0.430926 --> 0.430911).  Saving model ...
Validation loss decreased (0.430911 --> 0.430895).  Saving model ...
Validation loss decreased (0.430895 --> 0.430880).  Saving model ...
Validation loss decreased (0.430880 --> 0.430865).  Saving model ...
Validation loss decreased (0.430865 --> 0.430849).  Saving model ...
Validation loss decreased (0.430849 --> 0.430834).  Saving model ...
Validation loss decreased (0.430834 --> 0.430818).  Saving model ...
Validation loss decreased (0.430818 --> 0.430803).  Saving model ...
Validation loss decreased (0.430803 --> 0.430788).  Saving model ...
Validation loss decreased (0.430788 --> 0.430772).  Saving model ...
Validation loss decreased (0.430772 --> 0.430757).  Saving model ...
Validation loss decreased (0.430757 --> 0.430741).  Saving model ...
Validation loss decreased (0.430741 --> 0.430726).  Saving model ...
Validation loss decreased (0.430726 --> 0.430710).  Saving model ...
Validation loss decreased (0.430710 --> 0.430695).  Saving model ...
Validation loss decreased (0.430695 --> 0.430680).  Saving model ...
Validation loss decreased (0.430680 --> 0.430664).  Saving model ...
Validation loss decreased (0.430664 --> 0.430649).  Saving model ...
Validation loss decreased (0.430649 --> 0.430633).  Saving model ...
Validation loss decreased (0.430633 --> 0.430618).  Saving model ...
Validation loss decreased (0.430618 --> 0.430602).  Saving model ...
Validation loss decreased (0.430602 --> 0.430587).  Saving model ...
Validation loss decreased (0.430587 --> 0.430572).  Saving model ...
Validation loss decreased (0.430572 --> 0.430556).  Saving model ...
Validation loss decreased (0.430556 --> 0.430541).  Saving model ...
Validation loss decreased (0.430541 --> 0.430525).  Saving model ...
Validation loss decreased (0.430525 --> 0.430510).  Saving model ...
Validation loss decreased (0.430510 --> 0.430495).  Saving model ...
Validation loss decreased (0.430495 --> 0.430479).  Saving model ...
Validation loss decreased (0.430479 --> 0.430464).  Saving model ...
Validation loss decreased (0.430464 --> 0.430448).  Saving model ...
Validation loss decreased (0.430448 --> 0.430433).  Saving model ...
Validation loss decreased (0.430433 --> 0.430417).  Saving model ...
Validation loss decreased (0.430417 --> 0.430402).  Saving model ...
Validation loss decreased (0.430402 --> 0.430387).  Saving model ...
Validation loss decreased (0.430387 --> 0.430371).  Saving model ...
Validation loss decreased (0.430371 --> 0.430356).  Saving model ...
Validation loss decreased (0.430356 --> 0.430340).  Saving model ...
Validation loss decreased (0.430340 --> 0.430325).  Saving model ...
Validation loss decreased (0.430325 --> 0.430310).  Saving model ...
Validation loss decreased (0.430310 --> 0.430294).  Saving model ...
Validation loss decreased (0.430294 --> 0.430279).  Saving model ...
Validation loss decreased (0.430279 --> 0.430263).  Saving model ...
Validation loss decreased (0.430263 --> 0.430248).  Saving model ...
Validation loss decreased (0.430248 --> 0.430232).  Saving model ...
Validation loss decreased (0.430232 --> 0.430217).  Saving model ...
Validation loss decreased (0.430217 --> 0.430202).  Saving model ...
Validation loss decreased (0.430202 --> 0.430186).  Saving model ...
Validation loss decreased (0.430186 --> 0.430171).  Saving model ...
Validation loss decreased (0.430171 --> 0.430155).  Saving model ...
Validation loss decreased (0.430155 --> 0.430140).  Saving model ...
Validation loss decreased (0.430140 --> 0.430125).  Saving model ...
Validation loss decreased (0.430125 --> 0.430109).  Saving model ...
Validation loss decreased (0.430109 --> 0.430094).  Saving model ...
Validation loss decreased (0.430094 --> 0.430078).  Saving model ...
Validation loss decreased (0.430078 --> 0.430063).  Saving model ...
Validation loss decreased (0.430063 --> 0.430048).  Saving model ...
Validation loss decreased (0.430048 --> 0.430032).  Saving model ...
Validation loss decreased (0.430032 --> 0.430017).  Saving model ...
Validation loss decreased (0.430017 --> 0.430001).  Saving model ...
Validation loss decreased (0.430001 --> 0.429986).  Saving model ...
Validation loss decreased (0.429986 --> 0.429971).  Saving model ...
Validation loss decreased (0.429971 --> 0.429955).  Saving model ...
Validation loss decreased (0.429955 --> 0.429940).  Saving model ...
Validation loss decreased (0.429940 --> 0.429924).  Saving model ...
Validation loss decreased (0.429924 --> 0.429909).  Saving model ...
epoch 3101, loss 0.4299, train acc 80.00%, f1 0.6945, precision 0.7472, recall 0.6488, auc 0.7652
Validation loss decreased (0.429909 --> 0.429893).  Saving model ...
Validation loss decreased (0.429893 --> 0.429878).  Saving model ...
Validation loss decreased (0.429878 --> 0.429863).  Saving model ...
Validation loss decreased (0.429863 --> 0.429847).  Saving model ...
Validation loss decreased (0.429847 --> 0.429832).  Saving model ...
Validation loss decreased (0.429832 --> 0.429816).  Saving model ...
Validation loss decreased (0.429816 --> 0.429801).  Saving model ...
Validation loss decreased (0.429801 --> 0.429786).  Saving model ...
Validation loss decreased (0.429786 --> 0.429770).  Saving model ...
Validation loss decreased (0.429770 --> 0.429755).  Saving model ...
Validation loss decreased (0.429755 --> 0.429739).  Saving model ...
Validation loss decreased (0.429739 --> 0.429724).  Saving model ...
Validation loss decreased (0.429724 --> 0.429708).  Saving model ...
Validation loss decreased (0.429708 --> 0.429693).  Saving model ...
Validation loss decreased (0.429693 --> 0.429678).  Saving model ...
Validation loss decreased (0.429678 --> 0.429662).  Saving model ...
Validation loss decreased (0.429662 --> 0.429647).  Saving model ...
Validation loss decreased (0.429647 --> 0.429631).  Saving model ...
Validation loss decreased (0.429631 --> 0.429616).  Saving model ...
Validation loss decreased (0.429616 --> 0.429600).  Saving model ...
Validation loss decreased (0.429600 --> 0.429585).  Saving model ...
Validation loss decreased (0.429585 --> 0.429570).  Saving model ...
Validation loss decreased (0.429570 --> 0.429554).  Saving model ...
Validation loss decreased (0.429554 --> 0.429539).  Saving model ...
Validation loss decreased (0.429539 --> 0.429523).  Saving model ...
Validation loss decreased (0.429523 --> 0.429508).  Saving model ...
Validation loss decreased (0.429508 --> 0.429492).  Saving model ...
Validation loss decreased (0.429492 --> 0.429477).  Saving model ...
Validation loss decreased (0.429477 --> 0.429462).  Saving model ...
Validation loss decreased (0.429462 --> 0.429446).  Saving model ...
Validation loss decreased (0.429446 --> 0.429431).  Saving model ...
Validation loss decreased (0.429431 --> 0.429415).  Saving model ...
Validation loss decreased (0.429415 --> 0.429400).  Saving model ...
Validation loss decreased (0.429400 --> 0.429384).  Saving model ...
Validation loss decreased (0.429384 --> 0.429369).  Saving model ...
Validation loss decreased (0.429369 --> 0.429353).  Saving model ...
Validation loss decreased (0.429353 --> 0.429338).  Saving model ...
Validation loss decreased (0.429338 --> 0.429323).  Saving model ...
Validation loss decreased (0.429323 --> 0.429307).  Saving model ...
Validation loss decreased (0.429307 --> 0.429292).  Saving model ...
Validation loss decreased (0.429292 --> 0.429276).  Saving model ...
Validation loss decreased (0.429276 --> 0.429261).  Saving model ...
Validation loss decreased (0.429261 --> 0.429245).  Saving model ...
Validation loss decreased (0.429245 --> 0.429230).  Saving model ...
Validation loss decreased (0.429230 --> 0.429214).  Saving model ...
Validation loss decreased (0.429214 --> 0.429199).  Saving model ...
Validation loss decreased (0.429199 --> 0.429184).  Saving model ...
Validation loss decreased (0.429184 --> 0.429168).  Saving model ...
Validation loss decreased (0.429168 --> 0.429153).  Saving model ...
Validation loss decreased (0.429153 --> 0.429137).  Saving model ...
Validation loss decreased (0.429137 --> 0.429122).  Saving model ...
Validation loss decreased (0.429122 --> 0.429106).  Saving model ...
Validation loss decreased (0.429106 --> 0.429091).  Saving model ...
Validation loss decreased (0.429091 --> 0.429075).  Saving model ...
Validation loss decreased (0.429075 --> 0.429060).  Saving model ...
Validation loss decreased (0.429060 --> 0.429044).  Saving model ...
Validation loss decreased (0.429044 --> 0.429029).  Saving model ...
Validation loss decreased (0.429029 --> 0.429013).  Saving model ...
Validation loss decreased (0.429013 --> 0.428998).  Saving model ...
Validation loss decreased (0.428998 --> 0.428982).  Saving model ...
Validation loss decreased (0.428982 --> 0.428967).  Saving model ...
Validation loss decreased (0.428967 --> 0.428951).  Saving model ...
Validation loss decreased (0.428951 --> 0.428936).  Saving model ...
Validation loss decreased (0.428936 --> 0.428920).  Saving model ...
Validation loss decreased (0.428920 --> 0.428905).  Saving model ...
Validation loss decreased (0.428905 --> 0.428889).  Saving model ...
Validation loss decreased (0.428889 --> 0.428874).  Saving model ...
Validation loss decreased (0.428874 --> 0.428858).  Saving model ...
Validation loss decreased (0.428858 --> 0.428843).  Saving model ...
Validation loss decreased (0.428843 --> 0.428827).  Saving model ...
Validation loss decreased (0.428827 --> 0.428812).  Saving model ...
Validation loss decreased (0.428812 --> 0.428796).  Saving model ...
Validation loss decreased (0.428796 --> 0.428781).  Saving model ...
Validation loss decreased (0.428781 --> 0.428765).  Saving model ...
Validation loss decreased (0.428765 --> 0.428750).  Saving model ...
Validation loss decreased (0.428750 --> 0.428734).  Saving model ...
Validation loss decreased (0.428734 --> 0.428719).  Saving model ...
Validation loss decreased (0.428719 --> 0.428703).  Saving model ...
Validation loss decreased (0.428703 --> 0.428688).  Saving model ...
Validation loss decreased (0.428688 --> 0.428672).  Saving model ...
Validation loss decreased (0.428672 --> 0.428657).  Saving model ...
Validation loss decreased (0.428657 --> 0.428641).  Saving model ...
Validation loss decreased (0.428641 --> 0.428626).  Saving model ...
Validation loss decreased (0.428626 --> 0.428610).  Saving model ...
Validation loss decreased (0.428610 --> 0.428595).  Saving model ...
Validation loss decreased (0.428595 --> 0.428579).  Saving model ...
Validation loss decreased (0.428579 --> 0.428564).  Saving model ...
Validation loss decreased (0.428564 --> 0.428548).  Saving model ...
Validation loss decreased (0.428548 --> 0.428533).  Saving model ...
Validation loss decreased (0.428533 --> 0.428517).  Saving model ...
Validation loss decreased (0.428517 --> 0.428501).  Saving model ...
Validation loss decreased (0.428501 --> 0.428486).  Saving model ...
Validation loss decreased (0.428486 --> 0.428470).  Saving model ...
Validation loss decreased (0.428470 --> 0.428455).  Saving model ...
Validation loss decreased (0.428455 --> 0.428439).  Saving model ...
Validation loss decreased (0.428439 --> 0.428424).  Saving model ...
Validation loss decreased (0.428424 --> 0.428408).  Saving model ...
Validation loss decreased (0.428408 --> 0.428392).  Saving model ...
Validation loss decreased (0.428392 --> 0.428377).  Saving model ...
Validation loss decreased (0.428377 --> 0.428361).  Saving model ...
epoch 3201, loss 0.4284, train acc 80.17%, f1 0.6963, precision 0.7514, recall 0.6488, auc 0.7665
Validation loss decreased (0.428361 --> 0.428346).  Saving model ...
Validation loss decreased (0.428346 --> 0.428330).  Saving model ...
Validation loss decreased (0.428330 --> 0.428315).  Saving model ...
Validation loss decreased (0.428315 --> 0.428299).  Saving model ...
Validation loss decreased (0.428299 --> 0.428283).  Saving model ...
Validation loss decreased (0.428283 --> 0.428268).  Saving model ...
Validation loss decreased (0.428268 --> 0.428252).  Saving model ...
Validation loss decreased (0.428252 --> 0.428236).  Saving model ...
Validation loss decreased (0.428236 --> 0.428221).  Saving model ...
Validation loss decreased (0.428221 --> 0.428205).  Saving model ...
Validation loss decreased (0.428205 --> 0.428190).  Saving model ...
Validation loss decreased (0.428190 --> 0.428174).  Saving model ...
Validation loss decreased (0.428174 --> 0.428158).  Saving model ...
Validation loss decreased (0.428158 --> 0.428143).  Saving model ...
Validation loss decreased (0.428143 --> 0.428127).  Saving model ...
Validation loss decreased (0.428127 --> 0.428111).  Saving model ...
Validation loss decreased (0.428111 --> 0.428096).  Saving model ...
Validation loss decreased (0.428096 --> 0.428080).  Saving model ...
Validation loss decreased (0.428080 --> 0.428064).  Saving model ...
Validation loss decreased (0.428064 --> 0.428049).  Saving model ...
Validation loss decreased (0.428049 --> 0.428033).  Saving model ...
Validation loss decreased (0.428033 --> 0.428017).  Saving model ...
Validation loss decreased (0.428017 --> 0.428002).  Saving model ...
Validation loss decreased (0.428002 --> 0.427986).  Saving model ...
Validation loss decreased (0.427986 --> 0.427970).  Saving model ...
Validation loss decreased (0.427970 --> 0.427955).  Saving model ...
Validation loss decreased (0.427955 --> 0.427939).  Saving model ...
Validation loss decreased (0.427939 --> 0.427923).  Saving model ...
Validation loss decreased (0.427923 --> 0.427908).  Saving model ...
Validation loss decreased (0.427908 --> 0.427892).  Saving model ...
Validation loss decreased (0.427892 --> 0.427876).  Saving model ...
Validation loss decreased (0.427876 --> 0.427860).  Saving model ...
Validation loss decreased (0.427860 --> 0.427845).  Saving model ...
Validation loss decreased (0.427845 --> 0.427829).  Saving model ...
Validation loss decreased (0.427829 --> 0.427813).  Saving model ...
Validation loss decreased (0.427813 --> 0.427798).  Saving model ...
Validation loss decreased (0.427798 --> 0.427782).  Saving model ...
Validation loss decreased (0.427782 --> 0.427766).  Saving model ...
Validation loss decreased (0.427766 --> 0.427750).  Saving model ...
Validation loss decreased (0.427750 --> 0.427735).  Saving model ...
Validation loss decreased (0.427735 --> 0.427719).  Saving model ...
Validation loss decreased (0.427719 --> 0.427703).  Saving model ...
Validation loss decreased (0.427703 --> 0.427687).  Saving model ...
Validation loss decreased (0.427687 --> 0.427671).  Saving model ...
Validation loss decreased (0.427671 --> 0.427656).  Saving model ...
Validation loss decreased (0.427656 --> 0.427640).  Saving model ...
Validation loss decreased (0.427640 --> 0.427624).  Saving model ...
Validation loss decreased (0.427624 --> 0.427608).  Saving model ...
Validation loss decreased (0.427608 --> 0.427592).  Saving model ...
Validation loss decreased (0.427592 --> 0.427577).  Saving model ...
Validation loss decreased (0.427577 --> 0.427561).  Saving model ...
Validation loss decreased (0.427561 --> 0.427545).  Saving model ...
Validation loss decreased (0.427545 --> 0.427529).  Saving model ...
Validation loss decreased (0.427529 --> 0.427513).  Saving model ...
Validation loss decreased (0.427513 --> 0.427497).  Saving model ...
Validation loss decreased (0.427497 --> 0.427481).  Saving model ...
Validation loss decreased (0.427481 --> 0.427466).  Saving model ...
Validation loss decreased (0.427466 --> 0.427450).  Saving model ...
Validation loss decreased (0.427450 --> 0.427434).  Saving model ...
Validation loss decreased (0.427434 --> 0.427418).  Saving model ...
Validation loss decreased (0.427418 --> 0.427402).  Saving model ...
Validation loss decreased (0.427402 --> 0.427386).  Saving model ...
Validation loss decreased (0.427386 --> 0.427370).  Saving model ...
Validation loss decreased (0.427370 --> 0.427354).  Saving model ...
Validation loss decreased (0.427354 --> 0.427338).  Saving model ...
Validation loss decreased (0.427338 --> 0.427322).  Saving model ...
Validation loss decreased (0.427322 --> 0.427306).  Saving model ...
Validation loss decreased (0.427306 --> 0.427290).  Saving model ...
Validation loss decreased (0.427290 --> 0.427274).  Saving model ...
Validation loss decreased (0.427274 --> 0.427258).  Saving model ...
Validation loss decreased (0.427258 --> 0.427242).  Saving model ...
Validation loss decreased (0.427242 --> 0.427226).  Saving model ...
Validation loss decreased (0.427226 --> 0.427210).  Saving model ...
Validation loss decreased (0.427210 --> 0.427194).  Saving model ...
Validation loss decreased (0.427194 --> 0.427178).  Saving model ...
Validation loss decreased (0.427178 --> 0.427162).  Saving model ...
Validation loss decreased (0.427162 --> 0.427146).  Saving model ...
Validation loss decreased (0.427146 --> 0.427130).  Saving model ...
Validation loss decreased (0.427130 --> 0.427114).  Saving model ...
Validation loss decreased (0.427114 --> 0.427098).  Saving model ...
Validation loss decreased (0.427098 --> 0.427082).  Saving model ...
Validation loss decreased (0.427082 --> 0.427066).  Saving model ...
Validation loss decreased (0.427066 --> 0.427050).  Saving model ...
Validation loss decreased (0.427050 --> 0.427034).  Saving model ...
Validation loss decreased (0.427034 --> 0.427018).  Saving model ...
Validation loss decreased (0.427018 --> 0.427002).  Saving model ...
Validation loss decreased (0.427002 --> 0.426985).  Saving model ...
Validation loss decreased (0.426985 --> 0.426969).  Saving model ...
Validation loss decreased (0.426969 --> 0.426953).  Saving model ...
Validation loss decreased (0.426953 --> 0.426937).  Saving model ...
Validation loss decreased (0.426937 --> 0.426921).  Saving model ...
Validation loss decreased (0.426921 --> 0.426905).  Saving model ...
Validation loss decreased (0.426905 --> 0.426888).  Saving model ...
Validation loss decreased (0.426888 --> 0.426872).  Saving model ...
Validation loss decreased (0.426872 --> 0.426856).  Saving model ...
Validation loss decreased (0.426856 --> 0.426840).  Saving model ...
Validation loss decreased (0.426840 --> 0.426823).  Saving model ...
Validation loss decreased (0.426823 --> 0.426807).  Saving model ...
Validation loss decreased (0.426807 --> 0.426791).  Saving model ...
Validation loss decreased (0.426791 --> 0.426775).  Saving model ...
epoch 3301, loss 0.4268, train acc 80.17%, f1 0.6963, precision 0.7514, recall 0.6488, auc 0.7665
Validation loss decreased (0.426775 --> 0.426758).  Saving model ...
Validation loss decreased (0.426758 --> 0.426742).  Saving model ...
Validation loss decreased (0.426742 --> 0.426726).  Saving model ...
Validation loss decreased (0.426726 --> 0.426709).  Saving model ...
Validation loss decreased (0.426709 --> 0.426693).  Saving model ...
Validation loss decreased (0.426693 --> 0.426677).  Saving model ...
Validation loss decreased (0.426677 --> 0.426660).  Saving model ...
Validation loss decreased (0.426660 --> 0.426644).  Saving model ...
Validation loss decreased (0.426644 --> 0.426628).  Saving model ...
Validation loss decreased (0.426628 --> 0.426611).  Saving model ...
Validation loss decreased (0.426611 --> 0.426595).  Saving model ...
Validation loss decreased (0.426595 --> 0.426578).  Saving model ...
Validation loss decreased (0.426578 --> 0.426562).  Saving model ...
Validation loss decreased (0.426562 --> 0.426546).  Saving model ...
Validation loss decreased (0.426546 --> 0.426529).  Saving model ...
Validation loss decreased (0.426529 --> 0.426513).  Saving model ...
Validation loss decreased (0.426513 --> 0.426496).  Saving model ...
Validation loss decreased (0.426496 --> 0.426480).  Saving model ...
Validation loss decreased (0.426480 --> 0.426463).  Saving model ...
Validation loss decreased (0.426463 --> 0.426447).  Saving model ...
Validation loss decreased (0.426447 --> 0.426430).  Saving model ...
Validation loss decreased (0.426430 --> 0.426413).  Saving model ...
Validation loss decreased (0.426413 --> 0.426397).  Saving model ...
Validation loss decreased (0.426397 --> 0.426380).  Saving model ...
Validation loss decreased (0.426380 --> 0.426364).  Saving model ...
Validation loss decreased (0.426364 --> 0.426347).  Saving model ...
Validation loss decreased (0.426347 --> 0.426330).  Saving model ...
Validation loss decreased (0.426330 --> 0.426314).  Saving model ...
Validation loss decreased (0.426314 --> 0.426297).  Saving model ...
Validation loss decreased (0.426297 --> 0.426281).  Saving model ...
Validation loss decreased (0.426281 --> 0.426264).  Saving model ...
Validation loss decreased (0.426264 --> 0.426247).  Saving model ...
Validation loss decreased (0.426247 --> 0.426230).  Saving model ...
Validation loss decreased (0.426230 --> 0.426214).  Saving model ...
Validation loss decreased (0.426214 --> 0.426197).  Saving model ...
Validation loss decreased (0.426197 --> 0.426180).  Saving model ...
Validation loss decreased (0.426180 --> 0.426163).  Saving model ...
Validation loss decreased (0.426163 --> 0.426147).  Saving model ...
Validation loss decreased (0.426147 --> 0.426130).  Saving model ...
Validation loss decreased (0.426130 --> 0.426113).  Saving model ...
Validation loss decreased (0.426113 --> 0.426096).  Saving model ...
Validation loss decreased (0.426096 --> 0.426079).  Saving model ...
Validation loss decreased (0.426079 --> 0.426063).  Saving model ...
Validation loss decreased (0.426063 --> 0.426046).  Saving model ...
Validation loss decreased (0.426046 --> 0.426029).  Saving model ...
Validation loss decreased (0.426029 --> 0.426012).  Saving model ...
Validation loss decreased (0.426012 --> 0.425995).  Saving model ...
Validation loss decreased (0.425995 --> 0.425978).  Saving model ...
Validation loss decreased (0.425978 --> 0.425961).  Saving model ...
Validation loss decreased (0.425961 --> 0.425944).  Saving model ...
Validation loss decreased (0.425944 --> 0.425927).  Saving model ...
Validation loss decreased (0.425927 --> 0.425910).  Saving model ...
Validation loss decreased (0.425910 --> 0.425893).  Saving model ...
Validation loss decreased (0.425893 --> 0.425876).  Saving model ...
Validation loss decreased (0.425876 --> 0.425859).  Saving model ...
Validation loss decreased (0.425859 --> 0.425842).  Saving model ...
Validation loss decreased (0.425842 --> 0.425825).  Saving model ...
Validation loss decreased (0.425825 --> 0.425808).  Saving model ...
Validation loss decreased (0.425808 --> 0.425791).  Saving model ...
Validation loss decreased (0.425791 --> 0.425774).  Saving model ...
Validation loss decreased (0.425774 --> 0.425757).  Saving model ...
Validation loss decreased (0.425757 --> 0.425740).  Saving model ...
Validation loss decreased (0.425740 --> 0.425722).  Saving model ...
Validation loss decreased (0.425722 --> 0.425705).  Saving model ...
Validation loss decreased (0.425705 --> 0.425688).  Saving model ...
Validation loss decreased (0.425688 --> 0.425671).  Saving model ...
Validation loss decreased (0.425671 --> 0.425654).  Saving model ...
Validation loss decreased (0.425654 --> 0.425636).  Saving model ...
Validation loss decreased (0.425636 --> 0.425619).  Saving model ...
Validation loss decreased (0.425619 --> 0.425602).  Saving model ...
Validation loss decreased (0.425602 --> 0.425585).  Saving model ...
Validation loss decreased (0.425585 --> 0.425567).  Saving model ...
Validation loss decreased (0.425567 --> 0.425550).  Saving model ...
Validation loss decreased (0.425550 --> 0.425533).  Saving model ...
Validation loss decreased (0.425533 --> 0.425516).  Saving model ...
Validation loss decreased (0.425516 --> 0.425498).  Saving model ...
Validation loss decreased (0.425498 --> 0.425481).  Saving model ...
Validation loss decreased (0.425481 --> 0.425464).  Saving model ...
Validation loss decreased (0.425464 --> 0.425446).  Saving model ...
Validation loss decreased (0.425446 --> 0.425429).  Saving model ...
Validation loss decreased (0.425429 --> 0.425411).  Saving model ...
Validation loss decreased (0.425411 --> 0.425394).  Saving model ...
Validation loss decreased (0.425394 --> 0.425377).  Saving model ...
Validation loss decreased (0.425377 --> 0.425359).  Saving model ...
Validation loss decreased (0.425359 --> 0.425342).  Saving model ...
Validation loss decreased (0.425342 --> 0.425324).  Saving model ...
Validation loss decreased (0.425324 --> 0.425307).  Saving model ...
Validation loss decreased (0.425307 --> 0.425290).  Saving model ...
Validation loss decreased (0.425290 --> 0.425272).  Saving model ...
Validation loss decreased (0.425272 --> 0.425255).  Saving model ...
Validation loss decreased (0.425255 --> 0.425237).  Saving model ...
Validation loss decreased (0.425237 --> 0.425220).  Saving model ...
Validation loss decreased (0.425220 --> 0.425202).  Saving model ...
Validation loss decreased (0.425202 --> 0.425185).  Saving model ...
Validation loss decreased (0.425185 --> 0.425167).  Saving model ...
Validation loss decreased (0.425167 --> 0.425149).  Saving model ...
Validation loss decreased (0.425149 --> 0.425132).  Saving model ...
Validation loss decreased (0.425132 --> 0.425114).  Saving model ...
Validation loss decreased (0.425114 --> 0.425097).  Saving model ...
Validation loss decreased (0.425097 --> 0.425079).  Saving model ...
epoch 3401, loss 0.4251, train acc 80.17%, f1 0.6963, precision 0.7514, recall 0.6488, auc 0.7665
Validation loss decreased (0.425079 --> 0.425062).  Saving model ...
Validation loss decreased (0.425062 --> 0.425044).  Saving model ...
Validation loss decreased (0.425044 --> 0.425026).  Saving model ...
Validation loss decreased (0.425026 --> 0.425009).  Saving model ...
Validation loss decreased (0.425009 --> 0.424991).  Saving model ...
Validation loss decreased (0.424991 --> 0.424974).  Saving model ...
Validation loss decreased (0.424974 --> 0.424956).  Saving model ...
Validation loss decreased (0.424956 --> 0.424938).  Saving model ...
Validation loss decreased (0.424938 --> 0.424921).  Saving model ...
Validation loss decreased (0.424921 --> 0.424903).  Saving model ...
Validation loss decreased (0.424903 --> 0.424885).  Saving model ...
Validation loss decreased (0.424885 --> 0.424868).  Saving model ...
Validation loss decreased (0.424868 --> 0.424850).  Saving model ...
Validation loss decreased (0.424850 --> 0.424833).  Saving model ...
Validation loss decreased (0.424833 --> 0.424815).  Saving model ...
Validation loss decreased (0.424815 --> 0.424797).  Saving model ...
Validation loss decreased (0.424797 --> 0.424780).  Saving model ...
Validation loss decreased (0.424780 --> 0.424762).  Saving model ...
Validation loss decreased (0.424762 --> 0.424744).  Saving model ...
Validation loss decreased (0.424744 --> 0.424727).  Saving model ...
Validation loss decreased (0.424727 --> 0.424709).  Saving model ...
Validation loss decreased (0.424709 --> 0.424691).  Saving model ...
Validation loss decreased (0.424691 --> 0.424673).  Saving model ...
Validation loss decreased (0.424673 --> 0.424656).  Saving model ...
Validation loss decreased (0.424656 --> 0.424638).  Saving model ...
Validation loss decreased (0.424638 --> 0.424620).  Saving model ...
Validation loss decreased (0.424620 --> 0.424603).  Saving model ...
Validation loss decreased (0.424603 --> 0.424585).  Saving model ...
Validation loss decreased (0.424585 --> 0.424567).  Saving model ...
Validation loss decreased (0.424567 --> 0.424550).  Saving model ...
Validation loss decreased (0.424550 --> 0.424532).  Saving model ...
Validation loss decreased (0.424532 --> 0.424514).  Saving model ...
Validation loss decreased (0.424514 --> 0.424497).  Saving model ...
Validation loss decreased (0.424497 --> 0.424479).  Saving model ...
Validation loss decreased (0.424479 --> 0.424461).  Saving model ...
Validation loss decreased (0.424461 --> 0.424444).  Saving model ...
Validation loss decreased (0.424444 --> 0.424426).  Saving model ...
Validation loss decreased (0.424426 --> 0.424408).  Saving model ...
Validation loss decreased (0.424408 --> 0.424390).  Saving model ...
Validation loss decreased (0.424390 --> 0.424373).  Saving model ...
Validation loss decreased (0.424373 --> 0.424355).  Saving model ...
Validation loss decreased (0.424355 --> 0.424337).  Saving model ...
Validation loss decreased (0.424337 --> 0.424320).  Saving model ...
Validation loss decreased (0.424320 --> 0.424302).  Saving model ...
Validation loss decreased (0.424302 --> 0.424284).  Saving model ...
Validation loss decreased (0.424284 --> 0.424267).  Saving model ...
Validation loss decreased (0.424267 --> 0.424249).  Saving model ...
Validation loss decreased (0.424249 --> 0.424231).  Saving model ...
Validation loss decreased (0.424231 --> 0.424214).  Saving model ...
Validation loss decreased (0.424214 --> 0.424196).  Saving model ...
Validation loss decreased (0.424196 --> 0.424178).  Saving model ...
Validation loss decreased (0.424178 --> 0.424161).  Saving model ...
Validation loss decreased (0.424161 --> 0.424143).  Saving model ...
Validation loss decreased (0.424143 --> 0.424125).  Saving model ...
Validation loss decreased (0.424125 --> 0.424108).  Saving model ...
Validation loss decreased (0.424108 --> 0.424090).  Saving model ...
Validation loss decreased (0.424090 --> 0.424073).  Saving model ...
Validation loss decreased (0.424073 --> 0.424055).  Saving model ...
Validation loss decreased (0.424055 --> 0.424037).  Saving model ...
Validation loss decreased (0.424037 --> 0.424020).  Saving model ...
Validation loss decreased (0.424020 --> 0.424002).  Saving model ...
Validation loss decreased (0.424002 --> 0.423984).  Saving model ...
Validation loss decreased (0.423984 --> 0.423967).  Saving model ...
Validation loss decreased (0.423967 --> 0.423949).  Saving model ...
Validation loss decreased (0.423949 --> 0.423932).  Saving model ...
Validation loss decreased (0.423932 --> 0.423914).  Saving model ...
Validation loss decreased (0.423914 --> 0.423896).  Saving model ...
Validation loss decreased (0.423896 --> 0.423879).  Saving model ...
Validation loss decreased (0.423879 --> 0.423861).  Saving model ...
Validation loss decreased (0.423861 --> 0.423844).  Saving model ...
Validation loss decreased (0.423844 --> 0.423826).  Saving model ...
Validation loss decreased (0.423826 --> 0.423809).  Saving model ...
Validation loss decreased (0.423809 --> 0.423791).  Saving model ...
Validation loss decreased (0.423791 --> 0.423773).  Saving model ...
Validation loss decreased (0.423773 --> 0.423756).  Saving model ...
Validation loss decreased (0.423756 --> 0.423738).  Saving model ...
Validation loss decreased (0.423738 --> 0.423721).  Saving model ...
Validation loss decreased (0.423721 --> 0.423703).  Saving model ...
Validation loss decreased (0.423703 --> 0.423686).  Saving model ...
Validation loss decreased (0.423686 --> 0.423668).  Saving model ...
Validation loss decreased (0.423668 --> 0.423651).  Saving model ...
Validation loss decreased (0.423651 --> 0.423633).  Saving model ...
Validation loss decreased (0.423633 --> 0.423616).  Saving model ...
Validation loss decreased (0.423616 --> 0.423598).  Saving model ...
Validation loss decreased (0.423598 --> 0.423581).  Saving model ...
Validation loss decreased (0.423581 --> 0.423563).  Saving model ...
Validation loss decreased (0.423563 --> 0.423546).  Saving model ...
Validation loss decreased (0.423546 --> 0.423528).  Saving model ...
Validation loss decreased (0.423528 --> 0.423511).  Saving model ...
Validation loss decreased (0.423511 --> 0.423493).  Saving model ...
Validation loss decreased (0.423493 --> 0.423476).  Saving model ...
Validation loss decreased (0.423476 --> 0.423458).  Saving model ...
Validation loss decreased (0.423458 --> 0.423441).  Saving model ...
Validation loss decreased (0.423441 --> 0.423423).  Saving model ...
Validation loss decreased (0.423423 --> 0.423406).  Saving model ...
Validation loss decreased (0.423406 --> 0.423388).  Saving model ...
Validation loss decreased (0.423388 --> 0.423371).  Saving model ...
Validation loss decreased (0.423371 --> 0.423353).  Saving model ...
Validation loss decreased (0.423353 --> 0.423336).  Saving model ...
Validation loss decreased (0.423336 --> 0.423319).  Saving model ...
epoch 3501, loss 0.4233, train acc 80.51%, f1 0.7016, precision 0.7571, recall 0.6537, auc 0.7703
Validation loss decreased (0.423319 --> 0.423301).  Saving model ...
Validation loss decreased (0.423301 --> 0.423284).  Saving model ...
Validation loss decreased (0.423284 --> 0.423266).  Saving model ...
Validation loss decreased (0.423266 --> 0.423249).  Saving model ...
Validation loss decreased (0.423249 --> 0.423231).  Saving model ...
Validation loss decreased (0.423231 --> 0.423214).  Saving model ...
Validation loss decreased (0.423214 --> 0.423196).  Saving model ...
Validation loss decreased (0.423196 --> 0.423179).  Saving model ...
Validation loss decreased (0.423179 --> 0.423162).  Saving model ...
Validation loss decreased (0.423162 --> 0.423144).  Saving model ...
Validation loss decreased (0.423144 --> 0.423127).  Saving model ...
Validation loss decreased (0.423127 --> 0.423109).  Saving model ...
Validation loss decreased (0.423109 --> 0.423092).  Saving model ...
Validation loss decreased (0.423092 --> 0.423075).  Saving model ...
Validation loss decreased (0.423075 --> 0.423057).  Saving model ...
Validation loss decreased (0.423057 --> 0.423040).  Saving model ...
Validation loss decreased (0.423040 --> 0.423022).  Saving model ...
Validation loss decreased (0.423022 --> 0.423005).  Saving model ...
Validation loss decreased (0.423005 --> 0.422988).  Saving model ...
Validation loss decreased (0.422988 --> 0.422970).  Saving model ...
Validation loss decreased (0.422970 --> 0.422953).  Saving model ...
Validation loss decreased (0.422953 --> 0.422935).  Saving model ...
Validation loss decreased (0.422935 --> 0.422918).  Saving model ...
Validation loss decreased (0.422918 --> 0.422900).  Saving model ...
Validation loss decreased (0.422900 --> 0.422883).  Saving model ...
Validation loss decreased (0.422883 --> 0.422866).  Saving model ...
Validation loss decreased (0.422866 --> 0.422848).  Saving model ...
Validation loss decreased (0.422848 --> 0.422831).  Saving model ...
Validation loss decreased (0.422831 --> 0.422813).  Saving model ...
Validation loss decreased (0.422813 --> 0.422796).  Saving model ...
Validation loss decreased (0.422796 --> 0.422779).  Saving model ...
Validation loss decreased (0.422779 --> 0.422761).  Saving model ...
Validation loss decreased (0.422761 --> 0.422744).  Saving model ...
Validation loss decreased (0.422744 --> 0.422726).  Saving model ...
Validation loss decreased (0.422726 --> 0.422709).  Saving model ...
Validation loss decreased (0.422709 --> 0.422692).  Saving model ...
Validation loss decreased (0.422692 --> 0.422674).  Saving model ...
Validation loss decreased (0.422674 --> 0.422657).  Saving model ...
Validation loss decreased (0.422657 --> 0.422639).  Saving model ...
Validation loss decreased (0.422639 --> 0.422622).  Saving model ...
Validation loss decreased (0.422622 --> 0.422604).  Saving model ...
Validation loss decreased (0.422604 --> 0.422587).  Saving model ...
Validation loss decreased (0.422587 --> 0.422570).  Saving model ...
Validation loss decreased (0.422570 --> 0.422552).  Saving model ...
Validation loss decreased (0.422552 --> 0.422535).  Saving model ...
Validation loss decreased (0.422535 --> 0.422517).  Saving model ...
Validation loss decreased (0.422517 --> 0.422500).  Saving model ...
Validation loss decreased (0.422500 --> 0.422482).  Saving model ...
Validation loss decreased (0.422482 --> 0.422465).  Saving model ...
Validation loss decreased (0.422465 --> 0.422448).  Saving model ...
Validation loss decreased (0.422448 --> 0.422430).  Saving model ...
Validation loss decreased (0.422430 --> 0.422413).  Saving model ...
Validation loss decreased (0.422413 --> 0.422395).  Saving model ...
Validation loss decreased (0.422395 --> 0.422378).  Saving model ...
Validation loss decreased (0.422378 --> 0.422360).  Saving model ...
Validation loss decreased (0.422360 --> 0.422343).  Saving model ...
Validation loss decreased (0.422343 --> 0.422325).  Saving model ...
Validation loss decreased (0.422325 --> 0.422308).  Saving model ...
Validation loss decreased (0.422308 --> 0.422290).  Saving model ...
Validation loss decreased (0.422290 --> 0.422273).  Saving model ...
Validation loss decreased (0.422273 --> 0.422255).  Saving model ...
Validation loss decreased (0.422255 --> 0.422238).  Saving model ...
Validation loss decreased (0.422238 --> 0.422220).  Saving model ...
Validation loss decreased (0.422220 --> 0.422203).  Saving model ...
Validation loss decreased (0.422203 --> 0.422185).  Saving model ...
Validation loss decreased (0.422185 --> 0.422168).  Saving model ...
Validation loss decreased (0.422168 --> 0.422150).  Saving model ...
Validation loss decreased (0.422150 --> 0.422133).  Saving model ...
Validation loss decreased (0.422133 --> 0.422115).  Saving model ...
Validation loss decreased (0.422115 --> 0.422097).  Saving model ...
Validation loss decreased (0.422097 --> 0.422080).  Saving model ...
Validation loss decreased (0.422080 --> 0.422062).  Saving model ...
Validation loss decreased (0.422062 --> 0.422045).  Saving model ...
Validation loss decreased (0.422045 --> 0.422027).  Saving model ...
Validation loss decreased (0.422027 --> 0.422010).  Saving model ...
Validation loss decreased (0.422010 --> 0.421992).  Saving model ...
Validation loss decreased (0.421992 --> 0.421974).  Saving model ...
Validation loss decreased (0.421974 --> 0.421957).  Saving model ...
Validation loss decreased (0.421957 --> 0.421939).  Saving model ...
Validation loss decreased (0.421939 --> 0.421921).  Saving model ...
Validation loss decreased (0.421921 --> 0.421904).  Saving model ...
Validation loss decreased (0.421904 --> 0.421886).  Saving model ...
Validation loss decreased (0.421886 --> 0.421868).  Saving model ...
Validation loss decreased (0.421868 --> 0.421851).  Saving model ...
Validation loss decreased (0.421851 --> 0.421833).  Saving model ...
Validation loss decreased (0.421833 --> 0.421815).  Saving model ...
Validation loss decreased (0.421815 --> 0.421798).  Saving model ...
Validation loss decreased (0.421798 --> 0.421780).  Saving model ...
Validation loss decreased (0.421780 --> 0.421762).  Saving model ...
Validation loss decreased (0.421762 --> 0.421744).  Saving model ...
Validation loss decreased (0.421744 --> 0.421727).  Saving model ...
Validation loss decreased (0.421727 --> 0.421709).  Saving model ...
Validation loss decreased (0.421709 --> 0.421691).  Saving model ...
Validation loss decreased (0.421691 --> 0.421673).  Saving model ...
Validation loss decreased (0.421673 --> 0.421656).  Saving model ...
Validation loss decreased (0.421656 --> 0.421638).  Saving model ...
Validation loss decreased (0.421638 --> 0.421620).  Saving model ...
Validation loss decreased (0.421620 --> 0.421602).  Saving model ...
Validation loss decreased (0.421602 --> 0.421584).  Saving model ...
Validation loss decreased (0.421584 --> 0.421567).  Saving model ...
epoch 3601, loss 0.4216, train acc 80.51%, f1 0.7016, precision 0.7571, recall 0.6537, auc 0.7703
Validation loss decreased (0.421567 --> 0.421549).  Saving model ...
Validation loss decreased (0.421549 --> 0.421531).  Saving model ...
Validation loss decreased (0.421531 --> 0.421513).  Saving model ...
Validation loss decreased (0.421513 --> 0.421495).  Saving model ...
Validation loss decreased (0.421495 --> 0.421477).  Saving model ...
Validation loss decreased (0.421477 --> 0.421459).  Saving model ...
Validation loss decreased (0.421459 --> 0.421441).  Saving model ...
Validation loss decreased (0.421441 --> 0.421423).  Saving model ...
Validation loss decreased (0.421423 --> 0.421405).  Saving model ...
Validation loss decreased (0.421405 --> 0.421387).  Saving model ...
Validation loss decreased (0.421387 --> 0.421369).  Saving model ...
Validation loss decreased (0.421369 --> 0.421351).  Saving model ...
Validation loss decreased (0.421351 --> 0.421333).  Saving model ...
Validation loss decreased (0.421333 --> 0.421315).  Saving model ...
Validation loss decreased (0.421315 --> 0.421297).  Saving model ...
Validation loss decreased (0.421297 --> 0.421279).  Saving model ...
Validation loss decreased (0.421279 --> 0.421261).  Saving model ...
Validation loss decreased (0.421261 --> 0.421243).  Saving model ...
Validation loss decreased (0.421243 --> 0.421225).  Saving model ...
Validation loss decreased (0.421225 --> 0.421207).  Saving model ...
Validation loss decreased (0.421207 --> 0.421189).  Saving model ...
Validation loss decreased (0.421189 --> 0.421171).  Saving model ...
Validation loss decreased (0.421171 --> 0.421152).  Saving model ...
Validation loss decreased (0.421152 --> 0.421134).  Saving model ...
Validation loss decreased (0.421134 --> 0.421116).  Saving model ...
Validation loss decreased (0.421116 --> 0.421098).  Saving model ...
Validation loss decreased (0.421098 --> 0.421080).  Saving model ...
Validation loss decreased (0.421080 --> 0.421061).  Saving model ...
Validation loss decreased (0.421061 --> 0.421043).  Saving model ...
Validation loss decreased (0.421043 --> 0.421025).  Saving model ...
Validation loss decreased (0.421025 --> 0.421007).  Saving model ...
Validation loss decreased (0.421007 --> 0.420988).  Saving model ...
Validation loss decreased (0.420988 --> 0.420970).  Saving model ...
Validation loss decreased (0.420970 --> 0.420952).  Saving model ...
Validation loss decreased (0.420952 --> 0.420933).  Saving model ...
Validation loss decreased (0.420933 --> 0.420915).  Saving model ...
Validation loss decreased (0.420915 --> 0.420897).  Saving model ...
Validation loss decreased (0.420897 --> 0.420878).  Saving model ...
Validation loss decreased (0.420878 --> 0.420860).  Saving model ...
Validation loss decreased (0.420860 --> 0.420841).  Saving model ...
Validation loss decreased (0.420841 --> 0.420823).  Saving model ...
Validation loss decreased (0.420823 --> 0.420804).  Saving model ...
Validation loss decreased (0.420804 --> 0.420786).  Saving model ...
Validation loss decreased (0.420786 --> 0.420767).  Saving model ...
Validation loss decreased (0.420767 --> 0.420749).  Saving model ...
Validation loss decreased (0.420749 --> 0.420730).  Saving model ...
Validation loss decreased (0.420730 --> 0.420712).  Saving model ...
Validation loss decreased (0.420712 --> 0.420693).  Saving model ...
Validation loss decreased (0.420693 --> 0.420674).  Saving model ...
Validation loss decreased (0.420674 --> 0.420656).  Saving model ...
Validation loss decreased (0.420656 --> 0.420637).  Saving model ...
Validation loss decreased (0.420637 --> 0.420618).  Saving model ...
Validation loss decreased (0.420618 --> 0.420600).  Saving model ...
Validation loss decreased (0.420600 --> 0.420581).  Saving model ...
Validation loss decreased (0.420581 --> 0.420562).  Saving model ...
Validation loss decreased (0.420562 --> 0.420544).  Saving model ...
Validation loss decreased (0.420544 --> 0.420525).  Saving model ...
Validation loss decreased (0.420525 --> 0.420506).  Saving model ...
Validation loss decreased (0.420506 --> 0.420487).  Saving model ...
Validation loss decreased (0.420487 --> 0.420468).  Saving model ...
Validation loss decreased (0.420468 --> 0.420450).  Saving model ...
Validation loss decreased (0.420450 --> 0.420431).  Saving model ...
Validation loss decreased (0.420431 --> 0.420412).  Saving model ...
Validation loss decreased (0.420412 --> 0.420393).  Saving model ...
Validation loss decreased (0.420393 --> 0.420374).  Saving model ...
Validation loss decreased (0.420374 --> 0.420355).  Saving model ...
Validation loss decreased (0.420355 --> 0.420336).  Saving model ...
Validation loss decreased (0.420336 --> 0.420317).  Saving model ...
Validation loss decreased (0.420317 --> 0.420298).  Saving model ...
Validation loss decreased (0.420298 --> 0.420279).  Saving model ...
Validation loss decreased (0.420279 --> 0.420260).  Saving model ...
Validation loss decreased (0.420260 --> 0.420241).  Saving model ...
Validation loss decreased (0.420241 --> 0.420222).  Saving model ...
Validation loss decreased (0.420222 --> 0.420203).  Saving model ...
Validation loss decreased (0.420203 --> 0.420184).  Saving model ...
Validation loss decreased (0.420184 --> 0.420164).  Saving model ...
Validation loss decreased (0.420164 --> 0.420145).  Saving model ...
Validation loss decreased (0.420145 --> 0.420126).  Saving model ...
Validation loss decreased (0.420126 --> 0.420107).  Saving model ...
Validation loss decreased (0.420107 --> 0.420088).  Saving model ...
Validation loss decreased (0.420088 --> 0.420068).  Saving model ...
Validation loss decreased (0.420068 --> 0.420049).  Saving model ...
Validation loss decreased (0.420049 --> 0.420030).  Saving model ...
Validation loss decreased (0.420030 --> 0.420010).  Saving model ...
Validation loss decreased (0.420010 --> 0.419991).  Saving model ...
Validation loss decreased (0.419991 --> 0.419972).  Saving model ...
Validation loss decreased (0.419972 --> 0.419952).  Saving model ...
Validation loss decreased (0.419952 --> 0.419933).  Saving model ...
Validation loss decreased (0.419933 --> 0.419913).  Saving model ...
Validation loss decreased (0.419913 --> 0.419894).  Saving model ...
Validation loss decreased (0.419894 --> 0.419874).  Saving model ...
Validation loss decreased (0.419874 --> 0.419855).  Saving model ...
Validation loss decreased (0.419855 --> 0.419835).  Saving model ...
Validation loss decreased (0.419835 --> 0.419816).  Saving model ...
Validation loss decreased (0.419816 --> 0.419796).  Saving model ...
Validation loss decreased (0.419796 --> 0.419777).  Saving model ...
Validation loss decreased (0.419777 --> 0.419757).  Saving model ...
Validation loss decreased (0.419757 --> 0.419738).  Saving model ...
Validation loss decreased (0.419738 --> 0.419718).  Saving model ...
Validation loss decreased (0.419718 --> 0.419698).  Saving model ...
epoch 3701, loss 0.4197, train acc 80.34%, f1 0.7013, precision 0.7500, recall 0.6585, auc 0.7701
Validation loss decreased (0.419698 --> 0.419679).  Saving model ...
Validation loss decreased (0.419679 --> 0.419659).  Saving model ...
Validation loss decreased (0.419659 --> 0.419639).  Saving model ...
Validation loss decreased (0.419639 --> 0.419619).  Saving model ...
Validation loss decreased (0.419619 --> 0.419600).  Saving model ...
Validation loss decreased (0.419600 --> 0.419580).  Saving model ...
Validation loss decreased (0.419580 --> 0.419560).  Saving model ...
Validation loss decreased (0.419560 --> 0.419540).  Saving model ...
Validation loss decreased (0.419540 --> 0.419520).  Saving model ...
Validation loss decreased (0.419520 --> 0.419500).  Saving model ...
Validation loss decreased (0.419500 --> 0.419480).  Saving model ...
Validation loss decreased (0.419480 --> 0.419461).  Saving model ...
Validation loss decreased (0.419461 --> 0.419441).  Saving model ...
Validation loss decreased (0.419441 --> 0.419421).  Saving model ...
Validation loss decreased (0.419421 --> 0.419401).  Saving model ...
Validation loss decreased (0.419401 --> 0.419381).  Saving model ...
Validation loss decreased (0.419381 --> 0.419361).  Saving model ...
Validation loss decreased (0.419361 --> 0.419341).  Saving model ...
Validation loss decreased (0.419341 --> 0.419321).  Saving model ...
Validation loss decreased (0.419321 --> 0.419300).  Saving model ...
Validation loss decreased (0.419300 --> 0.419280).  Saving model ...
Validation loss decreased (0.419280 --> 0.419260).  Saving model ...
Validation loss decreased (0.419260 --> 0.419240).  Saving model ...
Validation loss decreased (0.419240 --> 0.419220).  Saving model ...
Validation loss decreased (0.419220 --> 0.419200).  Saving model ...
Validation loss decreased (0.419200 --> 0.419179).  Saving model ...
Validation loss decreased (0.419179 --> 0.419159).  Saving model ...
Validation loss decreased (0.419159 --> 0.419139).  Saving model ...
Validation loss decreased (0.419139 --> 0.419119).  Saving model ...
Validation loss decreased (0.419119 --> 0.419098).  Saving model ...
Validation loss decreased (0.419098 --> 0.419078).  Saving model ...
Validation loss decreased (0.419078 --> 0.419058).  Saving model ...
Validation loss decreased (0.419058 --> 0.419037).  Saving model ...
Validation loss decreased (0.419037 --> 0.419017).  Saving model ...
Validation loss decreased (0.419017 --> 0.418997).  Saving model ...
Validation loss decreased (0.418997 --> 0.418976).  Saving model ...
Validation loss decreased (0.418976 --> 0.418956).  Saving model ...
Validation loss decreased (0.418956 --> 0.418935).  Saving model ...
Validation loss decreased (0.418935 --> 0.418915).  Saving model ...
Validation loss decreased (0.418915 --> 0.418894).  Saving model ...
Validation loss decreased (0.418894 --> 0.418874).  Saving model ...
Validation loss decreased (0.418874 --> 0.418853).  Saving model ...
Validation loss decreased (0.418853 --> 0.418833).  Saving model ...
Validation loss decreased (0.418833 --> 0.418812).  Saving model ...
Validation loss decreased (0.418812 --> 0.418792).  Saving model ...
Validation loss decreased (0.418792 --> 0.418771).  Saving model ...
Validation loss decreased (0.418771 --> 0.418751).  Saving model ...
Validation loss decreased (0.418751 --> 0.418730).  Saving model ...
Validation loss decreased (0.418730 --> 0.418709).  Saving model ...
Validation loss decreased (0.418709 --> 0.418689).  Saving model ...
Validation loss decreased (0.418689 --> 0.418668).  Saving model ...
Validation loss decreased (0.418668 --> 0.418647).  Saving model ...
Validation loss decreased (0.418647 --> 0.418627).  Saving model ...
Validation loss decreased (0.418627 --> 0.418606).  Saving model ...
Validation loss decreased (0.418606 --> 0.418585).  Saving model ...
Validation loss decreased (0.418585 --> 0.418565).  Saving model ...
Validation loss decreased (0.418565 --> 0.418544).  Saving model ...
Validation loss decreased (0.418544 --> 0.418523).  Saving model ...
Validation loss decreased (0.418523 --> 0.418502).  Saving model ...
Validation loss decreased (0.418502 --> 0.418481).  Saving model ...
Validation loss decreased (0.418481 --> 0.418460).  Saving model ...
Validation loss decreased (0.418460 --> 0.418440).  Saving model ...
Validation loss decreased (0.418440 --> 0.418419).  Saving model ...
Validation loss decreased (0.418419 --> 0.418398).  Saving model ...
Validation loss decreased (0.418398 --> 0.418377).  Saving model ...
Validation loss decreased (0.418377 --> 0.418356).  Saving model ...
Validation loss decreased (0.418356 --> 0.418335).  Saving model ...
Validation loss decreased (0.418335 --> 0.418314).  Saving model ...
Validation loss decreased (0.418314 --> 0.418293).  Saving model ...
Validation loss decreased (0.418293 --> 0.418272).  Saving model ...
Validation loss decreased (0.418272 --> 0.418251).  Saving model ...
Validation loss decreased (0.418251 --> 0.418230).  Saving model ...
Validation loss decreased (0.418230 --> 0.418209).  Saving model ...
Validation loss decreased (0.418209 --> 0.418188).  Saving model ...
Validation loss decreased (0.418188 --> 0.418167).  Saving model ...
Validation loss decreased (0.418167 --> 0.418146).  Saving model ...
Validation loss decreased (0.418146 --> 0.418125).  Saving model ...
Validation loss decreased (0.418125 --> 0.418104).  Saving model ...
Validation loss decreased (0.418104 --> 0.418083).  Saving model ...
Validation loss decreased (0.418083 --> 0.418062).  Saving model ...
Validation loss decreased (0.418062 --> 0.418041).  Saving model ...
Validation loss decreased (0.418041 --> 0.418020).  Saving model ...
Validation loss decreased (0.418020 --> 0.417999).  Saving model ...
Validation loss decreased (0.417999 --> 0.417977).  Saving model ...
Validation loss decreased (0.417977 --> 0.417956).  Saving model ...
Validation loss decreased (0.417956 --> 0.417935).  Saving model ...
Validation loss decreased (0.417935 --> 0.417914).  Saving model ...
Validation loss decreased (0.417914 --> 0.417893).  Saving model ...
Validation loss decreased (0.417893 --> 0.417872).  Saving model ...
Validation loss decreased (0.417872 --> 0.417850).  Saving model ...
Validation loss decreased (0.417850 --> 0.417829).  Saving model ...
Validation loss decreased (0.417829 --> 0.417808).  Saving model ...
Validation loss decreased (0.417808 --> 0.417787).  Saving model ...
Validation loss decreased (0.417787 --> 0.417765).  Saving model ...
Validation loss decreased (0.417765 --> 0.417744).  Saving model ...
Validation loss decreased (0.417744 --> 0.417723).  Saving model ...
Validation loss decreased (0.417723 --> 0.417701).  Saving model ...
Validation loss decreased (0.417701 --> 0.417680).  Saving model ...
Validation loss decreased (0.417680 --> 0.417659).  Saving model ...
Validation loss decreased (0.417659 --> 0.417638).  Saving model ...
epoch 3801, loss 0.4176, train acc 80.00%, f1 0.6961, precision 0.7444, recall 0.6537, auc 0.7663
Validation loss decreased (0.417638 --> 0.417616).  Saving model ...
Validation loss decreased (0.417616 --> 0.417595).  Saving model ...
Validation loss decreased (0.417595 --> 0.417574).  Saving model ...
Validation loss decreased (0.417574 --> 0.417552).  Saving model ...
Validation loss decreased (0.417552 --> 0.417531).  Saving model ...
Validation loss decreased (0.417531 --> 0.417509).  Saving model ...
Validation loss decreased (0.417509 --> 0.417488).  Saving model ...
Validation loss decreased (0.417488 --> 0.417467).  Saving model ...
Validation loss decreased (0.417467 --> 0.417445).  Saving model ...
Validation loss decreased (0.417445 --> 0.417424).  Saving model ...
Validation loss decreased (0.417424 --> 0.417402).  Saving model ...
Validation loss decreased (0.417402 --> 0.417381).  Saving model ...
Validation loss decreased (0.417381 --> 0.417360).  Saving model ...
Validation loss decreased (0.417360 --> 0.417338).  Saving model ...
Validation loss decreased (0.417338 --> 0.417317).  Saving model ...
Validation loss decreased (0.417317 --> 0.417295).  Saving model ...
Validation loss decreased (0.417295 --> 0.417274).  Saving model ...
Validation loss decreased (0.417274 --> 0.417252).  Saving model ...
Validation loss decreased (0.417252 --> 0.417231).  Saving model ...
Validation loss decreased (0.417231 --> 0.417209).  Saving model ...
Validation loss decreased (0.417209 --> 0.417188).  Saving model ...
Validation loss decreased (0.417188 --> 0.417166).  Saving model ...
Validation loss decreased (0.417166 --> 0.417145).  Saving model ...
Validation loss decreased (0.417145 --> 0.417123).  Saving model ...
Validation loss decreased (0.417123 --> 0.417102).  Saving model ...
Validation loss decreased (0.417102 --> 0.417080).  Saving model ...
Validation loss decreased (0.417080 --> 0.417059).  Saving model ...
Validation loss decreased (0.417059 --> 0.417037).  Saving model ...
Validation loss decreased (0.417037 --> 0.417016).  Saving model ...
Validation loss decreased (0.417016 --> 0.416994).  Saving model ...
Validation loss decreased (0.416994 --> 0.416973).  Saving model ...
Validation loss decreased (0.416973 --> 0.416951).  Saving model ...
Validation loss decreased (0.416951 --> 0.416929).  Saving model ...
Validation loss decreased (0.416929 --> 0.416908).  Saving model ...
Validation loss decreased (0.416908 --> 0.416886).  Saving model ...
Validation loss decreased (0.416886 --> 0.416865).  Saving model ...
Validation loss decreased (0.416865 --> 0.416843).  Saving model ...
Validation loss decreased (0.416843 --> 0.416822).  Saving model ...
Validation loss decreased (0.416822 --> 0.416800).  Saving model ...
Validation loss decreased (0.416800 --> 0.416778).  Saving model ...
Validation loss decreased (0.416778 --> 0.416757).  Saving model ...
Validation loss decreased (0.416757 --> 0.416735).  Saving model ...
Validation loss decreased (0.416735 --> 0.416714).  Saving model ...
Validation loss decreased (0.416714 --> 0.416692).  Saving model ...
Validation loss decreased (0.416692 --> 0.416670).  Saving model ...
Validation loss decreased (0.416670 --> 0.416649).  Saving model ...
Validation loss decreased (0.416649 --> 0.416627).  Saving model ...
Validation loss decreased (0.416627 --> 0.416605).  Saving model ...
Validation loss decreased (0.416605 --> 0.416584).  Saving model ...
Validation loss decreased (0.416584 --> 0.416562).  Saving model ...
Validation loss decreased (0.416562 --> 0.416541).  Saving model ...
Validation loss decreased (0.416541 --> 0.416519).  Saving model ...
Validation loss decreased (0.416519 --> 0.416497).  Saving model ...
Validation loss decreased (0.416497 --> 0.416476).  Saving model ...
Validation loss decreased (0.416476 --> 0.416454).  Saving model ...
Validation loss decreased (0.416454 --> 0.416432).  Saving model ...
Validation loss decreased (0.416432 --> 0.416411).  Saving model ...
Validation loss decreased (0.416411 --> 0.416389).  Saving model ...
Validation loss decreased (0.416389 --> 0.416367).  Saving model ...
Validation loss decreased (0.416367 --> 0.416346).  Saving model ...
Validation loss decreased (0.416346 --> 0.416324).  Saving model ...
Validation loss decreased (0.416324 --> 0.416302).  Saving model ...
Validation loss decreased (0.416302 --> 0.416281).  Saving model ...
Validation loss decreased (0.416281 --> 0.416259).  Saving model ...
Validation loss decreased (0.416259 --> 0.416237).  Saving model ...
Validation loss decreased (0.416237 --> 0.416216).  Saving model ...
Validation loss decreased (0.416216 --> 0.416194).  Saving model ...
Validation loss decreased (0.416194 --> 0.416172).  Saving model ...
Validation loss decreased (0.416172 --> 0.416151).  Saving model ...
Validation loss decreased (0.416151 --> 0.416129).  Saving model ...
Validation loss decreased (0.416129 --> 0.416107).  Saving model ...
Validation loss decreased (0.416107 --> 0.416086).  Saving model ...
Validation loss decreased (0.416086 --> 0.416064).  Saving model ...
Validation loss decreased (0.416064 --> 0.416042).  Saving model ...
Validation loss decreased (0.416042 --> 0.416021).  Saving model ...
Validation loss decreased (0.416021 --> 0.415999).  Saving model ...
Validation loss decreased (0.415999 --> 0.415977).  Saving model ...
Validation loss decreased (0.415977 --> 0.415956).  Saving model ...
Validation loss decreased (0.415956 --> 0.415934).  Saving model ...
Validation loss decreased (0.415934 --> 0.415912).  Saving model ...
Validation loss decreased (0.415912 --> 0.415891).  Saving model ...
Validation loss decreased (0.415891 --> 0.415869).  Saving model ...
Validation loss decreased (0.415869 --> 0.415847).  Saving model ...
Validation loss decreased (0.415847 --> 0.415826).  Saving model ...
Validation loss decreased (0.415826 --> 0.415804).  Saving model ...
Validation loss decreased (0.415804 --> 0.415782).  Saving model ...
Validation loss decreased (0.415782 --> 0.415761).  Saving model ...
Validation loss decreased (0.415761 --> 0.415739).  Saving model ...
Validation loss decreased (0.415739 --> 0.415717).  Saving model ...
Validation loss decreased (0.415717 --> 0.415695).  Saving model ...
Validation loss decreased (0.415695 --> 0.415674).  Saving model ...
Validation loss decreased (0.415674 --> 0.415652).  Saving model ...
Validation loss decreased (0.415652 --> 0.415630).  Saving model ...
Validation loss decreased (0.415630 --> 0.415609).  Saving model ...
Validation loss decreased (0.415609 --> 0.415587).  Saving model ...
Validation loss decreased (0.415587 --> 0.415565).  Saving model ...
Validation loss decreased (0.415565 --> 0.415544).  Saving model ...
Validation loss decreased (0.415544 --> 0.415522).  Saving model ...
Validation loss decreased (0.415522 --> 0.415500).  Saving model ...
Validation loss decreased (0.415500 --> 0.415479).  Saving model ...
epoch 3901, loss 0.4155, train acc 80.34%, f1 0.7013, precision 0.7500, recall 0.6585, auc 0.7701
Validation loss decreased (0.415479 --> 0.415457).  Saving model ...
Validation loss decreased (0.415457 --> 0.415435).  Saving model ...
Validation loss decreased (0.415435 --> 0.415414).  Saving model ...
Validation loss decreased (0.415414 --> 0.415392).  Saving model ...
Validation loss decreased (0.415392 --> 0.415371).  Saving model ...
Validation loss decreased (0.415371 --> 0.415349).  Saving model ...
Validation loss decreased (0.415349 --> 0.415327).  Saving model ...
Validation loss decreased (0.415327 --> 0.415306).  Saving model ...
Validation loss decreased (0.415306 --> 0.415284).  Saving model ...
Validation loss decreased (0.415284 --> 0.415262).  Saving model ...
Validation loss decreased (0.415262 --> 0.415241).  Saving model ...
Validation loss decreased (0.415241 --> 0.415219).  Saving model ...
Validation loss decreased (0.415219 --> 0.415197).  Saving model ...
Validation loss decreased (0.415197 --> 0.415176).  Saving model ...
Validation loss decreased (0.415176 --> 0.415154).  Saving model ...
Validation loss decreased (0.415154 --> 0.415132).  Saving model ...
Validation loss decreased (0.415132 --> 0.415111).  Saving model ...
Validation loss decreased (0.415111 --> 0.415089).  Saving model ...
Validation loss decreased (0.415089 --> 0.415068).  Saving model ...
Validation loss decreased (0.415068 --> 0.415046).  Saving model ...
Validation loss decreased (0.415046 --> 0.415024).  Saving model ...
Validation loss decreased (0.415024 --> 0.415003).  Saving model ...
Validation loss decreased (0.415003 --> 0.414981).  Saving model ...
Validation loss decreased (0.414981 --> 0.414960).  Saving model ...
Validation loss decreased (0.414960 --> 0.414938).  Saving model ...
Validation loss decreased (0.414938 --> 0.414916).  Saving model ...
Validation loss decreased (0.414916 --> 0.414895).  Saving model ...
Validation loss decreased (0.414895 --> 0.414873).  Saving model ...
Validation loss decreased (0.414873 --> 0.414852).  Saving model ...
Validation loss decreased (0.414852 --> 0.414830).  Saving model ...
Validation loss decreased (0.414830 --> 0.414809).  Saving model ...
Validation loss decreased (0.414809 --> 0.414787).  Saving model ...
Validation loss decreased (0.414787 --> 0.414765).  Saving model ...
Validation loss decreased (0.414765 --> 0.414744).  Saving model ...
Validation loss decreased (0.414744 --> 0.414722).  Saving model ...
Validation loss decreased (0.414722 --> 0.414701).  Saving model ...
Validation loss decreased (0.414701 --> 0.414679).  Saving model ...
Validation loss decreased (0.414679 --> 0.414658).  Saving model ...
Validation loss decreased (0.414658 --> 0.414636).  Saving model ...
Validation loss decreased (0.414636 --> 0.414615).  Saving model ...
Validation loss decreased (0.414615 --> 0.414593).  Saving model ...
Validation loss decreased (0.414593 --> 0.414572).  Saving model ...
Validation loss decreased (0.414572 --> 0.414550).  Saving model ...
Validation loss decreased (0.414550 --> 0.414529).  Saving model ...
Validation loss decreased (0.414529 --> 0.414507).  Saving model ...
Validation loss decreased (0.414507 --> 0.414485).  Saving model ...
Validation loss decreased (0.414485 --> 0.414464).  Saving model ...
Validation loss decreased (0.414464 --> 0.414442).  Saving model ...
Validation loss decreased (0.414442 --> 0.414421).  Saving model ...
Validation loss decreased (0.414421 --> 0.414399).  Saving model ...
Validation loss decreased (0.414399 --> 0.414378).  Saving model ...
Validation loss decreased (0.414378 --> 0.414356).  Saving model ...
Validation loss decreased (0.414356 --> 0.414335).  Saving model ...
Validation loss decreased (0.414335 --> 0.414314).  Saving model ...
Validation loss decreased (0.414314 --> 0.414292).  Saving model ...
Validation loss decreased (0.414292 --> 0.414271).  Saving model ...
Validation loss decreased (0.414271 --> 0.414249).  Saving model ...
Validation loss decreased (0.414249 --> 0.414228).  Saving model ...
Validation loss decreased (0.414228 --> 0.414206).  Saving model ...
Validation loss decreased (0.414206 --> 0.414185).  Saving model ...
Validation loss decreased (0.414185 --> 0.414163).  Saving model ...
Validation loss decreased (0.414163 --> 0.414142).  Saving model ...
Validation loss decreased (0.414142 --> 0.414121).  Saving model ...
Validation loss decreased (0.414121 --> 0.414099).  Saving model ...
Validation loss decreased (0.414099 --> 0.414078).  Saving model ...
Validation loss decreased (0.414078 --> 0.414056).  Saving model ...
Validation loss decreased (0.414056 --> 0.414035).  Saving model ...
Validation loss decreased (0.414035 --> 0.414014).  Saving model ...
Validation loss decreased (0.414014 --> 0.413992).  Saving model ...
Validation loss decreased (0.413992 --> 0.413971).  Saving model ...
Validation loss decreased (0.413971 --> 0.413949).  Saving model ...
Validation loss decreased (0.413949 --> 0.413928).  Saving model ...
Validation loss decreased (0.413928 --> 0.413907).  Saving model ...
Validation loss decreased (0.413907 --> 0.413885).  Saving model ...
Validation loss decreased (0.413885 --> 0.413864).  Saving model ...
Validation loss decreased (0.413864 --> 0.413843).  Saving model ...
Validation loss decreased (0.413843 --> 0.413821).  Saving model ...
Validation loss decreased (0.413821 --> 0.413800).  Saving model ...
Validation loss decreased (0.413800 --> 0.413779).  Saving model ...
Validation loss decreased (0.413779 --> 0.413757).  Saving model ...
Validation loss decreased (0.413757 --> 0.413736).  Saving model ...
Validation loss decreased (0.413736 --> 0.413715).  Saving model ...
Validation loss decreased (0.413715 --> 0.413693).  Saving model ...
Validation loss decreased (0.413693 --> 0.413672).  Saving model ...
Validation loss decreased (0.413672 --> 0.413651).  Saving model ...
Validation loss decreased (0.413651 --> 0.413629).  Saving model ...
Validation loss decreased (0.413629 --> 0.413608).  Saving model ...
Validation loss decreased (0.413608 --> 0.413587).  Saving model ...
Validation loss decreased (0.413587 --> 0.413566).  Saving model ...
Validation loss decreased (0.413566 --> 0.413544).  Saving model ...
Validation loss decreased (0.413544 --> 0.413523).  Saving model ...
Validation loss decreased (0.413523 --> 0.413502).  Saving model ...
Validation loss decreased (0.413502 --> 0.413481).  Saving model ...
Validation loss decreased (0.413481 --> 0.413459).  Saving model ...
Validation loss decreased (0.413459 --> 0.413438).  Saving model ...
Validation loss decreased (0.413438 --> 0.413417).  Saving model ...
Validation loss decreased (0.413417 --> 0.413396).  Saving model ...
Validation loss decreased (0.413396 --> 0.413374).  Saving model ...
Validation loss decreased (0.413374 --> 0.413353).  Saving model ...
Validation loss decreased (0.413353 --> 0.413332).  Saving model ...
epoch 4001, loss 0.4133, train acc 80.68%, f1 0.7065, precision 0.7556, recall 0.6634, auc 0.7738
Validation loss decreased (0.413332 --> 0.413311).  Saving model ...
Validation loss decreased (0.413311 --> 0.413290).  Saving model ...
Validation loss decreased (0.413290 --> 0.413268).  Saving model ...
Validation loss decreased (0.413268 --> 0.413247).  Saving model ...
Validation loss decreased (0.413247 --> 0.413226).  Saving model ...
Validation loss decreased (0.413226 --> 0.413205).  Saving model ...
Validation loss decreased (0.413205 --> 0.413184).  Saving model ...
Validation loss decreased (0.413184 --> 0.413163).  Saving model ...
Validation loss decreased (0.413163 --> 0.413141).  Saving model ...
Validation loss decreased (0.413141 --> 0.413120).  Saving model ...
Validation loss decreased (0.413120 --> 0.413099).  Saving model ...
Validation loss decreased (0.413099 --> 0.413078).  Saving model ...
Validation loss decreased (0.413078 --> 0.413057).  Saving model ...
Validation loss decreased (0.413057 --> 0.413036).  Saving model ...
Validation loss decreased (0.413036 --> 0.413015).  Saving model ...
Validation loss decreased (0.413015 --> 0.412994).  Saving model ...
Validation loss decreased (0.412994 --> 0.412972).  Saving model ...
Validation loss decreased (0.412972 --> 0.412951).  Saving model ...
Validation loss decreased (0.412951 --> 0.412930).  Saving model ...
Validation loss decreased (0.412930 --> 0.412909).  Saving model ...
Validation loss decreased (0.412909 --> 0.412888).  Saving model ...
Validation loss decreased (0.412888 --> 0.412867).  Saving model ...
Validation loss decreased (0.412867 --> 0.412846).  Saving model ...
Validation loss decreased (0.412846 --> 0.412825).  Saving model ...
Validation loss decreased (0.412825 --> 0.412804).  Saving model ...
Validation loss decreased (0.412804 --> 0.412783).  Saving model ...
Validation loss decreased (0.412783 --> 0.412762).  Saving model ...
Validation loss decreased (0.412762 --> 0.412741).  Saving model ...
Validation loss decreased (0.412741 --> 0.412720).  Saving model ...
Validation loss decreased (0.412720 --> 0.412699).  Saving model ...
Validation loss decreased (0.412699 --> 0.412678).  Saving model ...
Validation loss decreased (0.412678 --> 0.412657).  Saving model ...
Validation loss decreased (0.412657 --> 0.412636).  Saving model ...
Validation loss decreased (0.412636 --> 0.412615).  Saving model ...
Validation loss decreased (0.412615 --> 0.412594).  Saving model ...
Validation loss decreased (0.412594 --> 0.412573).  Saving model ...
Validation loss decreased (0.412573 --> 0.412552).  Saving model ...
Validation loss decreased (0.412552 --> 0.412531).  Saving model ...
Validation loss decreased (0.412531 --> 0.412510).  Saving model ...
Validation loss decreased (0.412510 --> 0.412489).  Saving model ...
Validation loss decreased (0.412489 --> 0.412468).  Saving model ...
Validation loss decreased (0.412468 --> 0.412447).  Saving model ...
Validation loss decreased (0.412447 --> 0.412426).  Saving model ...
Validation loss decreased (0.412426 --> 0.412405).  Saving model ...
Validation loss decreased (0.412405 --> 0.412385).  Saving model ...
Validation loss decreased (0.412385 --> 0.412364).  Saving model ...
Validation loss decreased (0.412364 --> 0.412343).  Saving model ...
Validation loss decreased (0.412343 --> 0.412322).  Saving model ...
Validation loss decreased (0.412322 --> 0.412301).  Saving model ...
Validation loss decreased (0.412301 --> 0.412280).  Saving model ...
Validation loss decreased (0.412280 --> 0.412259).  Saving model ...
Validation loss decreased (0.412259 --> 0.412238).  Saving model ...
Validation loss decreased (0.412238 --> 0.412218).  Saving model ...
Validation loss decreased (0.412218 --> 0.412197).  Saving model ...
Validation loss decreased (0.412197 --> 0.412176).  Saving model ...
Validation loss decreased (0.412176 --> 0.412155).  Saving model ...
Validation loss decreased (0.412155 --> 0.412134).  Saving model ...
Validation loss decreased (0.412134 --> 0.412113).  Saving model ...
Validation loss decreased (0.412113 --> 0.412093).  Saving model ...
Validation loss decreased (0.412093 --> 0.412072).  Saving model ...
Validation loss decreased (0.412072 --> 0.412051).  Saving model ...
Validation loss decreased (0.412051 --> 0.412030).  Saving model ...
Validation loss decreased (0.412030 --> 0.412009).  Saving model ...
Validation loss decreased (0.412009 --> 0.411989).  Saving model ...
Validation loss decreased (0.411989 --> 0.411968).  Saving model ...
Validation loss decreased (0.411968 --> 0.411947).  Saving model ...
Validation loss decreased (0.411947 --> 0.411926).  Saving model ...
Validation loss decreased (0.411926 --> 0.411906).  Saving model ...
Validation loss decreased (0.411906 --> 0.411885).  Saving model ...
Validation loss decreased (0.411885 --> 0.411864).  Saving model ...
Validation loss decreased (0.411864 --> 0.411843).  Saving model ...
Validation loss decreased (0.411843 --> 0.411823).  Saving model ...
Validation loss decreased (0.411823 --> 0.411802).  Saving model ...
Validation loss decreased (0.411802 --> 0.411781).  Saving model ...
Validation loss decreased (0.411781 --> 0.411760).  Saving model ...
Validation loss decreased (0.411760 --> 0.411740).  Saving model ...
Validation loss decreased (0.411740 --> 0.411719).  Saving model ...
Validation loss decreased (0.411719 --> 0.411698).  Saving model ...
Validation loss decreased (0.411698 --> 0.411678).  Saving model ...
Validation loss decreased (0.411678 --> 0.411657).  Saving model ...
Validation loss decreased (0.411657 --> 0.411636).  Saving model ...
Validation loss decreased (0.411636 --> 0.411616).  Saving model ...
Validation loss decreased (0.411616 --> 0.411595).  Saving model ...
Validation loss decreased (0.411595 --> 0.411574).  Saving model ...
Validation loss decreased (0.411574 --> 0.411554).  Saving model ...
Validation loss decreased (0.411554 --> 0.411533).  Saving model ...
Validation loss decreased (0.411533 --> 0.411512).  Saving model ...
Validation loss decreased (0.411512 --> 0.411492).  Saving model ...
Validation loss decreased (0.411492 --> 0.411471).  Saving model ...
Validation loss decreased (0.411471 --> 0.411451).  Saving model ...
Validation loss decreased (0.411451 --> 0.411430).  Saving model ...
Validation loss decreased (0.411430 --> 0.411409).  Saving model ...
Validation loss decreased (0.411409 --> 0.411389).  Saving model ...
Validation loss decreased (0.411389 --> 0.411368).  Saving model ...
Validation loss decreased (0.411368 --> 0.411348).  Saving model ...
Validation loss decreased (0.411348 --> 0.411327).  Saving model ...
Validation loss decreased (0.411327 --> 0.411306).  Saving model ...
Validation loss decreased (0.411306 --> 0.411286).  Saving model ...
Validation loss decreased (0.411286 --> 0.411265).  Saving model ...
Validation loss decreased (0.411265 --> 0.411245).  Saving model ...
epoch 4101, loss 0.4112, train acc 80.85%, f1 0.7098, precision 0.7569, recall 0.6683, auc 0.7763
Validation loss decreased (0.411245 --> 0.411224).  Saving model ...
Validation loss decreased (0.411224 --> 0.411204).  Saving model ...
Validation loss decreased (0.411204 --> 0.411183).  Saving model ...
Validation loss decreased (0.411183 --> 0.411163).  Saving model ...
Validation loss decreased (0.411163 --> 0.411142).  Saving model ...
Validation loss decreased (0.411142 --> 0.411121).  Saving model ...
Validation loss decreased (0.411121 --> 0.411101).  Saving model ...
Validation loss decreased (0.411101 --> 0.411080).  Saving model ...
Validation loss decreased (0.411080 --> 0.411060).  Saving model ...
Validation loss decreased (0.411060 --> 0.411039).  Saving model ...
Validation loss decreased (0.411039 --> 0.411019).  Saving model ...
Validation loss decreased (0.411019 --> 0.410998).  Saving model ...
Validation loss decreased (0.410998 --> 0.410978).  Saving model ...
Validation loss decreased (0.410978 --> 0.410958).  Saving model ...
Validation loss decreased (0.410958 --> 0.410937).  Saving model ...
Validation loss decreased (0.410937 --> 0.410916).  Saving model ...
Validation loss decreased (0.410916 --> 0.410896).  Saving model ...
Validation loss decreased (0.410896 --> 0.410876).  Saving model ...
Validation loss decreased (0.410876 --> 0.410855).  Saving model ...
Validation loss decreased (0.410855 --> 0.410835).  Saving model ...
Validation loss decreased (0.410835 --> 0.410814).  Saving model ...
Validation loss decreased (0.410814 --> 0.410794).  Saving model ...
Validation loss decreased (0.410794 --> 0.410773).  Saving model ...
Validation loss decreased (0.410773 --> 0.410753).  Saving model ...
Validation loss decreased (0.410753 --> 0.410733).  Saving model ...
Validation loss decreased (0.410733 --> 0.410712).  Saving model ...
Validation loss decreased (0.410712 --> 0.410692).  Saving model ...
Validation loss decreased (0.410692 --> 0.410671).  Saving model ...
Validation loss decreased (0.410671 --> 0.410651).  Saving model ...
Validation loss decreased (0.410651 --> 0.410630).  Saving model ...
Validation loss decreased (0.410630 --> 0.410610).  Saving model ...
Validation loss decreased (0.410610 --> 0.410590).  Saving model ...
Validation loss decreased (0.410590 --> 0.410569).  Saving model ...
Validation loss decreased (0.410569 --> 0.410549).  Saving model ...
Validation loss decreased (0.410549 --> 0.410529).  Saving model ...
Validation loss decreased (0.410529 --> 0.410508).  Saving model ...
Validation loss decreased (0.410508 --> 0.410488).  Saving model ...
Validation loss decreased (0.410488 --> 0.410467).  Saving model ...
Validation loss decreased (0.410467 --> 0.410447).  Saving model ...
Validation loss decreased (0.410447 --> 0.410427).  Saving model ...
Validation loss decreased (0.410427 --> 0.410406).  Saving model ...
Validation loss decreased (0.410406 --> 0.410386).  Saving model ...
Validation loss decreased (0.410386 --> 0.410366).  Saving model ...
Validation loss decreased (0.410366 --> 0.410345).  Saving model ...
Validation loss decreased (0.410345 --> 0.410325).  Saving model ...
Validation loss decreased (0.410325 --> 0.410305).  Saving model ...
Validation loss decreased (0.410305 --> 0.410284).  Saving model ...
Validation loss decreased (0.410284 --> 0.410264).  Saving model ...
Validation loss decreased (0.410264 --> 0.410244).  Saving model ...
Validation loss decreased (0.410244 --> 0.410223).  Saving model ...
Validation loss decreased (0.410223 --> 0.410203).  Saving model ...
Validation loss decreased (0.410203 --> 0.410183).  Saving model ...
Validation loss decreased (0.410183 --> 0.410163).  Saving model ...
Validation loss decreased (0.410163 --> 0.410142).  Saving model ...
Validation loss decreased (0.410142 --> 0.410122).  Saving model ...
Validation loss decreased (0.410122 --> 0.410102).  Saving model ...
Validation loss decreased (0.410102 --> 0.410081).  Saving model ...
Validation loss decreased (0.410081 --> 0.410061).  Saving model ...
Validation loss decreased (0.410061 --> 0.410041).  Saving model ...
Validation loss decreased (0.410041 --> 0.410021).  Saving model ...
Validation loss decreased (0.410021 --> 0.410000).  Saving model ...
Validation loss decreased (0.410000 --> 0.409980).  Saving model ...
Validation loss decreased (0.409980 --> 0.409960).  Saving model ...
Validation loss decreased (0.409960 --> 0.409939).  Saving model ...
Validation loss decreased (0.409939 --> 0.409919).  Saving model ...
Validation loss decreased (0.409919 --> 0.409899).  Saving model ...
Validation loss decreased (0.409899 --> 0.409879).  Saving model ...
Validation loss decreased (0.409879 --> 0.409858).  Saving model ...
Validation loss decreased (0.409858 --> 0.409838).  Saving model ...
Validation loss decreased (0.409838 --> 0.409818).  Saving model ...
Validation loss decreased (0.409818 --> 0.409798).  Saving model ...
Validation loss decreased (0.409798 --> 0.409777).  Saving model ...
Validation loss decreased (0.409777 --> 0.409757).  Saving model ...
Validation loss decreased (0.409757 --> 0.409737).  Saving model ...
Validation loss decreased (0.409737 --> 0.409717).  Saving model ...
Validation loss decreased (0.409717 --> 0.409696).  Saving model ...
Validation loss decreased (0.409696 --> 0.409676).  Saving model ...
Validation loss decreased (0.409676 --> 0.409656).  Saving model ...
Validation loss decreased (0.409656 --> 0.409636).  Saving model ...
Validation loss decreased (0.409636 --> 0.409615).  Saving model ...
Validation loss decreased (0.409615 --> 0.409595).  Saving model ...
Validation loss decreased (0.409595 --> 0.409575).  Saving model ...
Validation loss decreased (0.409575 --> 0.409555).  Saving model ...
Validation loss decreased (0.409555 --> 0.409534).  Saving model ...
Validation loss decreased (0.409534 --> 0.409514).  Saving model ...
Validation loss decreased (0.409514 --> 0.409494).  Saving model ...
Validation loss decreased (0.409494 --> 0.409474).  Saving model ...
Validation loss decreased (0.409474 --> 0.409454).  Saving model ...
Validation loss decreased (0.409454 --> 0.409433).  Saving model ...
Validation loss decreased (0.409433 --> 0.409413).  Saving model ...
Validation loss decreased (0.409413 --> 0.409393).  Saving model ...
Validation loss decreased (0.409393 --> 0.409373).  Saving model ...
Validation loss decreased (0.409373 --> 0.409352).  Saving model ...
Validation loss decreased (0.409352 --> 0.409332).  Saving model ...
Validation loss decreased (0.409332 --> 0.409312).  Saving model ...
Validation loss decreased (0.409312 --> 0.409292).  Saving model ...
Validation loss decreased (0.409292 --> 0.409272).  Saving model ...
Validation loss decreased (0.409272 --> 0.409251).  Saving model ...
Validation loss decreased (0.409251 --> 0.409231).  Saving model ...
Validation loss decreased (0.409231 --> 0.409211).  Saving model ...
epoch 4201, loss 0.4092, train acc 81.20%, f1 0.7150, precision 0.7624, recall 0.6732, auc 0.7800
Validation loss decreased (0.409211 --> 0.409191).  Saving model ...
Validation loss decreased (0.409191 --> 0.409170).  Saving model ...
Validation loss decreased (0.409170 --> 0.409150).  Saving model ...
Validation loss decreased (0.409150 --> 0.409130).  Saving model ...
Validation loss decreased (0.409130 --> 0.409110).  Saving model ...
Validation loss decreased (0.409110 --> 0.409090).  Saving model ...
Validation loss decreased (0.409090 --> 0.409069).  Saving model ...
Validation loss decreased (0.409069 --> 0.409049).  Saving model ...
Validation loss decreased (0.409049 --> 0.409029).  Saving model ...
Validation loss decreased (0.409029 --> 0.409009).  Saving model ...
Validation loss decreased (0.409009 --> 0.408988).  Saving model ...
Validation loss decreased (0.408988 --> 0.408968).  Saving model ...
Validation loss decreased (0.408968 --> 0.408948).  Saving model ...
Validation loss decreased (0.408948 --> 0.408928).  Saving model ...
Validation loss decreased (0.408928 --> 0.408907).  Saving model ...
Validation loss decreased (0.408907 --> 0.408887).  Saving model ...
Validation loss decreased (0.408887 --> 0.408867).  Saving model ...
Validation loss decreased (0.408867 --> 0.408847).  Saving model ...
Validation loss decreased (0.408847 --> 0.408826).  Saving model ...
Validation loss decreased (0.408826 --> 0.408806).  Saving model ...
Validation loss decreased (0.408806 --> 0.408786).  Saving model ...
Validation loss decreased (0.408786 --> 0.408765).  Saving model ...
Validation loss decreased (0.408765 --> 0.408745).  Saving model ...
Validation loss decreased (0.408745 --> 0.408725).  Saving model ...
Validation loss decreased (0.408725 --> 0.408705).  Saving model ...
Validation loss decreased (0.408705 --> 0.408684).  Saving model ...
Validation loss decreased (0.408684 --> 0.408664).  Saving model ...
Validation loss decreased (0.408664 --> 0.408644).  Saving model ...
Validation loss decreased (0.408644 --> 0.408623).  Saving model ...
Validation loss decreased (0.408623 --> 0.408603).  Saving model ...
Validation loss decreased (0.408603 --> 0.408583).  Saving model ...
Validation loss decreased (0.408583 --> 0.408563).  Saving model ...
Validation loss decreased (0.408563 --> 0.408542).  Saving model ...
Validation loss decreased (0.408542 --> 0.408522).  Saving model ...
Validation loss decreased (0.408522 --> 0.408502).  Saving model ...
Validation loss decreased (0.408502 --> 0.408481).  Saving model ...
Validation loss decreased (0.408481 --> 0.408461).  Saving model ...
Validation loss decreased (0.408461 --> 0.408440).  Saving model ...
Validation loss decreased (0.408440 --> 0.408420).  Saving model ...
Validation loss decreased (0.408420 --> 0.408400).  Saving model ...
Validation loss decreased (0.408400 --> 0.408379).  Saving model ...
Validation loss decreased (0.408379 --> 0.408359).  Saving model ...
Validation loss decreased (0.408359 --> 0.408339).  Saving model ...
Validation loss decreased (0.408339 --> 0.408318).  Saving model ...
Validation loss decreased (0.408318 --> 0.408298).  Saving model ...
Validation loss decreased (0.408298 --> 0.408277).  Saving model ...
Validation loss decreased (0.408277 --> 0.408257).  Saving model ...
Validation loss decreased (0.408257 --> 0.408236).  Saving model ...
Validation loss decreased (0.408236 --> 0.408216).  Saving model ...
Validation loss decreased (0.408216 --> 0.408196).  Saving model ...
Validation loss decreased (0.408196 --> 0.408175).  Saving model ...
Validation loss decreased (0.408175 --> 0.408155).  Saving model ...
Validation loss decreased (0.408155 --> 0.408134).  Saving model ...
Validation loss decreased (0.408134 --> 0.408114).  Saving model ...
Validation loss decreased (0.408114 --> 0.408093).  Saving model ...
Validation loss decreased (0.408093 --> 0.408073).  Saving model ...
Validation loss decreased (0.408073 --> 0.408052).  Saving model ...
Validation loss decreased (0.408052 --> 0.408031).  Saving model ...
Validation loss decreased (0.408031 --> 0.408011).  Saving model ...
Validation loss decreased (0.408011 --> 0.407990).  Saving model ...
Validation loss decreased (0.407990 --> 0.407970).  Saving model ...
Validation loss decreased (0.407970 --> 0.407949).  Saving model ...
Validation loss decreased (0.407949 --> 0.407929).  Saving model ...
Validation loss decreased (0.407929 --> 0.407908).  Saving model ...
Validation loss decreased (0.407908 --> 0.407887).  Saving model ...
Validation loss decreased (0.407887 --> 0.407867).  Saving model ...
Validation loss decreased (0.407867 --> 0.407846).  Saving model ...
Validation loss decreased (0.407846 --> 0.407825).  Saving model ...
Validation loss decreased (0.407825 --> 0.407805).  Saving model ...
Validation loss decreased (0.407805 --> 0.407784).  Saving model ...
Validation loss decreased (0.407784 --> 0.407763).  Saving model ...
Validation loss decreased (0.407763 --> 0.407742).  Saving model ...
Validation loss decreased (0.407742 --> 0.407722).  Saving model ...
Validation loss decreased (0.407722 --> 0.407701).  Saving model ...
Validation loss decreased (0.407701 --> 0.407680).  Saving model ...
Validation loss decreased (0.407680 --> 0.407659).  Saving model ...
Validation loss decreased (0.407659 --> 0.407638).  Saving model ...
Validation loss decreased (0.407638 --> 0.407618).  Saving model ...
Validation loss decreased (0.407618 --> 0.407597).  Saving model ...
Validation loss decreased (0.407597 --> 0.407576).  Saving model ...
Validation loss decreased (0.407576 --> 0.407555).  Saving model ...
Validation loss decreased (0.407555 --> 0.407534).  Saving model ...
Validation loss decreased (0.407534 --> 0.407513).  Saving model ...
Validation loss decreased (0.407513 --> 0.407492).  Saving model ...
Validation loss decreased (0.407492 --> 0.407471).  Saving model ...
Validation loss decreased (0.407471 --> 0.407450).  Saving model ...
Validation loss decreased (0.407450 --> 0.407429).  Saving model ...
Validation loss decreased (0.407429 --> 0.407408).  Saving model ...
Validation loss decreased (0.407408 --> 0.407387).  Saving model ...
Validation loss decreased (0.407387 --> 0.407366).  Saving model ...
Validation loss decreased (0.407366 --> 0.407345).  Saving model ...
Validation loss decreased (0.407345 --> 0.407324).  Saving model ...
Validation loss decreased (0.407324 --> 0.407303).  Saving model ...
Validation loss decreased (0.407303 --> 0.407281).  Saving model ...
Validation loss decreased (0.407281 --> 0.407260).  Saving model ...
Validation loss decreased (0.407260 --> 0.407239).  Saving model ...
Validation loss decreased (0.407239 --> 0.407218).  Saving model ...
Validation loss decreased (0.407218 --> 0.407197).  Saving model ...
Validation loss decreased (0.407197 --> 0.407175).  Saving model ...
Validation loss decreased (0.407175 --> 0.407154).  Saving model ...
epoch 4301, loss 0.4072, train acc 81.37%, f1 0.7183, precision 0.7637, recall 0.6780, auc 0.7824
Validation loss decreased (0.407154 --> 0.407133).  Saving model ...
Validation loss decreased (0.407133 --> 0.407111).  Saving model ...
Validation loss decreased (0.407111 --> 0.407090).  Saving model ...
Validation loss decreased (0.407090 --> 0.407069).  Saving model ...
Validation loss decreased (0.407069 --> 0.407047).  Saving model ...
Validation loss decreased (0.407047 --> 0.407026).  Saving model ...
Validation loss decreased (0.407026 --> 0.407004).  Saving model ...
Validation loss decreased (0.407004 --> 0.406983).  Saving model ...
Validation loss decreased (0.406983 --> 0.406961).  Saving model ...
Validation loss decreased (0.406961 --> 0.406940).  Saving model ...
Validation loss decreased (0.406940 --> 0.406918).  Saving model ...
Validation loss decreased (0.406918 --> 0.406896).  Saving model ...
Validation loss decreased (0.406896 --> 0.406875).  Saving model ...
Validation loss decreased (0.406875 --> 0.406853).  Saving model ...
Validation loss decreased (0.406853 --> 0.406831).  Saving model ...
Validation loss decreased (0.406831 --> 0.406810).  Saving model ...
Validation loss decreased (0.406810 --> 0.406788).  Saving model ...
Validation loss decreased (0.406788 --> 0.406766).  Saving model ...
Validation loss decreased (0.406766 --> 0.406744).  Saving model ...
Validation loss decreased (0.406744 --> 0.406723).  Saving model ...
Validation loss decreased (0.406723 --> 0.406701).  Saving model ...
Validation loss decreased (0.406701 --> 0.406679).  Saving model ...
Validation loss decreased (0.406679 --> 0.406657).  Saving model ...
Validation loss decreased (0.406657 --> 0.406635).  Saving model ...
Validation loss decreased (0.406635 --> 0.406613).  Saving model ...
Validation loss decreased (0.406613 --> 0.406591).  Saving model ...
Validation loss decreased (0.406591 --> 0.406569).  Saving model ...
Validation loss decreased (0.406569 --> 0.406547).  Saving model ...
Validation loss decreased (0.406547 --> 0.406525).  Saving model ...
Validation loss decreased (0.406525 --> 0.406503).  Saving model ...
Validation loss decreased (0.406503 --> 0.406481).  Saving model ...
Validation loss decreased (0.406481 --> 0.406459).  Saving model ...
Validation loss decreased (0.406459 --> 0.406437).  Saving model ...
Validation loss decreased (0.406437 --> 0.406415).  Saving model ...
Validation loss decreased (0.406415 --> 0.406393).  Saving model ...
Validation loss decreased (0.406393 --> 0.406370).  Saving model ...
Validation loss decreased (0.406370 --> 0.406348).  Saving model ...
Validation loss decreased (0.406348 --> 0.406326).  Saving model ...
Validation loss decreased (0.406326 --> 0.406304).  Saving model ...
Validation loss decreased (0.406304 --> 0.406281).  Saving model ...
Validation loss decreased (0.406281 --> 0.406259).  Saving model ...
Validation loss decreased (0.406259 --> 0.406237).  Saving model ...
Validation loss decreased (0.406237 --> 0.406214).  Saving model ...
Validation loss decreased (0.406214 --> 0.406192).  Saving model ...
Validation loss decreased (0.406192 --> 0.406170).  Saving model ...
Validation loss decreased (0.406170 --> 0.406147).  Saving model ...
Validation loss decreased (0.406147 --> 0.406125).  Saving model ...
Validation loss decreased (0.406125 --> 0.406103).  Saving model ...
Validation loss decreased (0.406103 --> 0.406080).  Saving model ...
Validation loss decreased (0.406080 --> 0.406058).  Saving model ...
Validation loss decreased (0.406058 --> 0.406035).  Saving model ...
Validation loss decreased (0.406035 --> 0.406013).  Saving model ...
Validation loss decreased (0.406013 --> 0.405990).  Saving model ...
Validation loss decreased (0.405990 --> 0.405968).  Saving model ...
Validation loss decreased (0.405968 --> 0.405945).  Saving model ...
Validation loss decreased (0.405945 --> 0.405923).  Saving model ...
Validation loss decreased (0.405923 --> 0.405900).  Saving model ...
Validation loss decreased (0.405900 --> 0.405877).  Saving model ...
Validation loss decreased (0.405877 --> 0.405855).  Saving model ...
Validation loss decreased (0.405855 --> 0.405832).  Saving model ...
Validation loss decreased (0.405832 --> 0.405810).  Saving model ...
Validation loss decreased (0.405810 --> 0.405787).  Saving model ...
Validation loss decreased (0.405787 --> 0.405764).  Saving model ...
Validation loss decreased (0.405764 --> 0.405742).  Saving model ...
Validation loss decreased (0.405742 --> 0.405719).  Saving model ...
Validation loss decreased (0.405719 --> 0.405696).  Saving model ...
Validation loss decreased (0.405696 --> 0.405674).  Saving model ...
Validation loss decreased (0.405674 --> 0.405651).  Saving model ...
Validation loss decreased (0.405651 --> 0.405628).  Saving model ...
Validation loss decreased (0.405628 --> 0.405606).  Saving model ...
Validation loss decreased (0.405606 --> 0.405583).  Saving model ...
Validation loss decreased (0.405583 --> 0.405560).  Saving model ...
Validation loss decreased (0.405560 --> 0.405538).  Saving model ...
Validation loss decreased (0.405538 --> 0.405515).  Saving model ...
Validation loss decreased (0.405515 --> 0.405492).  Saving model ...
Validation loss decreased (0.405492 --> 0.405469).  Saving model ...
Validation loss decreased (0.405469 --> 0.405447).  Saving model ...
Validation loss decreased (0.405447 --> 0.405424).  Saving model ...
Validation loss decreased (0.405424 --> 0.405401).  Saving model ...
Validation loss decreased (0.405401 --> 0.405378).  Saving model ...
Validation loss decreased (0.405378 --> 0.405356).  Saving model ...
Validation loss decreased (0.405356 --> 0.405333).  Saving model ...
Validation loss decreased (0.405333 --> 0.405310).  Saving model ...
Validation loss decreased (0.405310 --> 0.405288).  Saving model ...
Validation loss decreased (0.405288 --> 0.405265).  Saving model ...
Validation loss decreased (0.405265 --> 0.405242).  Saving model ...
Validation loss decreased (0.405242 --> 0.405219).  Saving model ...
Validation loss decreased (0.405219 --> 0.405196).  Saving model ...
Validation loss decreased (0.405196 --> 0.405174).  Saving model ...
Validation loss decreased (0.405174 --> 0.405151).  Saving model ...
Validation loss decreased (0.405151 --> 0.405128).  Saving model ...
Validation loss decreased (0.405128 --> 0.405105).  Saving model ...
Validation loss decreased (0.405105 --> 0.405083).  Saving model ...
Validation loss decreased (0.405083 --> 0.405060).  Saving model ...
Validation loss decreased (0.405060 --> 0.405037).  Saving model ...
Validation loss decreased (0.405037 --> 0.405014).  Saving model ...
Validation loss decreased (0.405014 --> 0.404992).  Saving model ...
Validation loss decreased (0.404992 --> 0.404969).  Saving model ...
Validation loss decreased (0.404969 --> 0.404946).  Saving model ...
Validation loss decreased (0.404946 --> 0.404923).  Saving model ...
epoch 4401, loss 0.4049, train acc 81.37%, f1 0.7169, precision 0.7667, recall 0.6732, auc 0.7813
Validation loss decreased (0.404923 --> 0.404901).  Saving model ...
Validation loss decreased (0.404901 --> 0.404878).  Saving model ...
Validation loss decreased (0.404878 --> 0.404855).  Saving model ...
Validation loss decreased (0.404855 --> 0.404833).  Saving model ...
Validation loss decreased (0.404833 --> 0.404810).  Saving model ...
Validation loss decreased (0.404810 --> 0.404787).  Saving model ...
Validation loss decreased (0.404787 --> 0.404764).  Saving model ...
Validation loss decreased (0.404764 --> 0.404742).  Saving model ...
Validation loss decreased (0.404742 --> 0.404719).  Saving model ...
Validation loss decreased (0.404719 --> 0.404696).  Saving model ...
Validation loss decreased (0.404696 --> 0.404674).  Saving model ...
Validation loss decreased (0.404674 --> 0.404651).  Saving model ...
Validation loss decreased (0.404651 --> 0.404628).  Saving model ...
Validation loss decreased (0.404628 --> 0.404605).  Saving model ...
Validation loss decreased (0.404605 --> 0.404583).  Saving model ...
Validation loss decreased (0.404583 --> 0.404560).  Saving model ...
Validation loss decreased (0.404560 --> 0.404537).  Saving model ...
Validation loss decreased (0.404537 --> 0.404515).  Saving model ...
Validation loss decreased (0.404515 --> 0.404492).  Saving model ...
Validation loss decreased (0.404492 --> 0.404469).  Saving model ...
Validation loss decreased (0.404469 --> 0.404447).  Saving model ...
Validation loss decreased (0.404447 --> 0.404424).  Saving model ...
Validation loss decreased (0.404424 --> 0.404401).  Saving model ...
Validation loss decreased (0.404401 --> 0.404379).  Saving model ...
Validation loss decreased (0.404379 --> 0.404356).  Saving model ...
Validation loss decreased (0.404356 --> 0.404333).  Saving model ...
Validation loss decreased (0.404333 --> 0.404311).  Saving model ...
Validation loss decreased (0.404311 --> 0.404288).  Saving model ...
Validation loss decreased (0.404288 --> 0.404265).  Saving model ...
Validation loss decreased (0.404265 --> 0.404243).  Saving model ...
Validation loss decreased (0.404243 --> 0.404220).  Saving model ...
Validation loss decreased (0.404220 --> 0.404197).  Saving model ...
Validation loss decreased (0.404197 --> 0.404175).  Saving model ...
Validation loss decreased (0.404175 --> 0.404152).  Saving model ...
Validation loss decreased (0.404152 --> 0.404130).  Saving model ...
Validation loss decreased (0.404130 --> 0.404107).  Saving model ...
Validation loss decreased (0.404107 --> 0.404084).  Saving model ...
Validation loss decreased (0.404084 --> 0.404062).  Saving model ...
Validation loss decreased (0.404062 --> 0.404039).  Saving model ...
Validation loss decreased (0.404039 --> 0.404016).  Saving model ...
Validation loss decreased (0.404016 --> 0.403994).  Saving model ...
Validation loss decreased (0.403994 --> 0.403971).  Saving model ...
Validation loss decreased (0.403971 --> 0.403948).  Saving model ...
Validation loss decreased (0.403948 --> 0.403926).  Saving model ...
Validation loss decreased (0.403926 --> 0.403903).  Saving model ...
Validation loss decreased (0.403903 --> 0.403880).  Saving model ...
Validation loss decreased (0.403880 --> 0.403858).  Saving model ...
Validation loss decreased (0.403858 --> 0.403835).  Saving model ...
Validation loss decreased (0.403835 --> 0.403812).  Saving model ...
Validation loss decreased (0.403812 --> 0.403790).  Saving model ...
Validation loss decreased (0.403790 --> 0.403767).  Saving model ...
Validation loss decreased (0.403767 --> 0.403744).  Saving model ...
Validation loss decreased (0.403744 --> 0.403722).  Saving model ...
Validation loss decreased (0.403722 --> 0.403699).  Saving model ...
Validation loss decreased (0.403699 --> 0.403676).  Saving model ...
Validation loss decreased (0.403676 --> 0.403653).  Saving model ...
Validation loss decreased (0.403653 --> 0.403631).  Saving model ...
Validation loss decreased (0.403631 --> 0.403608).  Saving model ...
Validation loss decreased (0.403608 --> 0.403585).  Saving model ...
Validation loss decreased (0.403585 --> 0.403562).  Saving model ...
Validation loss decreased (0.403562 --> 0.403540).  Saving model ...
Validation loss decreased (0.403540 --> 0.403517).  Saving model ...
Validation loss decreased (0.403517 --> 0.403494).  Saving model ...
Validation loss decreased (0.403494 --> 0.403471).  Saving model ...
Validation loss decreased (0.403471 --> 0.403449).  Saving model ...
Validation loss decreased (0.403449 --> 0.403426).  Saving model ...
Validation loss decreased (0.403426 --> 0.403403).  Saving model ...
Validation loss decreased (0.403403 --> 0.403380).  Saving model ...
Validation loss decreased (0.403380 --> 0.403357).  Saving model ...
Validation loss decreased (0.403357 --> 0.403334).  Saving model ...
Validation loss decreased (0.403334 --> 0.403311).  Saving model ...
Validation loss decreased (0.403311 --> 0.403289).  Saving model ...
Validation loss decreased (0.403289 --> 0.403266).  Saving model ...
Validation loss decreased (0.403266 --> 0.403243).  Saving model ...
Validation loss decreased (0.403243 --> 0.403220).  Saving model ...
Validation loss decreased (0.403220 --> 0.403197).  Saving model ...
Validation loss decreased (0.403197 --> 0.403174).  Saving model ...
Validation loss decreased (0.403174 --> 0.403151).  Saving model ...
Validation loss decreased (0.403151 --> 0.403128).  Saving model ...
Validation loss decreased (0.403128 --> 0.403105).  Saving model ...
Validation loss decreased (0.403105 --> 0.403082).  Saving model ...
Validation loss decreased (0.403082 --> 0.403059).  Saving model ...
Validation loss decreased (0.403059 --> 0.403036).  Saving model ...
Validation loss decreased (0.403036 --> 0.403013).  Saving model ...
Validation loss decreased (0.403013 --> 0.402989).  Saving model ...
Validation loss decreased (0.402989 --> 0.402966).  Saving model ...
Validation loss decreased (0.402966 --> 0.402943).  Saving model ...
Validation loss decreased (0.402943 --> 0.402920).  Saving model ...
Validation loss decreased (0.402920 --> 0.402897).  Saving model ...
Validation loss decreased (0.402897 --> 0.402873).  Saving model ...
Validation loss decreased (0.402873 --> 0.402850).  Saving model ...
Validation loss decreased (0.402850 --> 0.402827).  Saving model ...
Validation loss decreased (0.402827 --> 0.402804).  Saving model ...
Validation loss decreased (0.402804 --> 0.402780).  Saving model ...
Validation loss decreased (0.402780 --> 0.402757).  Saving model ...
Validation loss decreased (0.402757 --> 0.402733).  Saving model ...
Validation loss decreased (0.402733 --> 0.402710).  Saving model ...
Validation loss decreased (0.402710 --> 0.402687).  Saving model ...
Validation loss decreased (0.402687 --> 0.402663).  Saving model ...
Validation loss decreased (0.402663 --> 0.402640).  Saving model ...
epoch 4501, loss 0.4026, train acc 81.54%, f1 0.7202, precision 0.7680, recall 0.6780, auc 0.7838
Validation loss decreased (0.402640 --> 0.402616).  Saving model ...
Validation loss decreased (0.402616 --> 0.402593).  Saving model ...
Validation loss decreased (0.402593 --> 0.402569).  Saving model ...
Validation loss decreased (0.402569 --> 0.402545).  Saving model ...
Validation loss decreased (0.402545 --> 0.402522).  Saving model ...
Validation loss decreased (0.402522 --> 0.402498).  Saving model ...
Validation loss decreased (0.402498 --> 0.402474).  Saving model ...
Validation loss decreased (0.402474 --> 0.402451).  Saving model ...
Validation loss decreased (0.402451 --> 0.402427).  Saving model ...
Validation loss decreased (0.402427 --> 0.402403).  Saving model ...
Validation loss decreased (0.402403 --> 0.402379).  Saving model ...
Validation loss decreased (0.402379 --> 0.402356).  Saving model ...
Validation loss decreased (0.402356 --> 0.402332).  Saving model ...
Validation loss decreased (0.402332 --> 0.402308).  Saving model ...
Validation loss decreased (0.402308 --> 0.402284).  Saving model ...
Validation loss decreased (0.402284 --> 0.402260).  Saving model ...
Validation loss decreased (0.402260 --> 0.402236).  Saving model ...
Validation loss decreased (0.402236 --> 0.402212).  Saving model ...
Validation loss decreased (0.402212 --> 0.402188).  Saving model ...
Validation loss decreased (0.402188 --> 0.402163).  Saving model ...
Validation loss decreased (0.402163 --> 0.402139).  Saving model ...
Validation loss decreased (0.402139 --> 0.402115).  Saving model ...
Validation loss decreased (0.402115 --> 0.402091).  Saving model ...
Validation loss decreased (0.402091 --> 0.402067).  Saving model ...
Validation loss decreased (0.402067 --> 0.402042).  Saving model ...
Validation loss decreased (0.402042 --> 0.402018).  Saving model ...
Validation loss decreased (0.402018 --> 0.401994).  Saving model ...
Validation loss decreased (0.401994 --> 0.401969).  Saving model ...
Validation loss decreased (0.401969 --> 0.401945).  Saving model ...
Validation loss decreased (0.401945 --> 0.401920).  Saving model ...
Validation loss decreased (0.401920 --> 0.401896).  Saving model ...
Validation loss decreased (0.401896 --> 0.401871).  Saving model ...
Validation loss decreased (0.401871 --> 0.401846).  Saving model ...
Validation loss decreased (0.401846 --> 0.401822).  Saving model ...
Validation loss decreased (0.401822 --> 0.401797).  Saving model ...
Validation loss decreased (0.401797 --> 0.401772).  Saving model ...
Validation loss decreased (0.401772 --> 0.401747).  Saving model ...
Validation loss decreased (0.401747 --> 0.401723).  Saving model ...
Validation loss decreased (0.401723 --> 0.401698).  Saving model ...
Validation loss decreased (0.401698 --> 0.401673).  Saving model ...
Validation loss decreased (0.401673 --> 0.401648).  Saving model ...
Validation loss decreased (0.401648 --> 0.401623).  Saving model ...
Validation loss decreased (0.401623 --> 0.401598).  Saving model ...
Validation loss decreased (0.401598 --> 0.401573).  Saving model ...
Validation loss decreased (0.401573 --> 0.401547).  Saving model ...
Validation loss decreased (0.401547 --> 0.401522).  Saving model ...
Validation loss decreased (0.401522 --> 0.401497).  Saving model ...
Validation loss decreased (0.401497 --> 0.401472).  Saving model ...
Validation loss decreased (0.401472 --> 0.401446).  Saving model ...
Validation loss decreased (0.401446 --> 0.401421).  Saving model ...
Validation loss decreased (0.401421 --> 0.401396).  Saving model ...
Validation loss decreased (0.401396 --> 0.401370).  Saving model ...
Validation loss decreased (0.401370 --> 0.401345).  Saving model ...
Validation loss decreased (0.401345 --> 0.401319).  Saving model ...
Validation loss decreased (0.401319 --> 0.401293).  Saving model ...
Validation loss decreased (0.401293 --> 0.401268).  Saving model ...
Validation loss decreased (0.401268 --> 0.401242).  Saving model ...
Validation loss decreased (0.401242 --> 0.401216).  Saving model ...
Validation loss decreased (0.401216 --> 0.401190).  Saving model ...
Validation loss decreased (0.401190 --> 0.401165).  Saving model ...
Validation loss decreased (0.401165 --> 0.401139).  Saving model ...
Validation loss decreased (0.401139 --> 0.401113).  Saving model ...
Validation loss decreased (0.401113 --> 0.401087).  Saving model ...
Validation loss decreased (0.401087 --> 0.401061).  Saving model ...
Validation loss decreased (0.401061 --> 0.401035).  Saving model ...
Validation loss decreased (0.401035 --> 0.401009).  Saving model ...
Validation loss decreased (0.401009 --> 0.400982).  Saving model ...
Validation loss decreased (0.400982 --> 0.400956).  Saving model ...
Validation loss decreased (0.400956 --> 0.400930).  Saving model ...
Validation loss decreased (0.400930 --> 0.400904).  Saving model ...
Validation loss decreased (0.400904 --> 0.400877).  Saving model ...
Validation loss decreased (0.400877 --> 0.400851).  Saving model ...
Validation loss decreased (0.400851 --> 0.400824).  Saving model ...
Validation loss decreased (0.400824 --> 0.400798).  Saving model ...
Validation loss decreased (0.400798 --> 0.400771).  Saving model ...
Validation loss decreased (0.400771 --> 0.400745).  Saving model ...
Validation loss decreased (0.400745 --> 0.400718).  Saving model ...
Validation loss decreased (0.400718 --> 0.400691).  Saving model ...
Validation loss decreased (0.400691 --> 0.400664).  Saving model ...
Validation loss decreased (0.400664 --> 0.400638).  Saving model ...
Validation loss decreased (0.400638 --> 0.400611).  Saving model ...
Validation loss decreased (0.400611 --> 0.400584).  Saving model ...
Validation loss decreased (0.400584 --> 0.400557).  Saving model ...
Validation loss decreased (0.400557 --> 0.400530).  Saving model ...
Validation loss decreased (0.400530 --> 0.400503).  Saving model ...
Validation loss decreased (0.400503 --> 0.400476).  Saving model ...
Validation loss decreased (0.400476 --> 0.400449).  Saving model ...
Validation loss decreased (0.400449 --> 0.400421).  Saving model ...
Validation loss decreased (0.400421 --> 0.400394).  Saving model ...
Validation loss decreased (0.400394 --> 0.400367).  Saving model ...
Validation loss decreased (0.400367 --> 0.400340).  Saving model ...
Validation loss decreased (0.400340 --> 0.400312).  Saving model ...
Validation loss decreased (0.400312 --> 0.400285).  Saving model ...
Validation loss decreased (0.400285 --> 0.400257).  Saving model ...
Validation loss decreased (0.400257 --> 0.400230).  Saving model ...
Validation loss decreased (0.400230 --> 0.400202).  Saving model ...
Validation loss decreased (0.400202 --> 0.400175).  Saving model ...
Validation loss decreased (0.400175 --> 0.400147).  Saving model ...
Validation loss decreased (0.400147 --> 0.400120).  Saving model ...
Validation loss decreased (0.400120 --> 0.400092).  Saving model ...
epoch 4601, loss 0.4001, train acc 81.54%, f1 0.7202, precision 0.7680, recall 0.6780, auc 0.7838
Validation loss decreased (0.400092 --> 0.400064).  Saving model ...
Validation loss decreased (0.400064 --> 0.400037).  Saving model ...
Validation loss decreased (0.400037 --> 0.400009).  Saving model ...
Validation loss decreased (0.400009 --> 0.399981).  Saving model ...
Validation loss decreased (0.399981 --> 0.399953).  Saving model ...
Validation loss decreased (0.399953 --> 0.399925).  Saving model ...
Validation loss decreased (0.399925 --> 0.399897).  Saving model ...
Validation loss decreased (0.399897 --> 0.399869).  Saving model ...
Validation loss decreased (0.399869 --> 0.399841).  Saving model ...
Validation loss decreased (0.399841 --> 0.399813).  Saving model ...
Validation loss decreased (0.399813 --> 0.399785).  Saving model ...
Validation loss decreased (0.399785 --> 0.399757).  Saving model ...
Validation loss decreased (0.399757 --> 0.399729).  Saving model ...
Validation loss decreased (0.399729 --> 0.399700).  Saving model ...
Validation loss decreased (0.399700 --> 0.399672).  Saving model ...
Validation loss decreased (0.399672 --> 0.399644).  Saving model ...
Validation loss decreased (0.399644 --> 0.399615).  Saving model ...
Validation loss decreased (0.399615 --> 0.399587).  Saving model ...
Validation loss decreased (0.399587 --> 0.399559).  Saving model ...
Validation loss decreased (0.399559 --> 0.399530).  Saving model ...
Validation loss decreased (0.399530 --> 0.399502).  Saving model ...
Validation loss decreased (0.399502 --> 0.399473).  Saving model ...
Validation loss decreased (0.399473 --> 0.399445).  Saving model ...
Validation loss decreased (0.399445 --> 0.399416).  Saving model ...
Validation loss decreased (0.399416 --> 0.399388).  Saving model ...
Validation loss decreased (0.399388 --> 0.399359).  Saving model ...
Validation loss decreased (0.399359 --> 0.399330).  Saving model ...
Validation loss decreased (0.399330 --> 0.399302).  Saving model ...
Validation loss decreased (0.399302 --> 0.399273).  Saving model ...
Validation loss decreased (0.399273 --> 0.399244).  Saving model ...
Validation loss decreased (0.399244 --> 0.399215).  Saving model ...
Validation loss decreased (0.399215 --> 0.399187).  Saving model ...
Validation loss decreased (0.399187 --> 0.399158).  Saving model ...
Validation loss decreased (0.399158 --> 0.399129).  Saving model ...
Validation loss decreased (0.399129 --> 0.399100).  Saving model ...
Validation loss decreased (0.399100 --> 0.399071).  Saving model ...
Validation loss decreased (0.399071 --> 0.399042).  Saving model ...
Validation loss decreased (0.399042 --> 0.399013).  Saving model ...
Validation loss decreased (0.399013 --> 0.398984).  Saving model ...
Validation loss decreased (0.398984 --> 0.398955).  Saving model ...
Validation loss decreased (0.398955 --> 0.398926).  Saving model ...
Validation loss decreased (0.398926 --> 0.398896).  Saving model ...
Validation loss decreased (0.398896 --> 0.398867).  Saving model ...
Validation loss decreased (0.398867 --> 0.398838).  Saving model ...
Validation loss decreased (0.398838 --> 0.398809).  Saving model ...
Validation loss decreased (0.398809 --> 0.398779).  Saving model ...
Validation loss decreased (0.398779 --> 0.398750).  Saving model ...
Validation loss decreased (0.398750 --> 0.398720).  Saving model ...
Validation loss decreased (0.398720 --> 0.398691).  Saving model ...
Validation loss decreased (0.398691 --> 0.398661).  Saving model ...
Validation loss decreased (0.398661 --> 0.398632).  Saving model ...
Validation loss decreased (0.398632 --> 0.398602).  Saving model ...
Validation loss decreased (0.398602 --> 0.398572).  Saving model ...
Validation loss decreased (0.398572 --> 0.398543).  Saving model ...
Validation loss decreased (0.398543 --> 0.398513).  Saving model ...
Validation loss decreased (0.398513 --> 0.398483).  Saving model ...
Validation loss decreased (0.398483 --> 0.398453).  Saving model ...
Validation loss decreased (0.398453 --> 0.398423).  Saving model ...
Validation loss decreased (0.398423 --> 0.398394).  Saving model ...
Validation loss decreased (0.398394 --> 0.398364).  Saving model ...
Validation loss decreased (0.398364 --> 0.398334).  Saving model ...
Validation loss decreased (0.398334 --> 0.398303).  Saving model ...
Validation loss decreased (0.398303 --> 0.398273).  Saving model ...
Validation loss decreased (0.398273 --> 0.398243).  Saving model ...
Validation loss decreased (0.398243 --> 0.398213).  Saving model ...
Validation loss decreased (0.398213 --> 0.398182).  Saving model ...
Validation loss decreased (0.398182 --> 0.398152).  Saving model ...
Validation loss decreased (0.398152 --> 0.398122).  Saving model ...
Validation loss decreased (0.398122 --> 0.398091).  Saving model ...
Validation loss decreased (0.398091 --> 0.398061).  Saving model ...
Validation loss decreased (0.398061 --> 0.398030).  Saving model ...
Validation loss decreased (0.398030 --> 0.397999).  Saving model ...
Validation loss decreased (0.397999 --> 0.397969).  Saving model ...
Validation loss decreased (0.397969 --> 0.397938).  Saving model ...
Validation loss decreased (0.397938 --> 0.397907).  Saving model ...
Validation loss decreased (0.397907 --> 0.397876).  Saving model ...
Validation loss decreased (0.397876 --> 0.397845).  Saving model ...
Validation loss decreased (0.397845 --> 0.397814).  Saving model ...
Validation loss decreased (0.397814 --> 0.397783).  Saving model ...
Validation loss decreased (0.397783 --> 0.397752).  Saving model ...
Validation loss decreased (0.397752 --> 0.397721).  Saving model ...
Validation loss decreased (0.397721 --> 0.397689).  Saving model ...
Validation loss decreased (0.397689 --> 0.397658).  Saving model ...
Validation loss decreased (0.397658 --> 0.397627).  Saving model ...
Validation loss decreased (0.397627 --> 0.397595).  Saving model ...
Validation loss decreased (0.397595 --> 0.397564).  Saving model ...
Validation loss decreased (0.397564 --> 0.397532).  Saving model ...
Validation loss decreased (0.397532 --> 0.397500).  Saving model ...
Validation loss decreased (0.397500 --> 0.397469).  Saving model ...
Validation loss decreased (0.397469 --> 0.397437).  Saving model ...
Validation loss decreased (0.397437 --> 0.397405).  Saving model ...
Validation loss decreased (0.397405 --> 0.397373).  Saving model ...
Validation loss decreased (0.397373 --> 0.397341).  Saving model ...
Validation loss decreased (0.397341 --> 0.397309).  Saving model ...
Validation loss decreased (0.397309 --> 0.397277).  Saving model ...
Validation loss decreased (0.397277 --> 0.397245).  Saving model ...
Validation loss decreased (0.397245 --> 0.397212).  Saving model ...
Validation loss decreased (0.397212 --> 0.397180).  Saving model ...
Validation loss decreased (0.397180 --> 0.397148).  Saving model ...
Validation loss decreased (0.397148 --> 0.397115).  Saving model ...
epoch 4701, loss 0.3971, train acc 81.88%, f1 0.7240, precision 0.7765, recall 0.6780, auc 0.7864
Validation loss decreased (0.397115 --> 0.397083).  Saving model ...
Validation loss decreased (0.397083 --> 0.397050).  Saving model ...
Validation loss decreased (0.397050 --> 0.397017).  Saving model ...
Validation loss decreased (0.397017 --> 0.396985).  Saving model ...
Validation loss decreased (0.396985 --> 0.396952).  Saving model ...
Validation loss decreased (0.396952 --> 0.396919).  Saving model ...
Validation loss decreased (0.396919 --> 0.396886).  Saving model ...
Validation loss decreased (0.396886 --> 0.396853).  Saving model ...
Validation loss decreased (0.396853 --> 0.396820).  Saving model ...
Validation loss decreased (0.396820 --> 0.396787).  Saving model ...
Validation loss decreased (0.396787 --> 0.396754).  Saving model ...
Validation loss decreased (0.396754 --> 0.396721).  Saving model ...
Validation loss decreased (0.396721 --> 0.396688).  Saving model ...
Validation loss decreased (0.396688 --> 0.396654).  Saving model ...
Validation loss decreased (0.396654 --> 0.396621).  Saving model ...
Validation loss decreased (0.396621 --> 0.396588).  Saving model ...
Validation loss decreased (0.396588 --> 0.396554).  Saving model ...
Validation loss decreased (0.396554 --> 0.396521).  Saving model ...
Validation loss decreased (0.396521 --> 0.396487).  Saving model ...
Validation loss decreased (0.396487 --> 0.396453).  Saving model ...
Validation loss decreased (0.396453 --> 0.396420).  Saving model ...
Validation loss decreased (0.396420 --> 0.396386).  Saving model ...
Validation loss decreased (0.396386 --> 0.396352).  Saving model ...
Validation loss decreased (0.396352 --> 0.396318).  Saving model ...
Validation loss decreased (0.396318 --> 0.396284).  Saving model ...
Validation loss decreased (0.396284 --> 0.396250).  Saving model ...
Validation loss decreased (0.396250 --> 0.396216).  Saving model ...
Validation loss decreased (0.396216 --> 0.396182).  Saving model ...
Validation loss decreased (0.396182 --> 0.396148).  Saving model ...
Validation loss decreased (0.396148 --> 0.396113).  Saving model ...
Validation loss decreased (0.396113 --> 0.396079).  Saving model ...
Validation loss decreased (0.396079 --> 0.396045).  Saving model ...
Validation loss decreased (0.396045 --> 0.396010).  Saving model ...
Validation loss decreased (0.396010 --> 0.395976).  Saving model ...
Validation loss decreased (0.395976 --> 0.395941).  Saving model ...
Validation loss decreased (0.395941 --> 0.395907).  Saving model ...
Validation loss decreased (0.395907 --> 0.395872).  Saving model ...
Validation loss decreased (0.395872 --> 0.395837).  Saving model ...
Validation loss decreased (0.395837 --> 0.395803).  Saving model ...
Validation loss decreased (0.395803 --> 0.395768).  Saving model ...
Validation loss decreased (0.395768 --> 0.395733).  Saving model ...
Validation loss decreased (0.395733 --> 0.395698).  Saving model ...
Validation loss decreased (0.395698 --> 0.395663).  Saving model ...
Validation loss decreased (0.395663 --> 0.395628).  Saving model ...
Validation loss decreased (0.395628 --> 0.395593).  Saving model ...
Validation loss decreased (0.395593 --> 0.395558).  Saving model ...
Validation loss decreased (0.395558 --> 0.395523).  Saving model ...
Validation loss decreased (0.395523 --> 0.395487).  Saving model ...
Validation loss decreased (0.395487 --> 0.395452).  Saving model ...
Validation loss decreased (0.395452 --> 0.395417).  Saving model ...
Validation loss decreased (0.395417 --> 0.395381).  Saving model ...
Validation loss decreased (0.395381 --> 0.395346).  Saving model ...
Validation loss decreased (0.395346 --> 0.395310).  Saving model ...
Validation loss decreased (0.395310 --> 0.395275).  Saving model ...
Validation loss decreased (0.395275 --> 0.395239).  Saving model ...
Validation loss decreased (0.395239 --> 0.395204).  Saving model ...
Validation loss decreased (0.395204 --> 0.395168).  Saving model ...
Validation loss decreased (0.395168 --> 0.395132).  Saving model ...
Validation loss decreased (0.395132 --> 0.395096).  Saving model ...
Validation loss decreased (0.395096 --> 0.395060).  Saving model ...
Validation loss decreased (0.395060 --> 0.395024).  Saving model ...
Validation loss decreased (0.395024 --> 0.394988).  Saving model ...
Validation loss decreased (0.394988 --> 0.394952).  Saving model ...
Validation loss decreased (0.394952 --> 0.394916).  Saving model ...
Validation loss decreased (0.394916 --> 0.394880).  Saving model ...
Validation loss decreased (0.394880 --> 0.394843).  Saving model ...
Validation loss decreased (0.394843 --> 0.394807).  Saving model ...
Validation loss decreased (0.394807 --> 0.394771).  Saving model ...
Validation loss decreased (0.394771 --> 0.394734).  Saving model ...
Validation loss decreased (0.394734 --> 0.394698).  Saving model ...
Validation loss decreased (0.394698 --> 0.394661).  Saving model ...
Validation loss decreased (0.394661 --> 0.394624).  Saving model ...
Validation loss decreased (0.394624 --> 0.394588).  Saving model ...
Validation loss decreased (0.394588 --> 0.394551).  Saving model ...
Validation loss decreased (0.394551 --> 0.394514).  Saving model ...
Validation loss decreased (0.394514 --> 0.394477).  Saving model ...
Validation loss decreased (0.394477 --> 0.394440).  Saving model ...
Validation loss decreased (0.394440 --> 0.394403).  Saving model ...
Validation loss decreased (0.394403 --> 0.394366).  Saving model ...
Validation loss decreased (0.394366 --> 0.394328).  Saving model ...
Validation loss decreased (0.394328 --> 0.394291).  Saving model ...
Validation loss decreased (0.394291 --> 0.394254).  Saving model ...
Validation loss decreased (0.394254 --> 0.394216).  Saving model ...
Validation loss decreased (0.394216 --> 0.394179).  Saving model ...
Validation loss decreased (0.394179 --> 0.394141).  Saving model ...
Validation loss decreased (0.394141 --> 0.394103).  Saving model ...
Validation loss decreased (0.394103 --> 0.394066).  Saving model ...
Validation loss decreased (0.394066 --> 0.394028).  Saving model ...
Validation loss decreased (0.394028 --> 0.393990).  Saving model ...
Validation loss decreased (0.393990 --> 0.393952).  Saving model ...
Validation loss decreased (0.393952 --> 0.393914).  Saving model ...
Validation loss decreased (0.393914 --> 0.393876).  Saving model ...
Validation loss decreased (0.393876 --> 0.393837).  Saving model ...
Validation loss decreased (0.393837 --> 0.393799).  Saving model ...
Validation loss decreased (0.393799 --> 0.393761).  Saving model ...
Validation loss decreased (0.393761 --> 0.393722).  Saving model ...
Validation loss decreased (0.393722 --> 0.393684).  Saving model ...
Validation loss decreased (0.393684 --> 0.393645).  Saving model ...
Validation loss decreased (0.393645 --> 0.393606).  Saving model ...
Validation loss decreased (0.393606 --> 0.393567).  Saving model ...
epoch 4801, loss 0.3936, train acc 82.74%, f1 0.7377, precision 0.7889, recall 0.6927, auc 0.7963
Validation loss decreased (0.393567 --> 0.393528).  Saving model ...
Validation loss decreased (0.393528 --> 0.393489).  Saving model ...
Validation loss decreased (0.393489 --> 0.393450).  Saving model ...
Validation loss decreased (0.393450 --> 0.393411).  Saving model ...
Validation loss decreased (0.393411 --> 0.393372).  Saving model ...
Validation loss decreased (0.393372 --> 0.393332).  Saving model ...
Validation loss decreased (0.393332 --> 0.393293).  Saving model ...
Validation loss decreased (0.393293 --> 0.393253).  Saving model ...
Validation loss decreased (0.393253 --> 0.393213).  Saving model ...
Validation loss decreased (0.393213 --> 0.393174).  Saving model ...
Validation loss decreased (0.393174 --> 0.393134).  Saving model ...
Validation loss decreased (0.393134 --> 0.393094).  Saving model ...
Validation loss decreased (0.393094 --> 0.393054).  Saving model ...
Validation loss decreased (0.393054 --> 0.393013).  Saving model ...
Validation loss decreased (0.393013 --> 0.392973).  Saving model ...
Validation loss decreased (0.392973 --> 0.392933).  Saving model ...
Validation loss decreased (0.392933 --> 0.392892).  Saving model ...
Validation loss decreased (0.392892 --> 0.392852).  Saving model ...
Validation loss decreased (0.392852 --> 0.392811).  Saving model ...
Validation loss decreased (0.392811 --> 0.392770).  Saving model ...
Validation loss decreased (0.392770 --> 0.392729).  Saving model ...
Validation loss decreased (0.392729 --> 0.392688).  Saving model ...
Validation loss decreased (0.392688 --> 0.392647).  Saving model ...
Validation loss decreased (0.392647 --> 0.392606).  Saving model ...
Validation loss decreased (0.392606 --> 0.392565).  Saving model ...
Validation loss decreased (0.392565 --> 0.392523).  Saving model ...
Validation loss decreased (0.392523 --> 0.392482).  Saving model ...
Validation loss decreased (0.392482 --> 0.392440).  Saving model ...
Validation loss decreased (0.392440 --> 0.392399).  Saving model ...
Validation loss decreased (0.392399 --> 0.392357).  Saving model ...
Validation loss decreased (0.392357 --> 0.392315).  Saving model ...
Validation loss decreased (0.392315 --> 0.392273).  Saving model ...
Validation loss decreased (0.392273 --> 0.392231).  Saving model ...
Validation loss decreased (0.392231 --> 0.392189).  Saving model ...
Validation loss decreased (0.392189 --> 0.392147).  Saving model ...
Validation loss decreased (0.392147 --> 0.392104).  Saving model ...
Validation loss decreased (0.392104 --> 0.392062).  Saving model ...
Validation loss decreased (0.392062 --> 0.392019).  Saving model ...
Validation loss decreased (0.392019 --> 0.391977).  Saving model ...
Validation loss decreased (0.391977 --> 0.391934).  Saving model ...
Validation loss decreased (0.391934 --> 0.391891).  Saving model ...
Validation loss decreased (0.391891 --> 0.391848).  Saving model ...
Validation loss decreased (0.391848 --> 0.391805).  Saving model ...
Validation loss decreased (0.391805 --> 0.391762).  Saving model ...
Validation loss decreased (0.391762 --> 0.391719).  Saving model ...
Validation loss decreased (0.391719 --> 0.391676).  Saving model ...
Validation loss decreased (0.391676 --> 0.391633).  Saving model ...
Validation loss decreased (0.391633 --> 0.391589).  Saving model ...
Validation loss decreased (0.391589 --> 0.391546).  Saving model ...
Validation loss decreased (0.391546 --> 0.391502).  Saving model ...
Validation loss decreased (0.391502 --> 0.391458).  Saving model ...
Validation loss decreased (0.391458 --> 0.391415).  Saving model ...
Validation loss decreased (0.391415 --> 0.391371).  Saving model ...
Validation loss decreased (0.391371 --> 0.391327).  Saving model ...
Validation loss decreased (0.391327 --> 0.391283).  Saving model ...
Validation loss decreased (0.391283 --> 0.391239).  Saving model ...
Validation loss decreased (0.391239 --> 0.391195).  Saving model ...
Validation loss decreased (0.391195 --> 0.391151).  Saving model ...
Validation loss decreased (0.391151 --> 0.391106).  Saving model ...
Validation loss decreased (0.391106 --> 0.391062).  Saving model ...
Validation loss decreased (0.391062 --> 0.391018).  Saving model ...
Validation loss decreased (0.391018 --> 0.390973).  Saving model ...
Validation loss decreased (0.390973 --> 0.390929).  Saving model ...
Validation loss decreased (0.390929 --> 0.390884).  Saving model ...
Validation loss decreased (0.390884 --> 0.390839).  Saving model ...
Validation loss decreased (0.390839 --> 0.390795).  Saving model ...
Validation loss decreased (0.390795 --> 0.390750).  Saving model ...
Validation loss decreased (0.390750 --> 0.390705).  Saving model ...
Validation loss decreased (0.390705 --> 0.390660).  Saving model ...
Validation loss decreased (0.390660 --> 0.390615).  Saving model ...
Validation loss decreased (0.390615 --> 0.390570).  Saving model ...
Validation loss decreased (0.390570 --> 0.390525).  Saving model ...
Validation loss decreased (0.390525 --> 0.390479).  Saving model ...
Validation loss decreased (0.390479 --> 0.390434).  Saving model ...
Validation loss decreased (0.390434 --> 0.390389).  Saving model ...
Validation loss decreased (0.390389 --> 0.390343).  Saving model ...
Validation loss decreased (0.390343 --> 0.390298).  Saving model ...
Validation loss decreased (0.390298 --> 0.390252).  Saving model ...
Validation loss decreased (0.390252 --> 0.390207).  Saving model ...
Validation loss decreased (0.390207 --> 0.390161).  Saving model ...
Validation loss decreased (0.390161 --> 0.390115).  Saving model ...
Validation loss decreased (0.390115 --> 0.390070).  Saving model ...
Validation loss decreased (0.390070 --> 0.390024).  Saving model ...
Validation loss decreased (0.390024 --> 0.389978).  Saving model ...
Validation loss decreased (0.389978 --> 0.389932).  Saving model ...
Validation loss decreased (0.389932 --> 0.389886).  Saving model ...
Validation loss decreased (0.389886 --> 0.389840).  Saving model ...
Validation loss decreased (0.389840 --> 0.389794).  Saving model ...
Validation loss decreased (0.389794 --> 0.389748).  Saving model ...
Validation loss decreased (0.389748 --> 0.389702).  Saving model ...
Validation loss decreased (0.389702 --> 0.389655).  Saving model ...
Validation loss decreased (0.389655 --> 0.389609).  Saving model ...
Validation loss decreased (0.389609 --> 0.389563).  Saving model ...
Validation loss decreased (0.389563 --> 0.389516).  Saving model ...
Validation loss decreased (0.389516 --> 0.389470).  Saving model ...
Validation loss decreased (0.389470 --> 0.389424).  Saving model ...
Validation loss decreased (0.389424 --> 0.389377).  Saving model ...
Validation loss decreased (0.389377 --> 0.389330).  Saving model ...
Validation loss decreased (0.389330 --> 0.389284).  Saving model ...
Validation loss decreased (0.389284 --> 0.389237).  Saving model ...
epoch 4901, loss 0.3892, train acc 83.08%, f1 0.7455, precision 0.7880, recall 0.7073, auc 0.8023
Validation loss decreased (0.389237 --> 0.389191).  Saving model ...
Validation loss decreased (0.389191 --> 0.389144).  Saving model ...
Validation loss decreased (0.389144 --> 0.389097).  Saving model ...
Validation loss decreased (0.389097 --> 0.389050).  Saving model ...
Validation loss decreased (0.389050 --> 0.389003).  Saving model ...
Validation loss decreased (0.389003 --> 0.388957).  Saving model ...
Validation loss decreased (0.388957 --> 0.388910).  Saving model ...
Validation loss decreased (0.388910 --> 0.388863).  Saving model ...
Validation loss decreased (0.388863 --> 0.388816).  Saving model ...
Validation loss decreased (0.388816 --> 0.388769).  Saving model ...
Validation loss decreased (0.388769 --> 0.388722).  Saving model ...
Validation loss decreased (0.388722 --> 0.388675).  Saving model ...
Validation loss decreased (0.388675 --> 0.388628).  Saving model ...
Validation loss decreased (0.388628 --> 0.388581).  Saving model ...
Validation loss decreased (0.388581 --> 0.388533).  Saving model ...
Validation loss decreased (0.388533 --> 0.388486).  Saving model ...
Validation loss decreased (0.388486 --> 0.388439).  Saving model ...
Validation loss decreased (0.388439 --> 0.388392).  Saving model ...
Validation loss decreased (0.388392 --> 0.388345).  Saving model ...
Validation loss decreased (0.388345 --> 0.388298).  Saving model ...
Validation loss decreased (0.388298 --> 0.388250).  Saving model ...
Validation loss decreased (0.388250 --> 0.388203).  Saving model ...
Validation loss decreased (0.388203 --> 0.388156).  Saving model ...
Validation loss decreased (0.388156 --> 0.388109).  Saving model ...
Validation loss decreased (0.388109 --> 0.388061).  Saving model ...
Validation loss decreased (0.388061 --> 0.388014).  Saving model ...
Validation loss decreased (0.388014 --> 0.387967).  Saving model ...
Validation loss decreased (0.387967 --> 0.387919).  Saving model ...
Validation loss decreased (0.387919 --> 0.387872).  Saving model ...
Validation loss decreased (0.387872 --> 0.387825).  Saving model ...
Validation loss decreased (0.387825 --> 0.387778).  Saving model ...
Validation loss decreased (0.387778 --> 0.387730).  Saving model ...
Validation loss decreased (0.387730 --> 0.387683).  Saving model ...
Validation loss decreased (0.387683 --> 0.387636).  Saving model ...
Validation loss decreased (0.387636 --> 0.387588).  Saving model ...
Validation loss decreased (0.387588 --> 0.387541).  Saving model ...
Validation loss decreased (0.387541 --> 0.387494).  Saving model ...
Validation loss decreased (0.387494 --> 0.387446).  Saving model ...
Validation loss decreased (0.387446 --> 0.387399).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.387399 --> 0.387352).  Saving model ...
Validation loss decreased (0.387352 --> 0.387304).  Saving model ...
Validation loss decreased (0.387304 --> 0.387257).  Saving model ...
Validation loss decreased (0.387257 --> 0.387210).  Saving model ...
Validation loss decreased (0.387210 --> 0.387162).  Saving model ...
Validation loss decreased (0.387162 --> 0.387115).  Saving model ...
Validation loss decreased (0.387115 --> 0.387068).  Saving model ...
Validation loss decreased (0.387068 --> 0.387020).  Saving model ...
Validation loss decreased (0.387020 --> 0.386973).  Saving model ...
Validation loss decreased (0.386973 --> 0.386926).  Saving model ...
Validation loss decreased (0.386926 --> 0.386878).  Saving model ...
Validation loss decreased (0.386878 --> 0.386831).  Saving model ...
Validation loss decreased (0.386831 --> 0.386784).  Saving model ...
Validation loss decreased (0.386784 --> 0.386736).  Saving model ...
Validation loss decreased (0.386736 --> 0.386689).  Saving model ...
Validation loss decreased (0.386689 --> 0.386642).  Saving model ...
Validation loss decreased (0.386642 --> 0.386594).  Saving model ...
Validation loss decreased (0.386594 --> 0.386547).  Saving model ...
Validation loss decreased (0.386547 --> 0.386499).  Saving model ...
Validation loss decreased (0.386499 --> 0.386452).  Saving model ...
Validation loss decreased (0.386452 --> 0.386405).  Saving model ...
Validation loss decreased (0.386405 --> 0.386357).  Saving model ...
Validation loss decreased (0.386357 --> 0.386310).  Saving model ...
Validation loss decreased (0.386310 --> 0.386262).  Saving model ...
Validation loss decreased (0.386262 --> 0.386215).  Saving model ...
Validation loss decreased (0.386215 --> 0.386167).  Saving model ...
Validation loss decreased (0.386167 --> 0.386120).  Saving model ...
Validation loss decreased (0.386120 --> 0.386072).  Saving model ...
Validation loss decreased (0.386072 --> 0.386025).  Saving model ...
Validation loss decreased (0.386025 --> 0.385977).  Saving model ...
Validation loss decreased (0.385977 --> 0.385930).  Saving model ...
Validation loss decreased (0.385930 --> 0.385882).  Saving model ...
Validation loss decreased (0.385882 --> 0.385834).  Saving model ...
Validation loss decreased (0.385834 --> 0.385786).  Saving model ...
Validation loss decreased (0.385786 --> 0.385739).  Saving model ...
Validation loss decreased (0.385739 --> 0.385691).  Saving model ...
Validation loss decreased (0.385691 --> 0.385643).  Saving model ...
Validation loss decreased (0.385643 --> 0.385595).  Saving model ...
Validation loss decreased (0.385595 --> 0.385547).  Saving model ...
Validation loss decreased (0.385547 --> 0.385499).  Saving model ...
Validation loss decreased (0.385499 --> 0.385451).  Saving model ...
Validation loss decreased (0.385451 --> 0.385403).  Saving model ...
Validation loss decreased (0.385403 --> 0.385355).  Saving model ...
Validation loss decreased (0.385355 --> 0.385307).  Saving model ...
Validation loss decreased (0.385307 --> 0.385258).  Saving model ...
Validation loss decreased (0.385258 --> 0.385210).  Saving model ...
Validation loss decreased (0.385210 --> 0.385162).  Saving model ...
Validation loss decreased (0.385162 --> 0.385113).  Saving model ...
Validation loss decreased (0.385113 --> 0.385065).  Saving model ...
Validation loss decreased (0.385065 --> 0.385016).  Saving model ...
Validation loss decreased (0.385016 --> 0.384967).  Saving model ...
Validation loss decreased (0.384967 --> 0.384919).  Saving model ...
Validation loss decreased (0.384919 --> 0.384870).  Saving model ...
Validation loss decreased (0.384870 --> 0.384821).  Saving model ...
Validation loss decreased (0.384821 --> 0.384772).  Saving model ...
Validation loss decreased (0.384772 --> 0.384723).  Saving model ...
Validation loss decreased (0.384723 --> 0.384674).  Saving model ...
Validation loss decreased (0.384674 --> 0.384624).  Saving model ...
Validation loss decreased (0.384624 --> 0.384575).  Saving model ...
Validation loss decreased (0.384575 --> 0.384525).  Saving model ...
Validation loss decreased (0.384525 --> 0.384476).  Saving model ...
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_5.csv
./test_pima/standlization_data/pima_std_test_5.csv
MLP_normal_True
normal_normal
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_5
./test_pima/result_MLP_normal_True_normal_normal/record_1/
----------------------



Traceback (most recent call last):
  File "./classifier_MLP/test.py", line 193, in <module>
    transform_method, ref_data_type, ref_num_type, ref_times, boundary_type = get_test_info(test_method)
  File "./classifier_MLP/test.py", line 137, in get_test_info
    return transform_method, ref_data_type, ref_num_type, ref_times, boundary_type
UnboundLocalError: local variable 'transform_method' referenced before assignment
