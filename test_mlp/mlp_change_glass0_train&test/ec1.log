nohup: ignoring input
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
../1_year_data/glass0_train_1.csv
epoch 1, loss 9.7337, train acc 50.00%, f1 0.2857, precision 0.4626, recall 0.4708
epoch 101, loss 2.2873, train acc 90.00%, f1 0.9180, precision 0.8990, recall 0.8917
epoch 201, loss 2.2738, train acc 94.00%, f1 0.9333, precision 0.9380, recall 0.9416
epoch 301, loss 1.6640, train acc 92.00%, f1 0.9231, precision 0.9286, recall 0.9231
epoch 401, loss 2.1584, train acc 76.00%, f1 0.7600, precision 0.7711, recall 0.7711
epoch 501, loss 2.8100, train acc 86.00%, f1 0.8511, precision 0.8600, recall 0.8653
epoch 601, loss 1.6804, train acc 86.00%, f1 0.8444, precision 0.8654, recall 0.8871
epoch 701, loss 2.7645, train acc 92.00%, f1 0.8947, precision 0.9048, recall 0.9394
epoch 801, loss 1.7288, train acc 94.00%, f1 0.9388, precision 0.9400, recall 0.9407
epoch 901, loss 2.2948, train acc 94.00%, f1 0.9434, precision 0.9391, recall 0.9412
epoch 1001, loss 2.3114, train acc 88.00%, f1 0.8929, precision 0.8917, recall 0.8766
epoch 1101, loss 3.2116, train acc 88.00%, f1 0.9062, precision 0.8806, recall 0.8625
epoch 1201, loss 1.6912, train acc 88.00%, f1 0.8750, precision 0.8830, recall 0.8880
epoch 1301, loss 2.7782, train acc 92.00%, f1 0.9200, precision 0.9200, recall 0.9200
epoch 1401, loss 2.6588, train acc 92.00%, f1 0.9200, precision 0.9200, recall 0.9200
epoch 1501, loss 2.3728, train acc 80.00%, f1 0.7500, precision 0.7917, recall 0.7917
epoch 1601, loss 3.9118, train acc 90.00%, f1 0.9020, precision 0.9022, recall 0.9042
epoch 1701, loss 3.2166, train acc 90.00%, f1 0.9020, precision 0.9042, recall 0.9022
epoch 1801, loss 11.6050, train acc 42.00%, f1 0.5915, precision 0.2100, recall 0.5000
epoch 1901, loss 11.0524, train acc 40.00%, f1 0.5714, precision 0.2000, recall 0.5000
epoch 2001, loss 12.7103, train acc 46.00%, f1 0.6301, precision 0.2300, recall 0.5000
epoch 2101, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 2201, loss 13.8155, train acc 50.00%, f1 0.6667, precision 0.2500, recall 0.5000
epoch 2301, loss 13.8155, train acc 50.00%, f1 0.6667, precision 0.2500, recall 0.5000
epoch 2401, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 2501, loss 16.5786, train acc 60.00%, f1 0.7500, precision 0.3000, recall 0.5000
epoch 2601, loss 17.1312, train acc 62.00%, f1 0.7654, precision 0.3100, recall 0.5000
epoch 2701, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 2801, loss 12.1576, train acc 44.00%, f1 0.6111, precision 0.2200, recall 0.5000
epoch 2901, loss 14.3681, train acc 52.00%, f1 0.6842, precision 0.2600, recall 0.5000
epoch 3001, loss 17.1312, train acc 62.00%, f1 0.7654, precision 0.3100, recall 0.5000
epoch 3101, loss 14.9208, train acc 54.00%, f1 0.7013, precision 0.2700, recall 0.5000
epoch 3201, loss 15.4734, train acc 56.00%, f1 0.7179, precision 0.2800, recall 0.5000
epoch 3301, loss 12.1576, train acc 44.00%, f1 0.6111, precision 0.2200, recall 0.5000
epoch 3401, loss 13.8155, train acc 50.00%, f1 0.6667, precision 0.2500, recall 0.5000
epoch 3501, loss 12.1576, train acc 44.00%, f1 0.6111, precision 0.2200, recall 0.5000
epoch 3601, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 3701, loss 16.0260, train acc 58.00%, f1 0.7342, precision 0.2900, recall 0.5000
epoch 3801, loss 13.8155, train acc 50.00%, f1 0.6667, precision 0.2500, recall 0.5000
epoch 3901, loss 12.7103, train acc 46.00%, f1 0.6301, precision 0.2300, recall 0.5000
epoch 4001, loss 15.4734, train acc 56.00%, f1 0.7179, precision 0.2800, recall 0.5000
epoch 4101, loss 11.6050, train acc 42.00%, f1 0.5915, precision 0.2100, recall 0.5000
epoch 4201, loss 11.0524, train acc 40.00%, f1 0.5714, precision 0.2000, recall 0.5000
epoch 4301, loss 16.0260, train acc 58.00%, f1 0.7342, precision 0.2900, recall 0.5000
epoch 4401, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 4501, loss 15.4734, train acc 56.00%, f1 0.7179, precision 0.2800, recall 0.5000
epoch 4601, loss 15.4734, train acc 56.00%, f1 0.7179, precision 0.2800, recall 0.5000
epoch 4701, loss 16.0260, train acc 58.00%, f1 0.7342, precision 0.2900, recall 0.5000
epoch 4801, loss 13.2629, train acc 48.00%, f1 0.6486, precision 0.2400, recall 0.5000
epoch 4901, loss 15.4734, train acc 56.00%, f1 0.7179, precision 0.2800, recall 0.5000
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
1.0 1.0 1.0
1.0 1.0 1.0
0.0 1.0 1.0
0.0 1.0 1.0
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
../1_year_data/glass0_train_1.csv
../1_year_data/glass0_test_origin_1.csv
../1_year_result/model_1/change_loss_model_1/my_model.pkl
(171, 9)
<class 'pandas.core.frame.DataFrame'>
train
(43, 9)
<class 'pandas.core.frame.DataFrame'>
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
0.0 0.7310585975646973
tensor([0.7311], device='cuda:0', grad_fn=<SelectBackward>)
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
1.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
0.0 1
1.0 1
1.0 1
0.0 1
0.0 1
accuracy is 0.32558139534883723
Precision is 0.32558139534883723
Recall is 1.0
F1 is 0.49122807017543857
