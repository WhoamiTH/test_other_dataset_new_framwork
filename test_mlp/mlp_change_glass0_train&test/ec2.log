nohup: ignoring input
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
../1_year_data/glass0_train_2.csv
epoch 1, loss 11.2636, train acc 50.16%, f1 0.6681, precision 0.2508, recall 0.5000
epoch 101, loss 14.2576, train acc 51.60%, f1 0.6807, precision 0.2580, recall 0.5000
epoch 201, loss 14.0587, train acc 50.88%, f1 0.6744, precision 0.2544, recall 0.5000
epoch 301, loss 13.4066, train acc 48.52%, f1 0.6534, precision 0.2426, recall 0.5000
epoch 401, loss 13.5281, train acc 48.96%, f1 0.6574, precision 0.2448, recall 0.5000
epoch 501, loss 13.7713, train acc 49.84%, f1 0.6652, precision 0.2492, recall 0.5000
epoch 601, loss 14.0918, train acc 51.00%, f1 0.6755, precision 0.2550, recall 0.5000
epoch 701, loss 13.1303, train acc 47.52%, f1 0.6443, precision 0.2376, recall 0.5000
epoch 801, loss 13.6718, train acc 49.48%, f1 0.6620, precision 0.2474, recall 0.5000
epoch 901, loss 13.7934, train acc 49.92%, f1 0.6660, precision 0.2496, recall 0.5000
epoch 1001, loss 14.1139, train acc 51.08%, f1 0.6762, precision 0.2554, recall 0.5000
epoch 1101, loss 14.0587, train acc 50.88%, f1 0.6744, precision 0.2544, recall 0.5000
epoch 1201, loss 13.6608, train acc 49.44%, f1 0.6617, precision 0.2472, recall 0.5000
epoch 1301, loss 14.0697, train acc 50.92%, f1 0.6748, precision 0.2546, recall 0.5000
epoch 1401, loss 12.7987, train acc 46.32%, f1 0.6331, precision 0.2316, recall 0.5000
epoch 1501, loss 13.7934, train acc 49.92%, f1 0.6660, precision 0.2496, recall 0.5000
epoch 1601, loss 14.1471, train acc 51.20%, f1 0.6772, precision 0.2560, recall 0.5000
epoch 1701, loss 14.3350, train acc 51.88%, f1 0.6832, precision 0.2594, recall 0.5000
epoch 1801, loss 13.2187, train acc 47.84%, f1 0.6472, precision 0.2392, recall 0.5000
epoch 1901, loss 13.7050, train acc 49.60%, f1 0.6631, precision 0.2480, recall 0.5000
epoch 2001, loss 14.1360, train acc 51.16%, f1 0.6769, precision 0.2558, recall 0.5000
epoch 2101, loss 13.6939, train acc 49.56%, f1 0.6627, precision 0.2478, recall 0.5000
epoch 2201, loss 14.2576, train acc 51.60%, f1 0.6807, precision 0.2580, recall 0.5000
epoch 2301, loss 13.3734, train acc 48.40%, f1 0.6523, precision 0.2420, recall 0.5000
epoch 2401, loss 13.7492, train acc 49.76%, f1 0.6645, precision 0.2488, recall 0.5000
epoch 2501, loss 14.0476, train acc 50.84%, f1 0.6741, precision 0.2542, recall 0.5000
epoch 2601, loss 13.7602, train acc 49.80%, f1 0.6649, precision 0.2490, recall 0.5000
epoch 2701, loss 14.0697, train acc 50.92%, f1 0.6748, precision 0.2546, recall 0.5000
epoch 2801, loss 13.7824, train acc 49.88%, f1 0.6656, precision 0.2494, recall 0.5000
epoch 2901, loss 13.7824, train acc 49.88%, f1 0.6656, precision 0.2494, recall 0.5000
epoch 3001, loss 14.4565, train acc 52.32%, f1 0.6870, precision 0.2616, recall 0.5000
epoch 3101, loss 13.9150, train acc 50.36%, f1 0.6699, precision 0.2518, recall 0.5000
epoch 3201, loss 13.4508, train acc 48.68%, f1 0.6548, precision 0.2434, recall 0.5000
epoch 3301, loss 14.0808, train acc 50.96%, f1 0.6751, precision 0.2548, recall 0.5000
epoch 3401, loss 13.9150, train acc 50.36%, f1 0.6699, precision 0.2518, recall 0.5000
epoch 3501, loss 13.7271, train acc 49.68%, f1 0.6638, precision 0.2484, recall 0.5000
epoch 3601, loss 13.8266, train acc 50.04%, f1 0.6670, precision 0.2502, recall 0.5000
epoch 3701, loss 13.8045, train acc 49.96%, f1 0.6663, precision 0.2498, recall 0.5000
epoch 3801, loss 13.7160, train acc 49.64%, f1 0.6635, precision 0.2482, recall 0.5000
epoch 3901, loss 14.1360, train acc 51.16%, f1 0.6769, precision 0.2558, recall 0.5000
epoch 4001, loss 13.9702, train acc 50.56%, f1 0.6716, precision 0.2528, recall 0.5000
epoch 4101, loss 13.6608, train acc 49.44%, f1 0.6617, precision 0.2472, recall 0.5000
epoch 4201, loss 14.3460, train acc 51.92%, f1 0.6835, precision 0.2596, recall 0.5000
epoch 4301, loss 13.9481, train acc 50.48%, f1 0.6709, precision 0.2524, recall 0.5000
epoch 4401, loss 13.8818, train acc 50.24%, f1 0.6688, precision 0.2512, recall 0.5000
epoch 4501, loss 14.1802, train acc 51.32%, f1 0.6783, precision 0.2566, recall 0.5000
epoch 4601, loss 13.5724, train acc 49.12%, f1 0.6588, precision 0.2456, recall 0.5000
epoch 4701, loss 13.8597, train acc 50.16%, f1 0.6681, precision 0.2508, recall 0.5000
epoch 4801, loss 14.0918, train acc 51.00%, f1 0.6755, precision 0.2550, recall 0.5000
epoch 4901, loss 13.8155, train acc 50.00%, f1 0.6667, precision 0.2500, recall 0.5000
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
../1_year_data/glass0_train_2.csv
../1_year_data/glass0_test_origin_2.csv
../1_year_result/model_1/change_loss_model_2/my_model.pkl
(171, 9)
<class 'pandas.core.frame.DataFrame'>
train
(43, 9)
<class 'pandas.core.frame.DataFrame'>
accuracy is 0.32558139534883723
Precision is 0.16279069767441862
Recall is 0.5
F1 is 0.49122807017543857
