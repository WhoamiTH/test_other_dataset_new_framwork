nohup: ignoring input
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_3
----------------------



epoch 1, loss 0.6932, train acc 49.75%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4975
Validation loss decreased (inf --> 0.693054).  Saving model ...
Validation loss decreased (0.693054 --> 0.692975).  Saving model ...
Validation loss decreased (0.692975 --> 0.692893).  Saving model ...
Validation loss decreased (0.692893 --> 0.692805).  Saving model ...
Validation loss decreased (0.692805 --> 0.692713).  Saving model ...
Validation loss decreased (0.692713 --> 0.692613).  Saving model ...
Validation loss decreased (0.692613 --> 0.692503).  Saving model ...
Validation loss decreased (0.692503 --> 0.692384).  Saving model ...
Validation loss decreased (0.692384 --> 0.692254).  Saving model ...
Validation loss decreased (0.692254 --> 0.692112).  Saving model ...
Validation loss decreased (0.692112 --> 0.691959).  Saving model ...
Validation loss decreased (0.691959 --> 0.691791).  Saving model ...
Validation loss decreased (0.691791 --> 0.691610).  Saving model ...
Validation loss decreased (0.691610 --> 0.691409).  Saving model ...
Validation loss decreased (0.691409 --> 0.691193).  Saving model ...
Validation loss decreased (0.691193 --> 0.690961).  Saving model ...
Validation loss decreased (0.690961 --> 0.690715).  Saving model ...
Validation loss decreased (0.690715 --> 0.690452).  Saving model ...
Validation loss decreased (0.690452 --> 0.690174).  Saving model ...
Validation loss decreased (0.690174 --> 0.689875).  Saving model ...
Validation loss decreased (0.689875 --> 0.689564).  Saving model ...
Validation loss decreased (0.689564 --> 0.689238).  Saving model ...
Validation loss decreased (0.689238 --> 0.688894).  Saving model ...
Validation loss decreased (0.688894 --> 0.688536).  Saving model ...
Validation loss decreased (0.688536 --> 0.688151).  Saving model ...
Validation loss decreased (0.688151 --> 0.687748).  Saving model ...
Validation loss decreased (0.687748 --> 0.687320).  Saving model ...
Validation loss decreased (0.687320 --> 0.686861).  Saving model ...
Validation loss decreased (0.686861 --> 0.686383).  Saving model ...
Validation loss decreased (0.686383 --> 0.685893).  Saving model ...
Validation loss decreased (0.685893 --> 0.685383).  Saving model ...
Validation loss decreased (0.685383 --> 0.684847).  Saving model ...
Validation loss decreased (0.684847 --> 0.684295).  Saving model ...
Validation loss decreased (0.684295 --> 0.683740).  Saving model ...
Validation loss decreased (0.683740 --> 0.683175).  Saving model ...
Validation loss decreased (0.683175 --> 0.682594).  Saving model ...
Validation loss decreased (0.682594 --> 0.681987).  Saving model ...
Validation loss decreased (0.681987 --> 0.681373).  Saving model ...
Validation loss decreased (0.681373 --> 0.680748).  Saving model ...
Validation loss decreased (0.680748 --> 0.680085).  Saving model ...
Validation loss decreased (0.680085 --> 0.679405).  Saving model ...
Validation loss decreased (0.679405 --> 0.678728).  Saving model ...
Validation loss decreased (0.678728 --> 0.678039).  Saving model ...
Validation loss decreased (0.678039 --> 0.677343).  Saving model ...
Validation loss decreased (0.677343 --> 0.676615).  Saving model ...
Validation loss decreased (0.676615 --> 0.675875).  Saving model ...
Validation loss decreased (0.675875 --> 0.675110).  Saving model ...
Validation loss decreased (0.675110 --> 0.674346).  Saving model ...
Validation loss decreased (0.674346 --> 0.673548).  Saving model ...
Validation loss decreased (0.673548 --> 0.672734).  Saving model ...
Validation loss decreased (0.672734 --> 0.671878).  Saving model ...
Validation loss decreased (0.671878 --> 0.671002).  Saving model ...
Validation loss decreased (0.671002 --> 0.670112).  Saving model ...
Validation loss decreased (0.670112 --> 0.669184).  Saving model ...
Validation loss decreased (0.669184 --> 0.668291).  Saving model ...
Validation loss decreased (0.668291 --> 0.667382).  Saving model ...
Validation loss decreased (0.667382 --> 0.666438).  Saving model ...
Validation loss decreased (0.666438 --> 0.665460).  Saving model ...
Validation loss decreased (0.665460 --> 0.664468).  Saving model ...
Validation loss decreased (0.664468 --> 0.663499).  Saving model ...
Validation loss decreased (0.663499 --> 0.662541).  Saving model ...
Validation loss decreased (0.662541 --> 0.661582).  Saving model ...
Validation loss decreased (0.661582 --> 0.660621).  Saving model ...
Validation loss decreased (0.660621 --> 0.659681).  Saving model ...
Validation loss decreased (0.659681 --> 0.658715).  Saving model ...
Validation loss decreased (0.658715 --> 0.657747).  Saving model ...
Validation loss decreased (0.657747 --> 0.656788).  Saving model ...
Validation loss decreased (0.656788 --> 0.655871).  Saving model ...
Validation loss decreased (0.655871 --> 0.654948).  Saving model ...
Validation loss decreased (0.654948 --> 0.654074).  Saving model ...
Validation loss decreased (0.654074 --> 0.653214).  Saving model ...
Validation loss decreased (0.653214 --> 0.652339).  Saving model ...
Validation loss decreased (0.652339 --> 0.651507).  Saving model ...
Validation loss decreased (0.651507 --> 0.650693).  Saving model ...
Validation loss decreased (0.650693 --> 0.649877).  Saving model ...
Validation loss decreased (0.649877 --> 0.649081).  Saving model ...
Validation loss decreased (0.649081 --> 0.648305).  Saving model ...
Validation loss decreased (0.648305 --> 0.647569).  Saving model ...
Validation loss decreased (0.647569 --> 0.646818).  Saving model ...
Validation loss decreased (0.646818 --> 0.646069).  Saving model ...
Validation loss decreased (0.646069 --> 0.645275).  Saving model ...
Validation loss decreased (0.645275 --> 0.644490).  Saving model ...
Validation loss decreased (0.644490 --> 0.643684).  Saving model ...
Validation loss decreased (0.643684 --> 0.642927).  Saving model ...
Validation loss decreased (0.642927 --> 0.642178).  Saving model ...
Validation loss decreased (0.642178 --> 0.641430).  Saving model ...
Validation loss decreased (0.641430 --> 0.640697).  Saving model ...
Validation loss decreased (0.640697 --> 0.639989).  Saving model ...
Validation loss decreased (0.639989 --> 0.639309).  Saving model ...
Validation loss decreased (0.639309 --> 0.638601).  Saving model ...
Validation loss decreased (0.638601 --> 0.637915).  Saving model ...
Validation loss decreased (0.637915 --> 0.637278).  Saving model ...
Validation loss decreased (0.637278 --> 0.636674).  Saving model ...
Validation loss decreased (0.636674 --> 0.636055).  Saving model ...
Validation loss decreased (0.636055 --> 0.635516).  Saving model ...
Validation loss decreased (0.635516 --> 0.634947).  Saving model ...
Validation loss decreased (0.634947 --> 0.634336).  Saving model ...
Validation loss decreased (0.634336 --> 0.633688).  Saving model ...
Validation loss decreased (0.633688 --> 0.633166).  Saving model ...
Validation loss decreased (0.633166 --> 0.632606).  Saving model ...
epoch 101, loss 0.5707, train acc 72.00%, f1 0.7200, precision 0.7200, recall 0.7200, auc 0.7200
Validation loss decreased (0.632606 --> 0.631988).  Saving model ...
Validation loss decreased (0.631988 --> 0.631392).  Saving model ...
Validation loss decreased (0.631392 --> 0.630799).  Saving model ...
Validation loss decreased (0.630799 --> 0.630167).  Saving model ...
Validation loss decreased (0.630167 --> 0.629512).  Saving model ...
Validation loss decreased (0.629512 --> 0.628908).  Saving model ...
Validation loss decreased (0.628908 --> 0.628283).  Saving model ...
Validation loss decreased (0.628283 --> 0.627635).  Saving model ...
Validation loss decreased (0.627635 --> 0.627055).  Saving model ...
Validation loss decreased (0.627055 --> 0.626573).  Saving model ...
Validation loss decreased (0.626573 --> 0.625992).  Saving model ...
Validation loss decreased (0.625992 --> 0.625479).  Saving model ...
Validation loss decreased (0.625479 --> 0.625027).  Saving model ...
Validation loss decreased (0.625027 --> 0.624568).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Validation loss decreased (0.624568 --> 0.624112).  Saving model ...
Validation loss decreased (0.624112 --> 0.623647).  Saving model ...
Validation loss decreased (0.623647 --> 0.623129).  Saving model ...
Validation loss decreased (0.623129 --> 0.622608).  Saving model ...
Validation loss decreased (0.622608 --> 0.622173).  Saving model ...
Validation loss decreased (0.622173 --> 0.621738).  Saving model ...
Validation loss decreased (0.621738 --> 0.621246).  Saving model ...
Validation loss decreased (0.621246 --> 0.620795).  Saving model ...
Validation loss decreased (0.620795 --> 0.620513).  Saving model ...
Validation loss decreased (0.620513 --> 0.620206).  Saving model ...
Validation loss decreased (0.620206 --> 0.619904).  Saving model ...
Validation loss decreased (0.619904 --> 0.619613).  Saving model ...
Validation loss decreased (0.619613 --> 0.619396).  Saving model ...
Validation loss decreased (0.619396 --> 0.619143).  Saving model ...
Validation loss decreased (0.619143 --> 0.618901).  Saving model ...
Validation loss decreased (0.618901 --> 0.618685).  Saving model ...
Validation loss decreased (0.618685 --> 0.618377).  Saving model ...
Validation loss decreased (0.618377 --> 0.618102).  Saving model ...
Validation loss decreased (0.618102 --> 0.617839).  Saving model ...
Validation loss decreased (0.617839 --> 0.617586).  Saving model ...
Validation loss decreased (0.617586 --> 0.617220).  Saving model ...
Validation loss decreased (0.617220 --> 0.616881).  Saving model ...
Validation loss decreased (0.616881 --> 0.616588).  Saving model ...
Validation loss decreased (0.616588 --> 0.616355).  Saving model ...
Validation loss decreased (0.616355 --> 0.616217).  Saving model ...
Validation loss decreased (0.616217 --> 0.616162).  Saving model ...
Validation loss decreased (0.616162 --> 0.616077).  Saving model ...
Validation loss decreased (0.616077 --> 0.615944).  Saving model ...
Validation loss decreased (0.615944 --> 0.615678).  Saving model ...
Validation loss decreased (0.615678 --> 0.615552).  Saving model ...
Validation loss decreased (0.615552 --> 0.615509).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 165, loss 0.4789, train acc 73.75%, f1 0.7382, precision 0.7363, recall 0.7400, auc 0.7375



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_Mirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_True/record_1/MLP_concat_Mirror_True_3
./test_pima/result_MLP_concat_Mirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.61

the Fscore is 0.5806451612903226

the precision is 0.4090909090909091

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_3
----------------------



epoch 1, loss 0.6931, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6231, train acc 77.90%, f1 0.7789, precision 0.7790, recall 0.7788, auc 0.7790
epoch 201, loss 0.4087, train acc 81.15%, f1 0.8116, precision 0.8113, recall 0.8118, auc 0.8115
epoch 301, loss 0.4188, train acc 82.48%, f1 0.8249, precision 0.8247, recall 0.8250, auc 0.8248
epoch 401, loss 0.3013, train acc 82.85%, f1 0.8285, precision 0.8285, recall 0.8286, auc 0.8285
epoch 501, loss 0.3628, train acc 83.03%, f1 0.8303, precision 0.8304, recall 0.8303, auc 0.8303
epoch 601, loss 0.3261, train acc 83.06%, f1 0.8306, precision 0.8306, recall 0.8306, auc 0.8306
epoch 701, loss 0.4043, train acc 83.09%, f1 0.8309, precision 0.8308, recall 0.8309, auc 0.8309
epoch 801, loss 0.3097, train acc 83.09%, f1 0.8309, precision 0.8309, recall 0.8309, auc 0.8309
epoch 901, loss 0.4447, train acc 83.05%, f1 0.8305, precision 0.8305, recall 0.8305, auc 0.8305
epoch 1001, loss 0.4167, train acc 83.08%, f1 0.8308, precision 0.8308, recall 0.8307, auc 0.8308
epoch 1101, loss 0.3590, train acc 83.12%, f1 0.8312, precision 0.8313, recall 0.8311, auc 0.8312
epoch 1201, loss 0.5075, train acc 83.12%, f1 0.8312, precision 0.8312, recall 0.8313, auc 0.8312
epoch 1301, loss 0.4119, train acc 83.12%, f1 0.8312, precision 0.8312, recall 0.8312, auc 0.8312
epoch 1401, loss 0.4130, train acc 83.12%, f1 0.8312, precision 0.8311, recall 0.8313, auc 0.8312
epoch 1501, loss 0.3341, train acc 83.10%, f1 0.8310, precision 0.8311, recall 0.8308, auc 0.8310
epoch 1601, loss 0.4105, train acc 83.10%, f1 0.8310, precision 0.8310, recall 0.8310, auc 0.8310
epoch 1701, loss 0.2916, train acc 83.09%, f1 0.8309, precision 0.8309, recall 0.8310, auc 0.8309
epoch 1801, loss 0.4535, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8314, auc 0.8314
epoch 1901, loss 0.3102, train acc 83.23%, f1 0.8323, precision 0.8323, recall 0.8322, auc 0.8323
epoch 2001, loss 0.3708, train acc 83.24%, f1 0.8324, precision 0.8324, recall 0.8324, auc 0.8324
epoch 2101, loss 0.3191, train acc 83.24%, f1 0.8324, precision 0.8326, recall 0.8322, auc 0.8324
epoch 2201, loss 0.2865, train acc 83.22%, f1 0.8322, precision 0.8323, recall 0.8321, auc 0.8322
epoch 2301, loss 0.3527, train acc 83.34%, f1 0.8334, precision 0.8337, recall 0.8331, auc 0.8334
epoch 2401, loss 0.4210, train acc 83.42%, f1 0.8342, precision 0.8343, recall 0.8341, auc 0.8342
epoch 2501, loss 0.3169, train acc 83.44%, f1 0.8344, precision 0.8346, recall 0.8343, auc 0.8344
epoch 2601, loss 0.3770, train acc 83.52%, f1 0.8352, precision 0.8351, recall 0.8353, auc 0.8352
epoch 2701, loss 0.4145, train acc 83.75%, f1 0.8375, precision 0.8377, recall 0.8373, auc 0.8375
epoch 2801, loss 0.4235, train acc 83.85%, f1 0.8385, precision 0.8386, recall 0.8384, auc 0.8385
epoch 2901, loss 0.3337, train acc 84.01%, f1 0.8402, precision 0.8398, recall 0.8405, auc 0.8401
epoch 3001, loss 0.3611, train acc 84.10%, f1 0.8409, precision 0.8412, recall 0.8407, auc 0.8410
epoch 3101, loss 0.3478, train acc 84.19%, f1 0.8418, precision 0.8420, recall 0.8416, auc 0.8419
epoch 3201, loss 0.4388, train acc 84.32%, f1 0.8432, precision 0.8433, recall 0.8431, auc 0.8432
epoch 3301, loss 0.4604, train acc 84.45%, f1 0.8444, precision 0.8450, recall 0.8439, auc 0.8445
epoch 3401, loss 0.3126, train acc 84.66%, f1 0.8467, precision 0.8464, recall 0.8469, auc 0.8466
epoch 3501, loss 0.4261, train acc 84.79%, f1 0.8480, precision 0.8476, recall 0.8485, auc 0.8479
epoch 3601, loss 0.2951, train acc 84.93%, f1 0.8492, precision 0.8496, recall 0.8487, auc 0.8493
epoch 3701, loss 0.3371, train acc 85.10%, f1 0.8510, precision 0.8510, recall 0.8510, auc 0.8510
epoch 3801, loss 0.2652, train acc 85.15%, f1 0.8514, precision 0.8518, recall 0.8510, auc 0.8515
epoch 3901, loss 0.3504, train acc 85.24%, f1 0.8524, precision 0.8523, recall 0.8526, auc 0.8524
epoch 4001, loss 0.3216, train acc 85.39%, f1 0.8539, precision 0.8541, recall 0.8537, auc 0.8539
epoch 4101, loss 0.3179, train acc 85.48%, f1 0.8547, precision 0.8550, recall 0.8544, auc 0.8548
epoch 4201, loss 0.3256, train acc 85.53%, f1 0.8552, precision 0.8558, recall 0.8545, auc 0.8553
epoch 4301, loss 0.2742, train acc 85.58%, f1 0.8558, precision 0.8559, recall 0.8557, auc 0.8558
epoch 4401, loss 0.3478, train acc 85.76%, f1 0.8575, precision 0.8581, recall 0.8569, auc 0.8576
epoch 4501, loss 0.3915, train acc 85.80%, f1 0.8579, precision 0.8587, recall 0.8571, auc 0.8580
epoch 4601, loss 0.3732, train acc 85.83%, f1 0.8582, precision 0.8589, recall 0.8575, auc 0.8583
epoch 4701, loss 0.3139, train acc 85.95%, f1 0.8595, precision 0.8595, recall 0.8594, auc 0.8595
epoch 4801, loss 0.2260, train acc 85.92%, f1 0.8592, precision 0.8594, recall 0.8589, auc 0.8592
epoch 4901, loss 0.3491, train acc 86.01%, f1 0.8600, precision 0.8602, recall 0.8598, auc 0.8601
epoch 5001, loss 0.2831, train acc 86.11%, f1 0.8610, precision 0.8612, recall 0.8609, auc 0.8611
epoch 5101, loss 0.3958, train acc 86.16%, f1 0.8617, precision 0.8611, recall 0.8622, auc 0.8616
epoch 5201, loss 0.3282, train acc 86.22%, f1 0.8622, precision 0.8619, recall 0.8625, auc 0.8622
epoch 5301, loss 0.3215, train acc 86.26%, f1 0.8627, precision 0.8619, recall 0.8636, auc 0.8626
epoch 5401, loss 0.3352, train acc 86.35%, f1 0.8635, precision 0.8634, recall 0.8635, auc 0.8635
epoch 5501, loss 0.3836, train acc 86.40%, f1 0.8640, precision 0.8639, recall 0.8642, auc 0.8640
epoch 5601, loss 0.3152, train acc 86.39%, f1 0.8639, precision 0.8639, recall 0.8638, auc 0.8639
epoch 5701, loss 0.3178, train acc 86.48%, f1 0.8649, precision 0.8644, recall 0.8654, auc 0.8648
epoch 5801, loss 0.3633, train acc 86.45%, f1 0.8646, precision 0.8643, recall 0.8648, auc 0.8645
epoch 5901, loss 0.4325, train acc 86.55%, f1 0.8656, precision 0.8653, recall 0.8659, auc 0.8655
epoch 6001, loss 0.3304, train acc 86.56%, f1 0.8657, precision 0.8653, recall 0.8660, auc 0.8656
epoch 6101, loss 0.3349, train acc 86.64%, f1 0.8664, precision 0.8661, recall 0.8667, auc 0.8664
epoch 6201, loss 0.2978, train acc 86.69%, f1 0.8668, precision 0.8672, recall 0.8664, auc 0.8669
epoch 6301, loss 0.2548, train acc 86.76%, f1 0.8677, precision 0.8674, recall 0.8680, auc 0.8676
epoch 6401, loss 0.3032, train acc 86.82%, f1 0.8682, precision 0.8681, recall 0.8682, auc 0.8682
epoch 6501, loss 0.2139, train acc 86.84%, f1 0.8684, precision 0.8686, recall 0.8681, auc 0.8684
epoch 6601, loss 0.2311, train acc 86.87%, f1 0.8686, precision 0.8688, recall 0.8685, auc 0.8687
epoch 6701, loss 0.2598, train acc 86.95%, f1 0.8695, precision 0.8689, recall 0.8702, auc 0.8695
epoch 6801, loss 0.2678, train acc 86.97%, f1 0.8698, precision 0.8696, recall 0.8699, auc 0.8697
epoch 6901, loss 0.2347, train acc 86.96%, f1 0.8696, precision 0.8699, recall 0.8693, auc 0.8696
epoch 7001, loss 0.2662, train acc 87.06%, f1 0.8705, precision 0.8708, recall 0.8703, auc 0.8706
epoch 7101, loss 0.2117, train acc 87.06%, f1 0.8704, precision 0.8713, recall 0.8696, auc 0.8706
epoch 7201, loss 0.3289, train acc 87.07%, f1 0.8708, precision 0.8706, recall 0.8710, auc 0.8707
epoch 7301, loss 0.3590, train acc 87.17%, f1 0.8715, precision 0.8728, recall 0.8702, auc 0.8717
epoch 7401, loss 0.3954, train acc 87.11%, f1 0.8711, precision 0.8713, recall 0.8709, auc 0.8711
epoch 7501, loss 0.3809, train acc 87.23%, f1 0.8723, precision 0.8721, recall 0.8726, auc 0.8723
epoch 7601, loss 0.2498, train acc 87.28%, f1 0.8728, precision 0.8726, recall 0.8730, auc 0.8728
epoch 7701, loss 0.3502, train acc 87.30%, f1 0.8728, precision 0.8740, recall 0.8717, auc 0.8730
epoch 7801, loss 0.3588, train acc 87.34%, f1 0.8734, precision 0.8731, recall 0.8738, auc 0.8734
epoch 7901, loss 0.3181, train acc 87.36%, f1 0.8736, precision 0.8738, recall 0.8734, auc 0.8736
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_Mirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_8000/record_1/MLP_concat_Mirror_8000_3
./test_pima/result_MLP_concat_Mirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6507407407407406

the Fscore is 0.6057142857142858

the precision is 0.4380165289256198

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_3
----------------------



epoch 1, loss 0.6931, train acc 50.06%, f1 0.0025, precision 0.9060, recall 0.0012, auc 0.5006
epoch 101, loss 0.5315, train acc 77.89%, f1 0.7771, precision 0.7835, recall 0.7708, auc 0.7789
epoch 201, loss 0.4174, train acc 81.08%, f1 0.8110, precision 0.8101, recall 0.8118, auc 0.8108
epoch 301, loss 0.3870, train acc 82.48%, f1 0.8251, precision 0.8236, recall 0.8266, auc 0.8248
epoch 401, loss 0.4029, train acc 82.91%, f1 0.8296, precision 0.8274, recall 0.8317, auc 0.8291
epoch 501, loss 0.3744, train acc 83.02%, f1 0.8305, precision 0.8289, recall 0.8322, auc 0.8302
epoch 601, loss 0.4163, train acc 83.13%, f1 0.8316, precision 0.8302, recall 0.8330, auc 0.8313
epoch 701, loss 0.2784, train acc 83.09%, f1 0.8313, precision 0.8294, recall 0.8333, auc 0.8309
epoch 801, loss 0.4046, train acc 83.04%, f1 0.8307, precision 0.8291, recall 0.8323, auc 0.8304
epoch 901, loss 0.3006, train acc 83.08%, f1 0.8310, precision 0.8299, recall 0.8320, auc 0.8308
epoch 1001, loss 0.3314, train acc 83.09%, f1 0.8310, precision 0.8303, recall 0.8318, auc 0.8309
epoch 1101, loss 0.4178, train acc 83.08%, f1 0.8310, precision 0.8297, recall 0.8324, auc 0.8308
epoch 1201, loss 0.3966, train acc 83.12%, f1 0.8313, precision 0.8307, recall 0.8319, auc 0.8312
epoch 1301, loss 0.3602, train acc 83.19%, f1 0.8321, precision 0.8312, recall 0.8330, auc 0.8319
epoch 1401, loss 0.2784, train acc 83.16%, f1 0.8317, precision 0.8313, recall 0.8322, auc 0.8316
epoch 1501, loss 0.4641, train acc 83.15%, f1 0.8317, precision 0.8310, recall 0.8323, auc 0.8315
epoch 1601, loss 0.3646, train acc 83.12%, f1 0.8312, precision 0.8310, recall 0.8314, auc 0.8312
epoch 1701, loss 0.4397, train acc 83.08%, f1 0.8309, precision 0.8304, recall 0.8314, auc 0.8308
epoch 1801, loss 0.4648, train acc 83.12%, f1 0.8312, precision 0.8311, recall 0.8312, auc 0.8312
epoch 1901, loss 0.3844, train acc 83.18%, f1 0.8318, precision 0.8319, recall 0.8318, auc 0.8318
epoch 2001, loss 0.3882, train acc 83.12%, f1 0.8313, precision 0.8305, recall 0.8322, auc 0.8312
epoch 2101, loss 0.3722, train acc 83.19%, f1 0.8320, precision 0.8314, recall 0.8327, auc 0.8319
epoch 2201, loss 0.3971, train acc 83.23%, f1 0.8322, precision 0.8323, recall 0.8322, auc 0.8323
epoch 2301, loss 0.3665, train acc 83.33%, f1 0.8333, precision 0.8331, recall 0.8335, auc 0.8333
epoch 2401, loss 0.4196, train acc 83.36%, f1 0.8337, precision 0.8334, recall 0.8340, auc 0.8336
epoch 2501, loss 0.3574, train acc 83.38%, f1 0.8339, precision 0.8337, recall 0.8340, auc 0.8338
epoch 2601, loss 0.3671, train acc 83.51%, f1 0.8351, precision 0.8350, recall 0.8352, auc 0.8351
epoch 2701, loss 0.3546, train acc 83.61%, f1 0.8363, precision 0.8354, recall 0.8372, auc 0.8361
epoch 2801, loss 0.4337, train acc 83.76%, f1 0.8377, precision 0.8370, recall 0.8385, auc 0.8376
epoch 2901, loss 0.4048, train acc 83.87%, f1 0.8388, precision 0.8381, recall 0.8394, auc 0.8387
epoch 3001, loss 0.4184, train acc 84.05%, f1 0.8406, precision 0.8401, recall 0.8411, auc 0.8405
epoch 3101, loss 0.3738, train acc 84.18%, f1 0.8418, precision 0.8422, recall 0.8413, auc 0.8418
epoch 3201, loss 0.2895, train acc 84.29%, f1 0.8429, precision 0.8429, recall 0.8429, auc 0.8429
epoch 3301, loss 0.3697, train acc 84.43%, f1 0.8443, precision 0.8445, recall 0.8441, auc 0.8443
epoch 3401, loss 0.3114, train acc 84.50%, f1 0.8451, precision 0.8444, recall 0.8458, auc 0.8450
epoch 3501, loss 0.3221, train acc 84.69%, f1 0.8467, precision 0.8474, recall 0.8460, auc 0.8469
epoch 3601, loss 0.3030, train acc 84.73%, f1 0.8471, precision 0.8481, recall 0.8461, auc 0.8473
epoch 3701, loss 0.2386, train acc 84.86%, f1 0.8488, precision 0.8478, recall 0.8498, auc 0.8486
epoch 3801, loss 0.3737, train acc 84.98%, f1 0.8498, precision 0.8499, recall 0.8498, auc 0.8498
epoch 3901, loss 0.3580, train acc 85.08%, f1 0.8509, precision 0.8504, recall 0.8514, auc 0.8508
epoch 4001, loss 0.3176, train acc 85.22%, f1 0.8521, precision 0.8525, recall 0.8518, auc 0.8522
epoch 4101, loss 0.2344, train acc 85.29%, f1 0.8529, precision 0.8528, recall 0.8530, auc 0.8529
epoch 4201, loss 0.4130, train acc 85.40%, f1 0.8539, precision 0.8546, recall 0.8532, auc 0.8540
epoch 4301, loss 0.3743, train acc 85.52%, f1 0.8552, precision 0.8551, recall 0.8552, auc 0.8552
epoch 4401, loss 0.3507, train acc 85.57%, f1 0.8559, precision 0.8545, recall 0.8573, auc 0.8557
epoch 4501, loss 0.2570, train acc 85.65%, f1 0.8564, precision 0.8570, recall 0.8559, auc 0.8565
epoch 4601, loss 0.3797, train acc 85.73%, f1 0.8574, precision 0.8570, recall 0.8578, auc 0.8573
epoch 4701, loss 0.2615, train acc 85.82%, f1 0.8583, precision 0.8581, recall 0.8584, auc 0.8582
epoch 4801, loss 0.2876, train acc 85.88%, f1 0.8589, precision 0.8585, recall 0.8593, auc 0.8588
epoch 4901, loss 0.2814, train acc 85.89%, f1 0.8589, precision 0.8590, recall 0.8588, auc 0.8589
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_Mirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_5000/record_1/MLP_concat_Mirror_5000_3
./test_pima/result_MLP_concat_Mirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.64

the Fscore is 0.6

the precision is 0.42857142857142855

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_3
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5421, train acc 77.82%, f1 0.7782, precision 0.7782, recall 0.7782, auc 0.7782
epoch 201, loss 0.3811, train acc 81.23%, f1 0.8123, precision 0.8122, recall 0.8124, auc 0.8123
epoch 301, loss 0.4362, train acc 82.48%, f1 0.8249, precision 0.8248, recall 0.8249, auc 0.8248
epoch 401, loss 0.4145, train acc 82.87%, f1 0.8287, precision 0.8286, recall 0.8287, auc 0.8287
epoch 501, loss 0.3367, train acc 83.06%, f1 0.8306, precision 0.8306, recall 0.8306, auc 0.8306
epoch 601, loss 0.2589, train acc 83.14%, f1 0.8314, precision 0.8315, recall 0.8314, auc 0.8314
epoch 701, loss 0.4257, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8314, auc 0.8314
epoch 801, loss 0.2965, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8314, auc 0.8315
epoch 901, loss 0.3309, train acc 83.05%, f1 0.8305, precision 0.8304, recall 0.8305, auc 0.8305
epoch 1001, loss 0.4303, train acc 83.04%, f1 0.8304, precision 0.8304, recall 0.8304, auc 0.8304
epoch 1101, loss 0.3708, train acc 83.09%, f1 0.8309, precision 0.8309, recall 0.8309, auc 0.8309
epoch 1201, loss 0.4144, train acc 83.06%, f1 0.8306, precision 0.8306, recall 0.8306, auc 0.8306
epoch 1301, loss 0.4334, train acc 83.10%, f1 0.8310, precision 0.8310, recall 0.8310, auc 0.8310
epoch 1401, loss 0.3978, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8312, auc 0.8313
epoch 1501, loss 0.3533, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8313, auc 0.8313
epoch 1601, loss 0.3366, train acc 83.15%, f1 0.8315, precision 0.8316, recall 0.8313, auc 0.8315
epoch 1701, loss 0.3944, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8315, auc 0.8315
epoch 1801, loss 0.4043, train acc 83.15%, f1 0.8315, precision 0.8316, recall 0.8314, auc 0.8315
epoch 1901, loss 0.3054, train acc 83.11%, f1 0.8311, precision 0.8312, recall 0.8311, auc 0.8311
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_Mirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_Mirror_2000/record_1/MLP_concat_Mirror_2000_3
./test_pima/result_MLP_concat_Mirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.585

the Fscore is 0.5654450261780105

the precision is 0.39416058394160586

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_3
----------------------



epoch 1, loss 0.6931, train acc 48.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693414).  Saving model ...
Validation loss decreased (0.693414 --> 0.693104).  Saving model ...
Validation loss decreased (0.693104 --> 0.692960).  Saving model ...
Validation loss decreased (0.692960 --> 0.692880).  Saving model ...
Validation loss decreased (0.692880 --> 0.692792).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
Validation loss decreased (0.692792 --> 0.692749).  Saving model ...
Validation loss decreased (0.692749 --> 0.692705).  Saving model ...
Validation loss decreased (0.692705 --> 0.692697).  Saving model ...
Validation loss decreased (0.692697 --> 0.692668).  Saving model ...
Validation loss decreased (0.692668 --> 0.692620).  Saving model ...
Validation loss decreased (0.692620 --> 0.692551).  Saving model ...
Validation loss decreased (0.692551 --> 0.692474).  Saving model ...
Validation loss decreased (0.692474 --> 0.692352).  Saving model ...
Validation loss decreased (0.692352 --> 0.692232).  Saving model ...
Validation loss decreased (0.692232 --> 0.692102).  Saving model ...
Validation loss decreased (0.692102 --> 0.691971).  Saving model ...
Validation loss decreased (0.691971 --> 0.691837).  Saving model ...
Validation loss decreased (0.691837 --> 0.691714).  Saving model ...
Validation loss decreased (0.691714 --> 0.691603).  Saving model ...
Validation loss decreased (0.691603 --> 0.691460).  Saving model ...
Validation loss decreased (0.691460 --> 0.691294).  Saving model ...
Validation loss decreased (0.691294 --> 0.691131).  Saving model ...
Validation loss decreased (0.691131 --> 0.690962).  Saving model ...
Validation loss decreased (0.690962 --> 0.690791).  Saving model ...
Validation loss decreased (0.690791 --> 0.690604).  Saving model ...
Validation loss decreased (0.690604 --> 0.690400).  Saving model ...
Validation loss decreased (0.690400 --> 0.690175).  Saving model ...
Validation loss decreased (0.690175 --> 0.689928).  Saving model ...
Validation loss decreased (0.689928 --> 0.689671).  Saving model ...
Validation loss decreased (0.689671 --> 0.689402).  Saving model ...
Validation loss decreased (0.689402 --> 0.689125).  Saving model ...
Validation loss decreased (0.689125 --> 0.688838).  Saving model ...
Validation loss decreased (0.688838 --> 0.688551).  Saving model ...
Validation loss decreased (0.688551 --> 0.688273).  Saving model ...
Validation loss decreased (0.688273 --> 0.687989).  Saving model ...
Validation loss decreased (0.687989 --> 0.687677).  Saving model ...
Validation loss decreased (0.687677 --> 0.687355).  Saving model ...
Validation loss decreased (0.687355 --> 0.687038).  Saving model ...
Validation loss decreased (0.687038 --> 0.686736).  Saving model ...
Validation loss decreased (0.686736 --> 0.686422).  Saving model ...
Validation loss decreased (0.686422 --> 0.686094).  Saving model ...
Validation loss decreased (0.686094 --> 0.685752).  Saving model ...
Validation loss decreased (0.685752 --> 0.685426).  Saving model ...
Validation loss decreased (0.685426 --> 0.685133).  Saving model ...
Validation loss decreased (0.685133 --> 0.684830).  Saving model ...
Validation loss decreased (0.684830 --> 0.684522).  Saving model ...
Validation loss decreased (0.684522 --> 0.684223).  Saving model ...
Validation loss decreased (0.684223 --> 0.683949).  Saving model ...
Validation loss decreased (0.683949 --> 0.683651).  Saving model ...
Validation loss decreased (0.683651 --> 0.683365).  Saving model ...
Validation loss decreased (0.683365 --> 0.683056).  Saving model ...
Validation loss decreased (0.683056 --> 0.682720).  Saving model ...
Validation loss decreased (0.682720 --> 0.682374).  Saving model ...
Validation loss decreased (0.682374 --> 0.682009).  Saving model ...
Validation loss decreased (0.682009 --> 0.681676).  Saving model ...
Validation loss decreased (0.681676 --> 0.681320).  Saving model ...
Validation loss decreased (0.681320 --> 0.680951).  Saving model ...
Validation loss decreased (0.680951 --> 0.680604).  Saving model ...
Validation loss decreased (0.680604 --> 0.680256).  Saving model ...
Validation loss decreased (0.680256 --> 0.679904).  Saving model ...
Validation loss decreased (0.679904 --> 0.679499).  Saving model ...
Validation loss decreased (0.679499 --> 0.679130).  Saving model ...
Validation loss decreased (0.679130 --> 0.678721).  Saving model ...
Validation loss decreased (0.678721 --> 0.678293).  Saving model ...
Validation loss decreased (0.678293 --> 0.677859).  Saving model ...
Validation loss decreased (0.677859 --> 0.677437).  Saving model ...
Validation loss decreased (0.677437 --> 0.677106).  Saving model ...
Validation loss decreased (0.677106 --> 0.676706).  Saving model ...
Validation loss decreased (0.676706 --> 0.676329).  Saving model ...
Validation loss decreased (0.676329 --> 0.675853).  Saving model ...
Validation loss decreased (0.675853 --> 0.675414).  Saving model ...
Validation loss decreased (0.675414 --> 0.674982).  Saving model ...
Validation loss decreased (0.674982 --> 0.674567).  Saving model ...
Validation loss decreased (0.674567 --> 0.674183).  Saving model ...
Validation loss decreased (0.674183 --> 0.673875).  Saving model ...
Validation loss decreased (0.673875 --> 0.673451).  Saving model ...
Validation loss decreased (0.673451 --> 0.672988).  Saving model ...
Validation loss decreased (0.672988 --> 0.672460).  Saving model ...
Validation loss decreased (0.672460 --> 0.672063).  Saving model ...
Validation loss decreased (0.672063 --> 0.671619).  Saving model ...
Validation loss decreased (0.671619 --> 0.671070).  Saving model ...
Validation loss decreased (0.671070 --> 0.670630).  Saving model ...
Validation loss decreased (0.670630 --> 0.670173).  Saving model ...
Validation loss decreased (0.670173 --> 0.669854).  Saving model ...
Validation loss decreased (0.669854 --> 0.669587).  Saving model ...
Validation loss decreased (0.669587 --> 0.669280).  Saving model ...
Validation loss decreased (0.669280 --> 0.668862).  Saving model ...
Validation loss decreased (0.668862 --> 0.668452).  Saving model ...
Validation loss decreased (0.668452 --> 0.668098).  Saving model ...
Validation loss decreased (0.668098 --> 0.667780).  Saving model ...
Validation loss decreased (0.667780 --> 0.667588).  Saving model ...
Validation loss decreased (0.667588 --> 0.667402).  Saving model ...
Validation loss decreased (0.667402 --> 0.667202).  Saving model ...
Validation loss decreased (0.667202 --> 0.666907).  Saving model ...
Validation loss decreased (0.666907 --> 0.666602).  Saving model ...
Validation loss decreased (0.666602 --> 0.666276).  Saving model ...
Validation loss decreased (0.666276 --> 0.665972).  Saving model ...
epoch 101, loss 0.5672, train acc 62.50%, f1 0.6575, precision 0.6207, recall 0.6990, auc 0.6227
Validation loss decreased (0.665972 --> 0.665492).  Saving model ...
Validation loss decreased (0.665492 --> 0.664907).  Saving model ...
Validation loss decreased (0.664907 --> 0.664177).  Saving model ...
Validation loss decreased (0.664177 --> 0.663508).  Saving model ...
Validation loss decreased (0.663508 --> 0.662895).  Saving model ...
Validation loss decreased (0.662895 --> 0.662374).  Saving model ...
Validation loss decreased (0.662374 --> 0.661803).  Saving model ...
Validation loss decreased (0.661803 --> 0.661216).  Saving model ...
Validation loss decreased (0.661216 --> 0.660432).  Saving model ...
Validation loss decreased (0.660432 --> 0.659657).  Saving model ...
Validation loss decreased (0.659657 --> 0.658869).  Saving model ...
Validation loss decreased (0.658869 --> 0.658153).  Saving model ...
Validation loss decreased (0.658153 --> 0.657382).  Saving model ...
Validation loss decreased (0.657382 --> 0.656454).  Saving model ...
Validation loss decreased (0.656454 --> 0.655365).  Saving model ...
Validation loss decreased (0.655365 --> 0.654419).  Saving model ...
Validation loss decreased (0.654419 --> 0.653543).  Saving model ...
Validation loss decreased (0.653543 --> 0.652624).  Saving model ...
Validation loss decreased (0.652624 --> 0.651743).  Saving model ...
Validation loss decreased (0.651743 --> 0.650724).  Saving model ...
Validation loss decreased (0.650724 --> 0.649709).  Saving model ...
Validation loss decreased (0.649709 --> 0.648750).  Saving model ...
Validation loss decreased (0.648750 --> 0.647614).  Saving model ...
Validation loss decreased (0.647614 --> 0.646516).  Saving model ...
Validation loss decreased (0.646516 --> 0.645606).  Saving model ...
Validation loss decreased (0.645606 --> 0.644765).  Saving model ...
Validation loss decreased (0.644765 --> 0.643837).  Saving model ...
Validation loss decreased (0.643837 --> 0.643006).  Saving model ...
Validation loss decreased (0.643006 --> 0.642241).  Saving model ...
Validation loss decreased (0.642241 --> 0.641534).  Saving model ...
Validation loss decreased (0.641534 --> 0.640727).  Saving model ...
Validation loss decreased (0.640727 --> 0.639974).  Saving model ...
Validation loss decreased (0.639974 --> 0.639255).  Saving model ...
Validation loss decreased (0.639255 --> 0.638695).  Saving model ...
Validation loss decreased (0.638695 --> 0.638119).  Saving model ...
Validation loss decreased (0.638119 --> 0.637599).  Saving model ...
Validation loss decreased (0.637599 --> 0.636828).  Saving model ...
Validation loss decreased (0.636828 --> 0.635856).  Saving model ...
Validation loss decreased (0.635856 --> 0.634746).  Saving model ...
Validation loss decreased (0.634746 --> 0.633658).  Saving model ...
Validation loss decreased (0.633658 --> 0.632736).  Saving model ...
Validation loss decreased (0.632736 --> 0.631832).  Saving model ...
Validation loss decreased (0.631832 --> 0.630928).  Saving model ...
Validation loss decreased (0.630928 --> 0.629869).  Saving model ...
Validation loss decreased (0.629869 --> 0.628692).  Saving model ...
Validation loss decreased (0.628692 --> 0.627824).  Saving model ...
Validation loss decreased (0.627824 --> 0.626986).  Saving model ...
Validation loss decreased (0.626986 --> 0.626070).  Saving model ...
Validation loss decreased (0.626070 --> 0.624995).  Saving model ...
Validation loss decreased (0.624995 --> 0.623871).  Saving model ...
Validation loss decreased (0.623871 --> 0.622595).  Saving model ...
Validation loss decreased (0.622595 --> 0.621444).  Saving model ...
Validation loss decreased (0.621444 --> 0.620425).  Saving model ...
Validation loss decreased (0.620425 --> 0.619387).  Saving model ...
Validation loss decreased (0.619387 --> 0.618447).  Saving model ...
Validation loss decreased (0.618447 --> 0.617577).  Saving model ...
Validation loss decreased (0.617577 --> 0.616925).  Saving model ...
Validation loss decreased (0.616925 --> 0.616260).  Saving model ...
Validation loss decreased (0.616260 --> 0.615382).  Saving model ...
Validation loss decreased (0.615382 --> 0.614349).  Saving model ...
Validation loss decreased (0.614349 --> 0.613437).  Saving model ...
Validation loss decreased (0.613437 --> 0.612464).  Saving model ...
Validation loss decreased (0.612464 --> 0.611498).  Saving model ...
Validation loss decreased (0.611498 --> 0.610576).  Saving model ...
Validation loss decreased (0.610576 --> 0.609556).  Saving model ...
Validation loss decreased (0.609556 --> 0.608551).  Saving model ...
Validation loss decreased (0.608551 --> 0.607404).  Saving model ...
Validation loss decreased (0.607404 --> 0.606223).  Saving model ...
Validation loss decreased (0.606223 --> 0.604769).  Saving model ...
Validation loss decreased (0.604769 --> 0.603494).  Saving model ...
Validation loss decreased (0.603494 --> 0.602340).  Saving model ...
Validation loss decreased (0.602340 --> 0.601283).  Saving model ...
Validation loss decreased (0.601283 --> 0.600263).  Saving model ...
Validation loss decreased (0.600263 --> 0.599113).  Saving model ...
Validation loss decreased (0.599113 --> 0.598077).  Saving model ...
Validation loss decreased (0.598077 --> 0.596944).  Saving model ...
Validation loss decreased (0.596944 --> 0.595924).  Saving model ...
Validation loss decreased (0.595924 --> 0.594798).  Saving model ...
Validation loss decreased (0.594798 --> 0.593462).  Saving model ...
Validation loss decreased (0.593462 --> 0.592481).  Saving model ...
Validation loss decreased (0.592481 --> 0.591460).  Saving model ...
Validation loss decreased (0.591460 --> 0.590451).  Saving model ...
Validation loss decreased (0.590451 --> 0.589424).  Saving model ...
Validation loss decreased (0.589424 --> 0.588465).  Saving model ...
Validation loss decreased (0.588465 --> 0.587459).  Saving model ...
Validation loss decreased (0.587459 --> 0.586490).  Saving model ...
Validation loss decreased (0.586490 --> 0.585650).  Saving model ...
Validation loss decreased (0.585650 --> 0.584653).  Saving model ...
Validation loss decreased (0.584653 --> 0.583655).  Saving model ...
Validation loss decreased (0.583655 --> 0.582666).  Saving model ...
Validation loss decreased (0.582666 --> 0.581693).  Saving model ...
Validation loss decreased (0.581693 --> 0.580734).  Saving model ...
Validation loss decreased (0.580734 --> 0.579825).  Saving model ...
Validation loss decreased (0.579825 --> 0.578874).  Saving model ...
Validation loss decreased (0.578874 --> 0.577780).  Saving model ...
Validation loss decreased (0.577780 --> 0.576576).  Saving model ...
Validation loss decreased (0.576576 --> 0.575630).  Saving model ...
Validation loss decreased (0.575630 --> 0.574853).  Saving model ...
Validation loss decreased (0.574853 --> 0.573943).  Saving model ...
Validation loss decreased (0.573943 --> 0.572761).  Saving model ...
epoch 201, loss 0.3662, train acc 72.50%, f1 0.7393, precision 0.7222, recall 0.7573, auc 0.7240
Validation loss decreased (0.572761 --> 0.571622).  Saving model ...
Validation loss decreased (0.571622 --> 0.570644).  Saving model ...
Validation loss decreased (0.570644 --> 0.569606).  Saving model ...
Validation loss decreased (0.569606 --> 0.568491).  Saving model ...
Validation loss decreased (0.568491 --> 0.567464).  Saving model ...
Validation loss decreased (0.567464 --> 0.566412).  Saving model ...
Validation loss decreased (0.566412 --> 0.565271).  Saving model ...
Validation loss decreased (0.565271 --> 0.564016).  Saving model ...
Validation loss decreased (0.564016 --> 0.562720).  Saving model ...
Validation loss decreased (0.562720 --> 0.561325).  Saving model ...
Validation loss decreased (0.561325 --> 0.560020).  Saving model ...
Validation loss decreased (0.560020 --> 0.558774).  Saving model ...
Validation loss decreased (0.558774 --> 0.557581).  Saving model ...
Validation loss decreased (0.557581 --> 0.556408).  Saving model ...
Validation loss decreased (0.556408 --> 0.555221).  Saving model ...
Validation loss decreased (0.555221 --> 0.554204).  Saving model ...
Validation loss decreased (0.554204 --> 0.553137).  Saving model ...
Validation loss decreased (0.553137 --> 0.552116).  Saving model ...
Validation loss decreased (0.552116 --> 0.551182).  Saving model ...
Validation loss decreased (0.551182 --> 0.550124).  Saving model ...
Validation loss decreased (0.550124 --> 0.549302).  Saving model ...
Validation loss decreased (0.549302 --> 0.548403).  Saving model ...
Validation loss decreased (0.548403 --> 0.547462).  Saving model ...
Validation loss decreased (0.547462 --> 0.546517).  Saving model ...
Validation loss decreased (0.546517 --> 0.545521).  Saving model ...
Validation loss decreased (0.545521 --> 0.544647).  Saving model ...
Validation loss decreased (0.544647 --> 0.543676).  Saving model ...
Validation loss decreased (0.543676 --> 0.542720).  Saving model ...
Validation loss decreased (0.542720 --> 0.541754).  Saving model ...
Validation loss decreased (0.541754 --> 0.540604).  Saving model ...
Validation loss decreased (0.540604 --> 0.539602).  Saving model ...
Validation loss decreased (0.539602 --> 0.538598).  Saving model ...
Validation loss decreased (0.538598 --> 0.537751).  Saving model ...
Validation loss decreased (0.537751 --> 0.536792).  Saving model ...
Validation loss decreased (0.536792 --> 0.535872).  Saving model ...
Validation loss decreased (0.535872 --> 0.534933).  Saving model ...
Validation loss decreased (0.534933 --> 0.533939).  Saving model ...
Validation loss decreased (0.533939 --> 0.532819).  Saving model ...
Validation loss decreased (0.532819 --> 0.531771).  Saving model ...
Validation loss decreased (0.531771 --> 0.530664).  Saving model ...
Validation loss decreased (0.530664 --> 0.529492).  Saving model ...
Validation loss decreased (0.529492 --> 0.528241).  Saving model ...
Validation loss decreased (0.528241 --> 0.527023).  Saving model ...
Validation loss decreased (0.527023 --> 0.525790).  Saving model ...
Validation loss decreased (0.525790 --> 0.524579).  Saving model ...
Validation loss decreased (0.524579 --> 0.523434).  Saving model ...
Validation loss decreased (0.523434 --> 0.522380).  Saving model ...
Validation loss decreased (0.522380 --> 0.521410).  Saving model ...
Validation loss decreased (0.521410 --> 0.520490).  Saving model ...
Validation loss decreased (0.520490 --> 0.519383).  Saving model ...
Validation loss decreased (0.519383 --> 0.518188).  Saving model ...
Validation loss decreased (0.518188 --> 0.517101).  Saving model ...
Validation loss decreased (0.517101 --> 0.516094).  Saving model ...
Validation loss decreased (0.516094 --> 0.515237).  Saving model ...
Validation loss decreased (0.515237 --> 0.514357).  Saving model ...
Validation loss decreased (0.514357 --> 0.513733).  Saving model ...
Validation loss decreased (0.513733 --> 0.512975).  Saving model ...
Validation loss decreased (0.512975 --> 0.511953).  Saving model ...
Validation loss decreased (0.511953 --> 0.510905).  Saving model ...
Validation loss decreased (0.510905 --> 0.509783).  Saving model ...
Validation loss decreased (0.509783 --> 0.508618).  Saving model ...
Validation loss decreased (0.508618 --> 0.507716).  Saving model ...
Validation loss decreased (0.507716 --> 0.506864).  Saving model ...
Validation loss decreased (0.506864 --> 0.505994).  Saving model ...
Validation loss decreased (0.505994 --> 0.505100).  Saving model ...
Validation loss decreased (0.505100 --> 0.504186).  Saving model ...
Validation loss decreased (0.504186 --> 0.503448).  Saving model ...
Validation loss decreased (0.503448 --> 0.502610).  Saving model ...
Validation loss decreased (0.502610 --> 0.501690).  Saving model ...
Validation loss decreased (0.501690 --> 0.500853).  Saving model ...
Validation loss decreased (0.500853 --> 0.500044).  Saving model ...
Validation loss decreased (0.500044 --> 0.499173).  Saving model ...
Validation loss decreased (0.499173 --> 0.498312).  Saving model ...
Validation loss decreased (0.498312 --> 0.497521).  Saving model ...
Validation loss decreased (0.497521 --> 0.496755).  Saving model ...
Validation loss decreased (0.496755 --> 0.496142).  Saving model ...
Validation loss decreased (0.496142 --> 0.495763).  Saving model ...
Validation loss decreased (0.495763 --> 0.495396).  Saving model ...
Validation loss decreased (0.495396 --> 0.494985).  Saving model ...
Validation loss decreased (0.494985 --> 0.494508).  Saving model ...
Validation loss decreased (0.494508 --> 0.494009).  Saving model ...
Validation loss decreased (0.494009 --> 0.493549).  Saving model ...
Validation loss decreased (0.493549 --> 0.492912).  Saving model ...
Validation loss decreased (0.492912 --> 0.492446).  Saving model ...
Validation loss decreased (0.492446 --> 0.491909).  Saving model ...
Validation loss decreased (0.491909 --> 0.491544).  Saving model ...
Validation loss decreased (0.491544 --> 0.490975).  Saving model ...
Validation loss decreased (0.490975 --> 0.490546).  Saving model ...
Validation loss decreased (0.490546 --> 0.490068).  Saving model ...
Validation loss decreased (0.490068 --> 0.489729).  Saving model ...
Validation loss decreased (0.489729 --> 0.489477).  Saving model ...
Validation loss decreased (0.489477 --> 0.489375).  Saving model ...
Validation loss decreased (0.489375 --> 0.489188).  Saving model ...
Validation loss decreased (0.489188 --> 0.488831).  Saving model ...
Validation loss decreased (0.488831 --> 0.488373).  Saving model ...
Validation loss decreased (0.488373 --> 0.487986).  Saving model ...
Validation loss decreased (0.487986 --> 0.487414).  Saving model ...
Validation loss decreased (0.487414 --> 0.487094).  Saving model ...
Validation loss decreased (0.487094 --> 0.486833).  Saving model ...
Validation loss decreased (0.486833 --> 0.486628).  Saving model ...
epoch 301, loss 0.4205, train acc 80.50%, f1 0.8134, precision 0.8019, recall 0.8252, auc 0.8044
Validation loss decreased (0.486628 --> 0.486264).  Saving model ...
Validation loss decreased (0.486264 --> 0.485924).  Saving model ...
Validation loss decreased (0.485924 --> 0.485632).  Saving model ...
Validation loss decreased (0.485632 --> 0.485264).  Saving model ...
Validation loss decreased (0.485264 --> 0.484891).  Saving model ...
Validation loss decreased (0.484891 --> 0.484451).  Saving model ...
Validation loss decreased (0.484451 --> 0.484197).  Saving model ...
Validation loss decreased (0.484197 --> 0.483949).  Saving model ...
Validation loss decreased (0.483949 --> 0.483677).  Saving model ...
Validation loss decreased (0.483677 --> 0.483329).  Saving model ...
Validation loss decreased (0.483329 --> 0.482982).  Saving model ...
Validation loss decreased (0.482982 --> 0.482501).  Saving model ...
Validation loss decreased (0.482501 --> 0.482177).  Saving model ...
Validation loss decreased (0.482177 --> 0.482006).  Saving model ...
Validation loss decreased (0.482006 --> 0.481839).  Saving model ...
Validation loss decreased (0.481839 --> 0.481655).  Saving model ...
Validation loss decreased (0.481655 --> 0.481541).  Saving model ...
Validation loss decreased (0.481541 --> 0.481485).  Saving model ...
Validation loss decreased (0.481485 --> 0.481270).  Saving model ...
Validation loss decreased (0.481270 --> 0.480971).  Saving model ...
Validation loss decreased (0.480971 --> 0.480565).  Saving model ...
Validation loss decreased (0.480565 --> 0.480230).  Saving model ...
Validation loss decreased (0.480230 --> 0.480037).  Saving model ...
Validation loss decreased (0.480037 --> 0.479900).  Saving model ...
Validation loss decreased (0.479900 --> 0.479782).  Saving model ...
Validation loss decreased (0.479782 --> 0.479666).  Saving model ...
Validation loss decreased (0.479666 --> 0.479421).  Saving model ...
Validation loss decreased (0.479421 --> 0.479072).  Saving model ...
Validation loss decreased (0.479072 --> 0.478735).  Saving model ...
Validation loss decreased (0.478735 --> 0.478300).  Saving model ...
Validation loss decreased (0.478300 --> 0.477930).  Saving model ...
Validation loss decreased (0.477930 --> 0.477716).  Saving model ...
Validation loss decreased (0.477716 --> 0.477622).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.477622 --> 0.477589).  Saving model ...
Validation loss decreased (0.477589 --> 0.477546).  Saving model ...
Validation loss decreased (0.477546 --> 0.477374).  Saving model ...
Validation loss decreased (0.477374 --> 0.477057).  Saving model ...
Validation loss decreased (0.477057 --> 0.476797).  Saving model ...
Validation loss decreased (0.476797 --> 0.476460).  Saving model ...
Validation loss decreased (0.476460 --> 0.476023).  Saving model ...
Validation loss decreased (0.476023 --> 0.475680).  Saving model ...
Validation loss decreased (0.475680 --> 0.475514).  Saving model ...
Validation loss decreased (0.475514 --> 0.475113).  Saving model ...
Validation loss decreased (0.475113 --> 0.474700).  Saving model ...
Validation loss decreased (0.474700 --> 0.474256).  Saving model ...
Validation loss decreased (0.474256 --> 0.473848).  Saving model ...
Validation loss decreased (0.473848 --> 0.473294).  Saving model ...
Validation loss decreased (0.473294 --> 0.472894).  Saving model ...
Validation loss decreased (0.472894 --> 0.472598).  Saving model ...
Validation loss decreased (0.472598 --> 0.472385).  Saving model ...
Validation loss decreased (0.472385 --> 0.472158).  Saving model ...
Validation loss decreased (0.472158 --> 0.471944).  Saving model ...
Validation loss decreased (0.471944 --> 0.471590).  Saving model ...
Validation loss decreased (0.471590 --> 0.471213).  Saving model ...
Validation loss decreased (0.471213 --> 0.470739).  Saving model ...
Validation loss decreased (0.470739 --> 0.470461).  Saving model ...
Validation loss decreased (0.470461 --> 0.470310).  Saving model ...
Validation loss decreased (0.470310 --> 0.470140).  Saving model ...
Validation loss decreased (0.470140 --> 0.469843).  Saving model ...
Validation loss decreased (0.469843 --> 0.469537).  Saving model ...
Validation loss decreased (0.469537 --> 0.469314).  Saving model ...
Validation loss decreased (0.469314 --> 0.469042).  Saving model ...
Validation loss decreased (0.469042 --> 0.468866).  Saving model ...
Validation loss decreased (0.468866 --> 0.468627).  Saving model ...
Validation loss decreased (0.468627 --> 0.468156).  Saving model ...
Validation loss decreased (0.468156 --> 0.467575).  Saving model ...
Validation loss decreased (0.467575 --> 0.466901).  Saving model ...
Validation loss decreased (0.466901 --> 0.466278).  Saving model ...
Validation loss decreased (0.466278 --> 0.465689).  Saving model ...
Validation loss decreased (0.465689 --> 0.465162).  Saving model ...
Validation loss decreased (0.465162 --> 0.464637).  Saving model ...
Validation loss decreased (0.464637 --> 0.463974).  Saving model ...
Validation loss decreased (0.463974 --> 0.463251).  Saving model ...
Validation loss decreased (0.463251 --> 0.462616).  Saving model ...
Validation loss decreased (0.462616 --> 0.461831).  Saving model ...
Validation loss decreased (0.461831 --> 0.460870).  Saving model ...
Validation loss decreased (0.460870 --> 0.459775).  Saving model ...
Validation loss decreased (0.459775 --> 0.458734).  Saving model ...
Validation loss decreased (0.458734 --> 0.457891).  Saving model ...
Validation loss decreased (0.457891 --> 0.456974).  Saving model ...
Validation loss decreased (0.456974 --> 0.456080).  Saving model ...
Validation loss decreased (0.456080 --> 0.455405).  Saving model ...
Validation loss decreased (0.455405 --> 0.454677).  Saving model ...
Validation loss decreased (0.454677 --> 0.454051).  Saving model ...
Validation loss decreased (0.454051 --> 0.453516).  Saving model ...
Validation loss decreased (0.453516 --> 0.452987).  Saving model ...
Validation loss decreased (0.452987 --> 0.452486).  Saving model ...
Validation loss decreased (0.452486 --> 0.452155).  Saving model ...
Validation loss decreased (0.452155 --> 0.451755).  Saving model ...
Validation loss decreased (0.451755 --> 0.451470).  Saving model ...
Validation loss decreased (0.451470 --> 0.451038).  Saving model ...
Validation loss decreased (0.451038 --> 0.450768).  Saving model ...
Validation loss decreased (0.450768 --> 0.450731).  Saving model ...
Validation loss decreased (0.450731 --> 0.450635).  Saving model ...
Validation loss decreased (0.450635 --> 0.450630).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.450630 --> 0.450557).  Saving model ...
epoch 401, loss 0.3500, train acc 84.00%, f1 0.8491, precision 0.8257, recall 0.8738, auc 0.8390
Validation loss decreased (0.450557 --> 0.450257).  Saving model ...
Validation loss decreased (0.450257 --> 0.450098).  Saving model ...
Validation loss decreased (0.450098 --> 0.449897).  Saving model ...
Validation loss decreased (0.449897 --> 0.449611).  Saving model ...
Validation loss decreased (0.449611 --> 0.449200).  Saving model ...
Validation loss decreased (0.449200 --> 0.448627).  Saving model ...
Validation loss decreased (0.448627 --> 0.448112).  Saving model ...
Validation loss decreased (0.448112 --> 0.447546).  Saving model ...
Validation loss decreased (0.447546 --> 0.446801).  Saving model ...
Validation loss decreased (0.446801 --> 0.446212).  Saving model ...
Validation loss decreased (0.446212 --> 0.445685).  Saving model ...
Validation loss decreased (0.445685 --> 0.445083).  Saving model ...
Validation loss decreased (0.445083 --> 0.444553).  Saving model ...
Validation loss decreased (0.444553 --> 0.444037).  Saving model ...
Validation loss decreased (0.444037 --> 0.443539).  Saving model ...
Validation loss decreased (0.443539 --> 0.443124).  Saving model ...
Validation loss decreased (0.443124 --> 0.442683).  Saving model ...
Validation loss decreased (0.442683 --> 0.442320).  Saving model ...
Validation loss decreased (0.442320 --> 0.442019).  Saving model ...
Validation loss decreased (0.442019 --> 0.441636).  Saving model ...
Validation loss decreased (0.441636 --> 0.441353).  Saving model ...
Validation loss decreased (0.441353 --> 0.441222).  Saving model ...
Validation loss decreased (0.441222 --> 0.441098).  Saving model ...
Validation loss decreased (0.441098 --> 0.441045).  Saving model ...
Validation loss decreased (0.441045 --> 0.440925).  Saving model ...
Validation loss decreased (0.440925 --> 0.440738).  Saving model ...
Validation loss decreased (0.440738 --> 0.440664).  Saving model ...
Validation loss decreased (0.440664 --> 0.440566).  Saving model ...
Validation loss decreased (0.440566 --> 0.440196).  Saving model ...
Validation loss decreased (0.440196 --> 0.439664).  Saving model ...
Validation loss decreased (0.439664 --> 0.439233).  Saving model ...
Validation loss decreased (0.439233 --> 0.438843).  Saving model ...
Validation loss decreased (0.438843 --> 0.438575).  Saving model ...
Validation loss decreased (0.438575 --> 0.438154).  Saving model ...
Validation loss decreased (0.438154 --> 0.437633).  Saving model ...
Validation loss decreased (0.437633 --> 0.437044).  Saving model ...
Validation loss decreased (0.437044 --> 0.436408).  Saving model ...
Validation loss decreased (0.436408 --> 0.435875).  Saving model ...
Validation loss decreased (0.435875 --> 0.435298).  Saving model ...
Validation loss decreased (0.435298 --> 0.434766).  Saving model ...
Validation loss decreased (0.434766 --> 0.434141).  Saving model ...
Validation loss decreased (0.434141 --> 0.433541).  Saving model ...
Validation loss decreased (0.433541 --> 0.432917).  Saving model ...
Validation loss decreased (0.432917 --> 0.432438).  Saving model ...
Validation loss decreased (0.432438 --> 0.432016).  Saving model ...
Validation loss decreased (0.432016 --> 0.431531).  Saving model ...
Validation loss decreased (0.431531 --> 0.431133).  Saving model ...
Validation loss decreased (0.431133 --> 0.430802).  Saving model ...
Validation loss decreased (0.430802 --> 0.430383).  Saving model ...
Validation loss decreased (0.430383 --> 0.429903).  Saving model ...
Validation loss decreased (0.429903 --> 0.429272).  Saving model ...
Validation loss decreased (0.429272 --> 0.428666).  Saving model ...
Validation loss decreased (0.428666 --> 0.428318).  Saving model ...
Validation loss decreased (0.428318 --> 0.427945).  Saving model ...
Validation loss decreased (0.427945 --> 0.427594).  Saving model ...
Validation loss decreased (0.427594 --> 0.427145).  Saving model ...
Validation loss decreased (0.427145 --> 0.426414).  Saving model ...
Validation loss decreased (0.426414 --> 0.425692).  Saving model ...
Validation loss decreased (0.425692 --> 0.424980).  Saving model ...
Validation loss decreased (0.424980 --> 0.424121).  Saving model ...
Validation loss decreased (0.424121 --> 0.423216).  Saving model ...
Validation loss decreased (0.423216 --> 0.422461).  Saving model ...
Validation loss decreased (0.422461 --> 0.421795).  Saving model ...
Validation loss decreased (0.421795 --> 0.421152).  Saving model ...
Validation loss decreased (0.421152 --> 0.420478).  Saving model ...
Validation loss decreased (0.420478 --> 0.419876).  Saving model ...
Validation loss decreased (0.419876 --> 0.419303).  Saving model ...
Validation loss decreased (0.419303 --> 0.418814).  Saving model ...
Validation loss decreased (0.418814 --> 0.418271).  Saving model ...
Validation loss decreased (0.418271 --> 0.417725).  Saving model ...
Validation loss decreased (0.417725 --> 0.417337).  Saving model ...
Validation loss decreased (0.417337 --> 0.417040).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.417040 --> 0.416668).  Saving model ...
Validation loss decreased (0.416668 --> 0.416310).  Saving model ...
Validation loss decreased (0.416310 --> 0.416032).  Saving model ...
Validation loss decreased (0.416032 --> 0.415729).  Saving model ...
Validation loss decreased (0.415729 --> 0.415466).  Saving model ...
Validation loss decreased (0.415466 --> 0.415245).  Saving model ...
Validation loss decreased (0.415245 --> 0.415007).  Saving model ...
Validation loss decreased (0.415007 --> 0.414626).  Saving model ...
Validation loss decreased (0.414626 --> 0.414240).  Saving model ...
Validation loss decreased (0.414240 --> 0.413733).  Saving model ...
Validation loss decreased (0.413733 --> 0.413385).  Saving model ...
Validation loss decreased (0.413385 --> 0.413044).  Saving model ...
Validation loss decreased (0.413044 --> 0.412649).  Saving model ...
Validation loss decreased (0.412649 --> 0.412376).  Saving model ...
Validation loss decreased (0.412376 --> 0.412132).  Saving model ...
Validation loss decreased (0.412132 --> 0.412115).  Saving model ...
Validation loss decreased (0.412115 --> 0.412094).  Saving model ...
Validation loss decreased (0.412094 --> 0.412072).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
epoch 501, loss 0.3180, train acc 84.50%, f1 0.8517, precision 0.8396, recall 0.8641, auc 0.8444
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 510, loss 0.2785, train acc 84.50%, f1 0.8517, precision 0.8396, recall 0.8641, auc 0.8444



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_notMirror_True
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_True/record_1/MLP_concat_notMirror_True_3
./test_pima/result_MLP_concat_notMirror_True_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.5800000000000001

the Fscore is 0.5625

the precision is 0.391304347826087

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_3
----------------------



epoch 1, loss 0.6933, train acc 49.80%, f1 0.6649, precision 0.4980, recall 1.0000, auc 0.5000
epoch 101, loss 0.5703, train acc 77.73%, f1 0.7807, precision 0.7661, recall 0.7958, auc 0.7774
epoch 201, loss 0.3492, train acc 80.82%, f1 0.8082, precision 0.8051, recall 0.8113, auc 0.8082
epoch 301, loss 0.3649, train acc 82.44%, f1 0.8244, precision 0.8210, recall 0.8280, auc 0.8244
epoch 401, loss 0.4382, train acc 82.88%, f1 0.8289, precision 0.8253, recall 0.8325, auc 0.8288
epoch 501, loss 0.4567, train acc 82.97%, f1 0.8282, precision 0.8323, recall 0.8241, auc 0.8297
epoch 601, loss 0.4510, train acc 83.06%, f1 0.8300, precision 0.8299, recall 0.8301, auc 0.8306
epoch 701, loss 0.4247, train acc 83.06%, f1 0.8297, precision 0.8306, recall 0.8288, auc 0.8306
epoch 801, loss 0.4942, train acc 83.08%, f1 0.8301, precision 0.8302, recall 0.8301, auc 0.8308
epoch 901, loss 0.4910, train acc 83.08%, f1 0.8301, precision 0.8301, recall 0.8301, auc 0.8308
epoch 1001, loss 0.3271, train acc 83.09%, f1 0.8303, precision 0.8298, recall 0.8308, auc 0.8309
epoch 1101, loss 0.4610, train acc 83.10%, f1 0.8305, precision 0.8298, recall 0.8313, auc 0.8310
epoch 1201, loss 0.4410, train acc 83.12%, f1 0.8304, precision 0.8311, recall 0.8297, auc 0.8312
epoch 1301, loss 0.3203, train acc 83.12%, f1 0.8306, precision 0.8303, recall 0.8309, auc 0.8312
epoch 1401, loss 0.3171, train acc 83.13%, f1 0.8309, precision 0.8295, recall 0.8323, auc 0.8313
epoch 1501, loss 0.5116, train acc 83.11%, f1 0.8305, precision 0.8302, recall 0.8309, auc 0.8311
epoch 1601, loss 0.4164, train acc 83.07%, f1 0.8301, precision 0.8298, recall 0.8303, auc 0.8307
epoch 1701, loss 0.3493, train acc 83.04%, f1 0.8287, precision 0.8335, recall 0.8241, auc 0.8303
epoch 1801, loss 0.3406, train acc 83.14%, f1 0.8306, precision 0.8315, recall 0.8297, auc 0.8314
epoch 1901, loss 0.3561, train acc 83.15%, f1 0.8306, precision 0.8320, recall 0.8292, auc 0.8315
epoch 2001, loss 0.4814, train acc 83.13%, f1 0.8314, precision 0.8280, recall 0.8348, auc 0.8314
epoch 2101, loss 0.3016, train acc 83.11%, f1 0.8299, precision 0.8325, recall 0.8273, auc 0.8311
epoch 2201, loss 0.3886, train acc 83.15%, f1 0.8309, precision 0.8307, recall 0.8311, auc 0.8315
epoch 2301, loss 0.3346, train acc 83.13%, f1 0.8312, precision 0.8285, recall 0.8339, auc 0.8313
epoch 2401, loss 0.3813, train acc 83.18%, f1 0.8307, precision 0.8329, recall 0.8285, auc 0.8318
epoch 2501, loss 0.3647, train acc 83.12%, f1 0.8313, precision 0.8276, recall 0.8352, auc 0.8313
epoch 2601, loss 0.4323, train acc 83.15%, f1 0.8313, precision 0.8292, recall 0.8334, auc 0.8315
epoch 2701, loss 0.3861, train acc 83.13%, f1 0.8313, precision 0.8279, recall 0.8348, auc 0.8313
epoch 2801, loss 0.3775, train acc 83.22%, f1 0.8324, precision 0.8280, recall 0.8369, auc 0.8322
epoch 2901, loss 0.3377, train acc 83.23%, f1 0.8321, precision 0.8299, recall 0.8342, auc 0.8323
epoch 3001, loss 0.5410, train acc 83.23%, f1 0.8317, precision 0.8314, recall 0.8321, auc 0.8323
epoch 3101, loss 0.3852, train acc 83.23%, f1 0.8314, precision 0.8324, recall 0.8305, auc 0.8323
epoch 3201, loss 0.2800, train acc 83.26%, f1 0.8321, precision 0.8315, recall 0.8326, auc 0.8326
epoch 3301, loss 0.4446, train acc 83.33%, f1 0.8326, precision 0.8326, recall 0.8325, auc 0.8333
epoch 3401, loss 0.3526, train acc 83.38%, f1 0.8330, precision 0.8336, recall 0.8324, auc 0.8338
epoch 3501, loss 0.3479, train acc 83.46%, f1 0.8339, precision 0.8345, recall 0.8333, auc 0.8346
epoch 3601, loss 0.3927, train acc 83.53%, f1 0.8354, precision 0.8319, recall 0.8388, auc 0.8354
epoch 3701, loss 0.3810, train acc 83.57%, f1 0.8350, precision 0.8354, recall 0.8346, auc 0.8357
epoch 3801, loss 0.3716, train acc 83.71%, f1 0.8366, precision 0.8357, recall 0.8376, auc 0.8371
epoch 3901, loss 0.3679, train acc 83.79%, f1 0.8369, precision 0.8390, recall 0.8347, auc 0.8379
epoch 4001, loss 0.4623, train acc 83.95%, f1 0.8393, precision 0.8368, recall 0.8418, auc 0.8395
epoch 4101, loss 0.2366, train acc 84.02%, f1 0.8397, precision 0.8393, recall 0.8400, auc 0.8402
epoch 4201, loss 0.3572, train acc 84.21%, f1 0.8425, precision 0.8371, recall 0.8480, auc 0.8421
epoch 4301, loss 0.2850, train acc 84.27%, f1 0.8418, precision 0.8433, recall 0.8404, auc 0.8427
epoch 4401, loss 0.2789, train acc 84.41%, f1 0.8436, precision 0.8429, recall 0.8444, auc 0.8441
epoch 4501, loss 0.4956, train acc 84.59%, f1 0.8457, precision 0.8434, recall 0.8480, auc 0.8459
epoch 4601, loss 0.3279, train acc 84.63%, f1 0.8461, precision 0.8438, recall 0.8485, auc 0.8463
epoch 4701, loss 0.3394, train acc 84.79%, f1 0.8473, precision 0.8472, recall 0.8473, auc 0.8478
epoch 4801, loss 0.3554, train acc 84.88%, f1 0.8487, precision 0.8462, recall 0.8512, auc 0.8489
epoch 4901, loss 0.3564, train acc 85.08%, f1 0.8503, precision 0.8495, recall 0.8512, auc 0.8508
epoch 5001, loss 0.2844, train acc 85.05%, f1 0.8505, precision 0.8472, recall 0.8538, auc 0.8505
epoch 5101, loss 0.3923, train acc 85.23%, f1 0.8520, precision 0.8501, recall 0.8539, auc 0.8523
epoch 5201, loss 0.4260, train acc 85.28%, f1 0.8515, precision 0.8554, recall 0.8477, auc 0.8528
epoch 5301, loss 0.3099, train acc 85.47%, f1 0.8546, precision 0.8519, recall 0.8572, auc 0.8547
epoch 5401, loss 0.3090, train acc 85.54%, f1 0.8551, precision 0.8534, recall 0.8568, auc 0.8554
epoch 5501, loss 0.4037, train acc 85.58%, f1 0.8553, precision 0.8551, recall 0.8555, auc 0.8558
epoch 5601, loss 0.2628, train acc 85.68%, f1 0.8559, precision 0.8576, recall 0.8543, auc 0.8568
epoch 5701, loss 0.3765, train acc 85.75%, f1 0.8572, precision 0.8559, recall 0.8585, auc 0.8575
epoch 5801, loss 0.2597, train acc 85.77%, f1 0.8578, precision 0.8539, recall 0.8617, auc 0.8577
epoch 5901, loss 0.3256, train acc 85.92%, f1 0.8591, precision 0.8562, recall 0.8620, auc 0.8592
epoch 6001, loss 0.2372, train acc 85.92%, f1 0.8588, precision 0.8580, recall 0.8596, auc 0.8592
epoch 6101, loss 0.3150, train acc 86.04%, f1 0.8596, precision 0.8614, recall 0.8578, auc 0.8604
epoch 6201, loss 0.3087, train acc 86.07%, f1 0.8605, precision 0.8587, recall 0.8624, auc 0.8608
epoch 6301, loss 0.3893, train acc 86.23%, f1 0.8623, precision 0.8586, recall 0.8661, auc 0.8623
epoch 6401, loss 0.2776, train acc 86.29%, f1 0.8627, precision 0.8603, recall 0.8652, auc 0.8629
epoch 6501, loss 0.3055, train acc 86.29%, f1 0.8625, precision 0.8612, recall 0.8638, auc 0.8629
epoch 6601, loss 0.3603, train acc 86.38%, f1 0.8629, precision 0.8649, recall 0.8610, auc 0.8638
epoch 6701, loss 0.3743, train acc 86.40%, f1 0.8638, precision 0.8619, recall 0.8658, auc 0.8640
epoch 6801, loss 0.2921, train acc 86.47%, f1 0.8638, precision 0.8660, recall 0.8617, auc 0.8647
epoch 6901, loss 0.3453, train acc 86.51%, f1 0.8646, precision 0.8645, recall 0.8648, auc 0.8651
epoch 7001, loss 0.3111, train acc 86.58%, f1 0.8658, precision 0.8629, recall 0.8686, auc 0.8659
epoch 7101, loss 0.3695, train acc 86.66%, f1 0.8664, precision 0.8643, recall 0.8684, auc 0.8666
epoch 7201, loss 0.3416, train acc 86.71%, f1 0.8666, precision 0.8669, recall 0.8662, auc 0.8671
epoch 7301, loss 0.2077, train acc 86.75%, f1 0.8676, precision 0.8633, recall 0.8720, auc 0.8675
epoch 7401, loss 0.1962, train acc 86.79%, f1 0.8672, precision 0.8682, recall 0.8663, auc 0.8679
epoch 7501, loss 0.3323, train acc 86.81%, f1 0.8679, precision 0.8658, recall 0.8701, auc 0.8681
epoch 7601, loss 0.2544, train acc 86.85%, f1 0.8681, precision 0.8669, recall 0.8694, auc 0.8685
epoch 7701, loss 0.2595, train acc 86.89%, f1 0.8683, precision 0.8685, recall 0.8681, auc 0.8689
epoch 7801, loss 0.2548, train acc 86.97%, f1 0.8691, precision 0.8696, recall 0.8687, auc 0.8697
epoch 7901, loss 0.2395, train acc 86.94%, f1 0.8691, precision 0.8682, recall 0.8699, auc 0.8694
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_notMirror_8000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_8000/record_1/MLP_concat_notMirror_8000_3
./test_pima/result_MLP_concat_notMirror_8000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.6599999999999999

the Fscore is 0.6136363636363636

the precision is 0.4426229508196721

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_3
----------------------



epoch 1, loss 0.6937, train acc 49.91%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5703, train acc 77.81%, f1 0.7764, precision 0.7839, recall 0.7690, auc 0.7781
epoch 201, loss 0.4032, train acc 80.95%, f1 0.8110, precision 0.8059, recall 0.8162, auc 0.8095
epoch 301, loss 0.4062, train acc 82.39%, f1 0.8244, precision 0.8235, recall 0.8253, auc 0.8239
epoch 401, loss 0.4484, train acc 82.88%, f1 0.8283, precision 0.8323, recall 0.8243, auc 0.8288
epoch 501, loss 0.3887, train acc 83.03%, f1 0.8301, precision 0.8327, recall 0.8276, auc 0.8303
epoch 601, loss 0.4128, train acc 83.00%, f1 0.8306, precision 0.8290, recall 0.8322, auc 0.8299
epoch 701, loss 0.4564, train acc 83.04%, f1 0.8307, precision 0.8306, recall 0.8308, auc 0.8304
epoch 801, loss 0.3262, train acc 83.07%, f1 0.8310, precision 0.8312, recall 0.8308, auc 0.8307
epoch 901, loss 0.4238, train acc 83.12%, f1 0.8316, precision 0.8312, recall 0.8320, auc 0.8312
epoch 1001, loss 0.4018, train acc 83.17%, f1 0.8315, precision 0.8338, recall 0.8293, auc 0.8317
epoch 1101, loss 0.3644, train acc 83.15%, f1 0.8315, precision 0.8332, recall 0.8298, auc 0.8315
epoch 1201, loss 0.2845, train acc 83.16%, f1 0.8309, precision 0.8356, recall 0.8263, auc 0.8316
epoch 1301, loss 0.3822, train acc 83.14%, f1 0.8311, precision 0.8338, recall 0.8284, auc 0.8314
epoch 1401, loss 0.3266, train acc 83.14%, f1 0.8314, precision 0.8328, recall 0.8301, auc 0.8314
epoch 1501, loss 0.3837, train acc 83.07%, f1 0.8304, precision 0.8336, recall 0.8272, auc 0.8307
epoch 1601, loss 0.3486, train acc 83.09%, f1 0.8306, precision 0.8338, recall 0.8274, auc 0.8309
epoch 1701, loss 0.3358, train acc 83.09%, f1 0.8308, precision 0.8327, recall 0.8289, auc 0.8309
epoch 1801, loss 0.3359, train acc 83.09%, f1 0.8311, precision 0.8314, recall 0.8308, auc 0.8309
epoch 1901, loss 0.4316, train acc 83.13%, f1 0.8312, precision 0.8331, recall 0.8294, auc 0.8313
epoch 2001, loss 0.3957, train acc 83.10%, f1 0.8304, precision 0.8351, recall 0.8257, auc 0.8310
epoch 2101, loss 0.3899, train acc 83.10%, f1 0.8312, precision 0.8315, recall 0.8309, auc 0.8310
epoch 2201, loss 0.4086, train acc 83.11%, f1 0.8313, precision 0.8319, recall 0.8307, auc 0.8311
epoch 2301, loss 0.3169, train acc 83.13%, f1 0.8313, precision 0.8329, recall 0.8297, auc 0.8313
epoch 2401, loss 0.3011, train acc 83.13%, f1 0.8306, precision 0.8355, recall 0.8257, auc 0.8313
epoch 2501, loss 0.4447, train acc 83.15%, f1 0.8319, precision 0.8314, recall 0.8323, auc 0.8315
epoch 2601, loss 0.4640, train acc 83.14%, f1 0.8315, precision 0.8321, recall 0.8310, auc 0.8314
epoch 2701, loss 0.3042, train acc 83.19%, f1 0.8317, precision 0.8344, recall 0.8291, auc 0.8319
epoch 2801, loss 0.3435, train acc 83.21%, f1 0.8315, precision 0.8361, recall 0.8270, auc 0.8322
epoch 2901, loss 0.4478, train acc 83.14%, f1 0.8312, precision 0.8338, recall 0.8286, auc 0.8314
epoch 3001, loss 0.3504, train acc 83.22%, f1 0.8320, precision 0.8347, recall 0.8294, auc 0.8322
epoch 3101, loss 0.3645, train acc 83.19%, f1 0.8319, precision 0.8334, recall 0.8303, auc 0.8319
epoch 3201, loss 0.3293, train acc 83.27%, f1 0.8322, precision 0.8364, recall 0.8280, auc 0.8327
epoch 3301, loss 0.4405, train acc 83.32%, f1 0.8339, precision 0.8320, recall 0.8358, auc 0.8332
epoch 3401, loss 0.2900, train acc 83.43%, f1 0.8339, precision 0.8371, recall 0.8308, auc 0.8343
epoch 3501, loss 0.2839, train acc 83.47%, f1 0.8341, precision 0.8385, recall 0.8297, auc 0.8347
epoch 3601, loss 0.2956, train acc 83.61%, f1 0.8364, precision 0.8364, recall 0.8364, auc 0.8361
epoch 3701, loss 0.3989, train acc 83.68%, f1 0.8370, precision 0.8374, recall 0.8365, auc 0.8368
epoch 3801, loss 0.3646, train acc 83.74%, f1 0.8371, precision 0.8400, recall 0.8343, auc 0.8374
epoch 3901, loss 0.2990, train acc 83.92%, f1 0.8391, precision 0.8410, recall 0.8373, auc 0.8392
epoch 4001, loss 0.3915, train acc 83.99%, f1 0.8401, precision 0.8405, recall 0.8397, auc 0.8399
epoch 4101, loss 0.2862, train acc 84.19%, f1 0.8422, precision 0.8421, recall 0.8424, auc 0.8419
epoch 4201, loss 0.3186, train acc 84.32%, f1 0.8432, precision 0.8450, recall 0.8414, auc 0.8432
epoch 4301, loss 0.2883, train acc 84.46%, f1 0.8447, precision 0.8457, recall 0.8437, auc 0.8446
epoch 4401, loss 0.3509, train acc 84.62%, f1 0.8462, precision 0.8473, recall 0.8451, auc 0.8462
epoch 4501, loss 0.3829, train acc 84.83%, f1 0.8483, precision 0.8498, recall 0.8468, auc 0.8483
epoch 4601, loss 0.3427, train acc 84.91%, f1 0.8486, precision 0.8531, recall 0.8441, auc 0.8491
epoch 4701, loss 0.2645, train acc 85.04%, f1 0.8506, precision 0.8511, recall 0.8501, auc 0.8504
epoch 4801, loss 0.3246, train acc 85.15%, f1 0.8515, precision 0.8527, recall 0.8504, auc 0.8515
epoch 4901, loss 0.3154, train acc 85.18%, f1 0.8520, precision 0.8524, recall 0.8515, auc 0.8518
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_notMirror_5000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_5000/record_1/MLP_concat_notMirror_5000_3
./test_pima/result_MLP_concat_notMirror_5000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.64

the Fscore is 0.6

the precision is 0.42857142857142855

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_3
----------------------



epoch 1, loss 0.6935, train acc 49.90%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.5761, train acc 77.75%, f1 0.7813, precision 0.7696, recall 0.7933, auc 0.7774
epoch 201, loss 0.4536, train acc 81.02%, f1 0.8109, precision 0.8095, recall 0.8124, auc 0.8102
epoch 301, loss 0.2722, train acc 82.51%, f1 0.8249, precision 0.8278, recall 0.8220, auc 0.8251
epoch 401, loss 0.3340, train acc 82.88%, f1 0.8293, precision 0.8282, recall 0.8304, auc 0.8288
epoch 501, loss 0.3321, train acc 83.03%, f1 0.8300, precision 0.8330, recall 0.8270, auc 0.8303
epoch 601, loss 0.3347, train acc 83.12%, f1 0.8324, precision 0.8279, recall 0.8370, auc 0.8311
epoch 701, loss 0.4080, train acc 83.08%, f1 0.8310, precision 0.8316, recall 0.8303, auc 0.8308
epoch 801, loss 0.3691, train acc 83.05%, f1 0.8306, precision 0.8317, recall 0.8296, auc 0.8305
epoch 901, loss 0.4900, train acc 83.13%, f1 0.8319, precision 0.8307, recall 0.8331, auc 0.8313
epoch 1001, loss 0.3999, train acc 83.16%, f1 0.8315, precision 0.8334, recall 0.8297, auc 0.8316
epoch 1101, loss 0.3090, train acc 83.09%, f1 0.8311, precision 0.8315, recall 0.8308, auc 0.8309
epoch 1201, loss 0.2799, train acc 83.06%, f1 0.8316, precision 0.8281, recall 0.8352, auc 0.8306
epoch 1301, loss 0.4368, train acc 83.16%, f1 0.8314, precision 0.8340, recall 0.8288, auc 0.8316
epoch 1401, loss 0.3191, train acc 83.11%, f1 0.8316, precision 0.8308, recall 0.8325, auc 0.8311
epoch 1501, loss 0.3779, train acc 83.04%, f1 0.8310, precision 0.8297, recall 0.8322, auc 0.8304
epoch 1601, loss 0.3675, train acc 83.07%, f1 0.8313, precision 0.8297, recall 0.8328, auc 0.8307
epoch 1701, loss 0.4006, train acc 83.06%, f1 0.8310, precision 0.8309, recall 0.8310, auc 0.8306
epoch 1801, loss 0.3989, train acc 83.19%, f1 0.8323, precision 0.8320, recall 0.8325, auc 0.8319
epoch 1901, loss 0.3887, train acc 83.16%, f1 0.8317, precision 0.8328, recall 0.8306, auc 0.8316
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_concat_notMirror_2000
concat_pos_num_40_1
./test_pima/model_MLP_concat_notMirror_2000/record_1/MLP_concat_notMirror_2000_3
./test_pima/result_MLP_concat_notMirror_2000_concat_pos_num_40_1/record_1/
----------------------



the AUC is 0.585

the Fscore is 0.5654450261780105

the precision is 0.39416058394160586

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_3
----------------------



epoch 1, loss 0.6931, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
Validation loss decreased (inf --> 0.693090).  Saving model ...
Validation loss decreased (0.693090 --> 0.693013).  Saving model ...
Validation loss decreased (0.693013 --> 0.692932).  Saving model ...
Validation loss decreased (0.692932 --> 0.692846).  Saving model ...
Validation loss decreased (0.692846 --> 0.692750).  Saving model ...
Validation loss decreased (0.692750 --> 0.692648).  Saving model ...
Validation loss decreased (0.692648 --> 0.692537).  Saving model ...
Validation loss decreased (0.692537 --> 0.692414).  Saving model ...
Validation loss decreased (0.692414 --> 0.692276).  Saving model ...
Validation loss decreased (0.692276 --> 0.692127).  Saving model ...
Validation loss decreased (0.692127 --> 0.691965).  Saving model ...
Validation loss decreased (0.691965 --> 0.691787).  Saving model ...
Validation loss decreased (0.691787 --> 0.691593).  Saving model ...
Validation loss decreased (0.691593 --> 0.691386).  Saving model ...
Validation loss decreased (0.691386 --> 0.691165).  Saving model ...
Validation loss decreased (0.691165 --> 0.690926).  Saving model ...
Validation loss decreased (0.690926 --> 0.690668).  Saving model ...
Validation loss decreased (0.690668 --> 0.690399).  Saving model ...
Validation loss decreased (0.690399 --> 0.690109).  Saving model ...
Validation loss decreased (0.690109 --> 0.689803).  Saving model ...
Validation loss decreased (0.689803 --> 0.689476).  Saving model ...
Validation loss decreased (0.689476 --> 0.689127).  Saving model ...
Validation loss decreased (0.689127 --> 0.688756).  Saving model ...
Validation loss decreased (0.688756 --> 0.688364).  Saving model ...
Validation loss decreased (0.688364 --> 0.687959).  Saving model ...
Validation loss decreased (0.687959 --> 0.687541).  Saving model ...
Validation loss decreased (0.687541 --> 0.687102).  Saving model ...
Validation loss decreased (0.687102 --> 0.686636).  Saving model ...
Validation loss decreased (0.686636 --> 0.686145).  Saving model ...
Validation loss decreased (0.686145 --> 0.685633).  Saving model ...
Validation loss decreased (0.685633 --> 0.685108).  Saving model ...
Validation loss decreased (0.685108 --> 0.684579).  Saving model ...
Validation loss decreased (0.684579 --> 0.684018).  Saving model ...
Validation loss decreased (0.684018 --> 0.683439).  Saving model ...
Validation loss decreased (0.683439 --> 0.682849).  Saving model ...
Validation loss decreased (0.682849 --> 0.682232).  Saving model ...
Validation loss decreased (0.682232 --> 0.681578).  Saving model ...
Validation loss decreased (0.681578 --> 0.680888).  Saving model ...
Validation loss decreased (0.680888 --> 0.680191).  Saving model ...
Validation loss decreased (0.680191 --> 0.679471).  Saving model ...
Validation loss decreased (0.679471 --> 0.678743).  Saving model ...
Validation loss decreased (0.678743 --> 0.677981).  Saving model ...
Validation loss decreased (0.677981 --> 0.677190).  Saving model ...
Validation loss decreased (0.677190 --> 0.676371).  Saving model ...
Validation loss decreased (0.676371 --> 0.675534).  Saving model ...
Validation loss decreased (0.675534 --> 0.674679).  Saving model ...
Validation loss decreased (0.674679 --> 0.673812).  Saving model ...
Validation loss decreased (0.673812 --> 0.672911).  Saving model ...
Validation loss decreased (0.672911 --> 0.672004).  Saving model ...
Validation loss decreased (0.672004 --> 0.671069).  Saving model ...
Validation loss decreased (0.671069 --> 0.670117).  Saving model ...
Validation loss decreased (0.670117 --> 0.669142).  Saving model ...
Validation loss decreased (0.669142 --> 0.668169).  Saving model ...
Validation loss decreased (0.668169 --> 0.667160).  Saving model ...
Validation loss decreased (0.667160 --> 0.666145).  Saving model ...
Validation loss decreased (0.666145 --> 0.665084).  Saving model ...
Validation loss decreased (0.665084 --> 0.663979).  Saving model ...
Validation loss decreased (0.663979 --> 0.662860).  Saving model ...
Validation loss decreased (0.662860 --> 0.661726).  Saving model ...
Validation loss decreased (0.661726 --> 0.660564).  Saving model ...
Validation loss decreased (0.660564 --> 0.659383).  Saving model ...
Validation loss decreased (0.659383 --> 0.658172).  Saving model ...
Validation loss decreased (0.658172 --> 0.656958).  Saving model ...
Validation loss decreased (0.656958 --> 0.655748).  Saving model ...
Validation loss decreased (0.655748 --> 0.654502).  Saving model ...
Validation loss decreased (0.654502 --> 0.653242).  Saving model ...
Validation loss decreased (0.653242 --> 0.651935).  Saving model ...
Validation loss decreased (0.651935 --> 0.650601).  Saving model ...
Validation loss decreased (0.650601 --> 0.649276).  Saving model ...
Validation loss decreased (0.649276 --> 0.647936).  Saving model ...
Validation loss decreased (0.647936 --> 0.646577).  Saving model ...
Validation loss decreased (0.646577 --> 0.645215).  Saving model ...
Validation loss decreased (0.645215 --> 0.643830).  Saving model ...
Validation loss decreased (0.643830 --> 0.642417).  Saving model ...
Validation loss decreased (0.642417 --> 0.641031).  Saving model ...
Validation loss decreased (0.641031 --> 0.639632).  Saving model ...
Validation loss decreased (0.639632 --> 0.638247).  Saving model ...
Validation loss decreased (0.638247 --> 0.636836).  Saving model ...
Validation loss decreased (0.636836 --> 0.635386).  Saving model ...
Validation loss decreased (0.635386 --> 0.633890).  Saving model ...
Validation loss decreased (0.633890 --> 0.632380).  Saving model ...
Validation loss decreased (0.632380 --> 0.630834).  Saving model ...
Validation loss decreased (0.630834 --> 0.629258).  Saving model ...
Validation loss decreased (0.629258 --> 0.627644).  Saving model ...
Validation loss decreased (0.627644 --> 0.626030).  Saving model ...
Validation loss decreased (0.626030 --> 0.624424).  Saving model ...
Validation loss decreased (0.624424 --> 0.622811).  Saving model ...
Validation loss decreased (0.622811 --> 0.621202).  Saving model ...
Validation loss decreased (0.621202 --> 0.619567).  Saving model ...
Validation loss decreased (0.619567 --> 0.617933).  Saving model ...
Validation loss decreased (0.617933 --> 0.616288).  Saving model ...
Validation loss decreased (0.616288 --> 0.614645).  Saving model ...
Validation loss decreased (0.614645 --> 0.613049).  Saving model ...
Validation loss decreased (0.613049 --> 0.611416).  Saving model ...
Validation loss decreased (0.611416 --> 0.609793).  Saving model ...
Validation loss decreased (0.609793 --> 0.608220).  Saving model ...
Validation loss decreased (0.608220 --> 0.606669).  Saving model ...
Validation loss decreased (0.606669 --> 0.605158).  Saving model ...
Validation loss decreased (0.605158 --> 0.603606).  Saving model ...
Validation loss decreased (0.603606 --> 0.602023).  Saving model ...
epoch 101, loss 0.6195, train acc 83.25%, f1 0.8424, precision 0.7956, recall 0.8950, auc 0.8325
Validation loss decreased (0.602023 --> 0.600465).  Saving model ...
Validation loss decreased (0.600465 --> 0.598917).  Saving model ...
Validation loss decreased (0.598917 --> 0.597373).  Saving model ...
Validation loss decreased (0.597373 --> 0.595789).  Saving model ...
Validation loss decreased (0.595789 --> 0.594200).  Saving model ...
Validation loss decreased (0.594200 --> 0.592649).  Saving model ...
Validation loss decreased (0.592649 --> 0.591097).  Saving model ...
Validation loss decreased (0.591097 --> 0.589492).  Saving model ...
Validation loss decreased (0.589492 --> 0.587845).  Saving model ...
Validation loss decreased (0.587845 --> 0.586217).  Saving model ...
Validation loss decreased (0.586217 --> 0.584613).  Saving model ...
Validation loss decreased (0.584613 --> 0.583069).  Saving model ...
Validation loss decreased (0.583069 --> 0.581528).  Saving model ...
Validation loss decreased (0.581528 --> 0.580013).  Saving model ...
Validation loss decreased (0.580013 --> 0.578516).  Saving model ...
Validation loss decreased (0.578516 --> 0.577032).  Saving model ...
Validation loss decreased (0.577032 --> 0.575553).  Saving model ...
Validation loss decreased (0.575553 --> 0.574046).  Saving model ...
Validation loss decreased (0.574046 --> 0.572505).  Saving model ...
Validation loss decreased (0.572505 --> 0.570977).  Saving model ...
Validation loss decreased (0.570977 --> 0.569491).  Saving model ...
Validation loss decreased (0.569491 --> 0.567968).  Saving model ...
Validation loss decreased (0.567968 --> 0.566489).  Saving model ...
Validation loss decreased (0.566489 --> 0.565019).  Saving model ...
Validation loss decreased (0.565019 --> 0.563509).  Saving model ...
Validation loss decreased (0.563509 --> 0.562021).  Saving model ...
Validation loss decreased (0.562021 --> 0.560573).  Saving model ...
Validation loss decreased (0.560573 --> 0.559077).  Saving model ...
Validation loss decreased (0.559077 --> 0.557565).  Saving model ...
Validation loss decreased (0.557565 --> 0.556026).  Saving model ...
Validation loss decreased (0.556026 --> 0.554500).  Saving model ...
Validation loss decreased (0.554500 --> 0.552993).  Saving model ...
Validation loss decreased (0.552993 --> 0.551556).  Saving model ...
Validation loss decreased (0.551556 --> 0.550150).  Saving model ...
Validation loss decreased (0.550150 --> 0.548762).  Saving model ...
Validation loss decreased (0.548762 --> 0.547363).  Saving model ...
Validation loss decreased (0.547363 --> 0.545974).  Saving model ...
Validation loss decreased (0.545974 --> 0.544555).  Saving model ...
Validation loss decreased (0.544555 --> 0.543111).  Saving model ...
Validation loss decreased (0.543111 --> 0.541730).  Saving model ...
Validation loss decreased (0.541730 --> 0.540366).  Saving model ...
Validation loss decreased (0.540366 --> 0.539011).  Saving model ...
Validation loss decreased (0.539011 --> 0.537666).  Saving model ...
Validation loss decreased (0.537666 --> 0.536319).  Saving model ...
Validation loss decreased (0.536319 --> 0.534958).  Saving model ...
Validation loss decreased (0.534958 --> 0.533600).  Saving model ...
Validation loss decreased (0.533600 --> 0.532273).  Saving model ...
Validation loss decreased (0.532273 --> 0.530928).  Saving model ...
Validation loss decreased (0.530928 --> 0.529585).  Saving model ...
Validation loss decreased (0.529585 --> 0.528227).  Saving model ...
Validation loss decreased (0.528227 --> 0.526834).  Saving model ...
Validation loss decreased (0.526834 --> 0.525475).  Saving model ...
Validation loss decreased (0.525475 --> 0.524127).  Saving model ...
Validation loss decreased (0.524127 --> 0.522786).  Saving model ...
Validation loss decreased (0.522786 --> 0.521456).  Saving model ...
Validation loss decreased (0.521456 --> 0.520131).  Saving model ...
Validation loss decreased (0.520131 --> 0.518849).  Saving model ...
Validation loss decreased (0.518849 --> 0.517537).  Saving model ...
Validation loss decreased (0.517537 --> 0.516285).  Saving model ...
Validation loss decreased (0.516285 --> 0.515055).  Saving model ...
Validation loss decreased (0.515055 --> 0.513854).  Saving model ...
Validation loss decreased (0.513854 --> 0.512631).  Saving model ...
Validation loss decreased (0.512631 --> 0.511437).  Saving model ...
Validation loss decreased (0.511437 --> 0.510241).  Saving model ...
Validation loss decreased (0.510241 --> 0.509058).  Saving model ...
Validation loss decreased (0.509058 --> 0.507916).  Saving model ...
Validation loss decreased (0.507916 --> 0.506849).  Saving model ...
Validation loss decreased (0.506849 --> 0.505803).  Saving model ...
Validation loss decreased (0.505803 --> 0.504761).  Saving model ...
Validation loss decreased (0.504761 --> 0.503769).  Saving model ...
Validation loss decreased (0.503769 --> 0.502772).  Saving model ...
Validation loss decreased (0.502772 --> 0.501808).  Saving model ...
Validation loss decreased (0.501808 --> 0.500821).  Saving model ...
Validation loss decreased (0.500821 --> 0.499808).  Saving model ...
Validation loss decreased (0.499808 --> 0.498784).  Saving model ...
Validation loss decreased (0.498784 --> 0.497729).  Saving model ...
Validation loss decreased (0.497729 --> 0.496637).  Saving model ...
Validation loss decreased (0.496637 --> 0.495565).  Saving model ...
Validation loss decreased (0.495565 --> 0.494543).  Saving model ...
Validation loss decreased (0.494543 --> 0.493503).  Saving model ...
Validation loss decreased (0.493503 --> 0.492467).  Saving model ...
Validation loss decreased (0.492467 --> 0.491450).  Saving model ...
Validation loss decreased (0.491450 --> 0.490448).  Saving model ...
Validation loss decreased (0.490448 --> 0.489458).  Saving model ...
Validation loss decreased (0.489458 --> 0.488438).  Saving model ...
Validation loss decreased (0.488438 --> 0.487401).  Saving model ...
Validation loss decreased (0.487401 --> 0.486453).  Saving model ...
Validation loss decreased (0.486453 --> 0.485518).  Saving model ...
Validation loss decreased (0.485518 --> 0.484598).  Saving model ...
Validation loss decreased (0.484598 --> 0.483673).  Saving model ...
Validation loss decreased (0.483673 --> 0.482760).  Saving model ...
Validation loss decreased (0.482760 --> 0.481895).  Saving model ...
Validation loss decreased (0.481895 --> 0.481035).  Saving model ...
Validation loss decreased (0.481035 --> 0.480270).  Saving model ...
Validation loss decreased (0.480270 --> 0.479496).  Saving model ...
Validation loss decreased (0.479496 --> 0.478720).  Saving model ...
Validation loss decreased (0.478720 --> 0.477932).  Saving model ...
Validation loss decreased (0.477932 --> 0.477228).  Saving model ...
Validation loss decreased (0.477228 --> 0.476482).  Saving model ...
Validation loss decreased (0.476482 --> 0.475768).  Saving model ...
epoch 201, loss 0.4486, train acc 83.00%, f1 0.8308, precision 0.8267, recall 0.8350, auc 0.8300
Validation loss decreased (0.475768 --> 0.475024).  Saving model ...
Validation loss decreased (0.475024 --> 0.474310).  Saving model ...
Validation loss decreased (0.474310 --> 0.473584).  Saving model ...
Validation loss decreased (0.473584 --> 0.472881).  Saving model ...
Validation loss decreased (0.472881 --> 0.472118).  Saving model ...
Validation loss decreased (0.472118 --> 0.471341).  Saving model ...
Validation loss decreased (0.471341 --> 0.470601).  Saving model ...
Validation loss decreased (0.470601 --> 0.469844).  Saving model ...
Validation loss decreased (0.469844 --> 0.469052).  Saving model ...
Validation loss decreased (0.469052 --> 0.468269).  Saving model ...
Validation loss decreased (0.468269 --> 0.467468).  Saving model ...
Validation loss decreased (0.467468 --> 0.466666).  Saving model ...
Validation loss decreased (0.466666 --> 0.465915).  Saving model ...
Validation loss decreased (0.465915 --> 0.465180).  Saving model ...
Validation loss decreased (0.465180 --> 0.464502).  Saving model ...
Validation loss decreased (0.464502 --> 0.463868).  Saving model ...
Validation loss decreased (0.463868 --> 0.463198).  Saving model ...
Validation loss decreased (0.463198 --> 0.462527).  Saving model ...
Validation loss decreased (0.462527 --> 0.461790).  Saving model ...
Validation loss decreased (0.461790 --> 0.461084).  Saving model ...
Validation loss decreased (0.461084 --> 0.460407).  Saving model ...
Validation loss decreased (0.460407 --> 0.459705).  Saving model ...
Validation loss decreased (0.459705 --> 0.459017).  Saving model ...
Validation loss decreased (0.459017 --> 0.458394).  Saving model ...
Validation loss decreased (0.458394 --> 0.457764).  Saving model ...
Validation loss decreased (0.457764 --> 0.457142).  Saving model ...
Validation loss decreased (0.457142 --> 0.456518).  Saving model ...
Validation loss decreased (0.456518 --> 0.455866).  Saving model ...
Validation loss decreased (0.455866 --> 0.455212).  Saving model ...
Validation loss decreased (0.455212 --> 0.454553).  Saving model ...
Validation loss decreased (0.454553 --> 0.453909).  Saving model ...
Validation loss decreased (0.453909 --> 0.453261).  Saving model ...
Validation loss decreased (0.453261 --> 0.452604).  Saving model ...
Validation loss decreased (0.452604 --> 0.451982).  Saving model ...
Validation loss decreased (0.451982 --> 0.451350).  Saving model ...
Validation loss decreased (0.451350 --> 0.450720).  Saving model ...
Validation loss decreased (0.450720 --> 0.450048).  Saving model ...
Validation loss decreased (0.450048 --> 0.449414).  Saving model ...
Validation loss decreased (0.449414 --> 0.448789).  Saving model ...
Validation loss decreased (0.448789 --> 0.448173).  Saving model ...
Validation loss decreased (0.448173 --> 0.447578).  Saving model ...
Validation loss decreased (0.447578 --> 0.446995).  Saving model ...
Validation loss decreased (0.446995 --> 0.446447).  Saving model ...
Validation loss decreased (0.446447 --> 0.445910).  Saving model ...
Validation loss decreased (0.445910 --> 0.445390).  Saving model ...
Validation loss decreased (0.445390 --> 0.444875).  Saving model ...
Validation loss decreased (0.444875 --> 0.444340).  Saving model ...
Validation loss decreased (0.444340 --> 0.443790).  Saving model ...
Validation loss decreased (0.443790 --> 0.443285).  Saving model ...
Validation loss decreased (0.443285 --> 0.442775).  Saving model ...
Validation loss decreased (0.442775 --> 0.442294).  Saving model ...
Validation loss decreased (0.442294 --> 0.441851).  Saving model ...
Validation loss decreased (0.441851 --> 0.441413).  Saving model ...
Validation loss decreased (0.441413 --> 0.440931).  Saving model ...
Validation loss decreased (0.440931 --> 0.440449).  Saving model ...
Validation loss decreased (0.440449 --> 0.439982).  Saving model ...
Validation loss decreased (0.439982 --> 0.439543).  Saving model ...
Validation loss decreased (0.439543 --> 0.439125).  Saving model ...
Validation loss decreased (0.439125 --> 0.438700).  Saving model ...
Validation loss decreased (0.438700 --> 0.438297).  Saving model ...
Validation loss decreased (0.438297 --> 0.437857).  Saving model ...
Validation loss decreased (0.437857 --> 0.437465).  Saving model ...
Validation loss decreased (0.437465 --> 0.437053).  Saving model ...
Validation loss decreased (0.437053 --> 0.436639).  Saving model ...
Validation loss decreased (0.436639 --> 0.436208).  Saving model ...
Validation loss decreased (0.436208 --> 0.435813).  Saving model ...
Validation loss decreased (0.435813 --> 0.435442).  Saving model ...
Validation loss decreased (0.435442 --> 0.435051).  Saving model ...
Validation loss decreased (0.435051 --> 0.434669).  Saving model ...
Validation loss decreased (0.434669 --> 0.434236).  Saving model ...
Validation loss decreased (0.434236 --> 0.433792).  Saving model ...
Validation loss decreased (0.433792 --> 0.433376).  Saving model ...
Validation loss decreased (0.433376 --> 0.432931).  Saving model ...
Validation loss decreased (0.432931 --> 0.432489).  Saving model ...
Validation loss decreased (0.432489 --> 0.432076).  Saving model ...
Validation loss decreased (0.432076 --> 0.431620).  Saving model ...
Validation loss decreased (0.431620 --> 0.431162).  Saving model ...
Validation loss decreased (0.431162 --> 0.430658).  Saving model ...
Validation loss decreased (0.430658 --> 0.430147).  Saving model ...
Validation loss decreased (0.430147 --> 0.429656).  Saving model ...
Validation loss decreased (0.429656 --> 0.429202).  Saving model ...
Validation loss decreased (0.429202 --> 0.428739).  Saving model ...
Validation loss decreased (0.428739 --> 0.428330).  Saving model ...
Validation loss decreased (0.428330 --> 0.427941).  Saving model ...
Validation loss decreased (0.427941 --> 0.427575).  Saving model ...
Validation loss decreased (0.427575 --> 0.427202).  Saving model ...
Validation loss decreased (0.427202 --> 0.426835).  Saving model ...
Validation loss decreased (0.426835 --> 0.426475).  Saving model ...
Validation loss decreased (0.426475 --> 0.426154).  Saving model ...
Validation loss decreased (0.426154 --> 0.425789).  Saving model ...
Validation loss decreased (0.425789 --> 0.425491).  Saving model ...
Validation loss decreased (0.425491 --> 0.425188).  Saving model ...
Validation loss decreased (0.425188 --> 0.424876).  Saving model ...
Validation loss decreased (0.424876 --> 0.424593).  Saving model ...
Validation loss decreased (0.424593 --> 0.424391).  Saving model ...
Validation loss decreased (0.424391 --> 0.424164).  Saving model ...
Validation loss decreased (0.424164 --> 0.423918).  Saving model ...
Validation loss decreased (0.423918 --> 0.423686).  Saving model ...
Validation loss decreased (0.423686 --> 0.423437).  Saving model ...
Validation loss decreased (0.423437 --> 0.423153).  Saving model ...
epoch 301, loss 0.3865, train acc 82.75%, f1 0.8271, precision 0.8291, recall 0.8250, auc 0.8275
Validation loss decreased (0.423153 --> 0.422900).  Saving model ...
Validation loss decreased (0.422900 --> 0.422607).  Saving model ...
Validation loss decreased (0.422607 --> 0.422330).  Saving model ...
Validation loss decreased (0.422330 --> 0.422064).  Saving model ...
Validation loss decreased (0.422064 --> 0.421814).  Saving model ...
Validation loss decreased (0.421814 --> 0.421588).  Saving model ...
Validation loss decreased (0.421588 --> 0.421371).  Saving model ...
Validation loss decreased (0.421371 --> 0.421095).  Saving model ...
Validation loss decreased (0.421095 --> 0.420815).  Saving model ...
Validation loss decreased (0.420815 --> 0.420500).  Saving model ...
Validation loss decreased (0.420500 --> 0.420168).  Saving model ...
Validation loss decreased (0.420168 --> 0.419817).  Saving model ...
Validation loss decreased (0.419817 --> 0.419450).  Saving model ...
Validation loss decreased (0.419450 --> 0.419097).  Saving model ...
Validation loss decreased (0.419097 --> 0.418726).  Saving model ...
Validation loss decreased (0.418726 --> 0.418354).  Saving model ...
Validation loss decreased (0.418354 --> 0.417980).  Saving model ...
Validation loss decreased (0.417980 --> 0.417611).  Saving model ...
Validation loss decreased (0.417611 --> 0.417293).  Saving model ...
Validation loss decreased (0.417293 --> 0.417010).  Saving model ...
Validation loss decreased (0.417010 --> 0.416736).  Saving model ...
Validation loss decreased (0.416736 --> 0.416486).  Saving model ...
Validation loss decreased (0.416486 --> 0.416245).  Saving model ...
Validation loss decreased (0.416245 --> 0.415986).  Saving model ...
Validation loss decreased (0.415986 --> 0.415697).  Saving model ...
Validation loss decreased (0.415697 --> 0.415405).  Saving model ...
Validation loss decreased (0.415405 --> 0.415067).  Saving model ...
Validation loss decreased (0.415067 --> 0.414696).  Saving model ...
Validation loss decreased (0.414696 --> 0.414291).  Saving model ...
Validation loss decreased (0.414291 --> 0.413857).  Saving model ...
Validation loss decreased (0.413857 --> 0.413404).  Saving model ...
Validation loss decreased (0.413404 --> 0.412938).  Saving model ...
Validation loss decreased (0.412938 --> 0.412505).  Saving model ...
Validation loss decreased (0.412505 --> 0.412088).  Saving model ...
Validation loss decreased (0.412088 --> 0.411659).  Saving model ...
Validation loss decreased (0.411659 --> 0.411281).  Saving model ...
Validation loss decreased (0.411281 --> 0.410918).  Saving model ...
Validation loss decreased (0.410918 --> 0.410549).  Saving model ...
Validation loss decreased (0.410549 --> 0.410191).  Saving model ...
Validation loss decreased (0.410191 --> 0.409873).  Saving model ...
Validation loss decreased (0.409873 --> 0.409591).  Saving model ...
Validation loss decreased (0.409591 --> 0.409322).  Saving model ...
Validation loss decreased (0.409322 --> 0.409053).  Saving model ...
Validation loss decreased (0.409053 --> 0.408746).  Saving model ...
Validation loss decreased (0.408746 --> 0.408403).  Saving model ...
Validation loss decreased (0.408403 --> 0.408041).  Saving model ...
Validation loss decreased (0.408041 --> 0.407709).  Saving model ...
Validation loss decreased (0.407709 --> 0.407378).  Saving model ...
Validation loss decreased (0.407378 --> 0.407114).  Saving model ...
Validation loss decreased (0.407114 --> 0.406861).  Saving model ...
Validation loss decreased (0.406861 --> 0.406651).  Saving model ...
Validation loss decreased (0.406651 --> 0.406481).  Saving model ...
Validation loss decreased (0.406481 --> 0.406352).  Saving model ...
Validation loss decreased (0.406352 --> 0.406234).  Saving model ...
Validation loss decreased (0.406234 --> 0.406098).  Saving model ...
Validation loss decreased (0.406098 --> 0.405951).  Saving model ...
Validation loss decreased (0.405951 --> 0.405816).  Saving model ...
Validation loss decreased (0.405816 --> 0.405690).  Saving model ...
Validation loss decreased (0.405690 --> 0.405574).  Saving model ...
Validation loss decreased (0.405574 --> 0.405441).  Saving model ...
Validation loss decreased (0.405441 --> 0.405302).  Saving model ...
Validation loss decreased (0.405302 --> 0.405110).  Saving model ...
Validation loss decreased (0.405110 --> 0.404916).  Saving model ...
Validation loss decreased (0.404916 --> 0.404717).  Saving model ...
Validation loss decreased (0.404717 --> 0.404565).  Saving model ...
Validation loss decreased (0.404565 --> 0.404406).  Saving model ...
Validation loss decreased (0.404406 --> 0.404192).  Saving model ...
Validation loss decreased (0.404192 --> 0.404022).  Saving model ...
Validation loss decreased (0.404022 --> 0.403836).  Saving model ...
Validation loss decreased (0.403836 --> 0.403643).  Saving model ...
Validation loss decreased (0.403643 --> 0.403391).  Saving model ...
Validation loss decreased (0.403391 --> 0.403119).  Saving model ...
Validation loss decreased (0.403119 --> 0.402886).  Saving model ...
Validation loss decreased (0.402886 --> 0.402626).  Saving model ...
Validation loss decreased (0.402626 --> 0.402360).  Saving model ...
Validation loss decreased (0.402360 --> 0.402117).  Saving model ...
Validation loss decreased (0.402117 --> 0.401798).  Saving model ...
Validation loss decreased (0.401798 --> 0.401520).  Saving model ...
Validation loss decreased (0.401520 --> 0.401276).  Saving model ...
Validation loss decreased (0.401276 --> 0.401049).  Saving model ...
Validation loss decreased (0.401049 --> 0.400869).  Saving model ...
Validation loss decreased (0.400869 --> 0.400659).  Saving model ...
Validation loss decreased (0.400659 --> 0.400449).  Saving model ...
Validation loss decreased (0.400449 --> 0.400233).  Saving model ...
Validation loss decreased (0.400233 --> 0.400068).  Saving model ...
Validation loss decreased (0.400068 --> 0.399862).  Saving model ...
Validation loss decreased (0.399862 --> 0.399651).  Saving model ...
Validation loss decreased (0.399651 --> 0.399445).  Saving model ...
Validation loss decreased (0.399445 --> 0.399228).  Saving model ...
Validation loss decreased (0.399228 --> 0.399052).  Saving model ...
Validation loss decreased (0.399052 --> 0.398816).  Saving model ...
Validation loss decreased (0.398816 --> 0.398670).  Saving model ...
Validation loss decreased (0.398670 --> 0.398553).  Saving model ...
Validation loss decreased (0.398553 --> 0.398451).  Saving model ...
Validation loss decreased (0.398451 --> 0.398338).  Saving model ...
Validation loss decreased (0.398338 --> 0.398214).  Saving model ...
Validation loss decreased (0.398214 --> 0.398069).  Saving model ...
Validation loss decreased (0.398069 --> 0.397926).  Saving model ...
Validation loss decreased (0.397926 --> 0.397866).  Saving model ...
Validation loss decreased (0.397866 --> 0.397746).  Saving model ...
epoch 401, loss 0.4078, train acc 83.50%, f1 0.8342, precision 0.8384, recall 0.8300, auc 0.8350
Validation loss decreased (0.397746 --> 0.397608).  Saving model ...
Validation loss decreased (0.397608 --> 0.397411).  Saving model ...
Validation loss decreased (0.397411 --> 0.397190).  Saving model ...
Validation loss decreased (0.397190 --> 0.396991).  Saving model ...
Validation loss decreased (0.396991 --> 0.396817).  Saving model ...
Validation loss decreased (0.396817 --> 0.396645).  Saving model ...
Validation loss decreased (0.396645 --> 0.396483).  Saving model ...
Validation loss decreased (0.396483 --> 0.396371).  Saving model ...
Validation loss decreased (0.396371 --> 0.396289).  Saving model ...
Validation loss decreased (0.396289 --> 0.396223).  Saving model ...
Validation loss decreased (0.396223 --> 0.396162).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
Validation loss decreased (0.396162 --> 0.396122).  Saving model ...
Validation loss decreased (0.396122 --> 0.396049).  Saving model ...
Validation loss decreased (0.396049 --> 0.395966).  Saving model ...
Validation loss decreased (0.395966 --> 0.395909).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
Validation loss decreased (0.395909 --> 0.395886).  Saving model ...
Validation loss decreased (0.395886 --> 0.395857).  Saving model ...
Validation loss decreased (0.395857 --> 0.395829).  Saving model ...
Validation loss decreased (0.395829 --> 0.395782).  Saving model ...
Validation loss decreased (0.395782 --> 0.395703).  Saving model ...
Validation loss decreased (0.395703 --> 0.395641).  Saving model ...
Validation loss decreased (0.395641 --> 0.395555).  Saving model ...
Validation loss decreased (0.395555 --> 0.395438).  Saving model ...
Validation loss decreased (0.395438 --> 0.395341).  Saving model ...
Validation loss decreased (0.395341 --> 0.395237).  Saving model ...
Validation loss decreased (0.395237 --> 0.395157).  Saving model ...
Validation loss decreased (0.395157 --> 0.395023).  Saving model ...
Validation loss decreased (0.395023 --> 0.394818).  Saving model ...
Validation loss decreased (0.394818 --> 0.394614).  Saving model ...
Validation loss decreased (0.394614 --> 0.394373).  Saving model ...
Validation loss decreased (0.394373 --> 0.394178).  Saving model ...
Validation loss decreased (0.394178 --> 0.393913).  Saving model ...
Validation loss decreased (0.393913 --> 0.393648).  Saving model ...
Validation loss decreased (0.393648 --> 0.393380).  Saving model ...
Validation loss decreased (0.393380 --> 0.393142).  Saving model ...
Validation loss decreased (0.393142 --> 0.392863).  Saving model ...
Validation loss decreased (0.392863 --> 0.392520).  Saving model ...
Validation loss decreased (0.392520 --> 0.392164).  Saving model ...
Validation loss decreased (0.392164 --> 0.391869).  Saving model ...
Validation loss decreased (0.391869 --> 0.391586).  Saving model ...
Validation loss decreased (0.391586 --> 0.391370).  Saving model ...
Validation loss decreased (0.391370 --> 0.391135).  Saving model ...
Validation loss decreased (0.391135 --> 0.390810).  Saving model ...
Validation loss decreased (0.390810 --> 0.390491).  Saving model ...
Validation loss decreased (0.390491 --> 0.390209).  Saving model ...
Validation loss decreased (0.390209 --> 0.389929).  Saving model ...
Validation loss decreased (0.389929 --> 0.389670).  Saving model ...
Validation loss decreased (0.389670 --> 0.389423).  Saving model ...
Validation loss decreased (0.389423 --> 0.389173).  Saving model ...
Validation loss decreased (0.389173 --> 0.388995).  Saving model ...
Validation loss decreased (0.388995 --> 0.388791).  Saving model ...
Validation loss decreased (0.388791 --> 0.388599).  Saving model ...
Validation loss decreased (0.388599 --> 0.388423).  Saving model ...
Validation loss decreased (0.388423 --> 0.388291).  Saving model ...
Validation loss decreased (0.388291 --> 0.388111).  Saving model ...
Validation loss decreased (0.388111 --> 0.387911).  Saving model ...
Validation loss decreased (0.387911 --> 0.387720).  Saving model ...
Validation loss decreased (0.387720 --> 0.387445).  Saving model ...
Validation loss decreased (0.387445 --> 0.387172).  Saving model ...
Validation loss decreased (0.387172 --> 0.386924).  Saving model ...
Validation loss decreased (0.386924 --> 0.386680).  Saving model ...
Validation loss decreased (0.386680 --> 0.386385).  Saving model ...
Validation loss decreased (0.386385 --> 0.386056).  Saving model ...
Validation loss decreased (0.386056 --> 0.385751).  Saving model ...
Validation loss decreased (0.385751 --> 0.385400).  Saving model ...
Validation loss decreased (0.385400 --> 0.385091).  Saving model ...
Validation loss decreased (0.385091 --> 0.384793).  Saving model ...
Validation loss decreased (0.384793 --> 0.384543).  Saving model ...
Validation loss decreased (0.384543 --> 0.384322).  Saving model ...
Validation loss decreased (0.384322 --> 0.384089).  Saving model ...
Validation loss decreased (0.384089 --> 0.383865).  Saving model ...
Validation loss decreased (0.383865 --> 0.383652).  Saving model ...
Validation loss decreased (0.383652 --> 0.383444).  Saving model ...
Validation loss decreased (0.383444 --> 0.383197).  Saving model ...
Validation loss decreased (0.383197 --> 0.382925).  Saving model ...
Validation loss decreased (0.382925 --> 0.382625).  Saving model ...
Validation loss decreased (0.382625 --> 0.382331).  Saving model ...
Validation loss decreased (0.382331 --> 0.382021).  Saving model ...
Validation loss decreased (0.382021 --> 0.381661).  Saving model ...
Validation loss decreased (0.381661 --> 0.381323).  Saving model ...
Validation loss decreased (0.381323 --> 0.380981).  Saving model ...
Validation loss decreased (0.380981 --> 0.380665).  Saving model ...
Validation loss decreased (0.380665 --> 0.380317).  Saving model ...
Validation loss decreased (0.380317 --> 0.379946).  Saving model ...
Validation loss decreased (0.379946 --> 0.379604).  Saving model ...
Validation loss decreased (0.379604 --> 0.379277).  Saving model ...
Validation loss decreased (0.379277 --> 0.378978).  Saving model ...
Validation loss decreased (0.378978 --> 0.378725).  Saving model ...
Validation loss decreased (0.378725 --> 0.378488).  Saving model ...
Validation loss decreased (0.378488 --> 0.378215).  Saving model ...
Validation loss decreased (0.378215 --> 0.377985).  Saving model ...
Validation loss decreased (0.377985 --> 0.377705).  Saving model ...
Validation loss decreased (0.377705 --> 0.377427).  Saving model ...
Validation loss decreased (0.377427 --> 0.377236).  Saving model ...
Validation loss decreased (0.377236 --> 0.377010).  Saving model ...
epoch 501, loss 0.5043, train acc 83.25%, f1 0.8321, precision 0.8342, recall 0.8300, auc 0.8325
Validation loss decreased (0.377010 --> 0.376849).  Saving model ...
Validation loss decreased (0.376849 --> 0.376723).  Saving model ...
Validation loss decreased (0.376723 --> 0.376581).  Saving model ...
Validation loss decreased (0.376581 --> 0.376473).  Saving model ...
Validation loss decreased (0.376473 --> 0.376362).  Saving model ...
Validation loss decreased (0.376362 --> 0.376186).  Saving model ...
Validation loss decreased (0.376186 --> 0.375973).  Saving model ...
Validation loss decreased (0.375973 --> 0.375785).  Saving model ...
Validation loss decreased (0.375785 --> 0.375567).  Saving model ...
Validation loss decreased (0.375567 --> 0.375370).  Saving model ...
Validation loss decreased (0.375370 --> 0.375184).  Saving model ...
Validation loss decreased (0.375184 --> 0.374970).  Saving model ...
Validation loss decreased (0.374970 --> 0.374781).  Saving model ...
Validation loss decreased (0.374781 --> 0.374555).  Saving model ...
Validation loss decreased (0.374555 --> 0.374368).  Saving model ...
Validation loss decreased (0.374368 --> 0.374194).  Saving model ...
Validation loss decreased (0.374194 --> 0.374099).  Saving model ...
Validation loss decreased (0.374099 --> 0.373978).  Saving model ...
Validation loss decreased (0.373978 --> 0.373816).  Saving model ...
Validation loss decreased (0.373816 --> 0.373643).  Saving model ...
Validation loss decreased (0.373643 --> 0.373454).  Saving model ...
Validation loss decreased (0.373454 --> 0.373298).  Saving model ...
Validation loss decreased (0.373298 --> 0.373145).  Saving model ...
Validation loss decreased (0.373145 --> 0.373065).  Saving model ...
Validation loss decreased (0.373065 --> 0.372986).  Saving model ...
Validation loss decreased (0.372986 --> 0.372864).  Saving model ...
Validation loss decreased (0.372864 --> 0.372780).  Saving model ...
Validation loss decreased (0.372780 --> 0.372652).  Saving model ...
Validation loss decreased (0.372652 --> 0.372549).  Saving model ...
Validation loss decreased (0.372549 --> 0.372396).  Saving model ...
Validation loss decreased (0.372396 --> 0.372220).  Saving model ...
Validation loss decreased (0.372220 --> 0.372110).  Saving model ...
Validation loss decreased (0.372110 --> 0.371993).  Saving model ...
Validation loss decreased (0.371993 --> 0.371868).  Saving model ...
Validation loss decreased (0.371868 --> 0.371827).  Saving model ...
Validation loss decreased (0.371827 --> 0.371779).  Saving model ...
Validation loss decreased (0.371779 --> 0.371685).  Saving model ...
Validation loss decreased (0.371685 --> 0.371599).  Saving model ...
Validation loss decreased (0.371599 --> 0.371529).  Saving model ...
Validation loss decreased (0.371529 --> 0.371445).  Saving model ...
Validation loss decreased (0.371445 --> 0.371361).  Saving model ...
Validation loss decreased (0.371361 --> 0.371278).  Saving model ...
Validation loss decreased (0.371278 --> 0.371145).  Saving model ...
Validation loss decreased (0.371145 --> 0.371047).  Saving model ...
Validation loss decreased (0.371047 --> 0.370941).  Saving model ...
Validation loss decreased (0.370941 --> 0.370870).  Saving model ...
Validation loss decreased (0.370870 --> 0.370826).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.370826 --> 0.370791).  Saving model ...
Validation loss decreased (0.370791 --> 0.370728).  Saving model ...
Validation loss decreased (0.370728 --> 0.370677).  Saving model ...
Validation loss decreased (0.370677 --> 0.370586).  Saving model ...
Validation loss decreased (0.370586 --> 0.370527).  Saving model ...
Validation loss decreased (0.370527 --> 0.370486).  Saving model ...
Validation loss decreased (0.370486 --> 0.370426).  Saving model ...
Validation loss decreased (0.370426 --> 0.370335).  Saving model ...
Validation loss decreased (0.370335 --> 0.370299).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
Validation loss decreased (0.370299 --> 0.370297).  Saving model ...
Validation loss decreased (0.370297 --> 0.370137).  Saving model ...
Validation loss decreased (0.370137 --> 0.369981).  Saving model ...
Validation loss decreased (0.369981 --> 0.369840).  Saving model ...
Validation loss decreased (0.369840 --> 0.369684).  Saving model ...
Validation loss decreased (0.369684 --> 0.369561).  Saving model ...
Validation loss decreased (0.369561 --> 0.369397).  Saving model ...
Validation loss decreased (0.369397 --> 0.369200).  Saving model ...
Validation loss decreased (0.369200 --> 0.368950).  Saving model ...
Validation loss decreased (0.368950 --> 0.368670).  Saving model ...
Validation loss decreased (0.368670 --> 0.368509).  Saving model ...
Validation loss decreased (0.368509 --> 0.368398).  Saving model ...
Validation loss decreased (0.368398 --> 0.368316).  Saving model ...
Validation loss decreased (0.368316 --> 0.368229).  Saving model ...
Validation loss decreased (0.368229 --> 0.368124).  Saving model ...
Validation loss decreased (0.368124 --> 0.368001).  Saving model ...
Validation loss decreased (0.368001 --> 0.367927).  Saving model ...
Validation loss decreased (0.367927 --> 0.367816).  Saving model ...
Validation loss decreased (0.367816 --> 0.367712).  Saving model ...
Validation loss decreased (0.367712 --> 0.367597).  Saving model ...
Validation loss decreased (0.367597 --> 0.367521).  Saving model ...
Validation loss decreased (0.367521 --> 0.367506).  Saving model ...
Validation loss decreased (0.367506 --> 0.367492).  Saving model ...
Validation loss decreased (0.367492 --> 0.367443).  Saving model ...
Validation loss decreased (0.367443 --> 0.367415).  Saving model ...
Validation loss decreased (0.367415 --> 0.367388).  Saving model ...
Validation loss decreased (0.367388 --> 0.367318).  Saving model ...
epoch 601, loss 0.4004, train acc 83.50%, f1 0.8342, precision 0.8384, recall 0.8300, auc 0.8350
Validation loss decreased (0.367318 --> 0.367289).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.367289 --> 0.367285).  Saving model ...
Validation loss decreased (0.367285 --> 0.367168).  Saving model ...
Validation loss decreased (0.367168 --> 0.367016).  Saving model ...
Validation loss decreased (0.367016 --> 0.366872).  Saving model ...
Validation loss decreased (0.366872 --> 0.366793).  Saving model ...
Validation loss decreased (0.366793 --> 0.366731).  Saving model ...
Validation loss decreased (0.366731 --> 0.366659).  Saving model ...
Validation loss decreased (0.366659 --> 0.366614).  Saving model ...
Validation loss decreased (0.366614 --> 0.366553).  Saving model ...
Validation loss decreased (0.366553 --> 0.366472).  Saving model ...
Validation loss decreased (0.366472 --> 0.366424).  Saving model ...
Validation loss decreased (0.366424 --> 0.366327).  Saving model ...
Validation loss decreased (0.366327 --> 0.366201).  Saving model ...
Validation loss decreased (0.366201 --> 0.366130).  Saving model ...
Validation loss decreased (0.366130 --> 0.366075).  Saving model ...
Validation loss decreased (0.366075 --> 0.365967).  Saving model ...
Validation loss decreased (0.365967 --> 0.365863).  Saving model ...
Validation loss decreased (0.365863 --> 0.365701).  Saving model ...
Validation loss decreased (0.365701 --> 0.365571).  Saving model ...
Validation loss decreased (0.365571 --> 0.365479).  Saving model ...
Validation loss decreased (0.365479 --> 0.365372).  Saving model ...
Validation loss decreased (0.365372 --> 0.365232).  Saving model ...
Validation loss decreased (0.365232 --> 0.365128).  Saving model ...
Validation loss decreased (0.365128 --> 0.365080).  Saving model ...
Validation loss decreased (0.365080 --> 0.365026).  Saving model ...
Validation loss decreased (0.365026 --> 0.364955).  Saving model ...
Validation loss decreased (0.364955 --> 0.364895).  Saving model ...
Validation loss decreased (0.364895 --> 0.364821).  Saving model ...
Validation loss decreased (0.364821 --> 0.364713).  Saving model ...
Validation loss decreased (0.364713 --> 0.364589).  Saving model ...
Validation loss decreased (0.364589 --> 0.364460).  Saving model ...
Validation loss decreased (0.364460 --> 0.364314).  Saving model ...
Validation loss decreased (0.364314 --> 0.364231).  Saving model ...
Validation loss decreased (0.364231 --> 0.364170).  Saving model ...
Validation loss decreased (0.364170 --> 0.364135).  Saving model ...
Validation loss decreased (0.364135 --> 0.364095).  Saving model ...
Validation loss decreased (0.364095 --> 0.364021).  Saving model ...
Validation loss decreased (0.364021 --> 0.363854).  Saving model ...
Validation loss decreased (0.363854 --> 0.363667).  Saving model ...
Validation loss decreased (0.363667 --> 0.363505).  Saving model ...
Validation loss decreased (0.363505 --> 0.363350).  Saving model ...
Validation loss decreased (0.363350 --> 0.363183).  Saving model ...
Validation loss decreased (0.363183 --> 0.363063).  Saving model ...
Validation loss decreased (0.363063 --> 0.362952).  Saving model ...
Validation loss decreased (0.362952 --> 0.362918).  Saving model ...
Validation loss decreased (0.362918 --> 0.362872).  Saving model ...
Validation loss decreased (0.362872 --> 0.362795).  Saving model ...
Validation loss decreased (0.362795 --> 0.362706).  Saving model ...
Validation loss decreased (0.362706 --> 0.362664).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.362664 --> 0.362657).  Saving model ...
Validation loss decreased (0.362657 --> 0.362570).  Saving model ...
Validation loss decreased (0.362570 --> 0.362483).  Saving model ...
Validation loss decreased (0.362483 --> 0.362447).  Saving model ...
Validation loss decreased (0.362447 --> 0.362407).  Saving model ...
Validation loss decreased (0.362407 --> 0.362380).  Saving model ...
Validation loss decreased (0.362380 --> 0.362327).  Saving model ...
Validation loss decreased (0.362327 --> 0.362293).  Saving model ...
Validation loss decreased (0.362293 --> 0.362182).  Saving model ...
Validation loss decreased (0.362182 --> 0.362143).  Saving model ...
Validation loss decreased (0.362143 --> 0.362139).  Saving model ...
Validation loss decreased (0.362139 --> 0.362070).  Saving model ...
Validation loss decreased (0.362070 --> 0.362043).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.362043 --> 0.362037).  Saving model ...
Validation loss decreased (0.362037 --> 0.362006).  Saving model ...
Validation loss decreased (0.362006 --> 0.361943).  Saving model ...
Validation loss decreased (0.361943 --> 0.361852).  Saving model ...
Validation loss decreased (0.361852 --> 0.361745).  Saving model ...
Validation loss decreased (0.361745 --> 0.361653).  Saving model ...
Validation loss decreased (0.361653 --> 0.361578).  Saving model ...
Validation loss decreased (0.361578 --> 0.361519).  Saving model ...
Validation loss decreased (0.361519 --> 0.361395).  Saving model ...
Validation loss decreased (0.361395 --> 0.361269).  Saving model ...
Validation loss decreased (0.361269 --> 0.361143).  Saving model ...
Validation loss decreased (0.361143 --> 0.360944).  Saving model ...
Validation loss decreased (0.360944 --> 0.360737).  Saving model ...
Validation loss decreased (0.360737 --> 0.360508).  Saving model ...
Validation loss decreased (0.360508 --> 0.360323).  Saving model ...
Validation loss decreased (0.360323 --> 0.360151).  Saving model ...
Validation loss decreased (0.360151 --> 0.360074).  Saving model ...
Validation loss decreased (0.360074 --> 0.360030).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.360030 --> 0.359999).  Saving model ...
Validation loss decreased (0.359999 --> 0.359923).  Saving model ...
Validation loss decreased (0.359923 --> 0.359916).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
epoch 701, loss 0.3788, train acc 83.50%, f1 0.8350, precision 0.8350, recall 0.8350, auc 0.8350
EarlyStopping counter: 10 out of 20
Validation loss decreased (0.359916 --> 0.359863).  Saving model ...
Validation loss decreased (0.359863 --> 0.359749).  Saving model ...
Validation loss decreased (0.359749 --> 0.359661).  Saving model ...
Validation loss decreased (0.359661 --> 0.359567).  Saving model ...
Validation loss decreased (0.359567 --> 0.359489).  Saving model ...
Validation loss decreased (0.359489 --> 0.359451).  Saving model ...
Validation loss decreased (0.359451 --> 0.359384).  Saving model ...
Validation loss decreased (0.359384 --> 0.359376).  Saving model ...
Validation loss decreased (0.359376 --> 0.359361).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)

Early stopping epoch 730, loss 0.4190, train acc 83.50%, f1 0.8350, precision 0.8350, recall 0.8350, auc 0.8350



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_Mirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_True/record_1/MLP_minus_Mirror_True_3
./test_pima/result_MLP_minus_Mirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5800000000000001

the Fscore is 0.5625

the precision is 0.391304347826087

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_3
----------------------



epoch 1, loss 0.6931, train acc 52.23%, f1 0.0892, precision 0.9554, recall 0.0468, auc 0.5223
epoch 101, loss 0.5950, train acc 77.51%, f1 0.7751, precision 0.7751, recall 0.7752, auc 0.7751
epoch 201, loss 0.4946, train acc 80.04%, f1 0.8004, precision 0.8004, recall 0.8004, auc 0.8004
epoch 301, loss 0.4456, train acc 81.58%, f1 0.8158, precision 0.8158, recall 0.8158, auc 0.8158
epoch 401, loss 0.3995, train acc 82.49%, f1 0.8249, precision 0.8249, recall 0.8249, auc 0.8249
epoch 501, loss 0.3553, train acc 82.89%, f1 0.8289, precision 0.8289, recall 0.8289, auc 0.8289
epoch 601, loss 0.3459, train acc 83.03%, f1 0.8303, precision 0.8303, recall 0.8303, auc 0.8303
epoch 701, loss 0.3629, train acc 83.05%, f1 0.8305, precision 0.8305, recall 0.8305, auc 0.8305
epoch 801, loss 0.3426, train acc 83.08%, f1 0.8308, precision 0.8308, recall 0.8308, auc 0.8308
epoch 901, loss 0.2995, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8311, auc 0.8311
epoch 1001, loss 0.3207, train acc 83.10%, f1 0.8310, precision 0.8310, recall 0.8310, auc 0.8310
epoch 1101, loss 0.3781, train acc 83.09%, f1 0.8309, precision 0.8308, recall 0.8309, auc 0.8309
epoch 1201, loss 0.4756, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8314, auc 0.8314
epoch 1301, loss 0.4335, train acc 83.16%, f1 0.8316, precision 0.8316, recall 0.8316, auc 0.8316
epoch 1401, loss 0.3318, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8314, auc 0.8314
epoch 1501, loss 0.4173, train acc 83.12%, f1 0.8312, precision 0.8312, recall 0.8312, auc 0.8312
epoch 1601, loss 0.4153, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8313, auc 0.8313
epoch 1701, loss 0.5645, train acc 83.18%, f1 0.8318, precision 0.8318, recall 0.8318, auc 0.8318
epoch 1801, loss 0.4473, train acc 83.19%, f1 0.8319, precision 0.8319, recall 0.8319, auc 0.8319
epoch 1901, loss 0.3037, train acc 83.18%, f1 0.8318, precision 0.8318, recall 0.8318, auc 0.8318
epoch 2001, loss 0.4684, train acc 83.18%, f1 0.8318, precision 0.8318, recall 0.8318, auc 0.8318
epoch 2101, loss 0.3877, train acc 83.19%, f1 0.8319, precision 0.8319, recall 0.8320, auc 0.8319
epoch 2201, loss 0.3464, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8315, auc 0.8315
epoch 2301, loss 0.4463, train acc 83.13%, f1 0.8313, precision 0.8312, recall 0.8313, auc 0.8313
epoch 2401, loss 0.3529, train acc 83.18%, f1 0.8318, precision 0.8319, recall 0.8317, auc 0.8318
epoch 2501, loss 0.4941, train acc 83.11%, f1 0.8311, precision 0.8312, recall 0.8311, auc 0.8311
epoch 2601, loss 0.4448, train acc 83.12%, f1 0.8312, precision 0.8312, recall 0.8312, auc 0.8312
epoch 2701, loss 0.2991, train acc 83.14%, f1 0.8314, precision 0.8315, recall 0.8314, auc 0.8314
epoch 2801, loss 0.3228, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8313, auc 0.8314
epoch 2901, loss 0.3550, train acc 83.17%, f1 0.8317, precision 0.8317, recall 0.8316, auc 0.8317
epoch 3001, loss 0.5008, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8311, auc 0.8311
epoch 3101, loss 0.3376, train acc 83.10%, f1 0.8310, precision 0.8310, recall 0.8310, auc 0.8310
epoch 3201, loss 0.2269, train acc 83.08%, f1 0.8308, precision 0.8306, recall 0.8310, auc 0.8308
epoch 3301, loss 0.3694, train acc 83.12%, f1 0.8312, precision 0.8312, recall 0.8311, auc 0.8312
epoch 3401, loss 0.4426, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8312, auc 0.8311
epoch 3501, loss 0.3297, train acc 83.10%, f1 0.8310, precision 0.8310, recall 0.8310, auc 0.8310
epoch 3601, loss 0.3412, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8311, auc 0.8311
epoch 3701, loss 0.4134, train acc 83.13%, f1 0.8314, precision 0.8313, recall 0.8315, auc 0.8313
epoch 3801, loss 0.4371, train acc 83.16%, f1 0.8315, precision 0.8318, recall 0.8312, auc 0.8316
epoch 3901, loss 0.3844, train acc 83.17%, f1 0.8317, precision 0.8316, recall 0.8319, auc 0.8317
epoch 4001, loss 0.3884, train acc 83.16%, f1 0.8316, precision 0.8315, recall 0.8318, auc 0.8316
epoch 4101, loss 0.5634, train acc 83.15%, f1 0.8315, precision 0.8316, recall 0.8314, auc 0.8315
epoch 4201, loss 0.4179, train acc 83.21%, f1 0.8321, precision 0.8322, recall 0.8321, auc 0.8321
epoch 4301, loss 0.3454, train acc 83.16%, f1 0.8316, precision 0.8318, recall 0.8313, auc 0.8316
epoch 4401, loss 0.2762, train acc 83.21%, f1 0.8320, precision 0.8322, recall 0.8319, auc 0.8321
epoch 4501, loss 0.2746, train acc 83.25%, f1 0.8324, precision 0.8326, recall 0.8323, auc 0.8325
epoch 4601, loss 0.3691, train acc 83.22%, f1 0.8322, precision 0.8323, recall 0.8321, auc 0.8322
epoch 4701, loss 0.4836, train acc 83.20%, f1 0.8320, precision 0.8321, recall 0.8319, auc 0.8320
epoch 4801, loss 0.4026, train acc 83.22%, f1 0.8322, precision 0.8322, recall 0.8323, auc 0.8322
epoch 4901, loss 0.4125, train acc 83.27%, f1 0.8327, precision 0.8325, recall 0.8329, auc 0.8327
epoch 5001, loss 0.3673, train acc 83.28%, f1 0.8328, precision 0.8327, recall 0.8329, auc 0.8328
epoch 5101, loss 0.3108, train acc 83.34%, f1 0.8333, precision 0.8335, recall 0.8332, auc 0.8334
epoch 5201, loss 0.4398, train acc 83.35%, f1 0.8335, precision 0.8334, recall 0.8336, auc 0.8335
epoch 5301, loss 0.2971, train acc 83.25%, f1 0.8325, precision 0.8324, recall 0.8326, auc 0.8325
epoch 5401, loss 0.3525, train acc 83.35%, f1 0.8335, precision 0.8333, recall 0.8337, auc 0.8335
epoch 5501, loss 0.3950, train acc 83.40%, f1 0.8340, precision 0.8342, recall 0.8338, auc 0.8340
epoch 5601, loss 0.3258, train acc 83.42%, f1 0.8342, precision 0.8341, recall 0.8342, auc 0.8342
epoch 5701, loss 0.4241, train acc 83.37%, f1 0.8337, precision 0.8336, recall 0.8339, auc 0.8337
epoch 5801, loss 0.4178, train acc 83.42%, f1 0.8342, precision 0.8341, recall 0.8343, auc 0.8342
epoch 5901, loss 0.3741, train acc 83.45%, f1 0.8345, precision 0.8343, recall 0.8346, auc 0.8345
epoch 6001, loss 0.4155, train acc 83.52%, f1 0.8353, precision 0.8350, recall 0.8355, auc 0.8352
epoch 6101, loss 0.3399, train acc 83.48%, f1 0.8348, precision 0.8348, recall 0.8347, auc 0.8348
epoch 6201, loss 0.3295, train acc 83.52%, f1 0.8351, precision 0.8356, recall 0.8346, auc 0.8352
epoch 6301, loss 0.3060, train acc 83.57%, f1 0.8358, precision 0.8355, recall 0.8360, auc 0.8357
epoch 6401, loss 0.2645, train acc 83.58%, f1 0.8358, precision 0.8359, recall 0.8357, auc 0.8358
epoch 6501, loss 0.4139, train acc 83.58%, f1 0.8358, precision 0.8358, recall 0.8359, auc 0.8358
epoch 6601, loss 0.3759, train acc 83.62%, f1 0.8363, precision 0.8358, recall 0.8367, auc 0.8362
epoch 6701, loss 0.4247, train acc 83.66%, f1 0.8367, precision 0.8365, recall 0.8369, auc 0.8366
epoch 6801, loss 0.3248, train acc 83.67%, f1 0.8367, precision 0.8368, recall 0.8367, auc 0.8367
epoch 6901, loss 0.4441, train acc 83.70%, f1 0.8370, precision 0.8370, recall 0.8370, auc 0.8370
epoch 7001, loss 0.4152, train acc 83.76%, f1 0.8376, precision 0.8375, recall 0.8378, auc 0.8376
epoch 7101, loss 0.4125, train acc 83.82%, f1 0.8383, precision 0.8380, recall 0.8386, auc 0.8382
epoch 7201, loss 0.4381, train acc 83.81%, f1 0.8380, precision 0.8383, recall 0.8378, auc 0.8381
epoch 7301, loss 0.2835, train acc 83.81%, f1 0.8381, precision 0.8381, recall 0.8381, auc 0.8381
epoch 7401, loss 0.3620, train acc 83.85%, f1 0.8385, precision 0.8388, recall 0.8382, auc 0.8385
epoch 7501, loss 0.3770, train acc 83.91%, f1 0.8391, precision 0.8392, recall 0.8391, auc 0.8391
epoch 7601, loss 0.3171, train acc 83.99%, f1 0.8399, precision 0.8400, recall 0.8397, auc 0.8399
epoch 7701, loss 0.4031, train acc 83.95%, f1 0.8395, precision 0.8396, recall 0.8393, auc 0.8395
epoch 7801, loss 0.3573, train acc 83.97%, f1 0.8398, precision 0.8395, recall 0.8400, auc 0.8397
epoch 7901, loss 0.3367, train acc 83.95%, f1 0.8395, precision 0.8394, recall 0.8396, auc 0.8395
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_Mirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_8000/record_1/MLP_minus_Mirror_8000_3
./test_pima/result_MLP_minus_Mirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6

the Fscore is 0.5744680851063829

the precision is 0.40298507462686567

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_3
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.6667, precision 0.5000, recall 1.0000, auc 0.5000
epoch 101, loss 0.6127, train acc 77.77%, f1 0.7758, precision 0.7826, recall 0.7691, auc 0.7777
epoch 201, loss 0.4388, train acc 80.04%, f1 0.8002, precision 0.8010, recall 0.7994, auc 0.8004
epoch 301, loss 0.4387, train acc 81.69%, f1 0.8170, precision 0.8168, recall 0.8171, auc 0.8169
epoch 401, loss 0.3764, train acc 82.44%, f1 0.8245, precision 0.8241, recall 0.8248, auc 0.8244
epoch 501, loss 0.4541, train acc 82.87%, f1 0.8288, precision 0.8281, recall 0.8295, auc 0.8287
epoch 601, loss 0.3646, train acc 82.98%, f1 0.8299, precision 0.8296, recall 0.8302, auc 0.8298
epoch 701, loss 0.3797, train acc 83.04%, f1 0.8304, precision 0.8301, recall 0.8308, auc 0.8304
epoch 801, loss 0.3480, train acc 83.08%, f1 0.8308, precision 0.8307, recall 0.8308, auc 0.8308
epoch 901, loss 0.4430, train acc 83.08%, f1 0.8309, precision 0.8305, recall 0.8312, auc 0.8308
epoch 1001, loss 0.5727, train acc 83.10%, f1 0.8311, precision 0.8308, recall 0.8314, auc 0.8310
epoch 1101, loss 0.4296, train acc 83.13%, f1 0.8313, precision 0.8312, recall 0.8315, auc 0.8313
epoch 1201, loss 0.3802, train acc 83.10%, f1 0.8310, precision 0.8311, recall 0.8309, auc 0.8310
epoch 1301, loss 0.3949, train acc 83.09%, f1 0.8310, precision 0.8308, recall 0.8311, auc 0.8309
epoch 1401, loss 0.3652, train acc 83.14%, f1 0.8315, precision 0.8314, recall 0.8315, auc 0.8314
epoch 1501, loss 0.4768, train acc 83.15%, f1 0.8315, precision 0.8314, recall 0.8316, auc 0.8315
epoch 1601, loss 0.2442, train acc 83.17%, f1 0.8317, precision 0.8317, recall 0.8317, auc 0.8317
epoch 1701, loss 0.3706, train acc 83.17%, f1 0.8318, precision 0.8317, recall 0.8318, auc 0.8317
epoch 1801, loss 0.3532, train acc 83.22%, f1 0.8322, precision 0.8322, recall 0.8322, auc 0.8322
epoch 1901, loss 0.4362, train acc 83.21%, f1 0.8320, precision 0.8321, recall 0.8320, auc 0.8321
epoch 2001, loss 0.3304, train acc 83.15%, f1 0.8315, precision 0.8316, recall 0.8314, auc 0.8315
epoch 2101, loss 0.2724, train acc 83.15%, f1 0.8314, precision 0.8317, recall 0.8312, auc 0.8315
epoch 2201, loss 0.3333, train acc 83.14%, f1 0.8314, precision 0.8316, recall 0.8311, auc 0.8314
epoch 2301, loss 0.5252, train acc 83.19%, f1 0.8319, precision 0.8319, recall 0.8320, auc 0.8319
epoch 2401, loss 0.3477, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8315, auc 0.8315
epoch 2501, loss 0.3825, train acc 83.17%, f1 0.8317, precision 0.8317, recall 0.8317, auc 0.8317
epoch 2601, loss 0.5206, train acc 83.12%, f1 0.8311, precision 0.8313, recall 0.8310, auc 0.8312
epoch 2701, loss 0.5015, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8313, auc 0.8314
epoch 2801, loss 0.4706, train acc 83.12%, f1 0.8312, precision 0.8313, recall 0.8311, auc 0.8312
epoch 2901, loss 0.2812, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8313, auc 0.8314
epoch 3001, loss 0.3292, train acc 83.14%, f1 0.8314, precision 0.8315, recall 0.8313, auc 0.8314
epoch 3101, loss 0.4520, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8314, auc 0.8313
epoch 3201, loss 0.3148, train acc 83.14%, f1 0.8314, precision 0.8314, recall 0.8314, auc 0.8314
epoch 3301, loss 0.3354, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8312, auc 0.8313
epoch 3401, loss 0.3888, train acc 83.17%, f1 0.8317, precision 0.8317, recall 0.8316, auc 0.8317
epoch 3501, loss 0.3261, train acc 83.14%, f1 0.8314, precision 0.8316, recall 0.8312, auc 0.8314
epoch 3601, loss 0.2977, train acc 83.15%, f1 0.8315, precision 0.8316, recall 0.8315, auc 0.8315
epoch 3701, loss 0.3835, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8312, auc 0.8313
epoch 3801, loss 0.4117, train acc 83.11%, f1 0.8311, precision 0.8312, recall 0.8311, auc 0.8311
epoch 3901, loss 0.3317, train acc 83.18%, f1 0.8318, precision 0.8319, recall 0.8317, auc 0.8318
epoch 4001, loss 0.3397, train acc 83.13%, f1 0.8313, precision 0.8314, recall 0.8311, auc 0.8313
epoch 4101, loss 0.3226, train acc 83.16%, f1 0.8316, precision 0.8315, recall 0.8316, auc 0.8316
epoch 4201, loss 0.4615, train acc 83.16%, f1 0.8316, precision 0.8316, recall 0.8315, auc 0.8316
epoch 4301, loss 0.3589, train acc 83.23%, f1 0.8323, precision 0.8324, recall 0.8322, auc 0.8323
epoch 4401, loss 0.3088, train acc 83.25%, f1 0.8325, precision 0.8324, recall 0.8326, auc 0.8325
epoch 4501, loss 0.4131, train acc 83.17%, f1 0.8317, precision 0.8320, recall 0.8314, auc 0.8317
epoch 4601, loss 0.4003, train acc 83.22%, f1 0.8321, precision 0.8323, recall 0.8320, auc 0.8322
epoch 4701, loss 0.4722, train acc 83.17%, f1 0.8317, precision 0.8315, recall 0.8319, auc 0.8317
epoch 4801, loss 0.3843, train acc 83.30%, f1 0.8330, precision 0.8328, recall 0.8332, auc 0.8330
epoch 4901, loss 0.4065, train acc 83.24%, f1 0.8324, precision 0.8325, recall 0.8323, auc 0.8324
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_Mirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_5000/record_1/MLP_minus_Mirror_5000_3
./test_pima/result_MLP_minus_Mirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5607407407407408

the Fscore is 0.5492227979274612

the precision is 0.381294964028777

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_3
----------------------



epoch 1, loss 0.6932, train acc 50.00%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6197, train acc 76.81%, f1 0.7681, precision 0.7680, recall 0.7682, auc 0.7681
epoch 201, loss 0.5154, train acc 79.81%, f1 0.7981, precision 0.7981, recall 0.7981, auc 0.7981
epoch 301, loss 0.4594, train acc 81.57%, f1 0.8157, precision 0.8157, recall 0.8157, auc 0.8157
epoch 401, loss 0.3466, train acc 82.44%, f1 0.8244, precision 0.8244, recall 0.8243, auc 0.8244
epoch 501, loss 0.3149, train acc 82.85%, f1 0.8285, precision 0.8285, recall 0.8285, auc 0.8285
epoch 601, loss 0.4136, train acc 82.98%, f1 0.8298, precision 0.8298, recall 0.8298, auc 0.8298
epoch 701, loss 0.3319, train acc 83.07%, f1 0.8307, precision 0.8307, recall 0.8307, auc 0.8307
epoch 801, loss 0.3960, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8311, auc 0.8311
epoch 901, loss 0.4164, train acc 83.11%, f1 0.8311, precision 0.8311, recall 0.8311, auc 0.8311
epoch 1001, loss 0.3725, train acc 83.16%, f1 0.8316, precision 0.8316, recall 0.8316, auc 0.8316
epoch 1101, loss 0.4804, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8315, auc 0.8315
epoch 1201, loss 0.2841, train acc 83.17%, f1 0.8317, precision 0.8317, recall 0.8316, auc 0.8317
epoch 1301, loss 0.4727, train acc 83.17%, f1 0.8317, precision 0.8316, recall 0.8319, auc 0.8317
epoch 1401, loss 0.4737, train acc 83.16%, f1 0.8316, precision 0.8317, recall 0.8315, auc 0.8316
epoch 1501, loss 0.3919, train acc 83.13%, f1 0.8313, precision 0.8312, recall 0.8313, auc 0.8313
epoch 1601, loss 0.3859, train acc 83.15%, f1 0.8315, precision 0.8315, recall 0.8315, auc 0.8315
epoch 1701, loss 0.3512, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8314, auc 0.8313
epoch 1801, loss 0.4320, train acc 83.16%, f1 0.8316, precision 0.8316, recall 0.8316, auc 0.8316
epoch 1901, loss 0.3101, train acc 83.13%, f1 0.8313, precision 0.8313, recall 0.8313, auc 0.8313
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_Mirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_Mirror_2000/record_1/MLP_minus_Mirror_2000_3
./test_pima/result_MLP_minus_Mirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.62

the Fscore is 0.5869565217391305

the precision is 0.4153846153846154

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_3
----------------------



epoch 1, loss 0.6932, train acc 47.50%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.693031).  Saving model ...
Validation loss decreased (0.693031 --> 0.692874).  Saving model ...
Validation loss decreased (0.692874 --> 0.692820).  Saving model ...
Validation loss decreased (0.692820 --> 0.692780).  Saving model ...
Validation loss decreased (0.692780 --> 0.692753).  Saving model ...
Validation loss decreased (0.692753 --> 0.692666).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.692666 --> 0.692639).  Saving model ...
Validation loss decreased (0.692639 --> 0.692548).  Saving model ...
Validation loss decreased (0.692548 --> 0.692457).  Saving model ...
Validation loss decreased (0.692457 --> 0.692360).  Saving model ...
Validation loss decreased (0.692360 --> 0.692239).  Saving model ...
Validation loss decreased (0.692239 --> 0.692092).  Saving model ...
Validation loss decreased (0.692092 --> 0.691956).  Saving model ...
Validation loss decreased (0.691956 --> 0.691781).  Saving model ...
Validation loss decreased (0.691781 --> 0.691570).  Saving model ...
Validation loss decreased (0.691570 --> 0.691342).  Saving model ...
Validation loss decreased (0.691342 --> 0.691085).  Saving model ...
Validation loss decreased (0.691085 --> 0.690815).  Saving model ...
Validation loss decreased (0.690815 --> 0.690557).  Saving model ...
Validation loss decreased (0.690557 --> 0.690294).  Saving model ...
Validation loss decreased (0.690294 --> 0.689993).  Saving model ...
Validation loss decreased (0.689993 --> 0.689667).  Saving model ...
Validation loss decreased (0.689667 --> 0.689323).  Saving model ...
Validation loss decreased (0.689323 --> 0.688955).  Saving model ...
Validation loss decreased (0.688955 --> 0.688567).  Saving model ...
Validation loss decreased (0.688567 --> 0.688156).  Saving model ...
Validation loss decreased (0.688156 --> 0.687731).  Saving model ...
Validation loss decreased (0.687731 --> 0.687297).  Saving model ...
Validation loss decreased (0.687297 --> 0.686832).  Saving model ...
Validation loss decreased (0.686832 --> 0.686356).  Saving model ...
Validation loss decreased (0.686356 --> 0.685877).  Saving model ...
Validation loss decreased (0.685877 --> 0.685388).  Saving model ...
Validation loss decreased (0.685388 --> 0.684868).  Saving model ...
Validation loss decreased (0.684868 --> 0.684335).  Saving model ...
Validation loss decreased (0.684335 --> 0.683756).  Saving model ...
Validation loss decreased (0.683756 --> 0.683131).  Saving model ...
Validation loss decreased (0.683131 --> 0.682467).  Saving model ...
Validation loss decreased (0.682467 --> 0.681772).  Saving model ...
Validation loss decreased (0.681772 --> 0.681049).  Saving model ...
Validation loss decreased (0.681049 --> 0.680303).  Saving model ...
Validation loss decreased (0.680303 --> 0.679517).  Saving model ...
Validation loss decreased (0.679517 --> 0.678713).  Saving model ...
Validation loss decreased (0.678713 --> 0.677887).  Saving model ...
Validation loss decreased (0.677887 --> 0.677026).  Saving model ...
Validation loss decreased (0.677026 --> 0.676147).  Saving model ...
Validation loss decreased (0.676147 --> 0.675240).  Saving model ...
Validation loss decreased (0.675240 --> 0.674285).  Saving model ...
Validation loss decreased (0.674285 --> 0.673325).  Saving model ...
Validation loss decreased (0.673325 --> 0.672356).  Saving model ...
Validation loss decreased (0.672356 --> 0.671345).  Saving model ...
Validation loss decreased (0.671345 --> 0.670303).  Saving model ...
Validation loss decreased (0.670303 --> 0.669243).  Saving model ...
Validation loss decreased (0.669243 --> 0.668195).  Saving model ...
Validation loss decreased (0.668195 --> 0.667135).  Saving model ...
Validation loss decreased (0.667135 --> 0.666022).  Saving model ...
Validation loss decreased (0.666022 --> 0.664860).  Saving model ...
Validation loss decreased (0.664860 --> 0.663699).  Saving model ...
Validation loss decreased (0.663699 --> 0.662527).  Saving model ...
Validation loss decreased (0.662527 --> 0.661338).  Saving model ...
Validation loss decreased (0.661338 --> 0.660106).  Saving model ...
Validation loss decreased (0.660106 --> 0.658866).  Saving model ...
Validation loss decreased (0.658866 --> 0.657596).  Saving model ...
Validation loss decreased (0.657596 --> 0.656296).  Saving model ...
Validation loss decreased (0.656296 --> 0.654965).  Saving model ...
Validation loss decreased (0.654965 --> 0.653588).  Saving model ...
Validation loss decreased (0.653588 --> 0.652197).  Saving model ...
Validation loss decreased (0.652197 --> 0.650749).  Saving model ...
Validation loss decreased (0.650749 --> 0.649282).  Saving model ...
Validation loss decreased (0.649282 --> 0.647817).  Saving model ...
Validation loss decreased (0.647817 --> 0.646368).  Saving model ...
Validation loss decreased (0.646368 --> 0.644908).  Saving model ...
Validation loss decreased (0.644908 --> 0.643411).  Saving model ...
Validation loss decreased (0.643411 --> 0.641887).  Saving model ...
Validation loss decreased (0.641887 --> 0.640328).  Saving model ...
Validation loss decreased (0.640328 --> 0.638762).  Saving model ...
Validation loss decreased (0.638762 --> 0.637218).  Saving model ...
Validation loss decreased (0.637218 --> 0.635661).  Saving model ...
Validation loss decreased (0.635661 --> 0.634116).  Saving model ...
Validation loss decreased (0.634116 --> 0.632551).  Saving model ...
Validation loss decreased (0.632551 --> 0.630957).  Saving model ...
Validation loss decreased (0.630957 --> 0.629363).  Saving model ...
Validation loss decreased (0.629363 --> 0.627773).  Saving model ...
Validation loss decreased (0.627773 --> 0.626203).  Saving model ...
Validation loss decreased (0.626203 --> 0.624659).  Saving model ...
Validation loss decreased (0.624659 --> 0.623148).  Saving model ...
Validation loss decreased (0.623148 --> 0.621642).  Saving model ...
Validation loss decreased (0.621642 --> 0.620107).  Saving model ...
Validation loss decreased (0.620107 --> 0.618543).  Saving model ...
Validation loss decreased (0.618543 --> 0.616992).  Saving model ...
Validation loss decreased (0.616992 --> 0.615416).  Saving model ...
Validation loss decreased (0.615416 --> 0.613859).  Saving model ...
Validation loss decreased (0.613859 --> 0.612292).  Saving model ...
Validation loss decreased (0.612292 --> 0.610824).  Saving model ...
Validation loss decreased (0.610824 --> 0.609345).  Saving model ...
Validation loss decreased (0.609345 --> 0.607843).  Saving model ...
Validation loss decreased (0.607843 --> 0.606355).  Saving model ...
Validation loss decreased (0.606355 --> 0.604885).  Saving model ...
Validation loss decreased (0.604885 --> 0.603395).  Saving model ...
Validation loss decreased (0.603395 --> 0.601892).  Saving model ...
epoch 101, loss 0.6372, train acc 75.50%, f1 0.7610, precision 0.7800, recall 0.7429, auc 0.7556
Validation loss decreased (0.601892 --> 0.600425).  Saving model ...
Validation loss decreased (0.600425 --> 0.598934).  Saving model ...
Validation loss decreased (0.598934 --> 0.597431).  Saving model ...
Validation loss decreased (0.597431 --> 0.595966).  Saving model ...
Validation loss decreased (0.595966 --> 0.594477).  Saving model ...
Validation loss decreased (0.594477 --> 0.593004).  Saving model ...
Validation loss decreased (0.593004 --> 0.591567).  Saving model ...
Validation loss decreased (0.591567 --> 0.590126).  Saving model ...
Validation loss decreased (0.590126 --> 0.588682).  Saving model ...
Validation loss decreased (0.588682 --> 0.587210).  Saving model ...
Validation loss decreased (0.587210 --> 0.585699).  Saving model ...
Validation loss decreased (0.585699 --> 0.584175).  Saving model ...
Validation loss decreased (0.584175 --> 0.582668).  Saving model ...
Validation loss decreased (0.582668 --> 0.581232).  Saving model ...
Validation loss decreased (0.581232 --> 0.579769).  Saving model ...
Validation loss decreased (0.579769 --> 0.578336).  Saving model ...
Validation loss decreased (0.578336 --> 0.576891).  Saving model ...
Validation loss decreased (0.576891 --> 0.575423).  Saving model ...
Validation loss decreased (0.575423 --> 0.574062).  Saving model ...
Validation loss decreased (0.574062 --> 0.572714).  Saving model ...
Validation loss decreased (0.572714 --> 0.571357).  Saving model ...
Validation loss decreased (0.571357 --> 0.569991).  Saving model ...
Validation loss decreased (0.569991 --> 0.568657).  Saving model ...
Validation loss decreased (0.568657 --> 0.567349).  Saving model ...
Validation loss decreased (0.567349 --> 0.566046).  Saving model ...
Validation loss decreased (0.566046 --> 0.564719).  Saving model ...
Validation loss decreased (0.564719 --> 0.563411).  Saving model ...
Validation loss decreased (0.563411 --> 0.562100).  Saving model ...
Validation loss decreased (0.562100 --> 0.560761).  Saving model ...
Validation loss decreased (0.560761 --> 0.559482).  Saving model ...
Validation loss decreased (0.559482 --> 0.558235).  Saving model ...
Validation loss decreased (0.558235 --> 0.556965).  Saving model ...
Validation loss decreased (0.556965 --> 0.555698).  Saving model ...
Validation loss decreased (0.555698 --> 0.554474).  Saving model ...
Validation loss decreased (0.554474 --> 0.553261).  Saving model ...
Validation loss decreased (0.553261 --> 0.552079).  Saving model ...
Validation loss decreased (0.552079 --> 0.550881).  Saving model ...
Validation loss decreased (0.550881 --> 0.549687).  Saving model ...
Validation loss decreased (0.549687 --> 0.548498).  Saving model ...
Validation loss decreased (0.548498 --> 0.547355).  Saving model ...
Validation loss decreased (0.547355 --> 0.546212).  Saving model ...
Validation loss decreased (0.546212 --> 0.545066).  Saving model ...
Validation loss decreased (0.545066 --> 0.543956).  Saving model ...
Validation loss decreased (0.543956 --> 0.542863).  Saving model ...
Validation loss decreased (0.542863 --> 0.541760).  Saving model ...
Validation loss decreased (0.541760 --> 0.540673).  Saving model ...
Validation loss decreased (0.540673 --> 0.539607).  Saving model ...
Validation loss decreased (0.539607 --> 0.538527).  Saving model ...
Validation loss decreased (0.538527 --> 0.537441).  Saving model ...
Validation loss decreased (0.537441 --> 0.536386).  Saving model ...
Validation loss decreased (0.536386 --> 0.535363).  Saving model ...
Validation loss decreased (0.535363 --> 0.534354).  Saving model ...
Validation loss decreased (0.534354 --> 0.533371).  Saving model ...
Validation loss decreased (0.533371 --> 0.532372).  Saving model ...
Validation loss decreased (0.532372 --> 0.531362).  Saving model ...
Validation loss decreased (0.531362 --> 0.530382).  Saving model ...
Validation loss decreased (0.530382 --> 0.529406).  Saving model ...
Validation loss decreased (0.529406 --> 0.528421).  Saving model ...
Validation loss decreased (0.528421 --> 0.527474).  Saving model ...
Validation loss decreased (0.527474 --> 0.526523).  Saving model ...
Validation loss decreased (0.526523 --> 0.525577).  Saving model ...
Validation loss decreased (0.525577 --> 0.524630).  Saving model ...
Validation loss decreased (0.524630 --> 0.523655).  Saving model ...
Validation loss decreased (0.523655 --> 0.522692).  Saving model ...
Validation loss decreased (0.522692 --> 0.521796).  Saving model ...
Validation loss decreased (0.521796 --> 0.520923).  Saving model ...
Validation loss decreased (0.520923 --> 0.520032).  Saving model ...
Validation loss decreased (0.520032 --> 0.519163).  Saving model ...
Validation loss decreased (0.519163 --> 0.518300).  Saving model ...
Validation loss decreased (0.518300 --> 0.517444).  Saving model ...
Validation loss decreased (0.517444 --> 0.516561).  Saving model ...
Validation loss decreased (0.516561 --> 0.515720).  Saving model ...
Validation loss decreased (0.515720 --> 0.514916).  Saving model ...
Validation loss decreased (0.514916 --> 0.514095).  Saving model ...
Validation loss decreased (0.514095 --> 0.513271).  Saving model ...
Validation loss decreased (0.513271 --> 0.512495).  Saving model ...
Validation loss decreased (0.512495 --> 0.511745).  Saving model ...
Validation loss decreased (0.511745 --> 0.511039).  Saving model ...
Validation loss decreased (0.511039 --> 0.510303).  Saving model ...
Validation loss decreased (0.510303 --> 0.509552).  Saving model ...
Validation loss decreased (0.509552 --> 0.508821).  Saving model ...
Validation loss decreased (0.508821 --> 0.508092).  Saving model ...
Validation loss decreased (0.508092 --> 0.507369).  Saving model ...
Validation loss decreased (0.507369 --> 0.506659).  Saving model ...
Validation loss decreased (0.506659 --> 0.505940).  Saving model ...
Validation loss decreased (0.505940 --> 0.505238).  Saving model ...
Validation loss decreased (0.505238 --> 0.504549).  Saving model ...
Validation loss decreased (0.504549 --> 0.503831).  Saving model ...
Validation loss decreased (0.503831 --> 0.503101).  Saving model ...
Validation loss decreased (0.503101 --> 0.502389).  Saving model ...
Validation loss decreased (0.502389 --> 0.501691).  Saving model ...
Validation loss decreased (0.501691 --> 0.500977).  Saving model ...
Validation loss decreased (0.500977 --> 0.500292).  Saving model ...
Validation loss decreased (0.500292 --> 0.499595).  Saving model ...
Validation loss decreased (0.499595 --> 0.498893).  Saving model ...
Validation loss decreased (0.498893 --> 0.498242).  Saving model ...
Validation loss decreased (0.498242 --> 0.497581).  Saving model ...
Validation loss decreased (0.497581 --> 0.496948).  Saving model ...
Validation loss decreased (0.496948 --> 0.496338).  Saving model ...
Validation loss decreased (0.496338 --> 0.495737).  Saving model ...
epoch 201, loss 0.4622, train acc 76.50%, f1 0.7751, precision 0.7788, recall 0.7714, auc 0.7647
Validation loss decreased (0.495737 --> 0.495135).  Saving model ...
Validation loss decreased (0.495135 --> 0.494548).  Saving model ...
Validation loss decreased (0.494548 --> 0.493989).  Saving model ...
Validation loss decreased (0.493989 --> 0.493465).  Saving model ...
Validation loss decreased (0.493465 --> 0.492934).  Saving model ...
Validation loss decreased (0.492934 --> 0.492415).  Saving model ...
Validation loss decreased (0.492415 --> 0.491888).  Saving model ...
Validation loss decreased (0.491888 --> 0.491414).  Saving model ...
Validation loss decreased (0.491414 --> 0.490889).  Saving model ...
Validation loss decreased (0.490889 --> 0.490395).  Saving model ...
Validation loss decreased (0.490395 --> 0.489911).  Saving model ...
Validation loss decreased (0.489911 --> 0.489428).  Saving model ...
Validation loss decreased (0.489428 --> 0.488958).  Saving model ...
Validation loss decreased (0.488958 --> 0.488502).  Saving model ...
Validation loss decreased (0.488502 --> 0.488037).  Saving model ...
Validation loss decreased (0.488037 --> 0.487571).  Saving model ...
Validation loss decreased (0.487571 --> 0.487067).  Saving model ...
Validation loss decreased (0.487067 --> 0.486525).  Saving model ...
Validation loss decreased (0.486525 --> 0.485965).  Saving model ...
Validation loss decreased (0.485965 --> 0.485422).  Saving model ...
Validation loss decreased (0.485422 --> 0.484887).  Saving model ...
Validation loss decreased (0.484887 --> 0.484356).  Saving model ...
Validation loss decreased (0.484356 --> 0.483807).  Saving model ...
Validation loss decreased (0.483807 --> 0.483263).  Saving model ...
Validation loss decreased (0.483263 --> 0.482716).  Saving model ...
Validation loss decreased (0.482716 --> 0.482208).  Saving model ...
Validation loss decreased (0.482208 --> 0.481683).  Saving model ...
Validation loss decreased (0.481683 --> 0.481174).  Saving model ...
Validation loss decreased (0.481174 --> 0.480612).  Saving model ...
Validation loss decreased (0.480612 --> 0.480084).  Saving model ...
Validation loss decreased (0.480084 --> 0.479552).  Saving model ...
Validation loss decreased (0.479552 --> 0.479075).  Saving model ...
Validation loss decreased (0.479075 --> 0.478614).  Saving model ...
Validation loss decreased (0.478614 --> 0.478143).  Saving model ...
Validation loss decreased (0.478143 --> 0.477695).  Saving model ...
Validation loss decreased (0.477695 --> 0.477257).  Saving model ...
Validation loss decreased (0.477257 --> 0.476815).  Saving model ...
Validation loss decreased (0.476815 --> 0.476425).  Saving model ...
Validation loss decreased (0.476425 --> 0.476026).  Saving model ...
Validation loss decreased (0.476026 --> 0.475622).  Saving model ...
Validation loss decreased (0.475622 --> 0.475179).  Saving model ...
Validation loss decreased (0.475179 --> 0.474766).  Saving model ...
Validation loss decreased (0.474766 --> 0.474360).  Saving model ...
Validation loss decreased (0.474360 --> 0.473943).  Saving model ...
Validation loss decreased (0.473943 --> 0.473551).  Saving model ...
Validation loss decreased (0.473551 --> 0.473190).  Saving model ...
Validation loss decreased (0.473190 --> 0.472796).  Saving model ...
Validation loss decreased (0.472796 --> 0.472402).  Saving model ...
Validation loss decreased (0.472402 --> 0.472026).  Saving model ...
Validation loss decreased (0.472026 --> 0.471626).  Saving model ...
Validation loss decreased (0.471626 --> 0.471268).  Saving model ...
Validation loss decreased (0.471268 --> 0.470940).  Saving model ...
Validation loss decreased (0.470940 --> 0.470625).  Saving model ...
Validation loss decreased (0.470625 --> 0.470340).  Saving model ...
Validation loss decreased (0.470340 --> 0.470047).  Saving model ...
Validation loss decreased (0.470047 --> 0.469784).  Saving model ...
Validation loss decreased (0.469784 --> 0.469556).  Saving model ...
Validation loss decreased (0.469556 --> 0.469336).  Saving model ...
Validation loss decreased (0.469336 --> 0.469122).  Saving model ...
Validation loss decreased (0.469122 --> 0.468936).  Saving model ...
Validation loss decreased (0.468936 --> 0.468699).  Saving model ...
Validation loss decreased (0.468699 --> 0.468435).  Saving model ...
Validation loss decreased (0.468435 --> 0.468182).  Saving model ...
Validation loss decreased (0.468182 --> 0.467887).  Saving model ...
Validation loss decreased (0.467887 --> 0.467540).  Saving model ...
Validation loss decreased (0.467540 --> 0.467224).  Saving model ...
Validation loss decreased (0.467224 --> 0.466920).  Saving model ...
Validation loss decreased (0.466920 --> 0.466635).  Saving model ...
Validation loss decreased (0.466635 --> 0.466365).  Saving model ...
Validation loss decreased (0.466365 --> 0.466029).  Saving model ...
Validation loss decreased (0.466029 --> 0.465713).  Saving model ...
Validation loss decreased (0.465713 --> 0.465400).  Saving model ...
Validation loss decreased (0.465400 --> 0.465119).  Saving model ...
Validation loss decreased (0.465119 --> 0.464843).  Saving model ...
Validation loss decreased (0.464843 --> 0.464536).  Saving model ...
Validation loss decreased (0.464536 --> 0.464235).  Saving model ...
Validation loss decreased (0.464235 --> 0.463909).  Saving model ...
Validation loss decreased (0.463909 --> 0.463565).  Saving model ...
Validation loss decreased (0.463565 --> 0.463288).  Saving model ...
Validation loss decreased (0.463288 --> 0.462996).  Saving model ...
Validation loss decreased (0.462996 --> 0.462717).  Saving model ...
Validation loss decreased (0.462717 --> 0.462426).  Saving model ...
Validation loss decreased (0.462426 --> 0.462125).  Saving model ...
Validation loss decreased (0.462125 --> 0.461819).  Saving model ...
Validation loss decreased (0.461819 --> 0.461528).  Saving model ...
Validation loss decreased (0.461528 --> 0.461317).  Saving model ...
Validation loss decreased (0.461317 --> 0.461112).  Saving model ...
Validation loss decreased (0.461112 --> 0.460831).  Saving model ...
Validation loss decreased (0.460831 --> 0.460527).  Saving model ...
Validation loss decreased (0.460527 --> 0.460203).  Saving model ...
Validation loss decreased (0.460203 --> 0.459873).  Saving model ...
Validation loss decreased (0.459873 --> 0.459535).  Saving model ...
Validation loss decreased (0.459535 --> 0.459187).  Saving model ...
Validation loss decreased (0.459187 --> 0.458853).  Saving model ...
Validation loss decreased (0.458853 --> 0.458496).  Saving model ...
Validation loss decreased (0.458496 --> 0.458151).  Saving model ...
Validation loss decreased (0.458151 --> 0.457791).  Saving model ...
Validation loss decreased (0.457791 --> 0.457438).  Saving model ...
Validation loss decreased (0.457438 --> 0.457103).  Saving model ...
Validation loss decreased (0.457103 --> 0.456807).  Saving model ...
epoch 301, loss 0.4849, train acc 79.00%, f1 0.8000, precision 0.8000, recall 0.8000, auc 0.7895
Validation loss decreased (0.456807 --> 0.456517).  Saving model ...
Validation loss decreased (0.456517 --> 0.456187).  Saving model ...
Validation loss decreased (0.456187 --> 0.455896).  Saving model ...
Validation loss decreased (0.455896 --> 0.455576).  Saving model ...
Validation loss decreased (0.455576 --> 0.455298).  Saving model ...
Validation loss decreased (0.455298 --> 0.455077).  Saving model ...
Validation loss decreased (0.455077 --> 0.454946).  Saving model ...
Validation loss decreased (0.454946 --> 0.454843).  Saving model ...
Validation loss decreased (0.454843 --> 0.454673).  Saving model ...
Validation loss decreased (0.454673 --> 0.454508).  Saving model ...
Validation loss decreased (0.454508 --> 0.454343).  Saving model ...
Validation loss decreased (0.454343 --> 0.454171).  Saving model ...
Validation loss decreased (0.454171 --> 0.454051).  Saving model ...
Validation loss decreased (0.454051 --> 0.453876).  Saving model ...
Validation loss decreased (0.453876 --> 0.453746).  Saving model ...
Validation loss decreased (0.453746 --> 0.453686).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.453686 --> 0.453648).  Saving model ...
Validation loss decreased (0.453648 --> 0.453621).  Saving model ...
Validation loss decreased (0.453621 --> 0.453606).  Saving model ...
Validation loss decreased (0.453606 --> 0.453547).  Saving model ...
Validation loss decreased (0.453547 --> 0.453501).  Saving model ...
Validation loss decreased (0.453501 --> 0.453435).  Saving model ...
Validation loss decreased (0.453435 --> 0.453324).  Saving model ...
Validation loss decreased (0.453324 --> 0.453156).  Saving model ...
Validation loss decreased (0.453156 --> 0.452993).  Saving model ...
Validation loss decreased (0.452993 --> 0.452839).  Saving model ...
Validation loss decreased (0.452839 --> 0.452685).  Saving model ...
Validation loss decreased (0.452685 --> 0.452481).  Saving model ...
Validation loss decreased (0.452481 --> 0.452289).  Saving model ...
Validation loss decreased (0.452289 --> 0.452116).  Saving model ...
Validation loss decreased (0.452116 --> 0.451924).  Saving model ...
Validation loss decreased (0.451924 --> 0.451702).  Saving model ...
Validation loss decreased (0.451702 --> 0.451517).  Saving model ...
Validation loss decreased (0.451517 --> 0.451361).  Saving model ...
Validation loss decreased (0.451361 --> 0.451159).  Saving model ...
Validation loss decreased (0.451159 --> 0.450978).  Saving model ...
Validation loss decreased (0.450978 --> 0.450851).  Saving model ...
Validation loss decreased (0.450851 --> 0.450786).  Saving model ...
Validation loss decreased (0.450786 --> 0.450770).  Saving model ...
Validation loss decreased (0.450770 --> 0.450726).  Saving model ...
Validation loss decreased (0.450726 --> 0.450706).  Saving model ...
Validation loss decreased (0.450706 --> 0.450653).  Saving model ...
Validation loss decreased (0.450653 --> 0.450544).  Saving model ...
Validation loss decreased (0.450544 --> 0.450414).  Saving model ...
Validation loss decreased (0.450414 --> 0.450307).  Saving model ...
Validation loss decreased (0.450307 --> 0.450191).  Saving model ...
Validation loss decreased (0.450191 --> 0.450138).  Saving model ...
Validation loss decreased (0.450138 --> 0.450089).  Saving model ...
Validation loss decreased (0.450089 --> 0.450055).  Saving model ...
Validation loss decreased (0.450055 --> 0.450005).  Saving model ...
Validation loss decreased (0.450005 --> 0.449914).  Saving model ...
Validation loss decreased (0.449914 --> 0.449812).  Saving model ...
Validation loss decreased (0.449812 --> 0.449639).  Saving model ...
Validation loss decreased (0.449639 --> 0.449477).  Saving model ...
Validation loss decreased (0.449477 --> 0.449293).  Saving model ...
Validation loss decreased (0.449293 --> 0.449107).  Saving model ...
Validation loss decreased (0.449107 --> 0.448961).  Saving model ...
Validation loss decreased (0.448961 --> 0.448782).  Saving model ...
Validation loss decreased (0.448782 --> 0.448608).  Saving model ...
Validation loss decreased (0.448608 --> 0.448445).  Saving model ...
Validation loss decreased (0.448445 --> 0.448262).  Saving model ...
Validation loss decreased (0.448262 --> 0.448065).  Saving model ...
Validation loss decreased (0.448065 --> 0.447885).  Saving model ...
Validation loss decreased (0.447885 --> 0.447803).  Saving model ...
Validation loss decreased (0.447803 --> 0.447703).  Saving model ...
Validation loss decreased (0.447703 --> 0.447676).  Saving model ...
Validation loss decreased (0.447676 --> 0.447625).  Saving model ...
Validation loss decreased (0.447625 --> 0.447569).  Saving model ...
Validation loss decreased (0.447569 --> 0.447432).  Saving model ...
Validation loss decreased (0.447432 --> 0.447283).  Saving model ...
Validation loss decreased (0.447283 --> 0.447146).  Saving model ...
Validation loss decreased (0.447146 --> 0.446930).  Saving model ...
Validation loss decreased (0.446930 --> 0.446731).  Saving model ...
Validation loss decreased (0.446731 --> 0.446537).  Saving model ...
Validation loss decreased (0.446537 --> 0.446409).  Saving model ...
Validation loss decreased (0.446409 --> 0.446261).  Saving model ...
Validation loss decreased (0.446261 --> 0.446173).  Saving model ...
Validation loss decreased (0.446173 --> 0.446059).  Saving model ...
Validation loss decreased (0.446059 --> 0.446031).  Saving model ...
Validation loss decreased (0.446031 --> 0.446021).  Saving model ...
Validation loss decreased (0.446021 --> 0.445954).  Saving model ...
Validation loss decreased (0.445954 --> 0.445914).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
Validation loss decreased (0.445914 --> 0.445879).  Saving model ...
epoch 401, loss 0.4027, train acc 80.00%, f1 0.8095, precision 0.8095, recall 0.8095, auc 0.7995
Validation loss decreased (0.445879 --> 0.445807).  Saving model ...
Validation loss decreased (0.445807 --> 0.445616).  Saving model ...
Validation loss decreased (0.445616 --> 0.445417).  Saving model ...
Validation loss decreased (0.445417 --> 0.445182).  Saving model ...
Validation loss decreased (0.445182 --> 0.445003).  Saving model ...
Validation loss decreased (0.445003 --> 0.444873).  Saving model ...
Validation loss decreased (0.444873 --> 0.444682).  Saving model ...
Validation loss decreased (0.444682 --> 0.444526).  Saving model ...
Validation loss decreased (0.444526 --> 0.444422).  Saving model ...
Validation loss decreased (0.444422 --> 0.444295).  Saving model ...
Validation loss decreased (0.444295 --> 0.444084).  Saving model ...
Validation loss decreased (0.444084 --> 0.443889).  Saving model ...
Validation loss decreased (0.443889 --> 0.443698).  Saving model ...
Validation loss decreased (0.443698 --> 0.443488).  Saving model ...
Validation loss decreased (0.443488 --> 0.443357).  Saving model ...
Validation loss decreased (0.443357 --> 0.443224).  Saving model ...
Validation loss decreased (0.443224 --> 0.443110).  Saving model ...
Validation loss decreased (0.443110 --> 0.443013).  Saving model ...
Validation loss decreased (0.443013 --> 0.442826).  Saving model ...
Validation loss decreased (0.442826 --> 0.442664).  Saving model ...
Validation loss decreased (0.442664 --> 0.442556).  Saving model ...
Validation loss decreased (0.442556 --> 0.442460).  Saving model ...
Validation loss decreased (0.442460 --> 0.442332).  Saving model ...
Validation loss decreased (0.442332 --> 0.442252).  Saving model ...
Validation loss decreased (0.442252 --> 0.442215).  Saving model ...
Validation loss decreased (0.442215 --> 0.442170).  Saving model ...
Validation loss decreased (0.442170 --> 0.442094).  Saving model ...
Validation loss decreased (0.442094 --> 0.442028).  Saving model ...
Validation loss decreased (0.442028 --> 0.441826).  Saving model ...
Validation loss decreased (0.441826 --> 0.441660).  Saving model ...
Validation loss decreased (0.441660 --> 0.441446).  Saving model ...
Validation loss decreased (0.441446 --> 0.441251).  Saving model ...
Validation loss decreased (0.441251 --> 0.441080).  Saving model ...
Validation loss decreased (0.441080 --> 0.440926).  Saving model ...
Validation loss decreased (0.440926 --> 0.440805).  Saving model ...
Validation loss decreased (0.440805 --> 0.440707).  Saving model ...
Validation loss decreased (0.440707 --> 0.440591).  Saving model ...
Validation loss decreased (0.440591 --> 0.440548).  Saving model ...
Validation loss decreased (0.440548 --> 0.440481).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.440481 --> 0.440471).  Saving model ...
Validation loss decreased (0.440471 --> 0.440448).  Saving model ...
Validation loss decreased (0.440448 --> 0.440433).  Saving model ...
Validation loss decreased (0.440433 --> 0.440428).  Saving model ...
Validation loss decreased (0.440428 --> 0.440328).  Saving model ...
Validation loss decreased (0.440328 --> 0.440177).  Saving model ...
Validation loss decreased (0.440177 --> 0.440000).  Saving model ...
Validation loss decreased (0.440000 --> 0.439781).  Saving model ...
Validation loss decreased (0.439781 --> 0.439599).  Saving model ...
Validation loss decreased (0.439599 --> 0.439412).  Saving model ...
Validation loss decreased (0.439412 --> 0.439190).  Saving model ...
Validation loss decreased (0.439190 --> 0.439003).  Saving model ...
Validation loss decreased (0.439003 --> 0.438914).  Saving model ...
Validation loss decreased (0.438914 --> 0.438859).  Saving model ...
Validation loss decreased (0.438859 --> 0.438759).  Saving model ...
Validation loss decreased (0.438759 --> 0.438598).  Saving model ...
Validation loss decreased (0.438598 --> 0.438398).  Saving model ...
Validation loss decreased (0.438398 --> 0.438249).  Saving model ...
Validation loss decreased (0.438249 --> 0.438163).  Saving model ...
Validation loss decreased (0.438163 --> 0.438057).  Saving model ...
Validation loss decreased (0.438057 --> 0.437958).  Saving model ...
Validation loss decreased (0.437958 --> 0.437824).  Saving model ...
Validation loss decreased (0.437824 --> 0.437746).  Saving model ...
Validation loss decreased (0.437746 --> 0.437722).  Saving model ...
Validation loss decreased (0.437722 --> 0.437636).  Saving model ...
Validation loss decreased (0.437636 --> 0.437534).  Saving model ...
Validation loss decreased (0.437534 --> 0.437505).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
Validation loss decreased (0.437505 --> 0.437442).  Saving model ...
EarlyStopping counter: 1 out of 20
Validation loss decreased (0.437442 --> 0.437430).  Saving model ...
Validation loss decreased (0.437430 --> 0.437423).  Saving model ...
Validation loss decreased (0.437423 --> 0.437319).  Saving model ...
Validation loss decreased (0.437319 --> 0.437184).  Saving model ...
Validation loss decreased (0.437184 --> 0.437064).  Saving model ...
Validation loss decreased (0.437064 --> 0.436929).  Saving model ...
Validation loss decreased (0.436929 --> 0.436794).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.436794 --> 0.436684).  Saving model ...
Validation loss decreased (0.436684 --> 0.436509).  Saving model ...
Validation loss decreased (0.436509 --> 0.436407).  Saving model ...
Validation loss decreased (0.436407 --> 0.436298).  Saving model ...
Validation loss decreased (0.436298 --> 0.436224).  Saving model ...
Validation loss decreased (0.436224 --> 0.436197).  Saving model ...
Validation loss decreased (0.436197 --> 0.436171).  Saving model ...
EarlyStopping counter: 1 out of 20
EarlyStopping counter: 2 out of 20
EarlyStopping counter: 3 out of 20
EarlyStopping counter: 4 out of 20
EarlyStopping counter: 5 out of 20
EarlyStopping counter: 6 out of 20
EarlyStopping counter: 7 out of 20
EarlyStopping counter: 8 out of 20
EarlyStopping counter: 9 out of 20
EarlyStopping counter: 10 out of 20
EarlyStopping counter: 11 out of 20
EarlyStopping counter: 12 out of 20
EarlyStopping counter: 13 out of 20
epoch 501, loss 0.3885, train acc 80.50%, f1 0.8152, precision 0.8113, recall 0.8190, auc 0.8043
EarlyStopping counter: 14 out of 20
EarlyStopping counter: 15 out of 20
EarlyStopping counter: 16 out of 20
EarlyStopping counter: 17 out of 20
EarlyStopping counter: 18 out of 20
EarlyStopping counter: 19 out of 20
EarlyStopping counter: 20 out of 20
Early stopping epoch 507, loss 0.5147, train acc 80.50%, f1 0.8152, precision 0.8113, recall 0.8190, auc 0.8043



/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_notMirror_True
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_True/record_1/MLP_minus_notMirror_True_3
./test_pima/result_MLP_minus_notMirror_True_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.575

the Fscore is 0.5595854922279793

the precision is 0.38848920863309355

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_3
----------------------



epoch 1, loss 0.6932, train acc 50.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
epoch 101, loss 0.6299, train acc 77.33%, f1 0.7710, precision 0.7778, recall 0.7644, auc 0.7733
epoch 201, loss 0.4830, train acc 79.82%, f1 0.7965, precision 0.8021, recall 0.7910, auc 0.7982
epoch 301, loss 0.3948, train acc 81.54%, f1 0.8153, precision 0.8144, recall 0.8161, auc 0.8154
epoch 401, loss 0.5509, train acc 82.32%, f1 0.8227, precision 0.8238, recall 0.8216, auc 0.8232
epoch 501, loss 0.4497, train acc 82.78%, f1 0.8276, precision 0.8274, recall 0.8279, auc 0.8278
epoch 601, loss 0.2726, train acc 82.96%, f1 0.8298, precision 0.8280, recall 0.8316, auc 0.8296
epoch 701, loss 0.3233, train acc 83.05%, f1 0.8301, precision 0.8308, recall 0.8295, auc 0.8305
epoch 801, loss 0.5021, train acc 83.12%, f1 0.8310, precision 0.8309, recall 0.8311, auc 0.8312
epoch 901, loss 0.4328, train acc 83.12%, f1 0.8313, precision 0.8296, recall 0.8330, auc 0.8312
epoch 1001, loss 0.4147, train acc 83.18%, f1 0.8316, precision 0.8316, recall 0.8316, auc 0.8318
epoch 1101, loss 0.3009, train acc 83.19%, f1 0.8323, precision 0.8290, recall 0.8356, auc 0.8319
epoch 1201, loss 0.3908, train acc 83.20%, f1 0.8325, precision 0.8288, recall 0.8363, auc 0.8320
epoch 1301, loss 0.5788, train acc 83.19%, f1 0.8323, precision 0.8293, recall 0.8353, auc 0.8319
epoch 1401, loss 0.2824, train acc 83.18%, f1 0.8318, precision 0.8303, recall 0.8334, auc 0.8318
epoch 1501, loss 0.3992, train acc 83.22%, f1 0.8315, precision 0.8336, recall 0.8295, auc 0.8322
epoch 1601, loss 0.2965, train acc 83.16%, f1 0.8320, precision 0.8290, recall 0.8350, auc 0.8316
epoch 1701, loss 0.4376, train acc 83.17%, f1 0.8319, precision 0.8298, recall 0.8340, auc 0.8317
epoch 1801, loss 0.2736, train acc 83.17%, f1 0.8318, precision 0.8304, recall 0.8332, auc 0.8317
epoch 1901, loss 0.3848, train acc 83.18%, f1 0.8323, precision 0.8284, recall 0.8362, auc 0.8318
epoch 2001, loss 0.4421, train acc 83.16%, f1 0.8320, precision 0.8290, recall 0.8351, auc 0.8317
epoch 2101, loss 0.3299, train acc 83.20%, f1 0.8319, precision 0.8311, recall 0.8326, auc 0.8320
epoch 2201, loss 0.3235, train acc 83.18%, f1 0.8320, precision 0.8300, recall 0.8339, auc 0.8318
epoch 2301, loss 0.3634, train acc 83.12%, f1 0.8312, precision 0.8298, recall 0.8327, auc 0.8312
epoch 2401, loss 0.4730, train acc 83.08%, f1 0.8310, precision 0.8291, recall 0.8329, auc 0.8308
epoch 2501, loss 0.4207, train acc 83.16%, f1 0.8315, precision 0.8311, recall 0.8318, auc 0.8316
epoch 2601, loss 0.4848, train acc 83.13%, f1 0.8317, precision 0.8285, recall 0.8350, auc 0.8313
epoch 2701, loss 0.4049, train acc 83.15%, f1 0.8314, precision 0.8307, recall 0.8321, auc 0.8315
epoch 2801, loss 0.3228, train acc 83.14%, f1 0.8311, precision 0.8315, recall 0.8308, auc 0.8314
epoch 2901, loss 0.3921, train acc 83.14%, f1 0.8315, precision 0.8299, recall 0.8330, auc 0.8314
epoch 3001, loss 0.5093, train acc 83.23%, f1 0.8328, precision 0.8294, recall 0.8362, auc 0.8323
epoch 3101, loss 0.2499, train acc 83.16%, f1 0.8320, precision 0.8288, recall 0.8352, auc 0.8316
epoch 3201, loss 0.3379, train acc 83.13%, f1 0.8317, precision 0.8287, recall 0.8347, auc 0.8313
epoch 3301, loss 0.3708, train acc 83.16%, f1 0.8317, precision 0.8298, recall 0.8335, auc 0.8316
epoch 3401, loss 0.5069, train acc 83.14%, f1 0.8312, precision 0.8307, recall 0.8317, auc 0.8314
epoch 3501, loss 0.3475, train acc 83.16%, f1 0.8313, precision 0.8315, recall 0.8312, auc 0.8316
epoch 3601, loss 0.4633, train acc 83.10%, f1 0.8309, precision 0.8303, recall 0.8315, auc 0.8310
epoch 3701, loss 0.2673, train acc 83.15%, f1 0.8315, precision 0.8301, recall 0.8329, auc 0.8315
epoch 3801, loss 0.2975, train acc 83.20%, f1 0.8317, precision 0.8320, recall 0.8313, auc 0.8320
epoch 3901, loss 0.3163, train acc 83.11%, f1 0.8313, precision 0.8288, recall 0.8339, auc 0.8311
epoch 4001, loss 0.3335, train acc 83.14%, f1 0.8310, precision 0.8316, recall 0.8304, auc 0.8314
epoch 4101, loss 0.2860, train acc 83.16%, f1 0.8316, precision 0.8303, recall 0.8328, auc 0.8316
epoch 4201, loss 0.2606, train acc 83.17%, f1 0.8315, precision 0.8314, recall 0.8316, auc 0.8317
epoch 4301, loss 0.3960, train acc 83.23%, f1 0.8324, precision 0.8309, recall 0.8338, auc 0.8323
epoch 4401, loss 0.4307, train acc 83.19%, f1 0.8322, precision 0.8296, recall 0.8349, auc 0.8319
epoch 4501, loss 0.2322, train acc 83.29%, f1 0.8330, precision 0.8311, recall 0.8349, auc 0.8329
epoch 4601, loss 0.3930, train acc 83.25%, f1 0.8322, precision 0.8323, recall 0.8321, auc 0.8325
epoch 4701, loss 0.3289, train acc 83.30%, f1 0.8328, precision 0.8326, recall 0.8330, auc 0.8330
epoch 4801, loss 0.2909, train acc 83.34%, f1 0.8332, precision 0.8328, recall 0.8337, auc 0.8334
epoch 4901, loss 0.3186, train acc 83.36%, f1 0.8330, precision 0.8345, recall 0.8316, auc 0.8336
epoch 5001, loss 0.3078, train acc 83.36%, f1 0.8333, precision 0.8337, recall 0.8329, auc 0.8336
epoch 5101, loss 0.3860, train acc 83.31%, f1 0.8336, precision 0.8297, recall 0.8376, auc 0.8331
epoch 5201, loss 0.5404, train acc 83.36%, f1 0.8336, precision 0.8322, recall 0.8350, auc 0.8336
epoch 5301, loss 0.3222, train acc 83.38%, f1 0.8341, precision 0.8316, recall 0.8366, auc 0.8338
epoch 5401, loss 0.3946, train acc 83.40%, f1 0.8342, precision 0.8318, recall 0.8367, auc 0.8340
epoch 5501, loss 0.2633, train acc 83.40%, f1 0.8335, precision 0.8346, recall 0.8324, auc 0.8340
epoch 5601, loss 0.4160, train acc 83.41%, f1 0.8342, precision 0.8327, recall 0.8356, auc 0.8341
epoch 5701, loss 0.1999, train acc 83.51%, f1 0.8348, precision 0.8352, recall 0.8345, auc 0.8351
epoch 5801, loss 0.3400, train acc 83.50%, f1 0.8350, precision 0.8341, recall 0.8358, auc 0.8350
epoch 5901, loss 0.6069, train acc 83.55%, f1 0.8355, precision 0.8347, recall 0.8362, auc 0.8355
epoch 6001, loss 0.2167, train acc 83.58%, f1 0.8364, precision 0.8320, recall 0.8409, auc 0.8358
epoch 6101, loss 0.3468, train acc 83.60%, f1 0.8366, precision 0.8324, recall 0.8409, auc 0.8360
epoch 6201, loss 0.5829, train acc 83.64%, f1 0.8357, precision 0.8377, recall 0.8338, auc 0.8364
epoch 6301, loss 0.3539, train acc 83.62%, f1 0.8364, precision 0.8343, recall 0.8385, auc 0.8362
epoch 6401, loss 0.2524, train acc 83.73%, f1 0.8369, precision 0.8378, recall 0.8361, auc 0.8373
epoch 6501, loss 0.2994, train acc 83.68%, f1 0.8373, precision 0.8335, recall 0.8411, auc 0.8368
epoch 6601, loss 0.3555, train acc 83.72%, f1 0.8377, precision 0.8340, recall 0.8414, auc 0.8372
epoch 6701, loss 0.3896, train acc 83.76%, f1 0.8375, precision 0.8368, recall 0.8383, auc 0.8376
epoch 6801, loss 0.2594, train acc 83.77%, f1 0.8379, precision 0.8358, recall 0.8399, auc 0.8377
epoch 6901, loss 0.4824, train acc 83.81%, f1 0.8382, precision 0.8365, recall 0.8400, auc 0.8381
epoch 7001, loss 0.3576, train acc 83.79%, f1 0.8386, precision 0.8339, recall 0.8434, auc 0.8379
epoch 7101, loss 0.4094, train acc 83.82%, f1 0.8378, precision 0.8389, recall 0.8366, auc 0.8382
epoch 7201, loss 0.3879, train acc 83.92%, f1 0.8394, precision 0.8370, recall 0.8419, auc 0.8392
epoch 7301, loss 0.4424, train acc 83.91%, f1 0.8390, precision 0.8383, recall 0.8397, auc 0.8391
epoch 7401, loss 0.2698, train acc 84.00%, f1 0.8402, precision 0.8378, recall 0.8427, auc 0.8400
epoch 7501, loss 0.4078, train acc 84.04%, f1 0.8402, precision 0.8397, recall 0.8408, auc 0.8404
epoch 7601, loss 0.5669, train acc 84.03%, f1 0.8405, precision 0.8380, recall 0.8431, auc 0.8403
epoch 7701, loss 0.3533, train acc 84.04%, f1 0.8405, precision 0.8385, recall 0.8426, auc 0.8404
epoch 7801, loss 0.3899, train acc 84.06%, f1 0.8411, precision 0.8374, recall 0.8448, auc 0.8406
epoch 7901, loss 0.2568, train acc 84.13%, f1 0.8414, precision 0.8397, recall 0.8432, auc 0.8413
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_notMirror_8000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_8000/record_1/MLP_minus_notMirror_8000_3
./test_pima/result_MLP_minus_notMirror_8000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.6207407407407408

the Fscore is 0.585635359116022

the precision is 0.41732283464566927

the recall is 0.9814814814814815

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_3
----------------------



epoch 1, loss 0.6929, train acc 50.15%, f1 0.6680, precision 0.5015, recall 1.0000, auc 0.5000
epoch 101, loss 0.5950, train acc 76.32%, f1 0.7852, precision 0.7202, recall 0.8630, auc 0.7629
epoch 201, loss 0.5220, train acc 79.85%, f1 0.8011, precision 0.7934, recall 0.8090, auc 0.7985
epoch 301, loss 0.4324, train acc 81.51%, f1 0.8155, precision 0.8160, recall 0.8151, auc 0.8151
epoch 401, loss 0.3643, train acc 82.43%, f1 0.8244, precision 0.8264, recall 0.8225, auc 0.8243
epoch 501, loss 0.4381, train acc 82.78%, f1 0.8269, precision 0.8341, recall 0.8198, auc 0.8279
epoch 601, loss 0.3423, train acc 82.98%, f1 0.8294, precision 0.8340, recall 0.8248, auc 0.8298
epoch 701, loss 0.4300, train acc 83.09%, f1 0.8304, precision 0.8351, recall 0.8259, auc 0.8309
epoch 801, loss 0.3230, train acc 83.11%, f1 0.8304, precision 0.8362, recall 0.8248, auc 0.8311
epoch 901, loss 0.4497, train acc 83.12%, f1 0.8307, precision 0.8355, recall 0.8260, auc 0.8312
epoch 1001, loss 0.5652, train acc 83.08%, f1 0.8301, precision 0.8359, recall 0.8244, auc 0.8308
epoch 1101, loss 0.4020, train acc 83.09%, f1 0.8299, precision 0.8373, recall 0.8226, auc 0.8309
epoch 1201, loss 0.4287, train acc 83.14%, f1 0.8312, precision 0.8350, recall 0.8275, auc 0.8315
epoch 1301, loss 0.4043, train acc 83.14%, f1 0.8309, precision 0.8360, recall 0.8259, auc 0.8314
epoch 1401, loss 0.3737, train acc 83.20%, f1 0.8317, precision 0.8357, recall 0.8278, auc 0.8320
epoch 1501, loss 0.5048, train acc 83.16%, f1 0.8309, precision 0.8373, recall 0.8245, auc 0.8317
epoch 1601, loss 0.3507, train acc 83.20%, f1 0.8320, precision 0.8347, recall 0.8292, auc 0.8320
epoch 1701, loss 0.4547, train acc 83.18%, f1 0.8314, precision 0.8357, recall 0.8272, auc 0.8318
epoch 1801, loss 0.4673, train acc 83.19%, f1 0.8317, precision 0.8349, recall 0.8286, auc 0.8319
epoch 1901, loss 0.3923, train acc 83.16%, f1 0.8311, precision 0.8359, recall 0.8264, auc 0.8316
epoch 2001, loss 0.3287, train acc 83.10%, f1 0.8307, precision 0.8345, recall 0.8270, auc 0.8310
epoch 2101, loss 0.5608, train acc 83.15%, f1 0.8312, precision 0.8351, recall 0.8273, auc 0.8315
epoch 2201, loss 0.3044, train acc 83.14%, f1 0.8315, precision 0.8334, recall 0.8296, auc 0.8314
epoch 2301, loss 0.5131, train acc 83.14%, f1 0.8316, precision 0.8333, recall 0.8299, auc 0.8314
epoch 2401, loss 0.3844, train acc 83.15%, f1 0.8314, precision 0.8345, recall 0.8284, auc 0.8315
epoch 2501, loss 0.4049, train acc 83.09%, f1 0.8304, precision 0.8355, recall 0.8254, auc 0.8309
epoch 2601, loss 0.4433, train acc 83.12%, f1 0.8311, precision 0.8342, recall 0.8279, auc 0.8312
epoch 2701, loss 0.3913, train acc 83.15%, f1 0.8310, precision 0.8363, recall 0.8257, auc 0.8315
epoch 2801, loss 0.4255, train acc 83.10%, f1 0.8309, precision 0.8337, recall 0.8282, auc 0.8310
epoch 2901, loss 0.3993, train acc 83.12%, f1 0.8314, precision 0.8332, recall 0.8296, auc 0.8313
epoch 3001, loss 0.4052, train acc 83.07%, f1 0.8309, precision 0.8328, recall 0.8290, auc 0.8307
epoch 3101, loss 0.2516, train acc 83.14%, f1 0.8316, precision 0.8329, recall 0.8304, auc 0.8314
epoch 3201, loss 0.3881, train acc 83.11%, f1 0.8314, precision 0.8326, recall 0.8301, auc 0.8311
epoch 3301, loss 0.4111, train acc 83.14%, f1 0.8314, precision 0.8344, recall 0.8284, auc 0.8315
epoch 3401, loss 0.4229, train acc 83.19%, f1 0.8315, precision 0.8362, recall 0.8268, auc 0.8319
epoch 3501, loss 0.4614, train acc 83.18%, f1 0.8322, precision 0.8327, recall 0.8316, auc 0.8318
epoch 3601, loss 0.4490, train acc 83.18%, f1 0.8314, precision 0.8363, recall 0.8264, auc 0.8319
epoch 3701, loss 0.4076, train acc 83.09%, f1 0.8312, precision 0.8322, recall 0.8302, auc 0.8309
epoch 3801, loss 0.4224, train acc 83.16%, f1 0.8312, precision 0.8356, recall 0.8269, auc 0.8316
epoch 3901, loss 0.4291, train acc 83.13%, f1 0.8313, precision 0.8339, recall 0.8287, auc 0.8313
epoch 4001, loss 0.2295, train acc 83.21%, f1 0.8321, precision 0.8346, recall 0.8297, auc 0.8321
epoch 4101, loss 0.4014, train acc 83.19%, f1 0.8318, precision 0.8348, recall 0.8289, auc 0.8319
epoch 4201, loss 0.4049, train acc 83.19%, f1 0.8321, precision 0.8337, recall 0.8305, auc 0.8319
epoch 4301, loss 0.4719, train acc 83.18%, f1 0.8317, precision 0.8344, recall 0.8291, auc 0.8318
epoch 4401, loss 0.3095, train acc 83.20%, f1 0.8319, precision 0.8348, recall 0.8289, auc 0.8320
epoch 4501, loss 0.3468, train acc 83.25%, f1 0.8328, precision 0.8337, recall 0.8320, auc 0.8325
epoch 4601, loss 0.3050, train acc 83.23%, f1 0.8329, precision 0.8326, recall 0.8332, auc 0.8323
epoch 4701, loss 0.3297, train acc 83.22%, f1 0.8328, precision 0.8321, recall 0.8335, auc 0.8322
epoch 4801, loss 0.5562, train acc 83.19%, f1 0.8322, precision 0.8333, recall 0.8311, auc 0.8319
epoch 4901, loss 0.3402, train acc 83.20%, f1 0.8328, precision 0.8315, recall 0.8340, auc 0.8320
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_notMirror_5000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_5000/record_1/MLP_minus_notMirror_5000_3
./test_pima/result_MLP_minus_notMirror_5000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.585

the Fscore is 0.5654450261780105

the precision is 0.39416058394160586

the recall is 1.0

Done
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_3
----------------------



epoch 1, loss 0.6931, train acc 49.80%, f1 0.6649, precision 0.4980, recall 1.0000, auc 0.5000
epoch 101, loss 0.6081, train acc 76.65%, f1 0.7745, precision 0.7460, recall 0.8054, auc 0.7666
epoch 201, loss 0.4470, train acc 79.53%, f1 0.7965, precision 0.7888, recall 0.8044, auc 0.7953
epoch 301, loss 0.3489, train acc 81.18%, f1 0.8107, precision 0.8124, recall 0.8090, auc 0.8118
epoch 401, loss 0.3388, train acc 82.22%, f1 0.8215, precision 0.8218, recall 0.8211, auc 0.8222
epoch 501, loss 0.3652, train acc 82.77%, f1 0.8267, precision 0.8284, recall 0.8249, auc 0.8277
epoch 601, loss 0.4097, train acc 82.98%, f1 0.8282, precision 0.8325, recall 0.8240, auc 0.8298
epoch 701, loss 0.3232, train acc 83.07%, f1 0.8297, precision 0.8313, recall 0.8280, auc 0.8307
epoch 801, loss 0.3967, train acc 83.07%, f1 0.8301, precision 0.8297, recall 0.8305, auc 0.8307
epoch 901, loss 0.2874, train acc 83.09%, f1 0.8299, precision 0.8314, recall 0.8285, auc 0.8309
epoch 1001, loss 0.4165, train acc 83.16%, f1 0.8310, precision 0.8308, recall 0.8311, auc 0.8316
epoch 1101, loss 0.2708, train acc 83.18%, f1 0.8310, precision 0.8317, recall 0.8303, auc 0.8318
epoch 1201, loss 0.4924, train acc 83.15%, f1 0.8312, precision 0.8296, recall 0.8328, auc 0.8315
epoch 1301, loss 0.3640, train acc 83.14%, f1 0.8302, precision 0.8330, recall 0.8274, auc 0.8314
epoch 1401, loss 0.3782, train acc 83.18%, f1 0.8313, precision 0.8306, recall 0.8320, auc 0.8318
epoch 1501, loss 0.4444, train acc 83.17%, f1 0.8313, precision 0.8301, recall 0.8325, auc 0.8317
epoch 1601, loss 0.3485, train acc 83.18%, f1 0.8308, precision 0.8325, recall 0.8292, auc 0.8318
epoch 1701, loss 0.3916, train acc 83.15%, f1 0.8309, precision 0.8308, recall 0.8309, auc 0.8315
epoch 1801, loss 0.4159, train acc 83.10%, f1 0.8303, precision 0.8306, recall 0.8300, auc 0.8310
epoch 1901, loss 0.2965, train acc 83.16%, f1 0.8310, precision 0.8304, recall 0.8317, auc 0.8316
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_minus_notMirror_2000
minus_pos_num_40_1
./test_pima/model_MLP_minus_notMirror_2000/record_1/MLP_minus_notMirror_2000_3
./test_pima/result_MLP_minus_notMirror_2000_minus_pos_num_40_1/record_1/
----------------------



the AUC is 0.5900000000000001

the Fscore is 0.5684210526315789

the precision is 0.39705882352941174

the recall is 1.0

Done
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_3
----------------------



epoch 1, loss 0.6903, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (inf --> 0.689013).  Saving model ...
Validation loss decreased (0.689013 --> 0.687697).  Saving model ...
Validation loss decreased (0.687697 --> 0.686399).  Saving model ...
Validation loss decreased (0.686399 --> 0.685120).  Saving model ...
Validation loss decreased (0.685120 --> 0.683860).  Saving model ...
Validation loss decreased (0.683860 --> 0.682618).  Saving model ...
Validation loss decreased (0.682618 --> 0.681395).  Saving model ...
Validation loss decreased (0.681395 --> 0.680190).  Saving model ...
Validation loss decreased (0.680190 --> 0.679003).  Saving model ...
Validation loss decreased (0.679003 --> 0.677834).  Saving model ...
Validation loss decreased (0.677834 --> 0.676683).  Saving model ...
Validation loss decreased (0.676683 --> 0.675548).  Saving model ...
Validation loss decreased (0.675548 --> 0.674431).  Saving model ...
Validation loss decreased (0.674431 --> 0.673331).  Saving model ...
Validation loss decreased (0.673331 --> 0.672247).  Saving model ...
Validation loss decreased (0.672247 --> 0.671180).  Saving model ...
Validation loss decreased (0.671180 --> 0.670129).  Saving model ...
Validation loss decreased (0.670129 --> 0.669094).  Saving model ...
Validation loss decreased (0.669094 --> 0.668076).  Saving model ...
Validation loss decreased (0.668076 --> 0.667073).  Saving model ...
Validation loss decreased (0.667073 --> 0.666087).  Saving model ...
Validation loss decreased (0.666087 --> 0.665116).  Saving model ...
Validation loss decreased (0.665116 --> 0.664160).  Saving model ...
Validation loss decreased (0.664160 --> 0.663221).  Saving model ...
Validation loss decreased (0.663221 --> 0.662296).  Saving model ...
Validation loss decreased (0.662296 --> 0.661386).  Saving model ...
Validation loss decreased (0.661386 --> 0.660492).  Saving model ...
Validation loss decreased (0.660492 --> 0.659612).  Saving model ...
Validation loss decreased (0.659612 --> 0.658746).  Saving model ...
Validation loss decreased (0.658746 --> 0.657895).  Saving model ...
Validation loss decreased (0.657895 --> 0.657058).  Saving model ...
Validation loss decreased (0.657058 --> 0.656236).  Saving model ...
Validation loss decreased (0.656236 --> 0.655426).  Saving model ...
Validation loss decreased (0.655426 --> 0.654631).  Saving model ...
Validation loss decreased (0.654631 --> 0.653849).  Saving model ...
Validation loss decreased (0.653849 --> 0.653079).  Saving model ...
Validation loss decreased (0.653079 --> 0.652323).  Saving model ...
Validation loss decreased (0.652323 --> 0.651580).  Saving model ...
Validation loss decreased (0.651580 --> 0.650849).  Saving model ...
Validation loss decreased (0.650849 --> 0.650131).  Saving model ...
Validation loss decreased (0.650131 --> 0.649424).  Saving model ...
Validation loss decreased (0.649424 --> 0.648730).  Saving model ...
Validation loss decreased (0.648730 --> 0.648048).  Saving model ...
Validation loss decreased (0.648048 --> 0.647377).  Saving model ...
Validation loss decreased (0.647377 --> 0.646717).  Saving model ...
Validation loss decreased (0.646717 --> 0.646069).  Saving model ...
Validation loss decreased (0.646069 --> 0.645431).  Saving model ...
Validation loss decreased (0.645431 --> 0.644805).  Saving model ...
Validation loss decreased (0.644805 --> 0.644188).  Saving model ...
Validation loss decreased (0.644188 --> 0.643583).  Saving model ...
Validation loss decreased (0.643583 --> 0.642987).  Saving model ...
Validation loss decreased (0.642987 --> 0.642402).  Saving model ...
Validation loss decreased (0.642402 --> 0.641826).  Saving model ...
Validation loss decreased (0.641826 --> 0.641260).  Saving model ...
Validation loss decreased (0.641260 --> 0.640703).  Saving model ...
Validation loss decreased (0.640703 --> 0.640155).  Saving model ...
Validation loss decreased (0.640155 --> 0.639617).  Saving model ...
Validation loss decreased (0.639617 --> 0.639087).  Saving model ...
Validation loss decreased (0.639087 --> 0.638566).  Saving model ...
Validation loss decreased (0.638566 --> 0.638053).  Saving model ...
Validation loss decreased (0.638053 --> 0.637548).  Saving model ...
Validation loss decreased (0.637548 --> 0.637052).  Saving model ...
Validation loss decreased (0.637052 --> 0.636563).  Saving model ...
Validation loss decreased (0.636563 --> 0.636082).  Saving model ...
Validation loss decreased (0.636082 --> 0.635608).  Saving model ...
Validation loss decreased (0.635608 --> 0.635142).  Saving model ...
Validation loss decreased (0.635142 --> 0.634682).  Saving model ...
Validation loss decreased (0.634682 --> 0.634230).  Saving model ...
Validation loss decreased (0.634230 --> 0.633784).  Saving model ...
Validation loss decreased (0.633784 --> 0.633345).  Saving model ...
Validation loss decreased (0.633345 --> 0.632913).  Saving model ...
Validation loss decreased (0.632913 --> 0.632486).  Saving model ...
Validation loss decreased (0.632486 --> 0.632065).  Saving model ...
Validation loss decreased (0.632065 --> 0.631651).  Saving model ...
Validation loss decreased (0.631651 --> 0.631242).  Saving model ...
Validation loss decreased (0.631242 --> 0.630838).  Saving model ...
Validation loss decreased (0.630838 --> 0.630440).  Saving model ...
Validation loss decreased (0.630440 --> 0.630047).  Saving model ...
Validation loss decreased (0.630047 --> 0.629659).  Saving model ...
Validation loss decreased (0.629659 --> 0.629276).  Saving model ...
Validation loss decreased (0.629276 --> 0.628898).  Saving model ...
Validation loss decreased (0.628898 --> 0.628524).  Saving model ...
Validation loss decreased (0.628524 --> 0.628155).  Saving model ...
Validation loss decreased (0.628155 --> 0.627790).  Saving model ...
Validation loss decreased (0.627790 --> 0.627429).  Saving model ...
Validation loss decreased (0.627429 --> 0.627072).  Saving model ...
Validation loss decreased (0.627072 --> 0.626719).  Saving model ...
Validation loss decreased (0.626719 --> 0.626370).  Saving model ...
Validation loss decreased (0.626370 --> 0.626024).  Saving model ...
Validation loss decreased (0.626024 --> 0.625682).  Saving model ...
Validation loss decreased (0.625682 --> 0.625344).  Saving model ...
Validation loss decreased (0.625344 --> 0.625008).  Saving model ...
Validation loss decreased (0.625008 --> 0.624676).  Saving model ...
Validation loss decreased (0.624676 --> 0.624346).  Saving model ...
Validation loss decreased (0.624346 --> 0.624020).  Saving model ...
Validation loss decreased (0.624020 --> 0.623696).  Saving model ...
Validation loss decreased (0.623696 --> 0.623375).  Saving model ...
Validation loss decreased (0.623375 --> 0.623057).  Saving model ...
Validation loss decreased (0.623057 --> 0.622741).  Saving model ...
Validation loss decreased (0.622741 --> 0.622427).  Saving model ...
epoch 101, loss 0.6224, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.622427 --> 0.622116).  Saving model ...
Validation loss decreased (0.622116 --> 0.621807).  Saving model ...
Validation loss decreased (0.621807 --> 0.621500).  Saving model ...
Validation loss decreased (0.621500 --> 0.621195).  Saving model ...
Validation loss decreased (0.621195 --> 0.620893).  Saving model ...
Validation loss decreased (0.620893 --> 0.620592).  Saving model ...
Validation loss decreased (0.620592 --> 0.620293).  Saving model ...
Validation loss decreased (0.620293 --> 0.619995).  Saving model ...
Validation loss decreased (0.619995 --> 0.619700).  Saving model ...
Validation loss decreased (0.619700 --> 0.619406).  Saving model ...
Validation loss decreased (0.619406 --> 0.619113).  Saving model ...
Validation loss decreased (0.619113 --> 0.618822).  Saving model ...
Validation loss decreased (0.618822 --> 0.618533).  Saving model ...
Validation loss decreased (0.618533 --> 0.618244).  Saving model ...
Validation loss decreased (0.618244 --> 0.617958).  Saving model ...
Validation loss decreased (0.617958 --> 0.617672).  Saving model ...
Validation loss decreased (0.617672 --> 0.617388).  Saving model ...
Validation loss decreased (0.617388 --> 0.617105).  Saving model ...
Validation loss decreased (0.617105 --> 0.616823).  Saving model ...
Validation loss decreased (0.616823 --> 0.616542).  Saving model ...
Validation loss decreased (0.616542 --> 0.616262).  Saving model ...
Validation loss decreased (0.616262 --> 0.615983).  Saving model ...
Validation loss decreased (0.615983 --> 0.615705).  Saving model ...
Validation loss decreased (0.615705 --> 0.615428).  Saving model ...
Validation loss decreased (0.615428 --> 0.615152).  Saving model ...
Validation loss decreased (0.615152 --> 0.614877).  Saving model ...
Validation loss decreased (0.614877 --> 0.614603).  Saving model ...
Validation loss decreased (0.614603 --> 0.614329).  Saving model ...
Validation loss decreased (0.614329 --> 0.614057).  Saving model ...
Validation loss decreased (0.614057 --> 0.613785).  Saving model ...
Validation loss decreased (0.613785 --> 0.613513).  Saving model ...
Validation loss decreased (0.613513 --> 0.613243).  Saving model ...
Validation loss decreased (0.613243 --> 0.612973).  Saving model ...
Validation loss decreased (0.612973 --> 0.612704).  Saving model ...
Validation loss decreased (0.612704 --> 0.612435).  Saving model ...
Validation loss decreased (0.612435 --> 0.612167).  Saving model ...
Validation loss decreased (0.612167 --> 0.611900).  Saving model ...
Validation loss decreased (0.611900 --> 0.611633).  Saving model ...
Validation loss decreased (0.611633 --> 0.611366).  Saving model ...
Validation loss decreased (0.611366 --> 0.611100).  Saving model ...
Validation loss decreased (0.611100 --> 0.610835).  Saving model ...
Validation loss decreased (0.610835 --> 0.610570).  Saving model ...
Validation loss decreased (0.610570 --> 0.610306).  Saving model ...
Validation loss decreased (0.610306 --> 0.610042).  Saving model ...
Validation loss decreased (0.610042 --> 0.609778).  Saving model ...
Validation loss decreased (0.609778 --> 0.609515).  Saving model ...
Validation loss decreased (0.609515 --> 0.609252).  Saving model ...
Validation loss decreased (0.609252 --> 0.608989).  Saving model ...
Validation loss decreased (0.608989 --> 0.608727).  Saving model ...
Validation loss decreased (0.608727 --> 0.608465).  Saving model ...
Validation loss decreased (0.608465 --> 0.608204).  Saving model ...
Validation loss decreased (0.608204 --> 0.607943).  Saving model ...
Validation loss decreased (0.607943 --> 0.607682).  Saving model ...
Validation loss decreased (0.607682 --> 0.607421).  Saving model ...
Validation loss decreased (0.607421 --> 0.607160).  Saving model ...
Validation loss decreased (0.607160 --> 0.606900).  Saving model ...
Validation loss decreased (0.606900 --> 0.606640).  Saving model ...
Validation loss decreased (0.606640 --> 0.606380).  Saving model ...
Validation loss decreased (0.606380 --> 0.606121).  Saving model ...
Validation loss decreased (0.606121 --> 0.605861).  Saving model ...
Validation loss decreased (0.605861 --> 0.605602).  Saving model ...
Validation loss decreased (0.605602 --> 0.605343).  Saving model ...
Validation loss decreased (0.605343 --> 0.605084).  Saving model ...
Validation loss decreased (0.605084 --> 0.604825).  Saving model ...
Validation loss decreased (0.604825 --> 0.604566).  Saving model ...
Validation loss decreased (0.604566 --> 0.604308).  Saving model ...
Validation loss decreased (0.604308 --> 0.604049).  Saving model ...
Validation loss decreased (0.604049 --> 0.603791).  Saving model ...
Validation loss decreased (0.603791 --> 0.603532).  Saving model ...
Validation loss decreased (0.603532 --> 0.603274).  Saving model ...
Validation loss decreased (0.603274 --> 0.603016).  Saving model ...
Validation loss decreased (0.603016 --> 0.602758).  Saving model ...
Validation loss decreased (0.602758 --> 0.602499).  Saving model ...
Validation loss decreased (0.602499 --> 0.602241).  Saving model ...
Validation loss decreased (0.602241 --> 0.601983).  Saving model ...
Validation loss decreased (0.601983 --> 0.601725).  Saving model ...
Validation loss decreased (0.601725 --> 0.601467).  Saving model ...
Validation loss decreased (0.601467 --> 0.601208).  Saving model ...
Validation loss decreased (0.601208 --> 0.600950).  Saving model ...
Validation loss decreased (0.600950 --> 0.600692).  Saving model ...
Validation loss decreased (0.600692 --> 0.600434).  Saving model ...
Validation loss decreased (0.600434 --> 0.600175).  Saving model ...
Validation loss decreased (0.600175 --> 0.599917).  Saving model ...
Validation loss decreased (0.599917 --> 0.599658).  Saving model ...
Validation loss decreased (0.599658 --> 0.599400).  Saving model ...
Validation loss decreased (0.599400 --> 0.599141).  Saving model ...
Validation loss decreased (0.599141 --> 0.598882).  Saving model ...
Validation loss decreased (0.598882 --> 0.598624).  Saving model ...
Validation loss decreased (0.598624 --> 0.598365).  Saving model ...
Validation loss decreased (0.598365 --> 0.598106).  Saving model ...
Validation loss decreased (0.598106 --> 0.597847).  Saving model ...
Validation loss decreased (0.597847 --> 0.597588).  Saving model ...
Validation loss decreased (0.597588 --> 0.597328).  Saving model ...
Validation loss decreased (0.597328 --> 0.597069).  Saving model ...
Validation loss decreased (0.597069 --> 0.596809).  Saving model ...
Validation loss decreased (0.596809 --> 0.596550).  Saving model ...
Validation loss decreased (0.596550 --> 0.596290).  Saving model ...
Validation loss decreased (0.596290 --> 0.596030).  Saving model ...
Validation loss decreased (0.596030 --> 0.595770).  Saving model ...
Validation loss decreased (0.595770 --> 0.595510).  Saving model ...
epoch 201, loss 0.5955, train acc 65.07%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.5000
Validation loss decreased (0.595510 --> 0.595250).  Saving model ...
Validation loss decreased (0.595250 --> 0.594989).  Saving model ...
Validation loss decreased (0.594989 --> 0.594729).  Saving model ...
Validation loss decreased (0.594729 --> 0.594468).  Saving model ...
Validation loss decreased (0.594468 --> 0.594208).  Saving model ...
Validation loss decreased (0.594208 --> 0.593947).  Saving model ...
Validation loss decreased (0.593947 --> 0.593685).  Saving model ...
Validation loss decreased (0.593685 --> 0.593424).  Saving model ...
Validation loss decreased (0.593424 --> 0.593163).  Saving model ...
Validation loss decreased (0.593163 --> 0.592902).  Saving model ...
Validation loss decreased (0.592902 --> 0.592640).  Saving model ...
Validation loss decreased (0.592640 --> 0.592378).  Saving model ...
Validation loss decreased (0.592378 --> 0.592116).  Saving model ...
Validation loss decreased (0.592116 --> 0.591854).  Saving model ...
Validation loss decreased (0.591854 --> 0.591592).  Saving model ...
Validation loss decreased (0.591592 --> 0.591330).  Saving model ...
Validation loss decreased (0.591330 --> 0.591068).  Saving model ...
Validation loss decreased (0.591068 --> 0.590805).  Saving model ...
Validation loss decreased (0.590805 --> 0.590542).  Saving model ...
Validation loss decreased (0.590542 --> 0.590280).  Saving model ...
Validation loss decreased (0.590280 --> 0.590017).  Saving model ...
Validation loss decreased (0.590017 --> 0.589754).  Saving model ...
Validation loss decreased (0.589754 --> 0.589491).  Saving model ...
Validation loss decreased (0.589491 --> 0.589228).  Saving model ...
Validation loss decreased (0.589228 --> 0.588965).  Saving model ...
Validation loss decreased (0.588965 --> 0.588701).  Saving model ...
Validation loss decreased (0.588701 --> 0.588438).  Saving model ...
Validation loss decreased (0.588438 --> 0.588174).  Saving model ...
Validation loss decreased (0.588174 --> 0.587911).  Saving model ...
Validation loss decreased (0.587911 --> 0.587647).  Saving model ...
Validation loss decreased (0.587647 --> 0.587383).  Saving model ...
Validation loss decreased (0.587383 --> 0.587119).  Saving model ...
Validation loss decreased (0.587119 --> 0.586855).  Saving model ...
Validation loss decreased (0.586855 --> 0.586591).  Saving model ...
Validation loss decreased (0.586591 --> 0.586327).  Saving model ...
Validation loss decreased (0.586327 --> 0.586063).  Saving model ...
Validation loss decreased (0.586063 --> 0.585799).  Saving model ...
Validation loss decreased (0.585799 --> 0.585535).  Saving model ...
Validation loss decreased (0.585535 --> 0.585271).  Saving model ...
Validation loss decreased (0.585271 --> 0.585006).  Saving model ...
Validation loss decreased (0.585006 --> 0.584742).  Saving model ...
Validation loss decreased (0.584742 --> 0.584478).  Saving model ...
Validation loss decreased (0.584478 --> 0.584213).  Saving model ...
Validation loss decreased (0.584213 --> 0.583949).  Saving model ...
Validation loss decreased (0.583949 --> 0.583685).  Saving model ...
Validation loss decreased (0.583685 --> 0.583420).  Saving model ...
Validation loss decreased (0.583420 --> 0.583156).  Saving model ...
Validation loss decreased (0.583156 --> 0.582892).  Saving model ...
Validation loss decreased (0.582892 --> 0.582627).  Saving model ...
Validation loss decreased (0.582627 --> 0.582363).  Saving model ...
Validation loss decreased (0.582363 --> 0.582099).  Saving model ...
Validation loss decreased (0.582099 --> 0.581834).  Saving model ...
Validation loss decreased (0.581834 --> 0.581570).  Saving model ...
Validation loss decreased (0.581570 --> 0.581306).  Saving model ...
Validation loss decreased (0.581306 --> 0.581042).  Saving model ...
Validation loss decreased (0.581042 --> 0.580778).  Saving model ...
Validation loss decreased (0.580778 --> 0.580514).  Saving model ...
Validation loss decreased (0.580514 --> 0.580250).  Saving model ...
Validation loss decreased (0.580250 --> 0.579986).  Saving model ...
Validation loss decreased (0.579986 --> 0.579722).  Saving model ...
Validation loss decreased (0.579722 --> 0.579459).  Saving model ...
Validation loss decreased (0.579459 --> 0.579195).  Saving model ...
Validation loss decreased (0.579195 --> 0.578931).  Saving model ...
Validation loss decreased (0.578931 --> 0.578668).  Saving model ...
Validation loss decreased (0.578668 --> 0.578405).  Saving model ...
Validation loss decreased (0.578405 --> 0.578141).  Saving model ...
Validation loss decreased (0.578141 --> 0.577878).  Saving model ...
Validation loss decreased (0.577878 --> 0.577615).  Saving model ...
Validation loss decreased (0.577615 --> 0.577353).  Saving model ...
Validation loss decreased (0.577353 --> 0.577090).  Saving model ...
Validation loss decreased (0.577090 --> 0.576827).  Saving model ...
Validation loss decreased (0.576827 --> 0.576565).  Saving model ...
Validation loss decreased (0.576565 --> 0.576303).  Saving model ...
Validation loss decreased (0.576303 --> 0.576041).  Saving model ...
Validation loss decreased (0.576041 --> 0.575779).  Saving model ...
Validation loss decreased (0.575779 --> 0.575517).  Saving model ...
Validation loss decreased (0.575517 --> 0.575255).  Saving model ...
Validation loss decreased (0.575255 --> 0.574994).  Saving model ...
Validation loss decreased (0.574994 --> 0.574733).  Saving model ...
Validation loss decreased (0.574733 --> 0.574472).  Saving model ...
Validation loss decreased (0.574472 --> 0.574211).  Saving model ...
Validation loss decreased (0.574211 --> 0.573950).  Saving model ...
Validation loss decreased (0.573950 --> 0.573690).  Saving model ...
Validation loss decreased (0.573690 --> 0.573430).  Saving model ...
Validation loss decreased (0.573430 --> 0.573170).  Saving model ...
Validation loss decreased (0.573170 --> 0.572910).  Saving model ...
Validation loss decreased (0.572910 --> 0.572650).  Saving model ...
Validation loss decreased (0.572650 --> 0.572391).  Saving model ...
Validation loss decreased (0.572391 --> 0.572132).  Saving model ...
Validation loss decreased (0.572132 --> 0.571873).  Saving model ...
Validation loss decreased (0.571873 --> 0.571615).  Saving model ...
Validation loss decreased (0.571615 --> 0.571356).  Saving model ...
Validation loss decreased (0.571356 --> 0.571098).  Saving model ...
Validation loss decreased (0.571098 --> 0.570841).  Saving model ...
Validation loss decreased (0.570841 --> 0.570583).  Saving model ...
Validation loss decreased (0.570583 --> 0.570326).  Saving model ...
Validation loss decreased (0.570326 --> 0.570069).  Saving model ...
Validation loss decreased (0.570069 --> 0.569812).  Saving model ...
Validation loss decreased (0.569812 --> 0.569556).  Saving model ...
Validation loss decreased (0.569556 --> 0.569300).  Saving model ...
epoch 301, loss 0.5693, train acc 64.90%, f1 0.0000, precision 0.0000, recall 0.0000, auc 0.4987
Validation loss decreased (0.569300 --> 0.569044).  Saving model ...
Validation loss decreased (0.569044 --> 0.568788).  Saving model ...
Validation loss decreased (0.568788 --> 0.568533).  Saving model ...
Validation loss decreased (0.568533 --> 0.568278).  Saving model ...
Validation loss decreased (0.568278 --> 0.568024).  Saving model ...
Validation loss decreased (0.568024 --> 0.567769).  Saving model ...
Validation loss decreased (0.567769 --> 0.567515).  Saving model ...
Validation loss decreased (0.567515 --> 0.567262).  Saving model ...
Validation loss decreased (0.567262 --> 0.567008).  Saving model ...
Validation loss decreased (0.567008 --> 0.566755).  Saving model ...
Validation loss decreased (0.566755 --> 0.566503).  Saving model ...
Validation loss decreased (0.566503 --> 0.566250).  Saving model ...
Validation loss decreased (0.566250 --> 0.565998).  Saving model ...
Validation loss decreased (0.565998 --> 0.565747).  Saving model ...
Validation loss decreased (0.565747 --> 0.565496).  Saving model ...
Validation loss decreased (0.565496 --> 0.565245).  Saving model ...
Validation loss decreased (0.565245 --> 0.564994).  Saving model ...
Validation loss decreased (0.564994 --> 0.564744).  Saving model ...
Validation loss decreased (0.564744 --> 0.564494).  Saving model ...
Validation loss decreased (0.564494 --> 0.564244).  Saving model ...
Validation loss decreased (0.564244 --> 0.563995).  Saving model ...
Validation loss decreased (0.563995 --> 0.563747).  Saving model ...
Validation loss decreased (0.563747 --> 0.563498).  Saving model ...
Validation loss decreased (0.563498 --> 0.563250).  Saving model ...
Validation loss decreased (0.563250 --> 0.563002).  Saving model ...
Validation loss decreased (0.563002 --> 0.562755).  Saving model ...
Validation loss decreased (0.562755 --> 0.562508).  Saving model ...
Validation loss decreased (0.562508 --> 0.562262).  Saving model ...
Validation loss decreased (0.562262 --> 0.562016).  Saving model ...
Validation loss decreased (0.562016 --> 0.561770).  Saving model ...
Validation loss decreased (0.561770 --> 0.561525).  Saving model ...
Validation loss decreased (0.561525 --> 0.561280).  Saving model ...
Validation loss decreased (0.561280 --> 0.561035).  Saving model ...
Validation loss decreased (0.561035 --> 0.560791).  Saving model ...
Validation loss decreased (0.560791 --> 0.560548).  Saving model ...
Validation loss decreased (0.560548 --> 0.560304).  Saving model ...
Validation loss decreased (0.560304 --> 0.560062).  Saving model ...
Validation loss decreased (0.560062 --> 0.559819).  Saving model ...
Validation loss decreased (0.559819 --> 0.559577).  Saving model ...
Validation loss decreased (0.559577 --> 0.559335).  Saving model ...
Validation loss decreased (0.559335 --> 0.559094).  Saving model ...
Validation loss decreased (0.559094 --> 0.558853).  Saving model ...
Validation loss decreased (0.558853 --> 0.558613).  Saving model ...
Validation loss decreased (0.558613 --> 0.558373).  Saving model ...
Validation loss decreased (0.558373 --> 0.558134).  Saving model ...
Validation loss decreased (0.558134 --> 0.557895).  Saving model ...
Validation loss decreased (0.557895 --> 0.557656).  Saving model ...
Validation loss decreased (0.557656 --> 0.557418).  Saving model ...
Validation loss decreased (0.557418 --> 0.557180).  Saving model ...
Validation loss decreased (0.557180 --> 0.556943).  Saving model ...
Validation loss decreased (0.556943 --> 0.556706).  Saving model ...
Validation loss decreased (0.556706 --> 0.556469).  Saving model ...
Validation loss decreased (0.556469 --> 0.556233).  Saving model ...
Validation loss decreased (0.556233 --> 0.555998).  Saving model ...
Validation loss decreased (0.555998 --> 0.555762).  Saving model ...
Validation loss decreased (0.555762 --> 0.555528).  Saving model ...
Validation loss decreased (0.555528 --> 0.555294).  Saving model ...
Validation loss decreased (0.555294 --> 0.555060).  Saving model ...
Validation loss decreased (0.555060 --> 0.554826).  Saving model ...
Validation loss decreased (0.554826 --> 0.554593).  Saving model ...
Validation loss decreased (0.554593 --> 0.554361).  Saving model ...
Validation loss decreased (0.554361 --> 0.554129).  Saving model ...
Validation loss decreased (0.554129 --> 0.553898).  Saving model ...
Validation loss decreased (0.553898 --> 0.553666).  Saving model ...
Validation loss decreased (0.553666 --> 0.553436).  Saving model ...
Validation loss decreased (0.553436 --> 0.553206).  Saving model ...
Validation loss decreased (0.553206 --> 0.552976).  Saving model ...
Validation loss decreased (0.552976 --> 0.552747).  Saving model ...
Validation loss decreased (0.552747 --> 0.552518).  Saving model ...
Validation loss decreased (0.552518 --> 0.552289).  Saving model ...
Validation loss decreased (0.552289 --> 0.552062).  Saving model ...
Validation loss decreased (0.552062 --> 0.551834).  Saving model ...
Validation loss decreased (0.551834 --> 0.551607).  Saving model ...
Validation loss decreased (0.551607 --> 0.551381).  Saving model ...
Validation loss decreased (0.551381 --> 0.551155).  Saving model ...
Validation loss decreased (0.551155 --> 0.550929).  Saving model ...
Validation loss decreased (0.550929 --> 0.550704).  Saving model ...
Validation loss decreased (0.550704 --> 0.550480).  Saving model ...
Validation loss decreased (0.550480 --> 0.550256).  Saving model ...
Validation loss decreased (0.550256 --> 0.550032).  Saving model ...
Validation loss decreased (0.550032 --> 0.549809).  Saving model ...
Validation loss decreased (0.549809 --> 0.549586).  Saving model ...
Validation loss decreased (0.549586 --> 0.549364).  Saving model ...
Validation loss decreased (0.549364 --> 0.549142).  Saving model ...
Validation loss decreased (0.549142 --> 0.548921).  Saving model ...
Validation loss decreased (0.548921 --> 0.548700).  Saving model ...
Validation loss decreased (0.548700 --> 0.548479).  Saving model ...
Validation loss decreased (0.548479 --> 0.548260).  Saving model ...
Validation loss decreased (0.548260 --> 0.548040).  Saving model ...
Validation loss decreased (0.548040 --> 0.547821).  Saving model ...
Validation loss decreased (0.547821 --> 0.547603).  Saving model ...
Validation loss decreased (0.547603 --> 0.547385).  Saving model ...
Validation loss decreased (0.547385 --> 0.547167).  Saving model ...
Validation loss decreased (0.547167 --> 0.546950).  Saving model ...
Validation loss decreased (0.546950 --> 0.546734).  Saving model ...
Validation loss decreased (0.546734 --> 0.546518).  Saving model ...
Validation loss decreased (0.546518 --> 0.546302).  Saving model ...
Validation loss decreased (0.546302 --> 0.546087).  Saving model ...
Validation loss decreased (0.546087 --> 0.545873).  Saving model ...
Validation loss decreased (0.545873 --> 0.545659).  Saving model ...
epoch 401, loss 0.5457, train acc 67.29%, f1 0.1586, precision 0.7826, recall 0.0882, auc 0.5375
Validation loss decreased (0.545659 --> 0.545445).  Saving model ...
Validation loss decreased (0.545445 --> 0.545232).  Saving model ...
Validation loss decreased (0.545232 --> 0.545019).  Saving model ...
Validation loss decreased (0.545019 --> 0.544807).  Saving model ...
Validation loss decreased (0.544807 --> 0.544595).  Saving model ...
Validation loss decreased (0.544595 --> 0.544384).  Saving model ...
Validation loss decreased (0.544384 --> 0.544173).  Saving model ...
Validation loss decreased (0.544173 --> 0.543963).  Saving model ...
Validation loss decreased (0.543963 --> 0.543753).  Saving model ...
Validation loss decreased (0.543753 --> 0.543544).  Saving model ...
Validation loss decreased (0.543544 --> 0.543335).  Saving model ...
Validation loss decreased (0.543335 --> 0.543127).  Saving model ...
Validation loss decreased (0.543127 --> 0.542919).  Saving model ...
Validation loss decreased (0.542919 --> 0.542711).  Saving model ...
Validation loss decreased (0.542711 --> 0.542504).  Saving model ...
Validation loss decreased (0.542504 --> 0.542298).  Saving model ...
Validation loss decreased (0.542298 --> 0.542092).  Saving model ...
Validation loss decreased (0.542092 --> 0.541887).  Saving model ...
Validation loss decreased (0.541887 --> 0.541682).  Saving model ...
Validation loss decreased (0.541682 --> 0.541477).  Saving model ...
Validation loss decreased (0.541477 --> 0.541273).  Saving model ...
Validation loss decreased (0.541273 --> 0.541070).  Saving model ...
Validation loss decreased (0.541070 --> 0.540867).  Saving model ...
Validation loss decreased (0.540867 --> 0.540664).  Saving model ...
Validation loss decreased (0.540664 --> 0.540462).  Saving model ...
Validation loss decreased (0.540462 --> 0.540260).  Saving model ...
Validation loss decreased (0.540260 --> 0.540059).  Saving model ...
Validation loss decreased (0.540059 --> 0.539859).  Saving model ...
Validation loss decreased (0.539859 --> 0.539659).  Saving model ...
Validation loss decreased (0.539659 --> 0.539459).  Saving model ...
Validation loss decreased (0.539459 --> 0.539260).  Saving model ...
Validation loss decreased (0.539260 --> 0.539061).  Saving model ...
Validation loss decreased (0.539061 --> 0.538863).  Saving model ...
Validation loss decreased (0.538863 --> 0.538665).  Saving model ...
Validation loss decreased (0.538665 --> 0.538468).  Saving model ...
Validation loss decreased (0.538468 --> 0.538271).  Saving model ...
Validation loss decreased (0.538271 --> 0.538075).  Saving model ...
Validation loss decreased (0.538075 --> 0.537879).  Saving model ...
Validation loss decreased (0.537879 --> 0.537683).  Saving model ...
Validation loss decreased (0.537683 --> 0.537489).  Saving model ...
Validation loss decreased (0.537489 --> 0.537294).  Saving model ...
Validation loss decreased (0.537294 --> 0.537100).  Saving model ...
Validation loss decreased (0.537100 --> 0.536907).  Saving model ...
Validation loss decreased (0.536907 --> 0.536714).  Saving model ...
Validation loss decreased (0.536714 --> 0.536521).  Saving model ...
Validation loss decreased (0.536521 --> 0.536329).  Saving model ...
Validation loss decreased (0.536329 --> 0.536138).  Saving model ...
Validation loss decreased (0.536138 --> 0.535947).  Saving model ...
Validation loss decreased (0.535947 --> 0.535756).  Saving model ...
Validation loss decreased (0.535756 --> 0.535566).  Saving model ...
Validation loss decreased (0.535566 --> 0.535376).  Saving model ...
Validation loss decreased (0.535376 --> 0.535187).  Saving model ...
Validation loss decreased (0.535187 --> 0.534999).  Saving model ...
Validation loss decreased (0.534999 --> 0.534810).  Saving model ...
Validation loss decreased (0.534810 --> 0.534623).  Saving model ...
Validation loss decreased (0.534623 --> 0.534435).  Saving model ...
Validation loss decreased (0.534435 --> 0.534249).  Saving model ...
Validation loss decreased (0.534249 --> 0.534062).  Saving model ...
Validation loss decreased (0.534062 --> 0.533876).  Saving model ...
Validation loss decreased (0.533876 --> 0.533691).  Saving model ...
Validation loss decreased (0.533691 --> 0.533506).  Saving model ...
Validation loss decreased (0.533506 --> 0.533322).  Saving model ...
Validation loss decreased (0.533322 --> 0.533138).  Saving model ...
Validation loss decreased (0.533138 --> 0.532954).  Saving model ...
Validation loss decreased (0.532954 --> 0.532771).  Saving model ...
Validation loss decreased (0.532771 --> 0.532588).  Saving model ...
Validation loss decreased (0.532588 --> 0.532406).  Saving model ...
Validation loss decreased (0.532406 --> 0.532225).  Saving model ...
Validation loss decreased (0.532225 --> 0.532044).  Saving model ...
Validation loss decreased (0.532044 --> 0.531863).  Saving model ...
Validation loss decreased (0.531863 --> 0.531683).  Saving model ...
Validation loss decreased (0.531683 --> 0.531503).  Saving model ...
Validation loss decreased (0.531503 --> 0.531324).  Saving model ...
Validation loss decreased (0.531324 --> 0.531145).  Saving model ...
Validation loss decreased (0.531145 --> 0.530966).  Saving model ...
Validation loss decreased (0.530966 --> 0.530788).  Saving model ...
Validation loss decreased (0.530788 --> 0.530611).  Saving model ...
Validation loss decreased (0.530611 --> 0.530434).  Saving model ...
Validation loss decreased (0.530434 --> 0.530257).  Saving model ...
Validation loss decreased (0.530257 --> 0.530081).  Saving model ...
Validation loss decreased (0.530081 --> 0.529906).  Saving model ...
Validation loss decreased (0.529906 --> 0.529730).  Saving model ...
Validation loss decreased (0.529730 --> 0.529556).  Saving model ...
Validation loss decreased (0.529556 --> 0.529381).  Saving model ...
Validation loss decreased (0.529381 --> 0.529208).  Saving model ...
Validation loss decreased (0.529208 --> 0.529034).  Saving model ...
Validation loss decreased (0.529034 --> 0.528861).  Saving model ...
Validation loss decreased (0.528861 --> 0.528689).  Saving model ...
Validation loss decreased (0.528689 --> 0.528517).  Saving model ...
Validation loss decreased (0.528517 --> 0.528345).  Saving model ...
Validation loss decreased (0.528345 --> 0.528174).  Saving model ...
Validation loss decreased (0.528174 --> 0.528004).  Saving model ...
Validation loss decreased (0.528004 --> 0.527833).  Saving model ...
Validation loss decreased (0.527833 --> 0.527664).  Saving model ...
Validation loss decreased (0.527664 --> 0.527494).  Saving model ...
Validation loss decreased (0.527494 --> 0.527326).  Saving model ...
Validation loss decreased (0.527326 --> 0.527157).  Saving model ...
Validation loss decreased (0.527157 --> 0.526989).  Saving model ...
Validation loss decreased (0.526989 --> 0.526822).  Saving model ...
Validation loss decreased (0.526822 --> 0.526655).  Saving model ...
epoch 501, loss 0.5267, train acc 71.23%, f1 0.3538, precision 0.8214, recall 0.2255, auc 0.5996
Validation loss decreased (0.526655 --> 0.526488).  Saving model ...
Validation loss decreased (0.526488 --> 0.526322).  Saving model ...
Validation loss decreased (0.526322 --> 0.526156).  Saving model ...
Validation loss decreased (0.526156 --> 0.525991).  Saving model ...
Validation loss decreased (0.525991 --> 0.525826).  Saving model ...
Validation loss decreased (0.525826 --> 0.525662).  Saving model ...
Validation loss decreased (0.525662 --> 0.525498).  Saving model ...
Validation loss decreased (0.525498 --> 0.525334).  Saving model ...
Validation loss decreased (0.525334 --> 0.525171).  Saving model ...
Validation loss decreased (0.525171 --> 0.525009).  Saving model ...
Validation loss decreased (0.525009 --> 0.524846).  Saving model ...
Validation loss decreased (0.524846 --> 0.524685).  Saving model ...
Validation loss decreased (0.524685 --> 0.524523).  Saving model ...
Validation loss decreased (0.524523 --> 0.524363).  Saving model ...
Validation loss decreased (0.524363 --> 0.524202).  Saving model ...
Validation loss decreased (0.524202 --> 0.524042).  Saving model ...
Validation loss decreased (0.524042 --> 0.523882).  Saving model ...
Validation loss decreased (0.523882 --> 0.523723).  Saving model ...
Validation loss decreased (0.523723 --> 0.523565).  Saving model ...
Validation loss decreased (0.523565 --> 0.523406).  Saving model ...
Validation loss decreased (0.523406 --> 0.523248).  Saving model ...
Validation loss decreased (0.523248 --> 0.523091).  Saving model ...
Validation loss decreased (0.523091 --> 0.522934).  Saving model ...
Validation loss decreased (0.522934 --> 0.522777).  Saving model ...
Validation loss decreased (0.522777 --> 0.522621).  Saving model ...
Validation loss decreased (0.522621 --> 0.522465).  Saving model ...
Validation loss decreased (0.522465 --> 0.522310).  Saving model ...
Validation loss decreased (0.522310 --> 0.522155).  Saving model ...
Validation loss decreased (0.522155 --> 0.522001).  Saving model ...
Validation loss decreased (0.522001 --> 0.521847).  Saving model ...
Validation loss decreased (0.521847 --> 0.521693).  Saving model ...
Validation loss decreased (0.521693 --> 0.521540).  Saving model ...
Validation loss decreased (0.521540 --> 0.521387).  Saving model ...
Validation loss decreased (0.521387 --> 0.521235).  Saving model ...
Validation loss decreased (0.521235 --> 0.521083).  Saving model ...
Validation loss decreased (0.521083 --> 0.520932).  Saving model ...
Validation loss decreased (0.520932 --> 0.520781).  Saving model ...
Validation loss decreased (0.520781 --> 0.520630).  Saving model ...
Validation loss decreased (0.520630 --> 0.520480).  Saving model ...
Validation loss decreased (0.520480 --> 0.520330).  Saving model ...
Validation loss decreased (0.520330 --> 0.520180).  Saving model ...
Validation loss decreased (0.520180 --> 0.520031).  Saving model ...
Validation loss decreased (0.520031 --> 0.519883).  Saving model ...
Validation loss decreased (0.519883 --> 0.519735).  Saving model ...
Validation loss decreased (0.519735 --> 0.519587).  Saving model ...
Validation loss decreased (0.519587 --> 0.519439).  Saving model ...
Validation loss decreased (0.519439 --> 0.519292).  Saving model ...
Validation loss decreased (0.519292 --> 0.519146).  Saving model ...
Validation loss decreased (0.519146 --> 0.519000).  Saving model ...
Validation loss decreased (0.519000 --> 0.518854).  Saving model ...
Validation loss decreased (0.518854 --> 0.518709).  Saving model ...
Validation loss decreased (0.518709 --> 0.518564).  Saving model ...
Validation loss decreased (0.518564 --> 0.518419).  Saving model ...
Validation loss decreased (0.518419 --> 0.518275).  Saving model ...
Validation loss decreased (0.518275 --> 0.518131).  Saving model ...
Validation loss decreased (0.518131 --> 0.517988).  Saving model ...
Validation loss decreased (0.517988 --> 0.517845).  Saving model ...
Validation loss decreased (0.517845 --> 0.517703).  Saving model ...
Validation loss decreased (0.517703 --> 0.517561).  Saving model ...
Validation loss decreased (0.517561 --> 0.517419).  Saving model ...
Validation loss decreased (0.517419 --> 0.517278).  Saving model ...
Validation loss decreased (0.517278 --> 0.517137).  Saving model ...
Validation loss decreased (0.517137 --> 0.516996).  Saving model ...
Validation loss decreased (0.516996 --> 0.516856).  Saving model ...
Validation loss decreased (0.516856 --> 0.516716).  Saving model ...
Validation loss decreased (0.516716 --> 0.516577).  Saving model ...
Validation loss decreased (0.516577 --> 0.516438).  Saving model ...
Validation loss decreased (0.516438 --> 0.516300).  Saving model ...
Validation loss decreased (0.516300 --> 0.516161).  Saving model ...
Validation loss decreased (0.516161 --> 0.516024).  Saving model ...
Validation loss decreased (0.516024 --> 0.515886).  Saving model ...
Validation loss decreased (0.515886 --> 0.515749).  Saving model ...
Validation loss decreased (0.515749 --> 0.515613).  Saving model ...
Validation loss decreased (0.515613 --> 0.515476).  Saving model ...
Validation loss decreased (0.515476 --> 0.515341).  Saving model ...
Validation loss decreased (0.515341 --> 0.515205).  Saving model ...
Validation loss decreased (0.515205 --> 0.515070).  Saving model ...
Validation loss decreased (0.515070 --> 0.514936).  Saving model ...
Validation loss decreased (0.514936 --> 0.514801).  Saving model ...
Validation loss decreased (0.514801 --> 0.514667).  Saving model ...
Validation loss decreased (0.514667 --> 0.514534).  Saving model ...
Validation loss decreased (0.514534 --> 0.514401).  Saving model ...
Validation loss decreased (0.514401 --> 0.514268).  Saving model ...
Validation loss decreased (0.514268 --> 0.514135).  Saving model ...
Validation loss decreased (0.514135 --> 0.514004).  Saving model ...
Validation loss decreased (0.514004 --> 0.513872).  Saving model ...
Validation loss decreased (0.513872 --> 0.513741).  Saving model ...
Validation loss decreased (0.513741 --> 0.513610).  Saving model ...
Validation loss decreased (0.513610 --> 0.513479).  Saving model ...
Validation loss decreased (0.513479 --> 0.513349).  Saving model ...
Validation loss decreased (0.513349 --> 0.513219).  Saving model ...
Validation loss decreased (0.513219 --> 0.513090).  Saving model ...
Validation loss decreased (0.513090 --> 0.512961).  Saving model ...
Validation loss decreased (0.512961 --> 0.512832).  Saving model ...
Validation loss decreased (0.512832 --> 0.512704).  Saving model ...
Validation loss decreased (0.512704 --> 0.512576).  Saving model ...
Validation loss decreased (0.512576 --> 0.512448).  Saving model ...
Validation loss decreased (0.512448 --> 0.512321).  Saving model ...
Validation loss decreased (0.512321 --> 0.512195).  Saving model ...
Validation loss decreased (0.512195 --> 0.512068).  Saving model ...
epoch 601, loss 0.5121, train acc 74.32%, f1 0.4966, precision 0.7872, recall 0.3627, auc 0.6551
Validation loss decreased (0.512068 --> 0.511942).  Saving model ...
Validation loss decreased (0.511942 --> 0.511816).  Saving model ...
Validation loss decreased (0.511816 --> 0.511691).  Saving model ...
Validation loss decreased (0.511691 --> 0.511566).  Saving model ...
Validation loss decreased (0.511566 --> 0.511441).  Saving model ...
Validation loss decreased (0.511441 --> 0.511317).  Saving model ...
Validation loss decreased (0.511317 --> 0.511193).  Saving model ...
Validation loss decreased (0.511193 --> 0.511069).  Saving model ...
Validation loss decreased (0.511069 --> 0.510946).  Saving model ...
Validation loss decreased (0.510946 --> 0.510823).  Saving model ...
Validation loss decreased (0.510823 --> 0.510701).  Saving model ...
Validation loss decreased (0.510701 --> 0.510579).  Saving model ...
Validation loss decreased (0.510579 --> 0.510457).  Saving model ...
Validation loss decreased (0.510457 --> 0.510336).  Saving model ...
Validation loss decreased (0.510336 --> 0.510214).  Saving model ...
Validation loss decreased (0.510214 --> 0.510094).  Saving model ...
Validation loss decreased (0.510094 --> 0.509973).  Saving model ...
Validation loss decreased (0.509973 --> 0.509853).  Saving model ...
Validation loss decreased (0.509853 --> 0.509734).  Saving model ...
Validation loss decreased (0.509734 --> 0.509614).  Saving model ...
Validation loss decreased (0.509614 --> 0.509495).  Saving model ...
Validation loss decreased (0.509495 --> 0.509377).  Saving model ...
Validation loss decreased (0.509377 --> 0.509259).  Saving model ...
Validation loss decreased (0.509259 --> 0.509141).  Saving model ...
Validation loss decreased (0.509141 --> 0.509023).  Saving model ...
Validation loss decreased (0.509023 --> 0.508906).  Saving model ...
Validation loss decreased (0.508906 --> 0.508789).  Saving model ...
Validation loss decreased (0.508789 --> 0.508672).  Saving model ...
Validation loss decreased (0.508672 --> 0.508556).  Saving model ...
Validation loss decreased (0.508556 --> 0.508440).  Saving model ...
Validation loss decreased (0.508440 --> 0.508325).  Saving model ...
Validation loss decreased (0.508325 --> 0.508209).  Saving model ...
Validation loss decreased (0.508209 --> 0.508094).  Saving model ...
Validation loss decreased (0.508094 --> 0.507980).  Saving model ...
Validation loss decreased (0.507980 --> 0.507866).  Saving model ...
Validation loss decreased (0.507866 --> 0.507752).  Saving model ...
Validation loss decreased (0.507752 --> 0.507638).  Saving model ...
Validation loss decreased (0.507638 --> 0.507525).  Saving model ...
Validation loss decreased (0.507525 --> 0.507412).  Saving model ...
Validation loss decreased (0.507412 --> 0.507300).  Saving model ...
Validation loss decreased (0.507300 --> 0.507187).  Saving model ...
Validation loss decreased (0.507187 --> 0.507076).  Saving model ...
Validation loss decreased (0.507076 --> 0.506964).  Saving model ...
Validation loss decreased (0.506964 --> 0.506853).  Saving model ...
Validation loss decreased (0.506853 --> 0.506742).  Saving model ...
Validation loss decreased (0.506742 --> 0.506631).  Saving model ...
Validation loss decreased (0.506631 --> 0.506521).  Saving model ...
Validation loss decreased (0.506521 --> 0.506411).  Saving model ...
Validation loss decreased (0.506411 --> 0.506302).  Saving model ...
Validation loss decreased (0.506302 --> 0.506192).  Saving model ...
Validation loss decreased (0.506192 --> 0.506083).  Saving model ...
Validation loss decreased (0.506083 --> 0.505975).  Saving model ...
Validation loss decreased (0.505975 --> 0.505866).  Saving model ...
Validation loss decreased (0.505866 --> 0.505758).  Saving model ...
Validation loss decreased (0.505758 --> 0.505651).  Saving model ...
Validation loss decreased (0.505651 --> 0.505543).  Saving model ...
Validation loss decreased (0.505543 --> 0.505436).  Saving model ...
Validation loss decreased (0.505436 --> 0.505330).  Saving model ...
Validation loss decreased (0.505330 --> 0.505223).  Saving model ...
Validation loss decreased (0.505223 --> 0.505117).  Saving model ...
Validation loss decreased (0.505117 --> 0.505011).  Saving model ...
Validation loss decreased (0.505011 --> 0.504906).  Saving model ...
Validation loss decreased (0.504906 --> 0.504801).  Saving model ...
Validation loss decreased (0.504801 --> 0.504696).  Saving model ...
Validation loss decreased (0.504696 --> 0.504591).  Saving model ...
Validation loss decreased (0.504591 --> 0.504487).  Saving model ...
Validation loss decreased (0.504487 --> 0.504383).  Saving model ...
Validation loss decreased (0.504383 --> 0.504280).  Saving model ...
Validation loss decreased (0.504280 --> 0.504176).  Saving model ...
Validation loss decreased (0.504176 --> 0.504073).  Saving model ...
Validation loss decreased (0.504073 --> 0.503971).  Saving model ...
Validation loss decreased (0.503971 --> 0.503868).  Saving model ...
Validation loss decreased (0.503868 --> 0.503766).  Saving model ...
Validation loss decreased (0.503766 --> 0.503665).  Saving model ...
Validation loss decreased (0.503665 --> 0.503563).  Saving model ...
Validation loss decreased (0.503563 --> 0.503462).  Saving model ...
Validation loss decreased (0.503462 --> 0.503361).  Saving model ...
Validation loss decreased (0.503361 --> 0.503261).  Saving model ...
Validation loss decreased (0.503261 --> 0.503160).  Saving model ...
Validation loss decreased (0.503160 --> 0.503060).  Saving model ...
Validation loss decreased (0.503060 --> 0.502961).  Saving model ...
Validation loss decreased (0.502961 --> 0.502861).  Saving model ...
Validation loss decreased (0.502861 --> 0.502762).  Saving model ...
Validation loss decreased (0.502762 --> 0.502664).  Saving model ...
Validation loss decreased (0.502664 --> 0.502565).  Saving model ...
Validation loss decreased (0.502565 --> 0.502467).  Saving model ...
Validation loss decreased (0.502467 --> 0.502369).  Saving model ...
Validation loss decreased (0.502369 --> 0.502271).  Saving model ...
Validation loss decreased (0.502271 --> 0.502174).  Saving model ...
Validation loss decreased (0.502174 --> 0.502077).  Saving model ...
Validation loss decreased (0.502077 --> 0.501980).  Saving model ...
Validation loss decreased (0.501980 --> 0.501884).  Saving model ...
Validation loss decreased (0.501884 --> 0.501788).  Saving model ...
Validation loss decreased (0.501788 --> 0.501692).  Saving model ...
Validation loss decreased (0.501692 --> 0.501596).  Saving model ...
Validation loss decreased (0.501596 --> 0.501501).  Saving model ...
Validation loss decreased (0.501501 --> 0.501406).  Saving model ...
Validation loss decreased (0.501406 --> 0.501311).  Saving model ...
Validation loss decreased (0.501311 --> 0.501217).  Saving model ...
Validation loss decreased (0.501217 --> 0.501123).  Saving model ...
epoch 701, loss 0.5011, train acc 75.17%, f1 0.5511, precision 0.7479, recall 0.4363, auc 0.6787
Validation loss decreased (0.501123 --> 0.501029).  Saving model ...
Validation loss decreased (0.501029 --> 0.500935).  Saving model ...
Validation loss decreased (0.500935 --> 0.500842).  Saving model ...
Validation loss decreased (0.500842 --> 0.500749).  Saving model ...
Validation loss decreased (0.500749 --> 0.500656).  Saving model ...
Validation loss decreased (0.500656 --> 0.500564).  Saving model ...
Validation loss decreased (0.500564 --> 0.500472).  Saving model ...
Validation loss decreased (0.500472 --> 0.500380).  Saving model ...
Validation loss decreased (0.500380 --> 0.500288).  Saving model ...
Validation loss decreased (0.500288 --> 0.500197).  Saving model ...
Validation loss decreased (0.500197 --> 0.500106).  Saving model ...
Validation loss decreased (0.500106 --> 0.500015).  Saving model ...
Validation loss decreased (0.500015 --> 0.499924).  Saving model ...
Validation loss decreased (0.499924 --> 0.499834).  Saving model ...
Validation loss decreased (0.499834 --> 0.499744).  Saving model ...
Validation loss decreased (0.499744 --> 0.499654).  Saving model ...
Validation loss decreased (0.499654 --> 0.499565).  Saving model ...
Validation loss decreased (0.499565 --> 0.499476).  Saving model ...
Validation loss decreased (0.499476 --> 0.499387).  Saving model ...
Validation loss decreased (0.499387 --> 0.499298).  Saving model ...
Validation loss decreased (0.499298 --> 0.499210).  Saving model ...
Validation loss decreased (0.499210 --> 0.499122).  Saving model ...
Validation loss decreased (0.499122 --> 0.499034).  Saving model ...
Validation loss decreased (0.499034 --> 0.498946).  Saving model ...
Validation loss decreased (0.498946 --> 0.498859).  Saving model ...
Validation loss decreased (0.498859 --> 0.498772).  Saving model ...
Validation loss decreased (0.498772 --> 0.498685).  Saving model ...
Validation loss decreased (0.498685 --> 0.498599).  Saving model ...
Validation loss decreased (0.498599 --> 0.498513).  Saving model ...
Validation loss decreased (0.498513 --> 0.498426).  Saving model ...
Validation loss decreased (0.498426 --> 0.498341).  Saving model ...
Validation loss decreased (0.498341 --> 0.498255).  Saving model ...
Validation loss decreased (0.498255 --> 0.498170).  Saving model ...
Validation loss decreased (0.498170 --> 0.498085).  Saving model ...
Validation loss decreased (0.498085 --> 0.498000).  Saving model ...
Validation loss decreased (0.498000 --> 0.497916).  Saving model ...
Validation loss decreased (0.497916 --> 0.497832).  Saving model ...
Validation loss decreased (0.497832 --> 0.497748).  Saving model ...
Validation loss decreased (0.497748 --> 0.497664).  Saving model ...
Validation loss decreased (0.497664 --> 0.497581).  Saving model ...
Validation loss decreased (0.497581 --> 0.497497).  Saving model ...
Validation loss decreased (0.497497 --> 0.497415).  Saving model ...
Validation loss decreased (0.497415 --> 0.497332).  Saving model ...
Validation loss decreased (0.497332 --> 0.497249).  Saving model ...
Validation loss decreased (0.497249 --> 0.497167).  Saving model ...
Validation loss decreased (0.497167 --> 0.497085).  Saving model ...
Validation loss decreased (0.497085 --> 0.497004).  Saving model ...
Validation loss decreased (0.497004 --> 0.496922).  Saving model ...
Validation loss decreased (0.496922 --> 0.496841).  Saving model ...
Validation loss decreased (0.496841 --> 0.496760).  Saving model ...
Validation loss decreased (0.496760 --> 0.496679).  Saving model ...
Validation loss decreased (0.496679 --> 0.496599).  Saving model ...
Validation loss decreased (0.496599 --> 0.496519).  Saving model ...
Validation loss decreased (0.496519 --> 0.496439).  Saving model ...
Validation loss decreased (0.496439 --> 0.496359).  Saving model ...
Validation loss decreased (0.496359 --> 0.496279).  Saving model ...
Validation loss decreased (0.496279 --> 0.496200).  Saving model ...
Validation loss decreased (0.496200 --> 0.496121).  Saving model ...
Validation loss decreased (0.496121 --> 0.496042).  Saving model ...
Validation loss decreased (0.496042 --> 0.495964).  Saving model ...
Validation loss decreased (0.495964 --> 0.495886).  Saving model ...
Validation loss decreased (0.495886 --> 0.495808).  Saving model ...
Validation loss decreased (0.495808 --> 0.495730).  Saving model ...
Validation loss decreased (0.495730 --> 0.495652).  Saving model ...
Validation loss decreased (0.495652 --> 0.495575).  Saving model ...
Validation loss decreased (0.495575 --> 0.495498).  Saving model ...
Validation loss decreased (0.495498 --> 0.495421).  Saving model ...
Validation loss decreased (0.495421 --> 0.495344).  Saving model ...
Validation loss decreased (0.495344 --> 0.495268).  Saving model ...
Validation loss decreased (0.495268 --> 0.495192).  Saving model ...
Validation loss decreased (0.495192 --> 0.495116).  Saving model ...
Validation loss decreased (0.495116 --> 0.495040).  Saving model ...
Validation loss decreased (0.495040 --> 0.494964).  Saving model ...
Validation loss decreased (0.494964 --> 0.494889).  Saving model ...
Validation loss decreased (0.494889 --> 0.494814).  Saving model ...
Validation loss decreased (0.494814 --> 0.494739).  Saving model ...
Validation loss decreased (0.494739 --> 0.494665).  Saving model ...
Validation loss decreased (0.494665 --> 0.494590).  Saving model ...
Validation loss decreased (0.494590 --> 0.494516).  Saving model ...
Validation loss decreased (0.494516 --> 0.494442).  Saving model ...
Validation loss decreased (0.494442 --> 0.494369).  Saving model ...
Validation loss decreased (0.494369 --> 0.494295).  Saving model ...
Validation loss decreased (0.494295 --> 0.494222).  Saving model ...
Validation loss decreased (0.494222 --> 0.494149).  Saving model ...
Validation loss decreased (0.494149 --> 0.494076).  Saving model ...
Validation loss decreased (0.494076 --> 0.494004).  Saving model ...
Validation loss decreased (0.494004 --> 0.493932).  Saving model ...
Validation loss decreased (0.493932 --> 0.493859).  Saving model ...
Validation loss decreased (0.493859 --> 0.493787).  Saving model ...
Validation loss decreased (0.493787 --> 0.493716).  Saving model ...
Validation loss decreased (0.493716 --> 0.493644).  Saving model ...
Validation loss decreased (0.493644 --> 0.493573).  Saving model ...
Validation loss decreased (0.493573 --> 0.493502).  Saving model ...
Validation loss decreased (0.493502 --> 0.493431).  Saving model ...
Validation loss decreased (0.493431 --> 0.493361).  Saving model ...
Validation loss decreased (0.493361 --> 0.493290).  Saving model ...
Validation loss decreased (0.493290 --> 0.493220).  Saving model ...
Validation loss decreased (0.493220 --> 0.493150).  Saving model ...
Validation loss decreased (0.493150 --> 0.493080).  Saving model ...
Validation loss decreased (0.493080 --> 0.493011).  Saving model ...
epoch 801, loss 0.4930, train acc 75.86%, f1 0.5937, precision 0.7203, recall 0.5049, auc 0.6998
Validation loss decreased (0.493011 --> 0.492941).  Saving model ...
Validation loss decreased (0.492941 --> 0.492872).  Saving model ...
Validation loss decreased (0.492872 --> 0.492803).  Saving model ...
Validation loss decreased (0.492803 --> 0.492735).  Saving model ...
Validation loss decreased (0.492735 --> 0.492666).  Saving model ...
Validation loss decreased (0.492666 --> 0.492598).  Saving model ...
Validation loss decreased (0.492598 --> 0.492530).  Saving model ...
Validation loss decreased (0.492530 --> 0.492462).  Saving model ...
Validation loss decreased (0.492462 --> 0.492394).  Saving model ...
Validation loss decreased (0.492394 --> 0.492327).  Saving model ...
Validation loss decreased (0.492327 --> 0.492260).  Saving model ...
Validation loss decreased (0.492260 --> 0.492193).  Saving model ...
Validation loss decreased (0.492193 --> 0.492126).  Saving model ...
Validation loss decreased (0.492126 --> 0.492059).  Saving model ...
Validation loss decreased (0.492059 --> 0.491993).  Saving model ...
Validation loss decreased (0.491993 --> 0.491926).  Saving model ...
Validation loss decreased (0.491926 --> 0.491860).  Saving model ...
Validation loss decreased (0.491860 --> 0.491794).  Saving model ...
Validation loss decreased (0.491794 --> 0.491729).  Saving model ...
Validation loss decreased (0.491729 --> 0.491663).  Saving model ...
Validation loss decreased (0.491663 --> 0.491598).  Saving model ...
Validation loss decreased (0.491598 --> 0.491533).  Saving model ...
Validation loss decreased (0.491533 --> 0.491468).  Saving model ...
Validation loss decreased (0.491468 --> 0.491403).  Saving model ...
Validation loss decreased (0.491403 --> 0.491339).  Saving model ...
Validation loss decreased (0.491339 --> 0.491275).  Saving model ...
Validation loss decreased (0.491275 --> 0.491211).  Saving model ...
Validation loss decreased (0.491211 --> 0.491147).  Saving model ...
Validation loss decreased (0.491147 --> 0.491083).  Saving model ...
Validation loss decreased (0.491083 --> 0.491020).  Saving model ...
Validation loss decreased (0.491020 --> 0.490956).  Saving model ...
Validation loss decreased (0.490956 --> 0.490893).  Saving model ...
Validation loss decreased (0.490893 --> 0.490830).  Saving model ...
Validation loss decreased (0.490830 --> 0.490768).  Saving model ...
Validation loss decreased (0.490768 --> 0.490705).  Saving model ...
Validation loss decreased (0.490705 --> 0.490643).  Saving model ...
Validation loss decreased (0.490643 --> 0.490580).  Saving model ...
Validation loss decreased (0.490580 --> 0.490518).  Saving model ...
Validation loss decreased (0.490518 --> 0.490457).  Saving model ...
Validation loss decreased (0.490457 --> 0.490395).  Saving model ...
Validation loss decreased (0.490395 --> 0.490334).  Saving model ...
Validation loss decreased (0.490334 --> 0.490272).  Saving model ...
Validation loss decreased (0.490272 --> 0.490211).  Saving model ...
Validation loss decreased (0.490211 --> 0.490151).  Saving model ...
Validation loss decreased (0.490151 --> 0.490090).  Saving model ...
Validation loss decreased (0.490090 --> 0.490029).  Saving model ...
Validation loss decreased (0.490029 --> 0.489969).  Saving model ...
Validation loss decreased (0.489969 --> 0.489909).  Saving model ...
Validation loss decreased (0.489909 --> 0.489849).  Saving model ...
Validation loss decreased (0.489849 --> 0.489789).  Saving model ...
Validation loss decreased (0.489789 --> 0.489729).  Saving model ...
Validation loss decreased (0.489729 --> 0.489670).  Saving model ...
Validation loss decreased (0.489670 --> 0.489611).  Saving model ...
Validation loss decreased (0.489611 --> 0.489552).  Saving model ...
Validation loss decreased (0.489552 --> 0.489493).  Saving model ...
Validation loss decreased (0.489493 --> 0.489434).  Saving model ...
Validation loss decreased (0.489434 --> 0.489376).  Saving model ...
Validation loss decreased (0.489376 --> 0.489317).  Saving model ...
Validation loss decreased (0.489317 --> 0.489259).  Saving model ...
Validation loss decreased (0.489259 --> 0.489201).  Saving model ...
Validation loss decreased (0.489201 --> 0.489143).  Saving model ...
Validation loss decreased (0.489143 --> 0.489085).  Saving model ...
Validation loss decreased (0.489085 --> 0.489028).  Saving model ...
Validation loss decreased (0.489028 --> 0.488971).  Saving model ...
Validation loss decreased (0.488971 --> 0.488914).  Saving model ...
Validation loss decreased (0.488914 --> 0.488857).  Saving model ...
Validation loss decreased (0.488857 --> 0.488800).  Saving model ...
Validation loss decreased (0.488800 --> 0.488743).  Saving model ...
Validation loss decreased (0.488743 --> 0.488687).  Saving model ...
Validation loss decreased (0.488687 --> 0.488630).  Saving model ...
Validation loss decreased (0.488630 --> 0.488574).  Saving model ...
Validation loss decreased (0.488574 --> 0.488518).  Saving model ...
Validation loss decreased (0.488518 --> 0.488462).  Saving model ...
Validation loss decreased (0.488462 --> 0.488407).  Saving model ...
Validation loss decreased (0.488407 --> 0.488351).  Saving model ...
Validation loss decreased (0.488351 --> 0.488296).  Saving model ...
Validation loss decreased (0.488296 --> 0.488241).  Saving model ...
Validation loss decreased (0.488241 --> 0.488186).  Saving model ...
Validation loss decreased (0.488186 --> 0.488131).  Saving model ...
Validation loss decreased (0.488131 --> 0.488076).  Saving model ...
Validation loss decreased (0.488076 --> 0.488022).  Saving model ...
Validation loss decreased (0.488022 --> 0.487967).  Saving model ...
Validation loss decreased (0.487967 --> 0.487913).  Saving model ...
Validation loss decreased (0.487913 --> 0.487859).  Saving model ...
Validation loss decreased (0.487859 --> 0.487805).  Saving model ...
Validation loss decreased (0.487805 --> 0.487752).  Saving model ...
Validation loss decreased (0.487752 --> 0.487698).  Saving model ...
Validation loss decreased (0.487698 --> 0.487645).  Saving model ...
Validation loss decreased (0.487645 --> 0.487591).  Saving model ...
Validation loss decreased (0.487591 --> 0.487538).  Saving model ...
Validation loss decreased (0.487538 --> 0.487485).  Saving model ...
Validation loss decreased (0.487485 --> 0.487433).  Saving model ...
Validation loss decreased (0.487433 --> 0.487380).  Saving model ...
Validation loss decreased (0.487380 --> 0.487328).  Saving model ...
Validation loss decreased (0.487328 --> 0.487275).  Saving model ...
Validation loss decreased (0.487275 --> 0.487223).  Saving model ...
Validation loss decreased (0.487223 --> 0.487171).  Saving model ...
Validation loss decreased (0.487171 --> 0.487119).  Saving model ...
Validation loss decreased (0.487119 --> 0.487068).  Saving model ...
Validation loss decreased (0.487068 --> 0.487016).  Saving model ...
epoch 901, loss 0.4870, train acc 76.54%, f1 0.6205, precision 0.7134, recall 0.5490, auc 0.7153
Validation loss decreased (0.487016 --> 0.486965).  Saving model ...
Validation loss decreased (0.486965 --> 0.486914).  Saving model ...
Validation loss decreased (0.486914 --> 0.486862).  Saving model ...
Validation loss decreased (0.486862 --> 0.486811).  Saving model ...
Validation loss decreased (0.486811 --> 0.486761).  Saving model ...
Validation loss decreased (0.486761 --> 0.486710).  Saving model ...
Validation loss decreased (0.486710 --> 0.486659).  Saving model ...
Validation loss decreased (0.486659 --> 0.486609).  Saving model ...
Validation loss decreased (0.486609 --> 0.486559).  Saving model ...
Validation loss decreased (0.486559 --> 0.486509).  Saving model ...
Validation loss decreased (0.486509 --> 0.486459).  Saving model ...
Validation loss decreased (0.486459 --> 0.486409).  Saving model ...
Validation loss decreased (0.486409 --> 0.486359).  Saving model ...
Validation loss decreased (0.486359 --> 0.486310).  Saving model ...
Validation loss decreased (0.486310 --> 0.486261).  Saving model ...
Validation loss decreased (0.486261 --> 0.486211).  Saving model ...
Validation loss decreased (0.486211 --> 0.486162).  Saving model ...
Validation loss decreased (0.486162 --> 0.486113).  Saving model ...
Validation loss decreased (0.486113 --> 0.486065).  Saving model ...
Validation loss decreased (0.486065 --> 0.486016).  Saving model ...
Validation loss decreased (0.486016 --> 0.485968).  Saving model ...
Validation loss decreased (0.485968 --> 0.485919).  Saving model ...
Validation loss decreased (0.485919 --> 0.485871).  Saving model ...
Validation loss decreased (0.485871 --> 0.485823).  Saving model ...
Validation loss decreased (0.485823 --> 0.485775).  Saving model ...
Validation loss decreased (0.485775 --> 0.485727).  Saving model ...
Validation loss decreased (0.485727 --> 0.485679).  Saving model ...
Validation loss decreased (0.485679 --> 0.485632).  Saving model ...
Validation loss decreased (0.485632 --> 0.485584).  Saving model ...
Validation loss decreased (0.485584 --> 0.485537).  Saving model ...
Validation loss decreased (0.485537 --> 0.485490).  Saving model ...
Validation loss decreased (0.485490 --> 0.485443).  Saving model ...
Validation loss decreased (0.485443 --> 0.485396).  Saving model ...
Validation loss decreased (0.485396 --> 0.485349).  Saving model ...
Validation loss decreased (0.485349 --> 0.485303).  Saving model ...
Validation loss decreased (0.485303 --> 0.485256).  Saving model ...
Validation loss decreased (0.485256 --> 0.485210).  Saving model ...
Validation loss decreased (0.485210 --> 0.485163).  Saving model ...
Validation loss decreased (0.485163 --> 0.485117).  Saving model ...
Validation loss decreased (0.485117 --> 0.485071).  Saving model ...
Validation loss decreased (0.485071 --> 0.485025).  Saving model ...
Validation loss decreased (0.485025 --> 0.484980).  Saving model ...
Validation loss decreased (0.484980 --> 0.484934).  Saving model ...
Validation loss decreased (0.484934 --> 0.484889).  Saving model ...
Validation loss decreased (0.484889 --> 0.484843).  Saving model ...
Validation loss decreased (0.484843 --> 0.484798).  Saving model ...
Validation loss decreased (0.484798 --> 0.484753).  Saving model ...
Validation loss decreased (0.484753 --> 0.484708).  Saving model ...
Validation loss decreased (0.484708 --> 0.484663).  Saving model ...
Validation loss decreased (0.484663 --> 0.484618).  Saving model ...
Validation loss decreased (0.484618 --> 0.484574).  Saving model ...
Validation loss decreased (0.484574 --> 0.484529).  Saving model ...
Validation loss decreased (0.484529 --> 0.484485).  Saving model ...
Validation loss decreased (0.484485 --> 0.484441).  Saving model ...
Validation loss decreased (0.484441 --> 0.484396).  Saving model ...
Validation loss decreased (0.484396 --> 0.484352).  Saving model ...
Validation loss decreased (0.484352 --> 0.484309).  Saving model ...
Validation loss decreased (0.484309 --> 0.484265).  Saving model ...
Validation loss decreased (0.484265 --> 0.484221).  Saving model ...
Validation loss decreased (0.484221 --> 0.484178).  Saving model ...
Validation loss decreased (0.484178 --> 0.484134).  Saving model ...
Validation loss decreased (0.484134 --> 0.484091).  Saving model ...
Validation loss decreased (0.484091 --> 0.484048).  Saving model ...
Validation loss decreased (0.484048 --> 0.484004).  Saving model ...
Validation loss decreased (0.484004 --> 0.483962).  Saving model ...
Validation loss decreased (0.483962 --> 0.483919).  Saving model ...
Validation loss decreased (0.483919 --> 0.483876).  Saving model ...
Validation loss decreased (0.483876 --> 0.483833).  Saving model ...
Validation loss decreased (0.483833 --> 0.483791).  Saving model ...
Validation loss decreased (0.483791 --> 0.483748).  Saving model ...
Validation loss decreased (0.483748 --> 0.483706).  Saving model ...
Validation loss decreased (0.483706 --> 0.483664).  Saving model ...
Validation loss decreased (0.483664 --> 0.483622).  Saving model ...
Validation loss decreased (0.483622 --> 0.483580).  Saving model ...
Validation loss decreased (0.483580 --> 0.483538).  Saving model ...
Validation loss decreased (0.483538 --> 0.483496).  Saving model ...
Validation loss decreased (0.483496 --> 0.483454).  Saving model ...
Validation loss decreased (0.483454 --> 0.483413).  Saving model ...
Validation loss decreased (0.483413 --> 0.483372).  Saving model ...
Validation loss decreased (0.483372 --> 0.483330).  Saving model ...
Validation loss decreased (0.483330 --> 0.483289).  Saving model ...
Validation loss decreased (0.483289 --> 0.483248).  Saving model ...
Validation loss decreased (0.483248 --> 0.483207).  Saving model ...
Validation loss decreased (0.483207 --> 0.483166).  Saving model ...
Validation loss decreased (0.483166 --> 0.483125).  Saving model ...
Validation loss decreased (0.483125 --> 0.483084).  Saving model ...
Validation loss decreased (0.483084 --> 0.483044).  Saving model ...
Validation loss decreased (0.483044 --> 0.483003).  Saving model ...
Validation loss decreased (0.483003 --> 0.482963).  Saving model ...
Validation loss decreased (0.482963 --> 0.482922).  Saving model ...
Validation loss decreased (0.482922 --> 0.482882).  Saving model ...
Validation loss decreased (0.482882 --> 0.482842).  Saving model ...
Validation loss decreased (0.482842 --> 0.482802).  Saving model ...
Validation loss decreased (0.482802 --> 0.482762).  Saving model ...
Validation loss decreased (0.482762 --> 0.482722).  Saving model ...
Validation loss decreased (0.482722 --> 0.482683).  Saving model ...
Validation loss decreased (0.482683 --> 0.482643).  Saving model ...
Validation loss decreased (0.482643 --> 0.482603).  Saving model ...
Validation loss decreased (0.482603 --> 0.482564).  Saving model ...
Validation loss decreased (0.482564 --> 0.482525).  Saving model ...
epoch 1001, loss 0.4825, train acc 76.54%, f1 0.6267, precision 0.7055, recall 0.5637, auc 0.7187
Validation loss decreased (0.482525 --> 0.482485).  Saving model ...
Validation loss decreased (0.482485 --> 0.482446).  Saving model ...
Validation loss decreased (0.482446 --> 0.482407).  Saving model ...
Validation loss decreased (0.482407 --> 0.482368).  Saving model ...
Validation loss decreased (0.482368 --> 0.482329).  Saving model ...
Validation loss decreased (0.482329 --> 0.482290).  Saving model ...
Validation loss decreased (0.482290 --> 0.482252).  Saving model ...
Validation loss decreased (0.482252 --> 0.482213).  Saving model ...
Validation loss decreased (0.482213 --> 0.482174).  Saving model ...
Validation loss decreased (0.482174 --> 0.482136).  Saving model ...
Validation loss decreased (0.482136 --> 0.482098).  Saving model ...
Validation loss decreased (0.482098 --> 0.482059).  Saving model ...
Validation loss decreased (0.482059 --> 0.482021).  Saving model ...
Validation loss decreased (0.482021 --> 0.481983).  Saving model ...
Validation loss decreased (0.481983 --> 0.481945).  Saving model ...
Validation loss decreased (0.481945 --> 0.481907).  Saving model ...
Validation loss decreased (0.481907 --> 0.481869).  Saving model ...
Validation loss decreased (0.481869 --> 0.481831).  Saving model ...
Validation loss decreased (0.481831 --> 0.481794).  Saving model ...
Validation loss decreased (0.481794 --> 0.481756).  Saving model ...
Validation loss decreased (0.481756 --> 0.481719).  Saving model ...
Validation loss decreased (0.481719 --> 0.481681).  Saving model ...
Validation loss decreased (0.481681 --> 0.481644).  Saving model ...
Validation loss decreased (0.481644 --> 0.481606).  Saving model ...
Validation loss decreased (0.481606 --> 0.481569).  Saving model ...
Validation loss decreased (0.481569 --> 0.481532).  Saving model ...
Validation loss decreased (0.481532 --> 0.481495).  Saving model ...
Validation loss decreased (0.481495 --> 0.481458).  Saving model ...
Validation loss decreased (0.481458 --> 0.481421).  Saving model ...
Validation loss decreased (0.481421 --> 0.481384).  Saving model ...
Validation loss decreased (0.481384 --> 0.481347).  Saving model ...
Validation loss decreased (0.481347 --> 0.481310).  Saving model ...
Validation loss decreased (0.481310 --> 0.481274).  Saving model ...
Validation loss decreased (0.481274 --> 0.481237).  Saving model ...
Validation loss decreased (0.481237 --> 0.481201).  Saving model ...
Validation loss decreased (0.481201 --> 0.481164).  Saving model ...
Validation loss decreased (0.481164 --> 0.481128).  Saving model ...
Validation loss decreased (0.481128 --> 0.481092).  Saving model ...
Validation loss decreased (0.481092 --> 0.481055).  Saving model ...
Validation loss decreased (0.481055 --> 0.481019).  Saving model ...
Validation loss decreased (0.481019 --> 0.480983).  Saving model ...
Validation loss decreased (0.480983 --> 0.480947).  Saving model ...
Validation loss decreased (0.480947 --> 0.480911).  Saving model ...
Validation loss decreased (0.480911 --> 0.480875).  Saving model ...
Validation loss decreased (0.480875 --> 0.480839).  Saving model ...
Validation loss decreased (0.480839 --> 0.480804).  Saving model ...
Validation loss decreased (0.480804 --> 0.480768).  Saving model ...
Validation loss decreased (0.480768 --> 0.480732).  Saving model ...
Validation loss decreased (0.480732 --> 0.480697).  Saving model ...
Validation loss decreased (0.480697 --> 0.480661).  Saving model ...
Validation loss decreased (0.480661 --> 0.480626).  Saving model ...
Validation loss decreased (0.480626 --> 0.480590).  Saving model ...
Validation loss decreased (0.480590 --> 0.480555).  Saving model ...
Validation loss decreased (0.480555 --> 0.480520).  Saving model ...
Validation loss decreased (0.480520 --> 0.480484).  Saving model ...
Validation loss decreased (0.480484 --> 0.480449).  Saving model ...
Validation loss decreased (0.480449 --> 0.480414).  Saving model ...
Validation loss decreased (0.480414 --> 0.480379).  Saving model ...
Validation loss decreased (0.480379 --> 0.480344).  Saving model ...
Validation loss decreased (0.480344 --> 0.480309).  Saving model ...
Validation loss decreased (0.480309 --> 0.480274).  Saving model ...
Validation loss decreased (0.480274 --> 0.480239).  Saving model ...
Validation loss decreased (0.480239 --> 0.480204).  Saving model ...
Validation loss decreased (0.480204 --> 0.480169).  Saving model ...
Validation loss decreased (0.480169 --> 0.480135).  Saving model ...
Validation loss decreased (0.480135 --> 0.480100).  Saving model ...
Validation loss decreased (0.480100 --> 0.480065).  Saving model ...
Validation loss decreased (0.480065 --> 0.480031).  Saving model ...
Validation loss decreased (0.480031 --> 0.479996).  Saving model ...
Validation loss decreased (0.479996 --> 0.479962).  Saving model ...
Validation loss decreased (0.479962 --> 0.479927).  Saving model ...
Validation loss decreased (0.479927 --> 0.479893).  Saving model ...
Validation loss decreased (0.479893 --> 0.479858).  Saving model ...
Validation loss decreased (0.479858 --> 0.479824).  Saving model ...
Validation loss decreased (0.479824 --> 0.479790).  Saving model ...
Validation loss decreased (0.479790 --> 0.479755).  Saving model ...
Validation loss decreased (0.479755 --> 0.479721).  Saving model ...
Validation loss decreased (0.479721 --> 0.479687).  Saving model ...
Validation loss decreased (0.479687 --> 0.479653).  Saving model ...
Validation loss decreased (0.479653 --> 0.479619).  Saving model ...
Validation loss decreased (0.479619 --> 0.479585).  Saving model ...
Validation loss decreased (0.479585 --> 0.479551).  Saving model ...
Validation loss decreased (0.479551 --> 0.479517).  Saving model ...
Validation loss decreased (0.479517 --> 0.479483).  Saving model ...
Validation loss decreased (0.479483 --> 0.479449).  Saving model ...
Validation loss decreased (0.479449 --> 0.479415).  Saving model ...
Validation loss decreased (0.479415 --> 0.479381).  Saving model ...
Validation loss decreased (0.479381 --> 0.479347).  Saving model ...
Validation loss decreased (0.479347 --> 0.479313).  Saving model ...
Validation loss decreased (0.479313 --> 0.479279).  Saving model ...
Validation loss decreased (0.479279 --> 0.479246).  Saving model ...
Validation loss decreased (0.479246 --> 0.479212).  Saving model ...
Validation loss decreased (0.479212 --> 0.479178).  Saving model ...
Validation loss decreased (0.479178 --> 0.479144).  Saving model ...
Validation loss decreased (0.479144 --> 0.479111).  Saving model ...
Validation loss decreased (0.479111 --> 0.479077).  Saving model ...
Validation loss decreased (0.479077 --> 0.479043).  Saving model ...
Validation loss decreased (0.479043 --> 0.479010).  Saving model ...
Validation loss decreased (0.479010 --> 0.478976).  Saving model ...
Validation loss decreased (0.478976 --> 0.478942).  Saving model ...
epoch 1101, loss 0.4789, train acc 76.71%, f1 0.6344, precision 0.7024, recall 0.5784, auc 0.7234
Validation loss decreased (0.478942 --> 0.478909).  Saving model ...
Validation loss decreased (0.478909 --> 0.478875).  Saving model ...
Validation loss decreased (0.478875 --> 0.478842).  Saving model ...
Validation loss decreased (0.478842 --> 0.478808).  Saving model ...
Validation loss decreased (0.478808 --> 0.478775).  Saving model ...
Validation loss decreased (0.478775 --> 0.478741).  Saving model ...
Validation loss decreased (0.478741 --> 0.478708).  Saving model ...
Validation loss decreased (0.478708 --> 0.478674).  Saving model ...
Validation loss decreased (0.478674 --> 0.478641).  Saving model ...
Validation loss decreased (0.478641 --> 0.478607).  Saving model ...
Validation loss decreased (0.478607 --> 0.478574).  Saving model ...
Validation loss decreased (0.478574 --> 0.478540).  Saving model ...
Validation loss decreased (0.478540 --> 0.478507).  Saving model ...
Validation loss decreased (0.478507 --> 0.478473).  Saving model ...
Validation loss decreased (0.478473 --> 0.478440).  Saving model ...
Validation loss decreased (0.478440 --> 0.478407).  Saving model ...
Validation loss decreased (0.478407 --> 0.478373).  Saving model ...
Validation loss decreased (0.478373 --> 0.478340).  Saving model ...
Validation loss decreased (0.478340 --> 0.478306).  Saving model ...
Validation loss decreased (0.478306 --> 0.478273).  Saving model ...
Validation loss decreased (0.478273 --> 0.478239).  Saving model ...
Validation loss decreased (0.478239 --> 0.478206).  Saving model ...
Validation loss decreased (0.478206 --> 0.478172).  Saving model ...
Validation loss decreased (0.478172 --> 0.478139).  Saving model ...
Validation loss decreased (0.478139 --> 0.478105).  Saving model ...
Validation loss decreased (0.478105 --> 0.478072).  Saving model ...
Validation loss decreased (0.478072 --> 0.478038).  Saving model ...
Validation loss decreased (0.478038 --> 0.478005).  Saving model ...
Validation loss decreased (0.478005 --> 0.477971).  Saving model ...
Validation loss decreased (0.477971 --> 0.477938).  Saving model ...
Validation loss decreased (0.477938 --> 0.477904).  Saving model ...
Validation loss decreased (0.477904 --> 0.477871).  Saving model ...
Validation loss decreased (0.477871 --> 0.477837).  Saving model ...
Validation loss decreased (0.477837 --> 0.477804).  Saving model ...
Validation loss decreased (0.477804 --> 0.477770).  Saving model ...
Validation loss decreased (0.477770 --> 0.477736).  Saving model ...
Validation loss decreased (0.477736 --> 0.477703).  Saving model ...
Validation loss decreased (0.477703 --> 0.477669).  Saving model ...
Validation loss decreased (0.477669 --> 0.477635).  Saving model ...
Validation loss decreased (0.477635 --> 0.477602).  Saving model ...
Validation loss decreased (0.477602 --> 0.477568).  Saving model ...
Validation loss decreased (0.477568 --> 0.477534).  Saving model ...
Validation loss decreased (0.477534 --> 0.477500).  Saving model ...
Validation loss decreased (0.477500 --> 0.477466).  Saving model ...
Validation loss decreased (0.477466 --> 0.477433).  Saving model ...
Validation loss decreased (0.477433 --> 0.477399).  Saving model ...
Validation loss decreased (0.477399 --> 0.477365).  Saving model ...
Validation loss decreased (0.477365 --> 0.477331).  Saving model ...
Validation loss decreased (0.477331 --> 0.477297).  Saving model ...
Validation loss decreased (0.477297 --> 0.477263).  Saving model ...
Validation loss decreased (0.477263 --> 0.477229).  Saving model ...
Validation loss decreased (0.477229 --> 0.477195).  Saving model ...
Validation loss decreased (0.477195 --> 0.477161).  Saving model ...
Validation loss decreased (0.477161 --> 0.477127).  Saving model ...
Validation loss decreased (0.477127 --> 0.477092).  Saving model ...
Validation loss decreased (0.477092 --> 0.477058).  Saving model ...
Validation loss decreased (0.477058 --> 0.477024).  Saving model ...
Validation loss decreased (0.477024 --> 0.476990).  Saving model ...
Validation loss decreased (0.476990 --> 0.476955).  Saving model ...
Validation loss decreased (0.476955 --> 0.476921).  Saving model ...
Validation loss decreased (0.476921 --> 0.476886).  Saving model ...
Validation loss decreased (0.476886 --> 0.476852).  Saving model ...
Validation loss decreased (0.476852 --> 0.476817).  Saving model ...
Validation loss decreased (0.476817 --> 0.476783).  Saving model ...
Validation loss decreased (0.476783 --> 0.476748).  Saving model ...
Validation loss decreased (0.476748 --> 0.476714).  Saving model ...
Validation loss decreased (0.476714 --> 0.476679).  Saving model ...
Validation loss decreased (0.476679 --> 0.476644).  Saving model ...
Validation loss decreased (0.476644 --> 0.476609).  Saving model ...
Validation loss decreased (0.476609 --> 0.476574).  Saving model ...
Validation loss decreased (0.476574 --> 0.476539).  Saving model ...
Validation loss decreased (0.476539 --> 0.476504).  Saving model ...
Validation loss decreased (0.476504 --> 0.476469).  Saving model ...
Validation loss decreased (0.476469 --> 0.476434).  Saving model ...
Validation loss decreased (0.476434 --> 0.476399).  Saving model ...
Validation loss decreased (0.476399 --> 0.476364).  Saving model ...
Validation loss decreased (0.476364 --> 0.476328).  Saving model ...
Validation loss decreased (0.476328 --> 0.476293).  Saving model ...
Validation loss decreased (0.476293 --> 0.476258).  Saving model ...
Validation loss decreased (0.476258 --> 0.476222).  Saving model ...
Validation loss decreased (0.476222 --> 0.476187).  Saving model ...
Validation loss decreased (0.476187 --> 0.476151).  Saving model ...
Validation loss decreased (0.476151 --> 0.476115).  Saving model ...
Validation loss decreased (0.476115 --> 0.476079).  Saving model ...
Validation loss decreased (0.476079 --> 0.476044).  Saving model ...
Validation loss decreased (0.476044 --> 0.476008).  Saving model ...
Validation loss decreased (0.476008 --> 0.475972).  Saving model ...
Validation loss decreased (0.475972 --> 0.475936).  Saving model ...
Validation loss decreased (0.475936 --> 0.475900).  Saving model ...
Validation loss decreased (0.475900 --> 0.475863).  Saving model ...
Validation loss decreased (0.475863 --> 0.475827).  Saving model ...
Validation loss decreased (0.475827 --> 0.475791).  Saving model ...
Validation loss decreased (0.475791 --> 0.475754).  Saving model ...
Validation loss decreased (0.475754 --> 0.475718).  Saving model ...
Validation loss decreased (0.475718 --> 0.475681).  Saving model ...
Validation loss decreased (0.475681 --> 0.475645).  Saving model ...
Validation loss decreased (0.475645 --> 0.475608).  Saving model ...
Validation loss decreased (0.475608 --> 0.475571).  Saving model ...
Validation loss decreased (0.475571 --> 0.475534).  Saving model ...
Validation loss decreased (0.475534 --> 0.475497).  Saving model ...
epoch 1201, loss 0.4755, train acc 77.40%, f1 0.6452, precision 0.7143, recall 0.5882, auc 0.7310
Validation loss decreased (0.475497 --> 0.475460).  Saving model ...
Validation loss decreased (0.475460 --> 0.475423).  Saving model ...
Validation loss decreased (0.475423 --> 0.475386).  Saving model ...
Validation loss decreased (0.475386 --> 0.475349).  Saving model ...
Validation loss decreased (0.475349 --> 0.475311).  Saving model ...
Validation loss decreased (0.475311 --> 0.475274).  Saving model ...
Validation loss decreased (0.475274 --> 0.475236).  Saving model ...
Validation loss decreased (0.475236 --> 0.475199).  Saving model ...
Validation loss decreased (0.475199 --> 0.475161).  Saving model ...
Validation loss decreased (0.475161 --> 0.475123).  Saving model ...
Validation loss decreased (0.475123 --> 0.475085).  Saving model ...
Validation loss decreased (0.475085 --> 0.475047).  Saving model ...
Validation loss decreased (0.475047 --> 0.475009).  Saving model ...
Validation loss decreased (0.475009 --> 0.474971).  Saving model ...
Validation loss decreased (0.474971 --> 0.474933).  Saving model ...
Validation loss decreased (0.474933 --> 0.474894).  Saving model ...
Validation loss decreased (0.474894 --> 0.474856).  Saving model ...
Validation loss decreased (0.474856 --> 0.474817).  Saving model ...
Validation loss decreased (0.474817 --> 0.474778).  Saving model ...
Validation loss decreased (0.474778 --> 0.474740).  Saving model ...
Validation loss decreased (0.474740 --> 0.474701).  Saving model ...
Validation loss decreased (0.474701 --> 0.474662).  Saving model ...
Validation loss decreased (0.474662 --> 0.474623).  Saving model ...
Validation loss decreased (0.474623 --> 0.474584).  Saving model ...
Validation loss decreased (0.474584 --> 0.474545).  Saving model ...
Validation loss decreased (0.474545 --> 0.474505).  Saving model ...
Validation loss decreased (0.474505 --> 0.474466).  Saving model ...
Validation loss decreased (0.474466 --> 0.474426).  Saving model ...
Validation loss decreased (0.474426 --> 0.474387).  Saving model ...
Validation loss decreased (0.474387 --> 0.474347).  Saving model ...
Validation loss decreased (0.474347 --> 0.474307).  Saving model ...
Validation loss decreased (0.474307 --> 0.474267).  Saving model ...
Validation loss decreased (0.474267 --> 0.474227).  Saving model ...
Validation loss decreased (0.474227 --> 0.474187).  Saving model ...
Validation loss decreased (0.474187 --> 0.474147).  Saving model ...
Validation loss decreased (0.474147 --> 0.474107).  Saving model ...
Validation loss decreased (0.474107 --> 0.474066).  Saving model ...
Validation loss decreased (0.474066 --> 0.474026).  Saving model ...
Validation loss decreased (0.474026 --> 0.473985).  Saving model ...
Validation loss decreased (0.473985 --> 0.473944).  Saving model ...
Validation loss decreased (0.473944 --> 0.473903).  Saving model ...
Validation loss decreased (0.473903 --> 0.473862).  Saving model ...
Validation loss decreased (0.473862 --> 0.473821).  Saving model ...
Validation loss decreased (0.473821 --> 0.473780).  Saving model ...
Validation loss decreased (0.473780 --> 0.473739).  Saving model ...
Validation loss decreased (0.473739 --> 0.473698).  Saving model ...
Validation loss decreased (0.473698 --> 0.473656).  Saving model ...
Validation loss decreased (0.473656 --> 0.473615).  Saving model ...
Validation loss decreased (0.473615 --> 0.473573).  Saving model ...
Validation loss decreased (0.473573 --> 0.473531).  Saving model ...
Validation loss decreased (0.473531 --> 0.473489).  Saving model ...
Validation loss decreased (0.473489 --> 0.473447).  Saving model ...
Validation loss decreased (0.473447 --> 0.473405).  Saving model ...
Validation loss decreased (0.473405 --> 0.473363).  Saving model ...
Validation loss decreased (0.473363 --> 0.473321).  Saving model ...
Validation loss decreased (0.473321 --> 0.473279).  Saving model ...
Validation loss decreased (0.473279 --> 0.473236).  Saving model ...
Validation loss decreased (0.473236 --> 0.473193).  Saving model ...
Validation loss decreased (0.473193 --> 0.473151).  Saving model ...
Validation loss decreased (0.473151 --> 0.473108).  Saving model ...
Validation loss decreased (0.473108 --> 0.473065).  Saving model ...
Validation loss decreased (0.473065 --> 0.473022).  Saving model ...
Validation loss decreased (0.473022 --> 0.472979).  Saving model ...
Validation loss decreased (0.472979 --> 0.472936).  Saving model ...
Validation loss decreased (0.472936 --> 0.472892).  Saving model ...
Validation loss decreased (0.472892 --> 0.472849).  Saving model ...
Validation loss decreased (0.472849 --> 0.472806).  Saving model ...
Validation loss decreased (0.472806 --> 0.472762).  Saving model ...
Validation loss decreased (0.472762 --> 0.472718).  Saving model ...
Validation loss decreased (0.472718 --> 0.472674).  Saving model ...
Validation loss decreased (0.472674 --> 0.472630).  Saving model ...
Validation loss decreased (0.472630 --> 0.472586).  Saving model ...
Validation loss decreased (0.472586 --> 0.472542).  Saving model ...
Validation loss decreased (0.472542 --> 0.472498).  Saving model ...
Validation loss decreased (0.472498 --> 0.472454).  Saving model ...
Validation loss decreased (0.472454 --> 0.472409).  Saving model ...
Validation loss decreased (0.472409 --> 0.472365).  Saving model ...
Validation loss decreased (0.472365 --> 0.472320).  Saving model ...
Validation loss decreased (0.472320 --> 0.472275).  Saving model ...
Validation loss decreased (0.472275 --> 0.472231).  Saving model ...
Validation loss decreased (0.472231 --> 0.472186).  Saving model ...
Validation loss decreased (0.472186 --> 0.472141).  Saving model ...
Validation loss decreased (0.472141 --> 0.472096).  Saving model ...
Validation loss decreased (0.472096 --> 0.472050).  Saving model ...
Validation loss decreased (0.472050 --> 0.472005).  Saving model ...
Validation loss decreased (0.472005 --> 0.471960).  Saving model ...
Validation loss decreased (0.471960 --> 0.471914).  Saving model ...
Validation loss decreased (0.471914 --> 0.471869).  Saving model ...
Validation loss decreased (0.471869 --> 0.471823).  Saving model ...
Validation loss decreased (0.471823 --> 0.471777).  Saving model ...
Validation loss decreased (0.471777 --> 0.471731).  Saving model ...
Validation loss decreased (0.471731 --> 0.471685).  Saving model ...
Validation loss decreased (0.471685 --> 0.471639).  Saving model ...
Validation loss decreased (0.471639 --> 0.471593).  Saving model ...
Validation loss decreased (0.471593 --> 0.471547).  Saving model ...
Validation loss decreased (0.471547 --> 0.471500).  Saving model ...
Validation loss decreased (0.471500 --> 0.471454).  Saving model ...
Validation loss decreased (0.471454 --> 0.471407).  Saving model ...
Validation loss decreased (0.471407 --> 0.471361).  Saving model ...
Validation loss decreased (0.471361 --> 0.471314).  Saving model ...
epoch 1301, loss 0.4713, train acc 77.91%, f1 0.6560, precision 0.7193, recall 0.6029, auc 0.7383
Validation loss decreased (0.471314 --> 0.471267).  Saving model ...
Validation loss decreased (0.471267 --> 0.471220).  Saving model ...
Validation loss decreased (0.471220 --> 0.471173).  Saving model ...
Validation loss decreased (0.471173 --> 0.471126).  Saving model ...
Validation loss decreased (0.471126 --> 0.471079).  Saving model ...
Validation loss decreased (0.471079 --> 0.471032).  Saving model ...
Validation loss decreased (0.471032 --> 0.470984).  Saving model ...
Validation loss decreased (0.470984 --> 0.470937).  Saving model ...
Validation loss decreased (0.470937 --> 0.470889).  Saving model ...
Validation loss decreased (0.470889 --> 0.470842).  Saving model ...
Validation loss decreased (0.470842 --> 0.470794).  Saving model ...
Validation loss decreased (0.470794 --> 0.470746).  Saving model ...
Validation loss decreased (0.470746 --> 0.470698).  Saving model ...
Validation loss decreased (0.470698 --> 0.470650).  Saving model ...
Validation loss decreased (0.470650 --> 0.470602).  Saving model ...
Validation loss decreased (0.470602 --> 0.470554).  Saving model ...
Validation loss decreased (0.470554 --> 0.470506).  Saving model ...
Validation loss decreased (0.470506 --> 0.470458).  Saving model ...
Validation loss decreased (0.470458 --> 0.470409).  Saving model ...
Validation loss decreased (0.470409 --> 0.470361).  Saving model ...
Validation loss decreased (0.470361 --> 0.470312).  Saving model ...
Validation loss decreased (0.470312 --> 0.470264).  Saving model ...
Validation loss decreased (0.470264 --> 0.470215).  Saving model ...
Validation loss decreased (0.470215 --> 0.470166).  Saving model ...
Validation loss decreased (0.470166 --> 0.470117).  Saving model ...
Validation loss decreased (0.470117 --> 0.470068).  Saving model ...
Validation loss decreased (0.470068 --> 0.470020).  Saving model ...
Validation loss decreased (0.470020 --> 0.469970).  Saving model ...
Validation loss decreased (0.469970 --> 0.469921).  Saving model ...
Validation loss decreased (0.469921 --> 0.469872).  Saving model ...
Validation loss decreased (0.469872 --> 0.469823).  Saving model ...
Validation loss decreased (0.469823 --> 0.469773).  Saving model ...
Validation loss decreased (0.469773 --> 0.469724).  Saving model ...
Validation loss decreased (0.469724 --> 0.469674).  Saving model ...
Validation loss decreased (0.469674 --> 0.469625).  Saving model ...
Validation loss decreased (0.469625 --> 0.469575).  Saving model ...
Validation loss decreased (0.469575 --> 0.469525).  Saving model ...
Validation loss decreased (0.469525 --> 0.469475).  Saving model ...
Validation loss decreased (0.469475 --> 0.469425).  Saving model ...
Validation loss decreased (0.469425 --> 0.469375).  Saving model ...
Validation loss decreased (0.469375 --> 0.469325).  Saving model ...
Validation loss decreased (0.469325 --> 0.469275).  Saving model ...
Validation loss decreased (0.469275 --> 0.469225).  Saving model ...
Validation loss decreased (0.469225 --> 0.469175).  Saving model ...
Validation loss decreased (0.469175 --> 0.469124).  Saving model ...
Validation loss decreased (0.469124 --> 0.469074).  Saving model ...
Validation loss decreased (0.469074 --> 0.469023).  Saving model ...
Validation loss decreased (0.469023 --> 0.468973).  Saving model ...
Validation loss decreased (0.468973 --> 0.468922).  Saving model ...
Validation loss decreased (0.468922 --> 0.468872).  Saving model ...
Validation loss decreased (0.468872 --> 0.468821).  Saving model ...
Validation loss decreased (0.468821 --> 0.468770).  Saving model ...
Validation loss decreased (0.468770 --> 0.468719).  Saving model ...
Validation loss decreased (0.468719 --> 0.468668).  Saving model ...
Validation loss decreased (0.468668 --> 0.468617).  Saving model ...
Validation loss decreased (0.468617 --> 0.468566).  Saving model ...
Validation loss decreased (0.468566 --> 0.468515).  Saving model ...
Validation loss decreased (0.468515 --> 0.468464).  Saving model ...
Validation loss decreased (0.468464 --> 0.468412).  Saving model ...
Validation loss decreased (0.468412 --> 0.468361).  Saving model ...
Validation loss decreased (0.468361 --> 0.468310).  Saving model ...
Validation loss decreased (0.468310 --> 0.468258).  Saving model ...
Validation loss decreased (0.468258 --> 0.468206).  Saving model ...
Validation loss decreased (0.468206 --> 0.468155).  Saving model ...
Validation loss decreased (0.468155 --> 0.468103).  Saving model ...
Validation loss decreased (0.468103 --> 0.468051).  Saving model ...
Validation loss decreased (0.468051 --> 0.468000).  Saving model ...
Validation loss decreased (0.468000 --> 0.467948).  Saving model ...
Validation loss decreased (0.467948 --> 0.467896).  Saving model ...
Validation loss decreased (0.467896 --> 0.467844).  Saving model ...
Validation loss decreased (0.467844 --> 0.467792).  Saving model ...
Validation loss decreased (0.467792 --> 0.467740).  Saving model ...
Validation loss decreased (0.467740 --> 0.467688).  Saving model ...
Validation loss decreased (0.467688 --> 0.467635).  Saving model ...
Validation loss decreased (0.467635 --> 0.467583).  Saving model ...
Validation loss decreased (0.467583 --> 0.467531).  Saving model ...
Validation loss decreased (0.467531 --> 0.467478).  Saving model ...
Validation loss decreased (0.467478 --> 0.467426).  Saving model ...
Validation loss decreased (0.467426 --> 0.467373).  Saving model ...
Validation loss decreased (0.467373 --> 0.467321).  Saving model ...
Validation loss decreased (0.467321 --> 0.467268).  Saving model ...
Validation loss decreased (0.467268 --> 0.467216).  Saving model ...
Validation loss decreased (0.467216 --> 0.467163).  Saving model ...
Validation loss decreased (0.467163 --> 0.467110).  Saving model ...
Validation loss decreased (0.467110 --> 0.467057).  Saving model ...
Validation loss decreased (0.467057 --> 0.467004).  Saving model ...
Validation loss decreased (0.467004 --> 0.466951).  Saving model ...
Validation loss decreased (0.466951 --> 0.466898).  Saving model ...
Validation loss decreased (0.466898 --> 0.466845).  Saving model ...
Validation loss decreased (0.466845 --> 0.466792).  Saving model ...
Validation loss decreased (0.466792 --> 0.466739).  Saving model ...
Validation loss decreased (0.466739 --> 0.466686).  Saving model ...
Validation loss decreased (0.466686 --> 0.466632).  Saving model ...
Validation loss decreased (0.466632 --> 0.466579).  Saving model ...
Validation loss decreased (0.466579 --> 0.466526).  Saving model ...
Validation loss decreased (0.466526 --> 0.466472).  Saving model ...
Validation loss decreased (0.466472 --> 0.466419).  Saving model ...
Validation loss decreased (0.466419 --> 0.466365).  Saving model ...
Validation loss decreased (0.466365 --> 0.466312).  Saving model ...
Validation loss decreased (0.466312 --> 0.466258).  Saving model ...
epoch 1401, loss 0.4663, train acc 77.74%, f1 0.6505, precision 0.7202, recall 0.5931, auc 0.7347
Validation loss decreased (0.466258 --> 0.466204).  Saving model ...
Validation loss decreased (0.466204 --> 0.466151).  Saving model ...
Validation loss decreased (0.466151 --> 0.466097).  Saving model ...
Validation loss decreased (0.466097 --> 0.466043).  Saving model ...
Validation loss decreased (0.466043 --> 0.465989).  Saving model ...
Validation loss decreased (0.465989 --> 0.465935).  Saving model ...
Validation loss decreased (0.465935 --> 0.465881).  Saving model ...
Validation loss decreased (0.465881 --> 0.465827).  Saving model ...
Validation loss decreased (0.465827 --> 0.465773).  Saving model ...
Validation loss decreased (0.465773 --> 0.465719).  Saving model ...
Validation loss decreased (0.465719 --> 0.465665).  Saving model ...
Validation loss decreased (0.465665 --> 0.465611).  Saving model ...
Validation loss decreased (0.465611 --> 0.465557).  Saving model ...
Validation loss decreased (0.465557 --> 0.465502).  Saving model ...
Validation loss decreased (0.465502 --> 0.465448).  Saving model ...
Validation loss decreased (0.465448 --> 0.465394).  Saving model ...
Validation loss decreased (0.465394 --> 0.465339).  Saving model ...
Validation loss decreased (0.465339 --> 0.465285).  Saving model ...
Validation loss decreased (0.465285 --> 0.465230).  Saving model ...
Validation loss decreased (0.465230 --> 0.465176).  Saving model ...
Validation loss decreased (0.465176 --> 0.465121).  Saving model ...
Validation loss decreased (0.465121 --> 0.465067).  Saving model ...
Validation loss decreased (0.465067 --> 0.465012).  Saving model ...
Validation loss decreased (0.465012 --> 0.464957).  Saving model ...
Validation loss decreased (0.464957 --> 0.464903).  Saving model ...
Validation loss decreased (0.464903 --> 0.464848).  Saving model ...
Validation loss decreased (0.464848 --> 0.464793).  Saving model ...
Validation loss decreased (0.464793 --> 0.464738).  Saving model ...
Validation loss decreased (0.464738 --> 0.464683).  Saving model ...
Validation loss decreased (0.464683 --> 0.464628).  Saving model ...
Validation loss decreased (0.464628 --> 0.464573).  Saving model ...
Validation loss decreased (0.464573 --> 0.464518).  Saving model ...
Validation loss decreased (0.464518 --> 0.464463).  Saving model ...
Validation loss decreased (0.464463 --> 0.464408).  Saving model ...
Validation loss decreased (0.464408 --> 0.464353).  Saving model ...
Validation loss decreased (0.464353 --> 0.464298).  Saving model ...
Validation loss decreased (0.464298 --> 0.464243).  Saving model ...
Validation loss decreased (0.464243 --> 0.464188).  Saving model ...
Validation loss decreased (0.464188 --> 0.464132).  Saving model ...
Validation loss decreased (0.464132 --> 0.464077).  Saving model ...
Validation loss decreased (0.464077 --> 0.464022).  Saving model ...
Validation loss decreased (0.464022 --> 0.463967).  Saving model ...
Validation loss decreased (0.463967 --> 0.463911).  Saving model ...
Validation loss decreased (0.463911 --> 0.463856).  Saving model ...
Validation loss decreased (0.463856 --> 0.463800).  Saving model ...
Validation loss decreased (0.463800 --> 0.463745).  Saving model ...
Validation loss decreased (0.463745 --> 0.463689).  Saving model ...
Validation loss decreased (0.463689 --> 0.463634).  Saving model ...
Validation loss decreased (0.463634 --> 0.463578).  Saving model ...
Validation loss decreased (0.463578 --> 0.463523).  Saving model ...
Validation loss decreased (0.463523 --> 0.463467).  Saving model ...
Validation loss decreased (0.463467 --> 0.463411).  Saving model ...
Validation loss decreased (0.463411 --> 0.463356).  Saving model ...
Validation loss decreased (0.463356 --> 0.463300).  Saving model ...
Validation loss decreased (0.463300 --> 0.463244).  Saving model ...
Validation loss decreased (0.463244 --> 0.463189).  Saving model ...
Validation loss decreased (0.463189 --> 0.463133).  Saving model ...
Validation loss decreased (0.463133 --> 0.463077).  Saving model ...
Validation loss decreased (0.463077 --> 0.463021).  Saving model ...
Validation loss decreased (0.463021 --> 0.462965).  Saving model ...
Validation loss decreased (0.462965 --> 0.462910).  Saving model ...
Validation loss decreased (0.462910 --> 0.462854).  Saving model ...
Validation loss decreased (0.462854 --> 0.462798).  Saving model ...
Validation loss decreased (0.462798 --> 0.462742).  Saving model ...
Validation loss decreased (0.462742 --> 0.462686).  Saving model ...
Validation loss decreased (0.462686 --> 0.462630).  Saving model ...
Validation loss decreased (0.462630 --> 0.462574).  Saving model ...
Validation loss decreased (0.462574 --> 0.462518).  Saving model ...
Validation loss decreased (0.462518 --> 0.462462).  Saving model ...
Validation loss decreased (0.462462 --> 0.462406).  Saving model ...
Validation loss decreased (0.462406 --> 0.462350).  Saving model ...
Validation loss decreased (0.462350 --> 0.462294).  Saving model ...
Validation loss decreased (0.462294 --> 0.462238).  Saving model ...
Validation loss decreased (0.462238 --> 0.462181).  Saving model ...
Validation loss decreased (0.462181 --> 0.462125).  Saving model ...
Validation loss decreased (0.462125 --> 0.462069).  Saving model ...
Validation loss decreased (0.462069 --> 0.462013).  Saving model ...
Validation loss decreased (0.462013 --> 0.461957).  Saving model ...
Validation loss decreased (0.461957 --> 0.461901).  Saving model ...
Validation loss decreased (0.461901 --> 0.461844).  Saving model ...
Validation loss decreased (0.461844 --> 0.461788).  Saving model ...
Validation loss decreased (0.461788 --> 0.461732).  Saving model ...
Validation loss decreased (0.461732 --> 0.461676).  Saving model ...
Validation loss decreased (0.461676 --> 0.461619).  Saving model ...
Validation loss decreased (0.461619 --> 0.461563).  Saving model ...
Validation loss decreased (0.461563 --> 0.461507).  Saving model ...
Validation loss decreased (0.461507 --> 0.461451).  Saving model ...
Validation loss decreased (0.461451 --> 0.461394).  Saving model ...
Validation loss decreased (0.461394 --> 0.461338).  Saving model ...
Validation loss decreased (0.461338 --> 0.461282).  Saving model ...
Validation loss decreased (0.461282 --> 0.461225).  Saving model ...
Validation loss decreased (0.461225 --> 0.461169).  Saving model ...
Validation loss decreased (0.461169 --> 0.461113).  Saving model ...
Validation loss decreased (0.461113 --> 0.461056).  Saving model ...
Validation loss decreased (0.461056 --> 0.461000).  Saving model ...
Validation loss decreased (0.461000 --> 0.460944).  Saving model ...
Validation loss decreased (0.460944 --> 0.460887).  Saving model ...
Validation loss decreased (0.460887 --> 0.460831).  Saving model ...
Validation loss decreased (0.460831 --> 0.460775).  Saving model ...
Validation loss decreased (0.460775 --> 0.460718).  Saving model ...
epoch 1501, loss 0.4607, train acc 78.60%, f1 0.6594, precision 0.7423, recall 0.5931, auc 0.7413
Validation loss decreased (0.460718 --> 0.460662).  Saving model ...
Validation loss decreased (0.460662 --> 0.460606).  Saving model ...
Validation loss decreased (0.460606 --> 0.460549).  Saving model ...
Validation loss decreased (0.460549 --> 0.460493).  Saving model ...
Validation loss decreased (0.460493 --> 0.460437).  Saving model ...
Validation loss decreased (0.460437 --> 0.460380).  Saving model ...
Validation loss decreased (0.460380 --> 0.460324).  Saving model ...
Validation loss decreased (0.460324 --> 0.460268).  Saving model ...
Validation loss decreased (0.460268 --> 0.460211).  Saving model ...
Validation loss decreased (0.460211 --> 0.460155).  Saving model ...
Validation loss decreased (0.460155 --> 0.460099).  Saving model ...
Validation loss decreased (0.460099 --> 0.460042).  Saving model ...
Validation loss decreased (0.460042 --> 0.459986).  Saving model ...
Validation loss decreased (0.459986 --> 0.459930).  Saving model ...
Validation loss decreased (0.459930 --> 0.459873).  Saving model ...
Validation loss decreased (0.459873 --> 0.459817).  Saving model ...
Validation loss decreased (0.459817 --> 0.459761).  Saving model ...
Validation loss decreased (0.459761 --> 0.459704).  Saving model ...
Validation loss decreased (0.459704 --> 0.459648).  Saving model ...
Validation loss decreased (0.459648 --> 0.459592).  Saving model ...
Validation loss decreased (0.459592 --> 0.459536).  Saving model ...
Validation loss decreased (0.459536 --> 0.459480).  Saving model ...
Validation loss decreased (0.459480 --> 0.459423).  Saving model ...
Validation loss decreased (0.459423 --> 0.459367).  Saving model ...
Validation loss decreased (0.459367 --> 0.459311).  Saving model ...
Validation loss decreased (0.459311 --> 0.459255).  Saving model ...
Validation loss decreased (0.459255 --> 0.459199).  Saving model ...
Validation loss decreased (0.459199 --> 0.459143).  Saving model ...
Validation loss decreased (0.459143 --> 0.459086).  Saving model ...
Validation loss decreased (0.459086 --> 0.459030).  Saving model ...
Validation loss decreased (0.459030 --> 0.458974).  Saving model ...
Validation loss decreased (0.458974 --> 0.458918).  Saving model ...
Validation loss decreased (0.458918 --> 0.458862).  Saving model ...
Validation loss decreased (0.458862 --> 0.458806).  Saving model ...
Validation loss decreased (0.458806 --> 0.458750).  Saving model ...
Validation loss decreased (0.458750 --> 0.458694).  Saving model ...
Validation loss decreased (0.458694 --> 0.458638).  Saving model ...
Validation loss decreased (0.458638 --> 0.458582).  Saving model ...
Validation loss decreased (0.458582 --> 0.458526).  Saving model ...
Validation loss decreased (0.458526 --> 0.458470).  Saving model ...
Validation loss decreased (0.458470 --> 0.458415).  Saving model ...
Validation loss decreased (0.458415 --> 0.458359).  Saving model ...
Validation loss decreased (0.458359 --> 0.458303).  Saving model ...
Validation loss decreased (0.458303 --> 0.458247).  Saving model ...
Validation loss decreased (0.458247 --> 0.458191).  Saving model ...
Validation loss decreased (0.458191 --> 0.458136).  Saving model ...
Validation loss decreased (0.458136 --> 0.458080).  Saving model ...
Validation loss decreased (0.458080 --> 0.458024).  Saving model ...
Validation loss decreased (0.458024 --> 0.457969).  Saving model ...
Validation loss decreased (0.457969 --> 0.457913).  Saving model ...
Validation loss decreased (0.457913 --> 0.457857).  Saving model ...
Validation loss decreased (0.457857 --> 0.457802).  Saving model ...
Validation loss decreased (0.457802 --> 0.457746).  Saving model ...
Validation loss decreased (0.457746 --> 0.457691).  Saving model ...
Validation loss decreased (0.457691 --> 0.457635).  Saving model ...
Validation loss decreased (0.457635 --> 0.457580).  Saving model ...
Validation loss decreased (0.457580 --> 0.457524).  Saving model ...
Validation loss decreased (0.457524 --> 0.457469).  Saving model ...
Validation loss decreased (0.457469 --> 0.457414).  Saving model ...
Validation loss decreased (0.457414 --> 0.457358).  Saving model ...
Validation loss decreased (0.457358 --> 0.457303).  Saving model ...
Validation loss decreased (0.457303 --> 0.457248).  Saving model ...
Validation loss decreased (0.457248 --> 0.457193).  Saving model ...
Validation loss decreased (0.457193 --> 0.457137).  Saving model ...
Validation loss decreased (0.457137 --> 0.457082).  Saving model ...
Validation loss decreased (0.457082 --> 0.457027).  Saving model ...
Validation loss decreased (0.457027 --> 0.456972).  Saving model ...
Validation loss decreased (0.456972 --> 0.456917).  Saving model ...
Validation loss decreased (0.456917 --> 0.456862).  Saving model ...
Validation loss decreased (0.456862 --> 0.456807).  Saving model ...
Validation loss decreased (0.456807 --> 0.456752).  Saving model ...
Validation loss decreased (0.456752 --> 0.456697).  Saving model ...
Validation loss decreased (0.456697 --> 0.456643).  Saving model ...
Validation loss decreased (0.456643 --> 0.456588).  Saving model ...
Validation loss decreased (0.456588 --> 0.456533).  Saving model ...
Validation loss decreased (0.456533 --> 0.456478).  Saving model ...
Validation loss decreased (0.456478 --> 0.456424).  Saving model ...
Validation loss decreased (0.456424 --> 0.456369).  Saving model ...
Validation loss decreased (0.456369 --> 0.456314).  Saving model ...
Validation loss decreased (0.456314 --> 0.456260).  Saving model ...
Validation loss decreased (0.456260 --> 0.456205).  Saving model ...
Validation loss decreased (0.456205 --> 0.456151).  Saving model ...
Validation loss decreased (0.456151 --> 0.456096).  Saving model ...
Validation loss decreased (0.456096 --> 0.456042).  Saving model ...
Validation loss decreased (0.456042 --> 0.455988).  Saving model ...
Validation loss decreased (0.455988 --> 0.455933).  Saving model ...
Validation loss decreased (0.455933 --> 0.455879).  Saving model ...
Validation loss decreased (0.455879 --> 0.455825).  Saving model ...
Validation loss decreased (0.455825 --> 0.455771).  Saving model ...
Validation loss decreased (0.455771 --> 0.455716).  Saving model ...
Validation loss decreased (0.455716 --> 0.455662).  Saving model ...
Validation loss decreased (0.455662 --> 0.455608).  Saving model ...
Validation loss decreased (0.455608 --> 0.455554).  Saving model ...
Validation loss decreased (0.455554 --> 0.455500).  Saving model ...
Validation loss decreased (0.455500 --> 0.455446).  Saving model ...
Validation loss decreased (0.455446 --> 0.455393).  Saving model ...
Validation loss decreased (0.455393 --> 0.455339).  Saving model ...
Validation loss decreased (0.455339 --> 0.455285).  Saving model ...
Validation loss decreased (0.455285 --> 0.455231).  Saving model ...
Validation loss decreased (0.455231 --> 0.455177).  Saving model ...
epoch 1601, loss 0.4552, train acc 78.25%, f1 0.6577, precision 0.7305, recall 0.5980, auc 0.7398
Validation loss decreased (0.455177 --> 0.455124).  Saving model ...
Validation loss decreased (0.455124 --> 0.455070).  Saving model ...
Validation loss decreased (0.455070 --> 0.455017).  Saving model ...
Validation loss decreased (0.455017 --> 0.454963).  Saving model ...
Validation loss decreased (0.454963 --> 0.454910).  Saving model ...
Validation loss decreased (0.454910 --> 0.454856).  Saving model ...
Validation loss decreased (0.454856 --> 0.454803).  Saving model ...
Validation loss decreased (0.454803 --> 0.454749).  Saving model ...
Validation loss decreased (0.454749 --> 0.454696).  Saving model ...
Validation loss decreased (0.454696 --> 0.454643).  Saving model ...
Validation loss decreased (0.454643 --> 0.454590).  Saving model ...
Validation loss decreased (0.454590 --> 0.454537).  Saving model ...
Validation loss decreased (0.454537 --> 0.454484).  Saving model ...
Validation loss decreased (0.454484 --> 0.454430).  Saving model ...
Validation loss decreased (0.454430 --> 0.454377).  Saving model ...
Validation loss decreased (0.454377 --> 0.454325).  Saving model ...
Validation loss decreased (0.454325 --> 0.454272).  Saving model ...
Validation loss decreased (0.454272 --> 0.454219).  Saving model ...
Validation loss decreased (0.454219 --> 0.454166).  Saving model ...
Validation loss decreased (0.454166 --> 0.454113).  Saving model ...
Validation loss decreased (0.454113 --> 0.454060).  Saving model ...
Validation loss decreased (0.454060 --> 0.454008).  Saving model ...
Validation loss decreased (0.454008 --> 0.453955).  Saving model ...
Validation loss decreased (0.453955 --> 0.453903).  Saving model ...
Validation loss decreased (0.453903 --> 0.453850).  Saving model ...
Validation loss decreased (0.453850 --> 0.453798).  Saving model ...
Validation loss decreased (0.453798 --> 0.453745).  Saving model ...
Validation loss decreased (0.453745 --> 0.453693).  Saving model ...
Validation loss decreased (0.453693 --> 0.453641).  Saving model ...
Validation loss decreased (0.453641 --> 0.453588).  Saving model ...
Validation loss decreased (0.453588 --> 0.453536).  Saving model ...
Validation loss decreased (0.453536 --> 0.453484).  Saving model ...
Validation loss decreased (0.453484 --> 0.453432).  Saving model ...
Validation loss decreased (0.453432 --> 0.453380).  Saving model ...
Validation loss decreased (0.453380 --> 0.453328).  Saving model ...
Validation loss decreased (0.453328 --> 0.453276).  Saving model ...
Validation loss decreased (0.453276 --> 0.453224).  Saving model ...
Validation loss decreased (0.453224 --> 0.453172).  Saving model ...
Validation loss decreased (0.453172 --> 0.453120).  Saving model ...
Validation loss decreased (0.453120 --> 0.453069).  Saving model ...
Validation loss decreased (0.453069 --> 0.453017).  Saving model ...
Validation loss decreased (0.453017 --> 0.452965).  Saving model ...
Validation loss decreased (0.452965 --> 0.452914).  Saving model ...
Validation loss decreased (0.452914 --> 0.452862).  Saving model ...
Validation loss decreased (0.452862 --> 0.452811).  Saving model ...
Validation loss decreased (0.452811 --> 0.452759).  Saving model ...
Validation loss decreased (0.452759 --> 0.452708).  Saving model ...
Validation loss decreased (0.452708 --> 0.452657).  Saving model ...
Validation loss decreased (0.452657 --> 0.452605).  Saving model ...
Validation loss decreased (0.452605 --> 0.452554).  Saving model ...
Validation loss decreased (0.452554 --> 0.452503).  Saving model ...
Validation loss decreased (0.452503 --> 0.452452).  Saving model ...
Validation loss decreased (0.452452 --> 0.452401).  Saving model ...
Validation loss decreased (0.452401 --> 0.452350).  Saving model ...
Validation loss decreased (0.452350 --> 0.452299).  Saving model ...
Validation loss decreased (0.452299 --> 0.452248).  Saving model ...
Validation loss decreased (0.452248 --> 0.452197).  Saving model ...
Validation loss decreased (0.452197 --> 0.452146).  Saving model ...
Validation loss decreased (0.452146 --> 0.452096).  Saving model ...
Validation loss decreased (0.452096 --> 0.452045).  Saving model ...
Validation loss decreased (0.452045 --> 0.451994).  Saving model ...
Validation loss decreased (0.451994 --> 0.451944).  Saving model ...
Validation loss decreased (0.451944 --> 0.451893).  Saving model ...
Validation loss decreased (0.451893 --> 0.451843).  Saving model ...
Validation loss decreased (0.451843 --> 0.451792).  Saving model ...
Validation loss decreased (0.451792 --> 0.451742).  Saving model ...
Validation loss decreased (0.451742 --> 0.451692).  Saving model ...
Validation loss decreased (0.451692 --> 0.451641).  Saving model ...
Validation loss decreased (0.451641 --> 0.451591).  Saving model ...
Validation loss decreased (0.451591 --> 0.451541).  Saving model ...
Validation loss decreased (0.451541 --> 0.451491).  Saving model ...
Validation loss decreased (0.451491 --> 0.451441).  Saving model ...
Validation loss decreased (0.451441 --> 0.451391).  Saving model ...
Validation loss decreased (0.451391 --> 0.451341).  Saving model ...
Validation loss decreased (0.451341 --> 0.451291).  Saving model ...
Validation loss decreased (0.451291 --> 0.451241).  Saving model ...
Validation loss decreased (0.451241 --> 0.451191).  Saving model ...
Validation loss decreased (0.451191 --> 0.451142).  Saving model ...
Validation loss decreased (0.451142 --> 0.451092).  Saving model ...
Validation loss decreased (0.451092 --> 0.451043).  Saving model ...
Validation loss decreased (0.451043 --> 0.450993).  Saving model ...
Validation loss decreased (0.450993 --> 0.450943).  Saving model ...
Validation loss decreased (0.450943 --> 0.450894).  Saving model ...
Validation loss decreased (0.450894 --> 0.450845).  Saving model ...
Validation loss decreased (0.450845 --> 0.450795).  Saving model ...
Validation loss decreased (0.450795 --> 0.450746).  Saving model ...
Validation loss decreased (0.450746 --> 0.450697).  Saving model ...
Validation loss decreased (0.450697 --> 0.450648).  Saving model ...
Validation loss decreased (0.450648 --> 0.450599).  Saving model ...
Validation loss decreased (0.450599 --> 0.450550).  Saving model ...
Validation loss decreased (0.450550 --> 0.450501).  Saving model ...
Validation loss decreased (0.450501 --> 0.450452).  Saving model ...
Validation loss decreased (0.450452 --> 0.450403).  Saving model ...
Validation loss decreased (0.450403 --> 0.450354).  Saving model ...
Validation loss decreased (0.450354 --> 0.450305).  Saving model ...
Validation loss decreased (0.450305 --> 0.450256).  Saving model ...
Validation loss decreased (0.450256 --> 0.450208).  Saving model ...
Validation loss decreased (0.450208 --> 0.450159).  Saving model ...
Validation loss decreased (0.450159 --> 0.450111).  Saving model ...
Validation loss decreased (0.450111 --> 0.450062).  Saving model ...
epoch 1701, loss 0.4501, train acc 78.08%, f1 0.6578, precision 0.7235, recall 0.6029, auc 0.7396
Validation loss decreased (0.450062 --> 0.450014).  Saving model ...
Validation loss decreased (0.450014 --> 0.449965).  Saving model ...
Validation loss decreased (0.449965 --> 0.449917).  Saving model ...
Validation loss decreased (0.449917 --> 0.449869).  Saving model ...
Validation loss decreased (0.449869 --> 0.449820).  Saving model ...
Validation loss decreased (0.449820 --> 0.449772).  Saving model ...
Validation loss decreased (0.449772 --> 0.449724).  Saving model ...
Validation loss decreased (0.449724 --> 0.449676).  Saving model ...
Validation loss decreased (0.449676 --> 0.449628).  Saving model ...
Validation loss decreased (0.449628 --> 0.449580).  Saving model ...
Validation loss decreased (0.449580 --> 0.449532).  Saving model ...
Validation loss decreased (0.449532 --> 0.449485).  Saving model ...
Validation loss decreased (0.449485 --> 0.449437).  Saving model ...
Validation loss decreased (0.449437 --> 0.449389).  Saving model ...
Validation loss decreased (0.449389 --> 0.449342).  Saving model ...
Validation loss decreased (0.449342 --> 0.449294).  Saving model ...
Validation loss decreased (0.449294 --> 0.449246).  Saving model ...
Validation loss decreased (0.449246 --> 0.449199).  Saving model ...
Validation loss decreased (0.449199 --> 0.449151).  Saving model ...
Validation loss decreased (0.449151 --> 0.449104).  Saving model ...
Validation loss decreased (0.449104 --> 0.449057).  Saving model ...
Validation loss decreased (0.449057 --> 0.449010).  Saving model ...
Validation loss decreased (0.449010 --> 0.448962).  Saving model ...
Validation loss decreased (0.448962 --> 0.448915).  Saving model ...
Validation loss decreased (0.448915 --> 0.448868).  Saving model ...
Validation loss decreased (0.448868 --> 0.448821).  Saving model ...
Validation loss decreased (0.448821 --> 0.448774).  Saving model ...
Validation loss decreased (0.448774 --> 0.448727).  Saving model ...
Validation loss decreased (0.448727 --> 0.448680).  Saving model ...
Validation loss decreased (0.448680 --> 0.448633).  Saving model ...
Validation loss decreased (0.448633 --> 0.448587).  Saving model ...
Validation loss decreased (0.448587 --> 0.448540).  Saving model ...
Validation loss decreased (0.448540 --> 0.448493).  Saving model ...
Validation loss decreased (0.448493 --> 0.448447).  Saving model ...
Validation loss decreased (0.448447 --> 0.448400).  Saving model ...
Validation loss decreased (0.448400 --> 0.448354).  Saving model ...
Validation loss decreased (0.448354 --> 0.448307).  Saving model ...
Validation loss decreased (0.448307 --> 0.448261).  Saving model ...
Validation loss decreased (0.448261 --> 0.448215).  Saving model ...
Validation loss decreased (0.448215 --> 0.448169).  Saving model ...
Validation loss decreased (0.448169 --> 0.448122).  Saving model ...
Validation loss decreased (0.448122 --> 0.448076).  Saving model ...
Validation loss decreased (0.448076 --> 0.448030).  Saving model ...
Validation loss decreased (0.448030 --> 0.447984).  Saving model ...
Validation loss decreased (0.447984 --> 0.447938).  Saving model ...
Validation loss decreased (0.447938 --> 0.447892).  Saving model ...
Validation loss decreased (0.447892 --> 0.447846).  Saving model ...
Validation loss decreased (0.447846 --> 0.447801).  Saving model ...
Validation loss decreased (0.447801 --> 0.447755).  Saving model ...
Validation loss decreased (0.447755 --> 0.447709).  Saving model ...
Validation loss decreased (0.447709 --> 0.447663).  Saving model ...
Validation loss decreased (0.447663 --> 0.447618).  Saving model ...
Validation loss decreased (0.447618 --> 0.447572).  Saving model ...
Validation loss decreased (0.447572 --> 0.447527).  Saving model ...
Validation loss decreased (0.447527 --> 0.447481).  Saving model ...
Validation loss decreased (0.447481 --> 0.447436).  Saving model ...
Validation loss decreased (0.447436 --> 0.447391).  Saving model ...
Validation loss decreased (0.447391 --> 0.447346).  Saving model ...
Validation loss decreased (0.447346 --> 0.447300).  Saving model ...
Validation loss decreased (0.447300 --> 0.447255).  Saving model ...
Validation loss decreased (0.447255 --> 0.447210).  Saving model ...
Validation loss decreased (0.447210 --> 0.447165).  Saving model ...
Validation loss decreased (0.447165 --> 0.447120).  Saving model ...
Validation loss decreased (0.447120 --> 0.447075).  Saving model ...
Validation loss decreased (0.447075 --> 0.447030).  Saving model ...
Validation loss decreased (0.447030 --> 0.446985).  Saving model ...
Validation loss decreased (0.446985 --> 0.446941).  Saving model ...
Validation loss decreased (0.446941 --> 0.446896).  Saving model ...
Validation loss decreased (0.446896 --> 0.446851).  Saving model ...
Validation loss decreased (0.446851 --> 0.446807).  Saving model ...
Validation loss decreased (0.446807 --> 0.446762).  Saving model ...
Validation loss decreased (0.446762 --> 0.446718).  Saving model ...
Validation loss decreased (0.446718 --> 0.446673).  Saving model ...
Validation loss decreased (0.446673 --> 0.446629).  Saving model ...
Validation loss decreased (0.446629 --> 0.446585).  Saving model ...
Validation loss decreased (0.446585 --> 0.446540).  Saving model ...
Validation loss decreased (0.446540 --> 0.446496).  Saving model ...
Validation loss decreased (0.446496 --> 0.446452).  Saving model ...
Validation loss decreased (0.446452 --> 0.446408).  Saving model ...
Validation loss decreased (0.446408 --> 0.446364).  Saving model ...
Validation loss decreased (0.446364 --> 0.446320).  Saving model ...
Validation loss decreased (0.446320 --> 0.446276).  Saving model ...
Validation loss decreased (0.446276 --> 0.446232).  Saving model ...
Validation loss decreased (0.446232 --> 0.446188).  Saving model ...
Validation loss decreased (0.446188 --> 0.446144).  Saving model ...
Validation loss decreased (0.446144 --> 0.446101).  Saving model ...
Validation loss decreased (0.446101 --> 0.446057).  Saving model ...
Validation loss decreased (0.446057 --> 0.446013).  Saving model ...
Validation loss decreased (0.446013 --> 0.445970).  Saving model ...
Validation loss decreased (0.445970 --> 0.445926).  Saving model ...
Validation loss decreased (0.445926 --> 0.445883).  Saving model ...
Validation loss decreased (0.445883 --> 0.445839).  Saving model ...
Validation loss decreased (0.445839 --> 0.445796).  Saving model ...
Validation loss decreased (0.445796 --> 0.445753).  Saving model ...
Validation loss decreased (0.445753 --> 0.445709).  Saving model ...
Validation loss decreased (0.445709 --> 0.445666).  Saving model ...
Validation loss decreased (0.445666 --> 0.445623).  Saving model ...
Validation loss decreased (0.445623 --> 0.445580).  Saving model ...
Validation loss decreased (0.445580 --> 0.445537).  Saving model ...
Validation loss decreased (0.445537 --> 0.445494).  Saving model ...
epoch 1801, loss 0.4455, train acc 78.42%, f1 0.6631, precision 0.7294, recall 0.6078, auc 0.7434
Validation loss decreased (0.445494 --> 0.445451).  Saving model ...
Validation loss decreased (0.445451 --> 0.445408).  Saving model ...
Validation loss decreased (0.445408 --> 0.445365).  Saving model ...
Validation loss decreased (0.445365 --> 0.445322).  Saving model ...
Validation loss decreased (0.445322 --> 0.445280).  Saving model ...
Validation loss decreased (0.445280 --> 0.445237).  Saving model ...
Validation loss decreased (0.445237 --> 0.445194).  Saving model ...
Validation loss decreased (0.445194 --> 0.445152).  Saving model ...
Validation loss decreased (0.445152 --> 0.445109).  Saving model ...
Validation loss decreased (0.445109 --> 0.445067).  Saving model ...
Validation loss decreased (0.445067 --> 0.445024).  Saving model ...
Validation loss decreased (0.445024 --> 0.444982).  Saving model ...
Validation loss decreased (0.444982 --> 0.444940).  Saving model ...
Validation loss decreased (0.444940 --> 0.444897).  Saving model ...
Validation loss decreased (0.444897 --> 0.444855).  Saving model ...
Validation loss decreased (0.444855 --> 0.444813).  Saving model ...
Validation loss decreased (0.444813 --> 0.444771).  Saving model ...
Validation loss decreased (0.444771 --> 0.444729).  Saving model ...
Validation loss decreased (0.444729 --> 0.444687).  Saving model ...
Validation loss decreased (0.444687 --> 0.444645).  Saving model ...
Validation loss decreased (0.444645 --> 0.444603).  Saving model ...
Validation loss decreased (0.444603 --> 0.444561).  Saving model ...
Validation loss decreased (0.444561 --> 0.444519).  Saving model ...
Validation loss decreased (0.444519 --> 0.444477).  Saving model ...
Validation loss decreased (0.444477 --> 0.444436).  Saving model ...
Validation loss decreased (0.444436 --> 0.444394).  Saving model ...
Validation loss decreased (0.444394 --> 0.444352).  Saving model ...
Validation loss decreased (0.444352 --> 0.444311).  Saving model ...
Validation loss decreased (0.444311 --> 0.444269).  Saving model ...
Validation loss decreased (0.444269 --> 0.444228).  Saving model ...
Validation loss decreased (0.444228 --> 0.444186).  Saving model ...
Validation loss decreased (0.444186 --> 0.444145).  Saving model ...
Validation loss decreased (0.444145 --> 0.444104).  Saving model ...
Validation loss decreased (0.444104 --> 0.444062).  Saving model ...
Validation loss decreased (0.444062 --> 0.444021).  Saving model ...
Validation loss decreased (0.444021 --> 0.443980).  Saving model ...
Validation loss decreased (0.443980 --> 0.443939).  Saving model ...
Validation loss decreased (0.443939 --> 0.443898).  Saving model ...
Validation loss decreased (0.443898 --> 0.443857).  Saving model ...
Validation loss decreased (0.443857 --> 0.443816).  Saving model ...
Validation loss decreased (0.443816 --> 0.443775).  Saving model ...
Validation loss decreased (0.443775 --> 0.443734).  Saving model ...
Validation loss decreased (0.443734 --> 0.443693).  Saving model ...
Validation loss decreased (0.443693 --> 0.443652).  Saving model ...
Validation loss decreased (0.443652 --> 0.443611).  Saving model ...
Validation loss decreased (0.443611 --> 0.443571).  Saving model ...
Validation loss decreased (0.443571 --> 0.443530).  Saving model ...
Validation loss decreased (0.443530 --> 0.443490).  Saving model ...
Validation loss decreased (0.443490 --> 0.443449).  Saving model ...
Validation loss decreased (0.443449 --> 0.443408).  Saving model ...
Validation loss decreased (0.443408 --> 0.443368).  Saving model ...
Validation loss decreased (0.443368 --> 0.443328).  Saving model ...
Validation loss decreased (0.443328 --> 0.443287).  Saving model ...
Validation loss decreased (0.443287 --> 0.443247).  Saving model ...
Validation loss decreased (0.443247 --> 0.443207).  Saving model ...
Validation loss decreased (0.443207 --> 0.443166).  Saving model ...
Validation loss decreased (0.443166 --> 0.443126).  Saving model ...
Validation loss decreased (0.443126 --> 0.443086).  Saving model ...
Validation loss decreased (0.443086 --> 0.443046).  Saving model ...
Validation loss decreased (0.443046 --> 0.443006).  Saving model ...
Validation loss decreased (0.443006 --> 0.442966).  Saving model ...
Validation loss decreased (0.442966 --> 0.442926).  Saving model ...
Validation loss decreased (0.442926 --> 0.442886).  Saving model ...
Validation loss decreased (0.442886 --> 0.442846).  Saving model ...
Validation loss decreased (0.442846 --> 0.442807).  Saving model ...
Validation loss decreased (0.442807 --> 0.442767).  Saving model ...
Validation loss decreased (0.442767 --> 0.442727).  Saving model ...
Validation loss decreased (0.442727 --> 0.442688).  Saving model ...
Validation loss decreased (0.442688 --> 0.442648).  Saving model ...
Validation loss decreased (0.442648 --> 0.442608).  Saving model ...
Validation loss decreased (0.442608 --> 0.442569).  Saving model ...
Validation loss decreased (0.442569 --> 0.442529).  Saving model ...
Validation loss decreased (0.442529 --> 0.442490).  Saving model ...
Validation loss decreased (0.442490 --> 0.442451).  Saving model ...
Validation loss decreased (0.442451 --> 0.442411).  Saving model ...
Validation loss decreased (0.442411 --> 0.442372).  Saving model ...
Validation loss decreased (0.442372 --> 0.442333).  Saving model ...
Validation loss decreased (0.442333 --> 0.442294).  Saving model ...
Validation loss decreased (0.442294 --> 0.442254).  Saving model ...
Validation loss decreased (0.442254 --> 0.442215).  Saving model ...
Validation loss decreased (0.442215 --> 0.442176).  Saving model ...
Validation loss decreased (0.442176 --> 0.442137).  Saving model ...
Validation loss decreased (0.442137 --> 0.442098).  Saving model ...
Validation loss decreased (0.442098 --> 0.442060).  Saving model ...
Validation loss decreased (0.442060 --> 0.442021).  Saving model ...
Validation loss decreased (0.442021 --> 0.441982).  Saving model ...
Validation loss decreased (0.441982 --> 0.441943).  Saving model ...
Validation loss decreased (0.441943 --> 0.441904).  Saving model ...
Validation loss decreased (0.441904 --> 0.441866).  Saving model ...
Validation loss decreased (0.441866 --> 0.441827).  Saving model ...
Validation loss decreased (0.441827 --> 0.441788).  Saving model ...
Validation loss decreased (0.441788 --> 0.441750).  Saving model ...
Validation loss decreased (0.441750 --> 0.441711).  Saving model ...
Validation loss decreased (0.441711 --> 0.441673).  Saving model ...
Validation loss decreased (0.441673 --> 0.441634).  Saving model ...
Validation loss decreased (0.441634 --> 0.441596).  Saving model ...
Validation loss decreased (0.441596 --> 0.441558).  Saving model ...
Validation loss decreased (0.441558 --> 0.441519).  Saving model ...
Validation loss decreased (0.441519 --> 0.441481).  Saving model ...
Validation loss decreased (0.441481 --> 0.441443).  Saving model ...
epoch 1901, loss 0.4414, train acc 78.60%, f1 0.6702, precision 0.7257, recall 0.6225, auc 0.7481
Validation loss decreased (0.441443 --> 0.441405).  Saving model ...
Validation loss decreased (0.441405 --> 0.441367).  Saving model ...
Validation loss decreased (0.441367 --> 0.441329).  Saving model ...
Validation loss decreased (0.441329 --> 0.441291).  Saving model ...
Validation loss decreased (0.441291 --> 0.441253).  Saving model ...
Validation loss decreased (0.441253 --> 0.441215).  Saving model ...
Validation loss decreased (0.441215 --> 0.441177).  Saving model ...
Validation loss decreased (0.441177 --> 0.441139).  Saving model ...
Validation loss decreased (0.441139 --> 0.441101).  Saving model ...
Validation loss decreased (0.441101 --> 0.441064).  Saving model ...
Validation loss decreased (0.441064 --> 0.441026).  Saving model ...
Validation loss decreased (0.441026 --> 0.440988).  Saving model ...
Validation loss decreased (0.440988 --> 0.440951).  Saving model ...
Validation loss decreased (0.440951 --> 0.440913).  Saving model ...
Validation loss decreased (0.440913 --> 0.440876).  Saving model ...
Validation loss decreased (0.440876 --> 0.440838).  Saving model ...
Validation loss decreased (0.440838 --> 0.440801).  Saving model ...
Validation loss decreased (0.440801 --> 0.440763).  Saving model ...
Validation loss decreased (0.440763 --> 0.440726).  Saving model ...
Validation loss decreased (0.440726 --> 0.440689).  Saving model ...
Validation loss decreased (0.440689 --> 0.440651).  Saving model ...
Validation loss decreased (0.440651 --> 0.440614).  Saving model ...
Validation loss decreased (0.440614 --> 0.440577).  Saving model ...
Validation loss decreased (0.440577 --> 0.440540).  Saving model ...
Validation loss decreased (0.440540 --> 0.440503).  Saving model ...
Validation loss decreased (0.440503 --> 0.440466).  Saving model ...
Validation loss decreased (0.440466 --> 0.440429).  Saving model ...
Validation loss decreased (0.440429 --> 0.440392).  Saving model ...
Validation loss decreased (0.440392 --> 0.440355).  Saving model ...
Validation loss decreased (0.440355 --> 0.440318).  Saving model ...
Validation loss decreased (0.440318 --> 0.440281).  Saving model ...
Validation loss decreased (0.440281 --> 0.440244).  Saving model ...
Validation loss decreased (0.440244 --> 0.440208).  Saving model ...
Validation loss decreased (0.440208 --> 0.440171).  Saving model ...
Validation loss decreased (0.440171 --> 0.440134).  Saving model ...
Validation loss decreased (0.440134 --> 0.440098).  Saving model ...
Validation loss decreased (0.440098 --> 0.440061).  Saving model ...
Validation loss decreased (0.440061 --> 0.440025).  Saving model ...
Validation loss decreased (0.440025 --> 0.439988).  Saving model ...
Validation loss decreased (0.439988 --> 0.439952).  Saving model ...
Validation loss decreased (0.439952 --> 0.439915).  Saving model ...
Validation loss decreased (0.439915 --> 0.439879).  Saving model ...
Validation loss decreased (0.439879 --> 0.439843).  Saving model ...
Validation loss decreased (0.439843 --> 0.439807).  Saving model ...
Validation loss decreased (0.439807 --> 0.439770).  Saving model ...
Validation loss decreased (0.439770 --> 0.439734).  Saving model ...
Validation loss decreased (0.439734 --> 0.439698).  Saving model ...
Validation loss decreased (0.439698 --> 0.439662).  Saving model ...
Validation loss decreased (0.439662 --> 0.439626).  Saving model ...
Validation loss decreased (0.439626 --> 0.439590).  Saving model ...
Validation loss decreased (0.439590 --> 0.439554).  Saving model ...
Validation loss decreased (0.439554 --> 0.439518).  Saving model ...
Validation loss decreased (0.439518 --> 0.439482).  Saving model ...
Validation loss decreased (0.439482 --> 0.439446).  Saving model ...
Validation loss decreased (0.439446 --> 0.439411).  Saving model ...
Validation loss decreased (0.439411 --> 0.439375).  Saving model ...
Validation loss decreased (0.439375 --> 0.439339).  Saving model ...
Validation loss decreased (0.439339 --> 0.439303).  Saving model ...
Validation loss decreased (0.439303 --> 0.439268).  Saving model ...
Validation loss decreased (0.439268 --> 0.439232).  Saving model ...
Validation loss decreased (0.439232 --> 0.439197).  Saving model ...
Validation loss decreased (0.439197 --> 0.439161).  Saving model ...
Validation loss decreased (0.439161 --> 0.439126).  Saving model ...
Validation loss decreased (0.439126 --> 0.439090).  Saving model ...
Validation loss decreased (0.439090 --> 0.439055).  Saving model ...
Validation loss decreased (0.439055 --> 0.439020).  Saving model ...
Validation loss decreased (0.439020 --> 0.438984).  Saving model ...
Validation loss decreased (0.438984 --> 0.438949).  Saving model ...
Validation loss decreased (0.438949 --> 0.438914).  Saving model ...
Validation loss decreased (0.438914 --> 0.438879).  Saving model ...
Validation loss decreased (0.438879 --> 0.438844).  Saving model ...
Validation loss decreased (0.438844 --> 0.438809).  Saving model ...
Validation loss decreased (0.438809 --> 0.438774).  Saving model ...
Validation loss decreased (0.438774 --> 0.438739).  Saving model ...
Validation loss decreased (0.438739 --> 0.438704).  Saving model ...
Validation loss decreased (0.438704 --> 0.438669).  Saving model ...
Validation loss decreased (0.438669 --> 0.438634).  Saving model ...
Validation loss decreased (0.438634 --> 0.438599).  Saving model ...
Validation loss decreased (0.438599 --> 0.438564).  Saving model ...
Validation loss decreased (0.438564 --> 0.438530).  Saving model ...
Validation loss decreased (0.438530 --> 0.438495).  Saving model ...
Validation loss decreased (0.438495 --> 0.438460).  Saving model ...
Validation loss decreased (0.438460 --> 0.438426).  Saving model ...
Validation loss decreased (0.438426 --> 0.438391).  Saving model ...
Validation loss decreased (0.438391 --> 0.438357).  Saving model ...
Validation loss decreased (0.438357 --> 0.438322).  Saving model ...
Validation loss decreased (0.438322 --> 0.438288).  Saving model ...
Validation loss decreased (0.438288 --> 0.438253).  Saving model ...
Validation loss decreased (0.438253 --> 0.438219).  Saving model ...
Validation loss decreased (0.438219 --> 0.438185).  Saving model ...
Validation loss decreased (0.438185 --> 0.438150).  Saving model ...
Validation loss decreased (0.438150 --> 0.438116).  Saving model ...
Validation loss decreased (0.438116 --> 0.438082).  Saving model ...
Validation loss decreased (0.438082 --> 0.438048).  Saving model ...
Validation loss decreased (0.438048 --> 0.438014).  Saving model ...
Validation loss decreased (0.438014 --> 0.437979).  Saving model ...
Validation loss decreased (0.437979 --> 0.437945).  Saving model ...
Validation loss decreased (0.437945 --> 0.437911).  Saving model ...
Validation loss decreased (0.437911 --> 0.437878).  Saving model ...
Validation loss decreased (0.437878 --> 0.437844).  Saving model ...
epoch 2001, loss 0.4378, train acc 79.45%, f1 0.6859, precision 0.7360, recall 0.6422, auc 0.7592
Validation loss decreased (0.437844 --> 0.437810).  Saving model ...
Validation loss decreased (0.437810 --> 0.437776).  Saving model ...
Validation loss decreased (0.437776 --> 0.437742).  Saving model ...
Validation loss decreased (0.437742 --> 0.437708).  Saving model ...
Validation loss decreased (0.437708 --> 0.437675).  Saving model ...
Validation loss decreased (0.437675 --> 0.437641).  Saving model ...
Validation loss decreased (0.437641 --> 0.437607).  Saving model ...
Validation loss decreased (0.437607 --> 0.437574).  Saving model ...
Validation loss decreased (0.437574 --> 0.437540).  Saving model ...
Validation loss decreased (0.437540 --> 0.437507).  Saving model ...
Validation loss decreased (0.437507 --> 0.437473).  Saving model ...
Validation loss decreased (0.437473 --> 0.437440).  Saving model ...
Validation loss decreased (0.437440 --> 0.437407).  Saving model ...
Validation loss decreased (0.437407 --> 0.437373).  Saving model ...
Validation loss decreased (0.437373 --> 0.437340).  Saving model ...
Validation loss decreased (0.437340 --> 0.437307).  Saving model ...
Validation loss decreased (0.437307 --> 0.437274).  Saving model ...
Validation loss decreased (0.437274 --> 0.437240).  Saving model ...
Validation loss decreased (0.437240 --> 0.437207).  Saving model ...
Validation loss decreased (0.437207 --> 0.437174).  Saving model ...
Validation loss decreased (0.437174 --> 0.437141).  Saving model ...
Validation loss decreased (0.437141 --> 0.437108).  Saving model ...
Validation loss decreased (0.437108 --> 0.437075).  Saving model ...
Validation loss decreased (0.437075 --> 0.437042).  Saving model ...
Validation loss decreased (0.437042 --> 0.437009).  Saving model ...
Validation loss decreased (0.437009 --> 0.436976).  Saving model ...
Validation loss decreased (0.436976 --> 0.436944).  Saving model ...
Validation loss decreased (0.436944 --> 0.436911).  Saving model ...
Validation loss decreased (0.436911 --> 0.436878).  Saving model ...
Validation loss decreased (0.436878 --> 0.436845).  Saving model ...
Validation loss decreased (0.436845 --> 0.436813).  Saving model ...
Validation loss decreased (0.436813 --> 0.436780).  Saving model ...
Validation loss decreased (0.436780 --> 0.436748).  Saving model ...
Validation loss decreased (0.436748 --> 0.436715).  Saving model ...
Validation loss decreased (0.436715 --> 0.436683).  Saving model ...
Validation loss decreased (0.436683 --> 0.436650).  Saving model ...
Validation loss decreased (0.436650 --> 0.436618).  Saving model ...
Validation loss decreased (0.436618 --> 0.436586).  Saving model ...
Validation loss decreased (0.436586 --> 0.436553).  Saving model ...
Validation loss decreased (0.436553 --> 0.436521).  Saving model ...
Validation loss decreased (0.436521 --> 0.436489).  Saving model ...
Validation loss decreased (0.436489 --> 0.436457).  Saving model ...
Validation loss decreased (0.436457 --> 0.436424).  Saving model ...
Validation loss decreased (0.436424 --> 0.436392).  Saving model ...
Validation loss decreased (0.436392 --> 0.436360).  Saving model ...
Validation loss decreased (0.436360 --> 0.436328).  Saving model ...
Validation loss decreased (0.436328 --> 0.436296).  Saving model ...
Validation loss decreased (0.436296 --> 0.436264).  Saving model ...
Validation loss decreased (0.436264 --> 0.436232).  Saving model ...
Validation loss decreased (0.436232 --> 0.436200).  Saving model ...
Validation loss decreased (0.436200 --> 0.436169).  Saving model ...
Validation loss decreased (0.436169 --> 0.436137).  Saving model ...
Validation loss decreased (0.436137 --> 0.436105).  Saving model ...
Validation loss decreased (0.436105 --> 0.436073).  Saving model ...
Validation loss decreased (0.436073 --> 0.436042).  Saving model ...
Validation loss decreased (0.436042 --> 0.436010).  Saving model ...
Validation loss decreased (0.436010 --> 0.435978).  Saving model ...
Validation loss decreased (0.435978 --> 0.435947).  Saving model ...
Validation loss decreased (0.435947 --> 0.435915).  Saving model ...
Validation loss decreased (0.435915 --> 0.435884).  Saving model ...
Validation loss decreased (0.435884 --> 0.435852).  Saving model ...
Validation loss decreased (0.435852 --> 0.435821).  Saving model ...
Validation loss decreased (0.435821 --> 0.435790).  Saving model ...
Validation loss decreased (0.435790 --> 0.435758).  Saving model ...
Validation loss decreased (0.435758 --> 0.435727).  Saving model ...
Validation loss decreased (0.435727 --> 0.435696).  Saving model ...
Validation loss decreased (0.435696 --> 0.435665).  Saving model ...
Validation loss decreased (0.435665 --> 0.435633).  Saving model ...
Validation loss decreased (0.435633 --> 0.435602).  Saving model ...
Validation loss decreased (0.435602 --> 0.435571).  Saving model ...
Validation loss decreased (0.435571 --> 0.435540).  Saving model ...
Validation loss decreased (0.435540 --> 0.435509).  Saving model ...
Validation loss decreased (0.435509 --> 0.435478).  Saving model ...
Validation loss decreased (0.435478 --> 0.435447).  Saving model ...
Validation loss decreased (0.435447 --> 0.435416).  Saving model ...
Validation loss decreased (0.435416 --> 0.435385).  Saving model ...
Validation loss decreased (0.435385 --> 0.435355).  Saving model ...
Validation loss decreased (0.435355 --> 0.435324).  Saving model ...
Validation loss decreased (0.435324 --> 0.435293).  Saving model ...
Validation loss decreased (0.435293 --> 0.435262).  Saving model ...
Validation loss decreased (0.435262 --> 0.435232).  Saving model ...
Validation loss decreased (0.435232 --> 0.435201).  Saving model ...
Validation loss decreased (0.435201 --> 0.435170).  Saving model ...
Validation loss decreased (0.435170 --> 0.435140).  Saving model ...
Validation loss decreased (0.435140 --> 0.435109).  Saving model ...
Validation loss decreased (0.435109 --> 0.435079).  Saving model ...
Validation loss decreased (0.435079 --> 0.435048).  Saving model ...
Validation loss decreased (0.435048 --> 0.435018).  Saving model ...
Validation loss decreased (0.435018 --> 0.434988).  Saving model ...
Validation loss decreased (0.434988 --> 0.434957).  Saving model ...
Validation loss decreased (0.434957 --> 0.434927).  Saving model ...
Validation loss decreased (0.434927 --> 0.434897).  Saving model ...
Validation loss decreased (0.434897 --> 0.434867).  Saving model ...
Validation loss decreased (0.434867 --> 0.434836).  Saving model ...
Validation loss decreased (0.434836 --> 0.434806).  Saving model ...
Validation loss decreased (0.434806 --> 0.434776).  Saving model ...
Validation loss decreased (0.434776 --> 0.434746).  Saving model ...
Validation loss decreased (0.434746 --> 0.434716).  Saving model ...
Validation loss decreased (0.434716 --> 0.434686).  Saving model ...
Validation loss decreased (0.434686 --> 0.434656).  Saving model ...
epoch 2101, loss 0.4347, train acc 79.11%, f1 0.6806, precision 0.7303, recall 0.6373, auc 0.7555
Validation loss decreased (0.434656 --> 0.434626).  Saving model ...
Validation loss decreased (0.434626 --> 0.434596).  Saving model ...
Validation loss decreased (0.434596 --> 0.434567).  Saving model ...
Validation loss decreased (0.434567 --> 0.434537).  Saving model ...
Validation loss decreased (0.434537 --> 0.434507).  Saving model ...
Validation loss decreased (0.434507 --> 0.434477).  Saving model ...
Validation loss decreased (0.434477 --> 0.434447).  Saving model ...
Validation loss decreased (0.434447 --> 0.434418).  Saving model ...
Validation loss decreased (0.434418 --> 0.434388).  Saving model ...
Validation loss decreased (0.434388 --> 0.434359).  Saving model ...
Validation loss decreased (0.434359 --> 0.434329).  Saving model ...
Validation loss decreased (0.434329 --> 0.434300).  Saving model ...
Validation loss decreased (0.434300 --> 0.434270).  Saving model ...
Validation loss decreased (0.434270 --> 0.434241).  Saving model ...
Validation loss decreased (0.434241 --> 0.434211).  Saving model ...
Validation loss decreased (0.434211 --> 0.434182).  Saving model ...
Validation loss decreased (0.434182 --> 0.434153).  Saving model ...
Validation loss decreased (0.434153 --> 0.434123).  Saving model ...
Validation loss decreased (0.434123 --> 0.434094).  Saving model ...
Validation loss decreased (0.434094 --> 0.434065).  Saving model ...
Validation loss decreased (0.434065 --> 0.434036).  Saving model ...
Validation loss decreased (0.434036 --> 0.434006).  Saving model ...
Validation loss decreased (0.434006 --> 0.433977).  Saving model ...
Validation loss decreased (0.433977 --> 0.433948).  Saving model ...
Validation loss decreased (0.433948 --> 0.433919).  Saving model ...
Validation loss decreased (0.433919 --> 0.433890).  Saving model ...
Validation loss decreased (0.433890 --> 0.433861).  Saving model ...
Validation loss decreased (0.433861 --> 0.433832).  Saving model ...
Validation loss decreased (0.433832 --> 0.433803).  Saving model ...
Validation loss decreased (0.433803 --> 0.433774).  Saving model ...
Validation loss decreased (0.433774 --> 0.433745).  Saving model ...
Validation loss decreased (0.433745 --> 0.433717).  Saving model ...
Validation loss decreased (0.433717 --> 0.433688).  Saving model ...
Validation loss decreased (0.433688 --> 0.433659).  Saving model ...
Validation loss decreased (0.433659 --> 0.433630).  Saving model ...
Validation loss decreased (0.433630 --> 0.433602).  Saving model ...
Validation loss decreased (0.433602 --> 0.433573).  Saving model ...
Validation loss decreased (0.433573 --> 0.433544).  Saving model ...
Validation loss decreased (0.433544 --> 0.433516).  Saving model ...
Validation loss decreased (0.433516 --> 0.433487).  Saving model ...
Validation loss decreased (0.433487 --> 0.433459).  Saving model ...
Validation loss decreased (0.433459 --> 0.433430).  Saving model ...
Validation loss decreased (0.433430 --> 0.433402).  Saving model ...
Validation loss decreased (0.433402 --> 0.433374).  Saving model ...
Validation loss decreased (0.433374 --> 0.433345).  Saving model ...
Validation loss decreased (0.433345 --> 0.433317).  Saving model ...
Validation loss decreased (0.433317 --> 0.433288).  Saving model ...
Validation loss decreased (0.433288 --> 0.433260).  Saving model ...
Validation loss decreased (0.433260 --> 0.433232).  Saving model ...
Validation loss decreased (0.433232 --> 0.433204).  Saving model ...
Validation loss decreased (0.433204 --> 0.433176).  Saving model ...
Validation loss decreased (0.433176 --> 0.433147).  Saving model ...
Validation loss decreased (0.433147 --> 0.433119).  Saving model ...
Validation loss decreased (0.433119 --> 0.433091).  Saving model ...
Validation loss decreased (0.433091 --> 0.433063).  Saving model ...
Validation loss decreased (0.433063 --> 0.433035).  Saving model ...
Validation loss decreased (0.433035 --> 0.433007).  Saving model ...
Validation loss decreased (0.433007 --> 0.432979).  Saving model ...
Validation loss decreased (0.432979 --> 0.432951).  Saving model ...
Validation loss decreased (0.432951 --> 0.432923).  Saving model ...
Validation loss decreased (0.432923 --> 0.432896).  Saving model ...
Validation loss decreased (0.432896 --> 0.432868).  Saving model ...
Validation loss decreased (0.432868 --> 0.432840).  Saving model ...
Validation loss decreased (0.432840 --> 0.432812).  Saving model ...
Validation loss decreased (0.432812 --> 0.432784).  Saving model ...
Validation loss decreased (0.432784 --> 0.432757).  Saving model ...
Validation loss decreased (0.432757 --> 0.432729).  Saving model ...
Validation loss decreased (0.432729 --> 0.432701).  Saving model ...
Validation loss decreased (0.432701 --> 0.432674).  Saving model ...
Validation loss decreased (0.432674 --> 0.432646).  Saving model ...
Validation loss decreased (0.432646 --> 0.432619).  Saving model ...
Validation loss decreased (0.432619 --> 0.432591).  Saving model ...
Validation loss decreased (0.432591 --> 0.432564).  Saving model ...
Validation loss decreased (0.432564 --> 0.432536).  Saving model ...
Validation loss decreased (0.432536 --> 0.432509).  Saving model ...
Validation loss decreased (0.432509 --> 0.432481).  Saving model ...
Validation loss decreased (0.432481 --> 0.432454).  Saving model ...
Validation loss decreased (0.432454 --> 0.432427).  Saving model ...
Validation loss decreased (0.432427 --> 0.432399).  Saving model ...
Validation loss decreased (0.432399 --> 0.432372).  Saving model ...
Validation loss decreased (0.432372 --> 0.432345).  Saving model ...
Validation loss decreased (0.432345 --> 0.432318).  Saving model ...
Validation loss decreased (0.432318 --> 0.432290).  Saving model ...
Validation loss decreased (0.432290 --> 0.432263).  Saving model ...
Validation loss decreased (0.432263 --> 0.432236).  Saving model ...
Validation loss decreased (0.432236 --> 0.432209).  Saving model ...
Validation loss decreased (0.432209 --> 0.432182).  Saving model ...
Validation loss decreased (0.432182 --> 0.432155).  Saving model ...
Validation loss decreased (0.432155 --> 0.432128).  Saving model ...
Validation loss decreased (0.432128 --> 0.432101).  Saving model ...
Validation loss decreased (0.432101 --> 0.432074).  Saving model ...
Validation loss decreased (0.432074 --> 0.432047).  Saving model ...
Validation loss decreased (0.432047 --> 0.432020).  Saving model ...
Validation loss decreased (0.432020 --> 0.431993).  Saving model ...
Validation loss decreased (0.431993 --> 0.431966).  Saving model ...
Validation loss decreased (0.431966 --> 0.431940).  Saving model ...
Validation loss decreased (0.431940 --> 0.431913).  Saving model ...
Validation loss decreased (0.431913 --> 0.431886).  Saving model ...
Validation loss decreased (0.431886 --> 0.431859).  Saving model ...
Validation loss decreased (0.431859 --> 0.431833).  Saving model ...
epoch 2201, loss 0.4318, train acc 79.11%, f1 0.6823, precision 0.7278, recall 0.6422, auc 0.7566
Validation loss decreased (0.431833 --> 0.431806).  Saving model ...
Validation loss decreased (0.431806 --> 0.431779).  Saving model ...
Validation loss decreased (0.431779 --> 0.431753).  Saving model ...
Validation loss decreased (0.431753 --> 0.431726).  Saving model ...
Validation loss decreased (0.431726 --> 0.431700).  Saving model ...
Validation loss decreased (0.431700 --> 0.431673).  Saving model ...
Validation loss decreased (0.431673 --> 0.431647).  Saving model ...
Validation loss decreased (0.431647 --> 0.431620).  Saving model ...
Validation loss decreased (0.431620 --> 0.431594).  Saving model ...
Validation loss decreased (0.431594 --> 0.431567).  Saving model ...
Validation loss decreased (0.431567 --> 0.431541).  Saving model ...
Validation loss decreased (0.431541 --> 0.431514).  Saving model ...
Validation loss decreased (0.431514 --> 0.431488).  Saving model ...
Validation loss decreased (0.431488 --> 0.431462).  Saving model ...
Validation loss decreased (0.431462 --> 0.431435).  Saving model ...
Validation loss decreased (0.431435 --> 0.431409).  Saving model ...
Validation loss decreased (0.431409 --> 0.431383).  Saving model ...
Validation loss decreased (0.431383 --> 0.431357).  Saving model ...
Validation loss decreased (0.431357 --> 0.431331).  Saving model ...
Validation loss decreased (0.431331 --> 0.431304).  Saving model ...
Validation loss decreased (0.431304 --> 0.431278).  Saving model ...
Validation loss decreased (0.431278 --> 0.431252).  Saving model ...
Validation loss decreased (0.431252 --> 0.431226).  Saving model ...
Validation loss decreased (0.431226 --> 0.431200).  Saving model ...
Validation loss decreased (0.431200 --> 0.431174).  Saving model ...
Validation loss decreased (0.431174 --> 0.431148).  Saving model ...
Validation loss decreased (0.431148 --> 0.431122).  Saving model ...
Validation loss decreased (0.431122 --> 0.431096).  Saving model ...
Validation loss decreased (0.431096 --> 0.431070).  Saving model ...
Validation loss decreased (0.431070 --> 0.431044).  Saving model ...
Validation loss decreased (0.431044 --> 0.431018).  Saving model ...
Validation loss decreased (0.431018 --> 0.430992).  Saving model ...
Validation loss decreased (0.430992 --> 0.430967).  Saving model ...
Validation loss decreased (0.430967 --> 0.430941).  Saving model ...
Validation loss decreased (0.430941 --> 0.430915).  Saving model ...
Validation loss decreased (0.430915 --> 0.430889).  Saving model ...
Validation loss decreased (0.430889 --> 0.430863).  Saving model ...
Validation loss decreased (0.430863 --> 0.430838).  Saving model ...
Validation loss decreased (0.430838 --> 0.430812).  Saving model ...
Validation loss decreased (0.430812 --> 0.430786).  Saving model ...
Validation loss decreased (0.430786 --> 0.430761).  Saving model ...
Validation loss decreased (0.430761 --> 0.430735).  Saving model ...
Validation loss decreased (0.430735 --> 0.430710).  Saving model ...
Validation loss decreased (0.430710 --> 0.430684).  Saving model ...
Validation loss decreased (0.430684 --> 0.430658).  Saving model ...
Validation loss decreased (0.430658 --> 0.430633).  Saving model ...
Validation loss decreased (0.430633 --> 0.430607).  Saving model ...
Validation loss decreased (0.430607 --> 0.430582).  Saving model ...
Validation loss decreased (0.430582 --> 0.430557).  Saving model ...
Validation loss decreased (0.430557 --> 0.430531).  Saving model ...
Validation loss decreased (0.430531 --> 0.430506).  Saving model ...
Validation loss decreased (0.430506 --> 0.430480).  Saving model ...
Validation loss decreased (0.430480 --> 0.430455).  Saving model ...
Validation loss decreased (0.430455 --> 0.430430).  Saving model ...
Validation loss decreased (0.430430 --> 0.430404).  Saving model ...
Validation loss decreased (0.430404 --> 0.430379).  Saving model ...
Validation loss decreased (0.430379 --> 0.430354).  Saving model ...
Validation loss decreased (0.430354 --> 0.430328).  Saving model ...
Validation loss decreased (0.430328 --> 0.430303).  Saving model ...
Validation loss decreased (0.430303 --> 0.430278).  Saving model ...
Validation loss decreased (0.430278 --> 0.430253).  Saving model ...
Validation loss decreased (0.430253 --> 0.430228).  Saving model ...
Validation loss decreased (0.430228 --> 0.430203).  Saving model ...
Validation loss decreased (0.430203 --> 0.430177).  Saving model ...
Validation loss decreased (0.430177 --> 0.430152).  Saving model ...
Validation loss decreased (0.430152 --> 0.430127).  Saving model ...
Validation loss decreased (0.430127 --> 0.430102).  Saving model ...
Validation loss decreased (0.430102 --> 0.430077).  Saving model ...
Validation loss decreased (0.430077 --> 0.430052).  Saving model ...
Validation loss decreased (0.430052 --> 0.430027).  Saving model ...
Validation loss decreased (0.430027 --> 0.430002).  Saving model ...
Validation loss decreased (0.430002 --> 0.429977).  Saving model ...
Validation loss decreased (0.429977 --> 0.429952).  Saving model ...
Validation loss decreased (0.429952 --> 0.429927).  Saving model ...
Validation loss decreased (0.429927 --> 0.429903).  Saving model ...
Validation loss decreased (0.429903 --> 0.429878).  Saving model ...
Validation loss decreased (0.429878 --> 0.429853).  Saving model ...
Validation loss decreased (0.429853 --> 0.429828).  Saving model ...
Validation loss decreased (0.429828 --> 0.429803).  Saving model ...
Validation loss decreased (0.429803 --> 0.429778).  Saving model ...
Validation loss decreased (0.429778 --> 0.429754).  Saving model ...
Validation loss decreased (0.429754 --> 0.429729).  Saving model ...
Validation loss decreased (0.429729 --> 0.429704).  Saving model ...
Validation loss decreased (0.429704 --> 0.429680).  Saving model ...
Validation loss decreased (0.429680 --> 0.429655).  Saving model ...
Validation loss decreased (0.429655 --> 0.429630).  Saving model ...
Validation loss decreased (0.429630 --> 0.429606).  Saving model ...
Validation loss decreased (0.429606 --> 0.429581).  Saving model ...
Validation loss decreased (0.429581 --> 0.429556).  Saving model ...
Validation loss decreased (0.429556 --> 0.429532).  Saving model ...
Validation loss decreased (0.429532 --> 0.429507).  Saving model ...
Validation loss decreased (0.429507 --> 0.429483).  Saving model ...
Validation loss decreased (0.429483 --> 0.429458).  Saving model ...
Validation loss decreased (0.429458 --> 0.429434).  Saving model ...
Validation loss decreased (0.429434 --> 0.429409).  Saving model ...
Validation loss decreased (0.429409 --> 0.429385).  Saving model ...
Validation loss decreased (0.429385 --> 0.429360).  Saving model ...
Validation loss decreased (0.429360 --> 0.429336).  Saving model ...
Validation loss decreased (0.429336 --> 0.429311).  Saving model ...
Validation loss decreased (0.429311 --> 0.429287).  Saving model ...
epoch 2301, loss 0.4293, train acc 79.28%, f1 0.6857, precision 0.7293, recall 0.6471, auc 0.7591
Validation loss decreased (0.429287 --> 0.429262).  Saving model ...
Validation loss decreased (0.429262 --> 0.429238).  Saving model ...
Validation loss decreased (0.429238 --> 0.429214).  Saving model ...
Validation loss decreased (0.429214 --> 0.429189).  Saving model ...
Validation loss decreased (0.429189 --> 0.429165).  Saving model ...
Validation loss decreased (0.429165 --> 0.429141).  Saving model ...
Validation loss decreased (0.429141 --> 0.429117).  Saving model ...
Validation loss decreased (0.429117 --> 0.429092).  Saving model ...
Validation loss decreased (0.429092 --> 0.429068).  Saving model ...
Validation loss decreased (0.429068 --> 0.429044).  Saving model ...
Validation loss decreased (0.429044 --> 0.429020).  Saving model ...
Validation loss decreased (0.429020 --> 0.428995).  Saving model ...
Validation loss decreased (0.428995 --> 0.428971).  Saving model ...
Validation loss decreased (0.428971 --> 0.428947).  Saving model ...
Validation loss decreased (0.428947 --> 0.428923).  Saving model ...
Validation loss decreased (0.428923 --> 0.428899).  Saving model ...
Validation loss decreased (0.428899 --> 0.428875).  Saving model ...
Validation loss decreased (0.428875 --> 0.428851).  Saving model ...
Validation loss decreased (0.428851 --> 0.428827).  Saving model ...
Validation loss decreased (0.428827 --> 0.428803).  Saving model ...
Validation loss decreased (0.428803 --> 0.428779).  Saving model ...
Validation loss decreased (0.428779 --> 0.428755).  Saving model ...
Validation loss decreased (0.428755 --> 0.428731).  Saving model ...
Validation loss decreased (0.428731 --> 0.428707).  Saving model ...
Validation loss decreased (0.428707 --> 0.428683).  Saving model ...
Validation loss decreased (0.428683 --> 0.428659).  Saving model ...
Validation loss decreased (0.428659 --> 0.428635).  Saving model ...
Validation loss decreased (0.428635 --> 0.428611).  Saving model ...
Validation loss decreased (0.428611 --> 0.428587).  Saving model ...
Validation loss decreased (0.428587 --> 0.428563).  Saving model ...
Validation loss decreased (0.428563 --> 0.428539).  Saving model ...
Validation loss decreased (0.428539 --> 0.428515).  Saving model ...
Validation loss decreased (0.428515 --> 0.428491).  Saving model ...
Validation loss decreased (0.428491 --> 0.428468).  Saving model ...
Validation loss decreased (0.428468 --> 0.428444).  Saving model ...
Validation loss decreased (0.428444 --> 0.428420).  Saving model ...
Validation loss decreased (0.428420 --> 0.428396).  Saving model ...
Validation loss decreased (0.428396 --> 0.428372).  Saving model ...
Validation loss decreased (0.428372 --> 0.428349).  Saving model ...
Validation loss decreased (0.428349 --> 0.428325).  Saving model ...
Validation loss decreased (0.428325 --> 0.428301).  Saving model ...
Validation loss decreased (0.428301 --> 0.428277).  Saving model ...
Validation loss decreased (0.428277 --> 0.428254).  Saving model ...
Validation loss decreased (0.428254 --> 0.428230).  Saving model ...
Validation loss decreased (0.428230 --> 0.428206).  Saving model ...
Validation loss decreased (0.428206 --> 0.428183).  Saving model ...
Validation loss decreased (0.428183 --> 0.428159).  Saving model ...
Validation loss decreased (0.428159 --> 0.428135).  Saving model ...
Validation loss decreased (0.428135 --> 0.428112).  Saving model ...
Validation loss decreased (0.428112 --> 0.428088).  Saving model ...
Validation loss decreased (0.428088 --> 0.428065).  Saving model ...
Validation loss decreased (0.428065 --> 0.428041).  Saving model ...
Validation loss decreased (0.428041 --> 0.428017).  Saving model ...
Validation loss decreased (0.428017 --> 0.427994).  Saving model ...
Validation loss decreased (0.427994 --> 0.427970).  Saving model ...
Validation loss decreased (0.427970 --> 0.427947).  Saving model ...
Validation loss decreased (0.427947 --> 0.427923).  Saving model ...
Validation loss decreased (0.427923 --> 0.427900).  Saving model ...
Validation loss decreased (0.427900 --> 0.427876).  Saving model ...
Validation loss decreased (0.427876 --> 0.427853).  Saving model ...
Validation loss decreased (0.427853 --> 0.427829).  Saving model ...
Validation loss decreased (0.427829 --> 0.427806).  Saving model ...
Validation loss decreased (0.427806 --> 0.427782).  Saving model ...
Validation loss decreased (0.427782 --> 0.427759).  Saving model ...
Validation loss decreased (0.427759 --> 0.427735).  Saving model ...
Validation loss decreased (0.427735 --> 0.427712).  Saving model ...
Validation loss decreased (0.427712 --> 0.427689).  Saving model ...
Validation loss decreased (0.427689 --> 0.427665).  Saving model ...
Validation loss decreased (0.427665 --> 0.427642).  Saving model ...
Validation loss decreased (0.427642 --> 0.427618).  Saving model ...
Validation loss decreased (0.427618 --> 0.427595).  Saving model ...
Validation loss decreased (0.427595 --> 0.427572).  Saving model ...
Validation loss decreased (0.427572 --> 0.427548).  Saving model ...
Validation loss decreased (0.427548 --> 0.427525).  Saving model ...
Validation loss decreased (0.427525 --> 0.427502).  Saving model ...
Validation loss decreased (0.427502 --> 0.427478).  Saving model ...
Validation loss decreased (0.427478 --> 0.427455).  Saving model ...
Validation loss decreased (0.427455 --> 0.427432).  Saving model ...
Validation loss decreased (0.427432 --> 0.427408).  Saving model ...
Validation loss decreased (0.427408 --> 0.427385).  Saving model ...
Validation loss decreased (0.427385 --> 0.427362).  Saving model ...
Validation loss decreased (0.427362 --> 0.427339).  Saving model ...
Validation loss decreased (0.427339 --> 0.427315).  Saving model ...
Validation loss decreased (0.427315 --> 0.427292).  Saving model ...
Validation loss decreased (0.427292 --> 0.427269).  Saving model ...
Validation loss decreased (0.427269 --> 0.427246).  Saving model ...
Validation loss decreased (0.427246 --> 0.427222).  Saving model ...
Validation loss decreased (0.427222 --> 0.427199).  Saving model ...
Validation loss decreased (0.427199 --> 0.427176).  Saving model ...
Validation loss decreased (0.427176 --> 0.427153).  Saving model ...
Validation loss decreased (0.427153 --> 0.427130).  Saving model ...
Validation loss decreased (0.427130 --> 0.427106).  Saving model ...
Validation loss decreased (0.427106 --> 0.427083).  Saving model ...
Validation loss decreased (0.427083 --> 0.427060).  Saving model ...
Validation loss decreased (0.427060 --> 0.427037).  Saving model ...
Validation loss decreased (0.427037 --> 0.427014).  Saving model ...
Validation loss decreased (0.427014 --> 0.426991).  Saving model ...
Validation loss decreased (0.426991 --> 0.426967).  Saving model ...
Validation loss decreased (0.426967 --> 0.426944).  Saving model ...
Validation loss decreased (0.426944 --> 0.426921).  Saving model ...
epoch 2401, loss 0.4269, train acc 78.94%, f1 0.6822, precision 0.7213, recall 0.6471, auc 0.7564
Validation loss decreased (0.426921 --> 0.426898).  Saving model ...
Validation loss decreased (0.426898 --> 0.426875).  Saving model ...
Validation loss decreased (0.426875 --> 0.426852).  Saving model ...
Validation loss decreased (0.426852 --> 0.426829).  Saving model ...
Validation loss decreased (0.426829 --> 0.426806).  Saving model ...
Validation loss decreased (0.426806 --> 0.426782).  Saving model ...
Validation loss decreased (0.426782 --> 0.426759).  Saving model ...
Validation loss decreased (0.426759 --> 0.426736).  Saving model ...
Validation loss decreased (0.426736 --> 0.426713).  Saving model ...
Validation loss decreased (0.426713 --> 0.426690).  Saving model ...
Validation loss decreased (0.426690 --> 0.426667).  Saving model ...
Validation loss decreased (0.426667 --> 0.426644).  Saving model ...
Validation loss decreased (0.426644 --> 0.426621).  Saving model ...
Validation loss decreased (0.426621 --> 0.426598).  Saving model ...
Validation loss decreased (0.426598 --> 0.426575).  Saving model ...
Validation loss decreased (0.426575 --> 0.426552).  Saving model ...
Validation loss decreased (0.426552 --> 0.426529).  Saving model ...
Validation loss decreased (0.426529 --> 0.426506).  Saving model ...
Validation loss decreased (0.426506 --> 0.426483).  Saving model ...
Validation loss decreased (0.426483 --> 0.426460).  Saving model ...
Validation loss decreased (0.426460 --> 0.426437).  Saving model ...
Validation loss decreased (0.426437 --> 0.426414).  Saving model ...
Validation loss decreased (0.426414 --> 0.426390).  Saving model ...
Validation loss decreased (0.426390 --> 0.426367).  Saving model ...
Validation loss decreased (0.426367 --> 0.426344).  Saving model ...
Validation loss decreased (0.426344 --> 0.426321).  Saving model ...
Validation loss decreased (0.426321 --> 0.426298).  Saving model ...
Validation loss decreased (0.426298 --> 0.426275).  Saving model ...
Validation loss decreased (0.426275 --> 0.426252).  Saving model ...
Validation loss decreased (0.426252 --> 0.426229).  Saving model ...
Validation loss decreased (0.426229 --> 0.426206).  Saving model ...
Validation loss decreased (0.426206 --> 0.426183).  Saving model ...
Validation loss decreased (0.426183 --> 0.426160).  Saving model ...
Validation loss decreased (0.426160 --> 0.426137).  Saving model ...
Validation loss decreased (0.426137 --> 0.426114).  Saving model ...
Validation loss decreased (0.426114 --> 0.426091).  Saving model ...
Validation loss decreased (0.426091 --> 0.426068).  Saving model ...
Validation loss decreased (0.426068 --> 0.426045).  Saving model ...
Validation loss decreased (0.426045 --> 0.426022).  Saving model ...
Validation loss decreased (0.426022 --> 0.425999).  Saving model ...
Validation loss decreased (0.425999 --> 0.425976).  Saving model ...
Validation loss decreased (0.425976 --> 0.425953).  Saving model ...
Validation loss decreased (0.425953 --> 0.425930).  Saving model ...
Validation loss decreased (0.425930 --> 0.425907).  Saving model ...
Validation loss decreased (0.425907 --> 0.425884).  Saving model ...
Validation loss decreased (0.425884 --> 0.425861).  Saving model ...
Validation loss decreased (0.425861 --> 0.425838).  Saving model ...
Validation loss decreased (0.425838 --> 0.425815).  Saving model ...
Validation loss decreased (0.425815 --> 0.425792).  Saving model ...
Validation loss decreased (0.425792 --> 0.425769).  Saving model ...
Validation loss decreased (0.425769 --> 0.425746).  Saving model ...
Validation loss decreased (0.425746 --> 0.425723).  Saving model ...
Validation loss decreased (0.425723 --> 0.425700).  Saving model ...
Validation loss decreased (0.425700 --> 0.425677).  Saving model ...
Validation loss decreased (0.425677 --> 0.425654).  Saving model ...
Validation loss decreased (0.425654 --> 0.425631).  Saving model ...
Validation loss decreased (0.425631 --> 0.425608).  Saving model ...
Validation loss decreased (0.425608 --> 0.425585).  Saving model ...
Validation loss decreased (0.425585 --> 0.425562).  Saving model ...
Validation loss decreased (0.425562 --> 0.425539).  Saving model ...
Validation loss decreased (0.425539 --> 0.425516).  Saving model ...
Validation loss decreased (0.425516 --> 0.425493).  Saving model ...
Validation loss decreased (0.425493 --> 0.425470).  Saving model ...
Validation loss decreased (0.425470 --> 0.425447).  Saving model ...
Validation loss decreased (0.425447 --> 0.425424).  Saving model ...
Validation loss decreased (0.425424 --> 0.425401).  Saving model ...
Validation loss decreased (0.425401 --> 0.425377).  Saving model ...
Validation loss decreased (0.425377 --> 0.425354).  Saving model ...
Validation loss decreased (0.425354 --> 0.425331).  Saving model ...
Validation loss decreased (0.425331 --> 0.425308).  Saving model ...
Validation loss decreased (0.425308 --> 0.425285).  Saving model ...
Validation loss decreased (0.425285 --> 0.425262).  Saving model ...
Validation loss decreased (0.425262 --> 0.425239).  Saving model ...
Validation loss decreased (0.425239 --> 0.425216).  Saving model ...
Validation loss decreased (0.425216 --> 0.425193).  Saving model ...
Validation loss decreased (0.425193 --> 0.425170).  Saving model ...
Validation loss decreased (0.425170 --> 0.425147).  Saving model ...
Validation loss decreased (0.425147 --> 0.425124).  Saving model ...
Validation loss decreased (0.425124 --> 0.425100).  Saving model ...
Validation loss decreased (0.425100 --> 0.425077).  Saving model ...
Validation loss decreased (0.425077 --> 0.425054).  Saving model ...
Validation loss decreased (0.425054 --> 0.425031).  Saving model ...
Validation loss decreased (0.425031 --> 0.425008).  Saving model ...
Validation loss decreased (0.425008 --> 0.424985).  Saving model ...
Validation loss decreased (0.424985 --> 0.424962).  Saving model ...
Validation loss decreased (0.424962 --> 0.424939).  Saving model ...
Validation loss decreased (0.424939 --> 0.424915).  Saving model ...
Validation loss decreased (0.424915 --> 0.424892).  Saving model ...
Validation loss decreased (0.424892 --> 0.424869).  Saving model ...
Validation loss decreased (0.424869 --> 0.424846).  Saving model ...
Validation loss decreased (0.424846 --> 0.424823).  Saving model ...
Validation loss decreased (0.424823 --> 0.424800).  Saving model ...
Validation loss decreased (0.424800 --> 0.424776).  Saving model ...
Validation loss decreased (0.424776 --> 0.424753).  Saving model ...
Validation loss decreased (0.424753 --> 0.424730).  Saving model ...
Validation loss decreased (0.424730 --> 0.424707).  Saving model ...
Validation loss decreased (0.424707 --> 0.424684).  Saving model ...
Validation loss decreased (0.424684 --> 0.424660).  Saving model ...
Validation loss decreased (0.424660 --> 0.424637).  Saving model ...
Validation loss decreased (0.424637 --> 0.424614).  Saving model ...
epoch 2501, loss 0.4246, train acc 79.28%, f1 0.6873, precision 0.7268, recall 0.6520, auc 0.7602
Validation loss decreased (0.424614 --> 0.424591).  Saving model ...
Validation loss decreased (0.424591 --> 0.424567).  Saving model ...
Validation loss decreased (0.424567 --> 0.424544).  Saving model ...
Validation loss decreased (0.424544 --> 0.424521).  Saving model ...
Validation loss decreased (0.424521 --> 0.424498).  Saving model ...
Validation loss decreased (0.424498 --> 0.424474).  Saving model ...
Validation loss decreased (0.424474 --> 0.424451).  Saving model ...
Validation loss decreased (0.424451 --> 0.424428).  Saving model ...
Validation loss decreased (0.424428 --> 0.424405).  Saving model ...
Validation loss decreased (0.424405 --> 0.424381).  Saving model ...
Validation loss decreased (0.424381 --> 0.424358).  Saving model ...
Validation loss decreased (0.424358 --> 0.424335).  Saving model ...
Validation loss decreased (0.424335 --> 0.424311).  Saving model ...
Validation loss decreased (0.424311 --> 0.424288).  Saving model ...
Validation loss decreased (0.424288 --> 0.424265).  Saving model ...
Validation loss decreased (0.424265 --> 0.424241).  Saving model ...
Validation loss decreased (0.424241 --> 0.424218).  Saving model ...
Validation loss decreased (0.424218 --> 0.424195).  Saving model ...
Validation loss decreased (0.424195 --> 0.424171).  Saving model ...
Validation loss decreased (0.424171 --> 0.424148).  Saving model ...
Validation loss decreased (0.424148 --> 0.424124).  Saving model ...
Validation loss decreased (0.424124 --> 0.424101).  Saving model ...
Validation loss decreased (0.424101 --> 0.424078).  Saving model ...
Validation loss decreased (0.424078 --> 0.424054).  Saving model ...
Validation loss decreased (0.424054 --> 0.424031).  Saving model ...
Validation loss decreased (0.424031 --> 0.424007).  Saving model ...
Validation loss decreased (0.424007 --> 0.423984).  Saving model ...
Validation loss decreased (0.423984 --> 0.423960).  Saving model ...
Validation loss decreased (0.423960 --> 0.423937).  Saving model ...
Validation loss decreased (0.423937 --> 0.423914).  Saving model ...
Validation loss decreased (0.423914 --> 0.423890).  Saving model ...
Validation loss decreased (0.423890 --> 0.423867).  Saving model ...
Validation loss decreased (0.423867 --> 0.423843).  Saving model ...
Validation loss decreased (0.423843 --> 0.423820).  Saving model ...
Validation loss decreased (0.423820 --> 0.423796).  Saving model ...
Validation loss decreased (0.423796 --> 0.423773).  Saving model ...
Validation loss decreased (0.423773 --> 0.423749).  Saving model ...
Validation loss decreased (0.423749 --> 0.423726).  Saving model ...
Validation loss decreased (0.423726 --> 0.423702).  Saving model ...
Validation loss decreased (0.423702 --> 0.423679).  Saving model ...
Validation loss decreased (0.423679 --> 0.423655).  Saving model ...
Validation loss decreased (0.423655 --> 0.423631).  Saving model ...
Validation loss decreased (0.423631 --> 0.423608).  Saving model ...
Validation loss decreased (0.423608 --> 0.423584).  Saving model ...
Validation loss decreased (0.423584 --> 0.423561).  Saving model ...
Validation loss decreased (0.423561 --> 0.423537).  Saving model ...
Validation loss decreased (0.423537 --> 0.423513).  Saving model ...
Validation loss decreased (0.423513 --> 0.423490).  Saving model ...
Validation loss decreased (0.423490 --> 0.423466).  Saving model ...
Validation loss decreased (0.423466 --> 0.423443).  Saving model ...
Validation loss decreased (0.423443 --> 0.423419).  Saving model ...
Validation loss decreased (0.423419 --> 0.423395).  Saving model ...
Validation loss decreased (0.423395 --> 0.423372).  Saving model ...
Validation loss decreased (0.423372 --> 0.423348).  Saving model ...
Validation loss decreased (0.423348 --> 0.423324).  Saving model ...
Validation loss decreased (0.423324 --> 0.423301).  Saving model ...
Validation loss decreased (0.423301 --> 0.423277).  Saving model ...
Validation loss decreased (0.423277 --> 0.423253).  Saving model ...
Validation loss decreased (0.423253 --> 0.423229).  Saving model ...
Validation loss decreased (0.423229 --> 0.423206).  Saving model ...
Validation loss decreased (0.423206 --> 0.423182).  Saving model ...
Validation loss decreased (0.423182 --> 0.423158).  Saving model ...
Validation loss decreased (0.423158 --> 0.423135).  Saving model ...
Validation loss decreased (0.423135 --> 0.423111).  Saving model ...
Validation loss decreased (0.423111 --> 0.423087).  Saving model ...
Validation loss decreased (0.423087 --> 0.423063).  Saving model ...
Validation loss decreased (0.423063 --> 0.423039).  Saving model ...
Validation loss decreased (0.423039 --> 0.423016).  Saving model ...
Validation loss decreased (0.423016 --> 0.422992).  Saving model ...
Validation loss decreased (0.422992 --> 0.422968).  Saving model ...
Validation loss decreased (0.422968 --> 0.422944).  Saving model ...
Validation loss decreased (0.422944 --> 0.422920).  Saving model ...
Validation loss decreased (0.422920 --> 0.422896).  Saving model ...
Validation loss decreased (0.422896 --> 0.422873).  Saving model ...
Validation loss decreased (0.422873 --> 0.422849).  Saving model ...
Validation loss decreased (0.422849 --> 0.422825).  Saving model ...
Validation loss decreased (0.422825 --> 0.422801).  Saving model ...
Validation loss decreased (0.422801 --> 0.422777).  Saving model ...
Validation loss decreased (0.422777 --> 0.422753).  Saving model ...
Validation loss decreased (0.422753 --> 0.422729).  Saving model ...
Validation loss decreased (0.422729 --> 0.422705).  Saving model ...
Validation loss decreased (0.422705 --> 0.422681).  Saving model ...
Validation loss decreased (0.422681 --> 0.422657).  Saving model ...
Validation loss decreased (0.422657 --> 0.422633).  Saving model ...
Validation loss decreased (0.422633 --> 0.422609).  Saving model ...
Validation loss decreased (0.422609 --> 0.422585).  Saving model ...
Validation loss decreased (0.422585 --> 0.422561).  Saving model ...
Validation loss decreased (0.422561 --> 0.422537).  Saving model ...
Validation loss decreased (0.422537 --> 0.422513).  Saving model ...
Validation loss decreased (0.422513 --> 0.422489).  Saving model ...
Validation loss decreased (0.422489 --> 0.422465).  Saving model ...
Validation loss decreased (0.422465 --> 0.422441).  Saving model ...
Validation loss decreased (0.422441 --> 0.422417).  Saving model ...
Validation loss decreased (0.422417 --> 0.422393).  Saving model ...
Validation loss decreased (0.422393 --> 0.422369).  Saving model ...
Validation loss decreased (0.422369 --> 0.422345).  Saving model ...
Validation loss decreased (0.422345 --> 0.422321).  Saving model ...
Validation loss decreased (0.422321 --> 0.422297).  Saving model ...
Validation loss decreased (0.422297 --> 0.422273).  Saving model ...
Validation loss decreased (0.422273 --> 0.422248).  Saving model ...
epoch 2601, loss 0.4222, train acc 79.28%, f1 0.6889, precision 0.7243, recall 0.6569, auc 0.7613
Validation loss decreased (0.422248 --> 0.422224).  Saving model ...
Validation loss decreased (0.422224 --> 0.422200).  Saving model ...
Validation loss decreased (0.422200 --> 0.422176).  Saving model ...
Validation loss decreased (0.422176 --> 0.422152).  Saving model ...
Validation loss decreased (0.422152 --> 0.422127).  Saving model ...
Validation loss decreased (0.422127 --> 0.422103).  Saving model ...
Validation loss decreased (0.422103 --> 0.422079).  Saving model ...
Validation loss decreased (0.422079 --> 0.422055).  Saving model ...
Validation loss decreased (0.422055 --> 0.422030).  Saving model ...
Validation loss decreased (0.422030 --> 0.422006).  Saving model ...
Validation loss decreased (0.422006 --> 0.421982).  Saving model ...
Validation loss decreased (0.421982 --> 0.421958).  Saving model ...
Validation loss decreased (0.421958 --> 0.421933).  Saving model ...
Validation loss decreased (0.421933 --> 0.421909).  Saving model ...
Validation loss decreased (0.421909 --> 0.421885).  Saving model ...
Validation loss decreased (0.421885 --> 0.421860).  Saving model ...
Validation loss decreased (0.421860 --> 0.421836).  Saving model ...
Validation loss decreased (0.421836 --> 0.421812).  Saving model ...
Validation loss decreased (0.421812 --> 0.421787).  Saving model ...
Validation loss decreased (0.421787 --> 0.421763).  Saving model ...
Validation loss decreased (0.421763 --> 0.421738).  Saving model ...
Validation loss decreased (0.421738 --> 0.421714).  Saving model ...
Validation loss decreased (0.421714 --> 0.421690).  Saving model ...
Validation loss decreased (0.421690 --> 0.421665).  Saving model ...
Validation loss decreased (0.421665 --> 0.421641).  Saving model ...
Validation loss decreased (0.421641 --> 0.421616).  Saving model ...
Validation loss decreased (0.421616 --> 0.421592).  Saving model ...
Validation loss decreased (0.421592 --> 0.421567).  Saving model ...
Validation loss decreased (0.421567 --> 0.421543).  Saving model ...
Validation loss decreased (0.421543 --> 0.421518).  Saving model ...
Validation loss decreased (0.421518 --> 0.421493).  Saving model ...
Validation loss decreased (0.421493 --> 0.421469).  Saving model ...
Validation loss decreased (0.421469 --> 0.421444).  Saving model ...
Validation loss decreased (0.421444 --> 0.421420).  Saving model ...
Validation loss decreased (0.421420 --> 0.421395).  Saving model ...
Validation loss decreased (0.421395 --> 0.421371).  Saving model ...
Validation loss decreased (0.421371 --> 0.421346).  Saving model ...
Validation loss decreased (0.421346 --> 0.421321).  Saving model ...
Validation loss decreased (0.421321 --> 0.421297).  Saving model ...
Validation loss decreased (0.421297 --> 0.421272).  Saving model ...
Validation loss decreased (0.421272 --> 0.421247).  Saving model ...
Validation loss decreased (0.421247 --> 0.421223).  Saving model ...
Validation loss decreased (0.421223 --> 0.421198).  Saving model ...
Validation loss decreased (0.421198 --> 0.421173).  Saving model ...
Validation loss decreased (0.421173 --> 0.421148).  Saving model ...
Validation loss decreased (0.421148 --> 0.421124).  Saving model ...
Validation loss decreased (0.421124 --> 0.421099).  Saving model ...
Validation loss decreased (0.421099 --> 0.421074).  Saving model ...
Validation loss decreased (0.421074 --> 0.421049).  Saving model ...
Validation loss decreased (0.421049 --> 0.421024).  Saving model ...
Validation loss decreased (0.421024 --> 0.421000).  Saving model ...
Validation loss decreased (0.421000 --> 0.420975).  Saving model ...
Validation loss decreased (0.420975 --> 0.420950).  Saving model ...
Validation loss decreased (0.420950 --> 0.420925).  Saving model ...
Validation loss decreased (0.420925 --> 0.420900).  Saving model ...
Validation loss decreased (0.420900 --> 0.420875).  Saving model ...
Validation loss decreased (0.420875 --> 0.420850).  Saving model ...
Validation loss decreased (0.420850 --> 0.420826).  Saving model ...
Validation loss decreased (0.420826 --> 0.420801).  Saving model ...
Validation loss decreased (0.420801 --> 0.420776).  Saving model ...
Validation loss decreased (0.420776 --> 0.420751).  Saving model ...
Validation loss decreased (0.420751 --> 0.420726).  Saving model ...
Validation loss decreased (0.420726 --> 0.420701).  Saving model ...
Validation loss decreased (0.420701 --> 0.420676).  Saving model ...
Validation loss decreased (0.420676 --> 0.420651).  Saving model ...
Validation loss decreased (0.420651 --> 0.420626).  Saving model ...
Validation loss decreased (0.420626 --> 0.420601).  Saving model ...
Validation loss decreased (0.420601 --> 0.420576).  Saving model ...
Validation loss decreased (0.420576 --> 0.420551).  Saving model ...
Validation loss decreased (0.420551 --> 0.420526).  Saving model ...
Validation loss decreased (0.420526 --> 0.420501).  Saving model ...
Validation loss decreased (0.420501 --> 0.420476).  Saving model ...
Validation loss decreased (0.420476 --> 0.420451).  Saving model ...
Validation loss decreased (0.420451 --> 0.420426).  Saving model ...
Validation loss decreased (0.420426 --> 0.420401).  Saving model ...
Validation loss decreased (0.420401 --> 0.420376).  Saving model ...
Validation loss decreased (0.420376 --> 0.420351).  Saving model ...
Validation loss decreased (0.420351 --> 0.420326).  Saving model ...
Validation loss decreased (0.420326 --> 0.420301).  Saving model ...
Validation loss decreased (0.420301 --> 0.420276).  Saving model ...
Validation loss decreased (0.420276 --> 0.420251).  Saving model ...
Validation loss decreased (0.420251 --> 0.420226).  Saving model ...
Validation loss decreased (0.420226 --> 0.420201).  Saving model ...
Validation loss decreased (0.420201 --> 0.420176).  Saving model ...
Validation loss decreased (0.420176 --> 0.420151).  Saving model ...
Validation loss decreased (0.420151 --> 0.420126).  Saving model ...
Validation loss decreased (0.420126 --> 0.420101).  Saving model ...
Validation loss decreased (0.420101 --> 0.420076).  Saving model ...
Validation loss decreased (0.420076 --> 0.420051).  Saving model ...
Validation loss decreased (0.420051 --> 0.420025).  Saving model ...
Validation loss decreased (0.420025 --> 0.420000).  Saving model ...
Validation loss decreased (0.420000 --> 0.419975).  Saving model ...
Validation loss decreased (0.419975 --> 0.419950).  Saving model ...
Validation loss decreased (0.419950 --> 0.419925).  Saving model ...
Validation loss decreased (0.419925 --> 0.419900).  Saving model ...
Validation loss decreased (0.419900 --> 0.419875).  Saving model ...
Validation loss decreased (0.419875 --> 0.419850).  Saving model ...
Validation loss decreased (0.419850 --> 0.419825).  Saving model ...
Validation loss decreased (0.419825 --> 0.419800).  Saving model ...
Validation loss decreased (0.419800 --> 0.419775).  Saving model ...
epoch 2701, loss 0.4198, train acc 79.62%, f1 0.6941, precision 0.7297, recall 0.6618, auc 0.7651
Validation loss decreased (0.419775 --> 0.419750).  Saving model ...
Validation loss decreased (0.419750 --> 0.419725).  Saving model ...
Validation loss decreased (0.419725 --> 0.419700).  Saving model ...
Validation loss decreased (0.419700 --> 0.419675).  Saving model ...
Validation loss decreased (0.419675 --> 0.419650).  Saving model ...
Validation loss decreased (0.419650 --> 0.419625).  Saving model ...
Validation loss decreased (0.419625 --> 0.419600).  Saving model ...
Validation loss decreased (0.419600 --> 0.419575).  Saving model ...
Validation loss decreased (0.419575 --> 0.419550).  Saving model ...
Validation loss decreased (0.419550 --> 0.419525).  Saving model ...
Validation loss decreased (0.419525 --> 0.419500).  Saving model ...
Validation loss decreased (0.419500 --> 0.419475).  Saving model ...
Validation loss decreased (0.419475 --> 0.419450).  Saving model ...
Validation loss decreased (0.419450 --> 0.419425).  Saving model ...
Validation loss decreased (0.419425 --> 0.419400).  Saving model ...
Validation loss decreased (0.419400 --> 0.419375).  Saving model ...
Validation loss decreased (0.419375 --> 0.419350).  Saving model ...
Validation loss decreased (0.419350 --> 0.419325).  Saving model ...
Validation loss decreased (0.419325 --> 0.419300).  Saving model ...
Validation loss decreased (0.419300 --> 0.419275).  Saving model ...
Validation loss decreased (0.419275 --> 0.419250).  Saving model ...
Validation loss decreased (0.419250 --> 0.419225).  Saving model ...
Validation loss decreased (0.419225 --> 0.419200).  Saving model ...
Validation loss decreased (0.419200 --> 0.419175).  Saving model ...
Validation loss decreased (0.419175 --> 0.419150).  Saving model ...
Validation loss decreased (0.419150 --> 0.419125).  Saving model ...
Validation loss decreased (0.419125 --> 0.419100).  Saving model ...
Validation loss decreased (0.419100 --> 0.419075).  Saving model ...
Validation loss decreased (0.419075 --> 0.419050).  Saving model ...
Validation loss decreased (0.419050 --> 0.419024).  Saving model ...
Validation loss decreased (0.419024 --> 0.419000).  Saving model ...
Validation loss decreased (0.419000 --> 0.418975).  Saving model ...
Validation loss decreased (0.418975 --> 0.418949).  Saving model ...
Validation loss decreased (0.418949 --> 0.418924).  Saving model ...
Validation loss decreased (0.418924 --> 0.418899).  Saving model ...
Validation loss decreased (0.418899 --> 0.418874).  Saving model ...
Validation loss decreased (0.418874 --> 0.418849).  Saving model ...
Validation loss decreased (0.418849 --> 0.418824).  Saving model ...
Validation loss decreased (0.418824 --> 0.418799).  Saving model ...
Validation loss decreased (0.418799 --> 0.418774).  Saving model ...
Validation loss decreased (0.418774 --> 0.418749).  Saving model ...
Validation loss decreased (0.418749 --> 0.418724).  Saving model ...
Validation loss decreased (0.418724 --> 0.418699).  Saving model ...
Validation loss decreased (0.418699 --> 0.418674).  Saving model ...
Validation loss decreased (0.418674 --> 0.418649).  Saving model ...
Validation loss decreased (0.418649 --> 0.418624).  Saving model ...
Validation loss decreased (0.418624 --> 0.418599).  Saving model ...
Validation loss decreased (0.418599 --> 0.418574).  Saving model ...
Validation loss decreased (0.418574 --> 0.418549).  Saving model ...
Validation loss decreased (0.418549 --> 0.418524).  Saving model ...
Validation loss decreased (0.418524 --> 0.418499).  Saving model ...
Validation loss decreased (0.418499 --> 0.418474).  Saving model ...
Validation loss decreased (0.418474 --> 0.418449).  Saving model ...
Validation loss decreased (0.418449 --> 0.418424).  Saving model ...
Validation loss decreased (0.418424 --> 0.418399).  Saving model ...
Validation loss decreased (0.418399 --> 0.418374).  Saving model ...
Validation loss decreased (0.418374 --> 0.418349).  Saving model ...
Validation loss decreased (0.418349 --> 0.418324).  Saving model ...
Validation loss decreased (0.418324 --> 0.418299).  Saving model ...
Validation loss decreased (0.418299 --> 0.418274).  Saving model ...
Validation loss decreased (0.418274 --> 0.418249).  Saving model ...
Validation loss decreased (0.418249 --> 0.418223).  Saving model ...
Validation loss decreased (0.418223 --> 0.418198).  Saving model ...
Validation loss decreased (0.418198 --> 0.418173).  Saving model ...
Validation loss decreased (0.418173 --> 0.418148).  Saving model ...
Validation loss decreased (0.418148 --> 0.418123).  Saving model ...
Validation loss decreased (0.418123 --> 0.418098).  Saving model ...
Validation loss decreased (0.418098 --> 0.418073).  Saving model ...
Validation loss decreased (0.418073 --> 0.418048).  Saving model ...
Validation loss decreased (0.418048 --> 0.418023).  Saving model ...
Validation loss decreased (0.418023 --> 0.417997).  Saving model ...
Validation loss decreased (0.417997 --> 0.417972).  Saving model ...
Validation loss decreased (0.417972 --> 0.417947).  Saving model ...
Validation loss decreased (0.417947 --> 0.417922).  Saving model ...
Validation loss decreased (0.417922 --> 0.417897).  Saving model ...
Validation loss decreased (0.417897 --> 0.417872).  Saving model ...
Validation loss decreased (0.417872 --> 0.417847).  Saving model ...
Validation loss decreased (0.417847 --> 0.417821).  Saving model ...
Validation loss decreased (0.417821 --> 0.417796).  Saving model ...
Validation loss decreased (0.417796 --> 0.417771).  Saving model ...
Validation loss decreased (0.417771 --> 0.417746).  Saving model ...
Validation loss decreased (0.417746 --> 0.417721).  Saving model ...
Validation loss decreased (0.417721 --> 0.417695).  Saving model ...
Validation loss decreased (0.417695 --> 0.417670).  Saving model ...
Validation loss decreased (0.417670 --> 0.417645).  Saving model ...
Validation loss decreased (0.417645 --> 0.417620).  Saving model ...
Validation loss decreased (0.417620 --> 0.417595).  Saving model ...
Validation loss decreased (0.417595 --> 0.417569).  Saving model ...
Validation loss decreased (0.417569 --> 0.417544).  Saving model ...
Validation loss decreased (0.417544 --> 0.417519).  Saving model ...
Validation loss decreased (0.417519 --> 0.417494).  Saving model ...
Validation loss decreased (0.417494 --> 0.417468).  Saving model ...
Validation loss decreased (0.417468 --> 0.417443).  Saving model ...
Validation loss decreased (0.417443 --> 0.417418).  Saving model ...
Validation loss decreased (0.417418 --> 0.417393).  Saving model ...
Validation loss decreased (0.417393 --> 0.417367).  Saving model ...
Validation loss decreased (0.417367 --> 0.417342).  Saving model ...
Validation loss decreased (0.417342 --> 0.417317).  Saving model ...
Validation loss decreased (0.417317 --> 0.417291).  Saving model ...
Validation loss decreased (0.417291 --> 0.417266).  Saving model ...
epoch 2801, loss 0.4173, train acc 79.97%, f1 0.6977, precision 0.7377, recall 0.6618, auc 0.7677
Validation loss decreased (0.417266 --> 0.417241).  Saving model ...
Validation loss decreased (0.417241 --> 0.417215).  Saving model ...
Validation loss decreased (0.417215 --> 0.417190).  Saving model ...
Validation loss decreased (0.417190 --> 0.417165).  Saving model ...
Validation loss decreased (0.417165 --> 0.417140).  Saving model ...
Validation loss decreased (0.417140 --> 0.417114).  Saving model ...
Validation loss decreased (0.417114 --> 0.417089).  Saving model ...
Validation loss decreased (0.417089 --> 0.417064).  Saving model ...
Validation loss decreased (0.417064 --> 0.417038).  Saving model ...
Validation loss decreased (0.417038 --> 0.417013).  Saving model ...
Validation loss decreased (0.417013 --> 0.416987).  Saving model ...
Validation loss decreased (0.416987 --> 0.416962).  Saving model ...
Validation loss decreased (0.416962 --> 0.416937).  Saving model ...
Validation loss decreased (0.416937 --> 0.416911).  Saving model ...
Validation loss decreased (0.416911 --> 0.416886).  Saving model ...
Validation loss decreased (0.416886 --> 0.416860).  Saving model ...
Validation loss decreased (0.416860 --> 0.416835).  Saving model ...
Validation loss decreased (0.416835 --> 0.416810).  Saving model ...
Validation loss decreased (0.416810 --> 0.416784).  Saving model ...
Validation loss decreased (0.416784 --> 0.416759).  Saving model ...
Validation loss decreased (0.416759 --> 0.416733).  Saving model ...
Validation loss decreased (0.416733 --> 0.416708).  Saving model ...
Validation loss decreased (0.416708 --> 0.416682).  Saving model ...
Validation loss decreased (0.416682 --> 0.416657).  Saving model ...
Validation loss decreased (0.416657 --> 0.416631).  Saving model ...
Validation loss decreased (0.416631 --> 0.416606).  Saving model ...
Validation loss decreased (0.416606 --> 0.416580).  Saving model ...
Validation loss decreased (0.416580 --> 0.416555).  Saving model ...
Validation loss decreased (0.416555 --> 0.416529).  Saving model ...
Validation loss decreased (0.416529 --> 0.416504).  Saving model ...
Validation loss decreased (0.416504 --> 0.416478).  Saving model ...
Validation loss decreased (0.416478 --> 0.416453).  Saving model ...
Validation loss decreased (0.416453 --> 0.416427).  Saving model ...
Validation loss decreased (0.416427 --> 0.416402).  Saving model ...
Validation loss decreased (0.416402 --> 0.416376).  Saving model ...
Validation loss decreased (0.416376 --> 0.416351).  Saving model ...
Validation loss decreased (0.416351 --> 0.416325).  Saving model ...
Validation loss decreased (0.416325 --> 0.416300).  Saving model ...
Validation loss decreased (0.416300 --> 0.416274).  Saving model ...
Validation loss decreased (0.416274 --> 0.416248).  Saving model ...
Validation loss decreased (0.416248 --> 0.416223).  Saving model ...
Validation loss decreased (0.416223 --> 0.416197).  Saving model ...
Validation loss decreased (0.416197 --> 0.416172).  Saving model ...
Validation loss decreased (0.416172 --> 0.416146).  Saving model ...
Validation loss decreased (0.416146 --> 0.416121).  Saving model ...
Validation loss decreased (0.416121 --> 0.416095).  Saving model ...
Validation loss decreased (0.416095 --> 0.416069).  Saving model ...
Validation loss decreased (0.416069 --> 0.416044).  Saving model ...
Validation loss decreased (0.416044 --> 0.416018).  Saving model ...
Validation loss decreased (0.416018 --> 0.415992).  Saving model ...
Validation loss decreased (0.415992 --> 0.415967).  Saving model ...
Validation loss decreased (0.415967 --> 0.415941).  Saving model ...
Validation loss decreased (0.415941 --> 0.415916).  Saving model ...
Validation loss decreased (0.415916 --> 0.415890).  Saving model ...
Validation loss decreased (0.415890 --> 0.415864).  Saving model ...
Validation loss decreased (0.415864 --> 0.415839).  Saving model ...
Validation loss decreased (0.415839 --> 0.415813).  Saving model ...
Validation loss decreased (0.415813 --> 0.415787).  Saving model ...
Validation loss decreased (0.415787 --> 0.415762).  Saving model ...
Validation loss decreased (0.415762 --> 0.415736).  Saving model ...
Validation loss decreased (0.415736 --> 0.415710).  Saving model ...
Validation loss decreased (0.415710 --> 0.415685).  Saving model ...
Validation loss decreased (0.415685 --> 0.415659).  Saving model ...
Validation loss decreased (0.415659 --> 0.415633).  Saving model ...
Validation loss decreased (0.415633 --> 0.415608).  Saving model ...
Validation loss decreased (0.415608 --> 0.415582).  Saving model ...
Validation loss decreased (0.415582 --> 0.415556).  Saving model ...
Validation loss decreased (0.415556 --> 0.415531).  Saving model ...
Validation loss decreased (0.415531 --> 0.415505).  Saving model ...
Validation loss decreased (0.415505 --> 0.415479).  Saving model ...
Validation loss decreased (0.415479 --> 0.415453).  Saving model ...
Validation loss decreased (0.415453 --> 0.415428).  Saving model ...
Validation loss decreased (0.415428 --> 0.415402).  Saving model ...
Validation loss decreased (0.415402 --> 0.415376).  Saving model ...
Validation loss decreased (0.415376 --> 0.415350).  Saving model ...
Validation loss decreased (0.415350 --> 0.415325).  Saving model ...
Validation loss decreased (0.415325 --> 0.415299).  Saving model ...
Validation loss decreased (0.415299 --> 0.415273).  Saving model ...
Validation loss decreased (0.415273 --> 0.415248).  Saving model ...
Validation loss decreased (0.415248 --> 0.415222).  Saving model ...
Validation loss decreased (0.415222 --> 0.415196).  Saving model ...
Validation loss decreased (0.415196 --> 0.415170).  Saving model ...
Validation loss decreased (0.415170 --> 0.415145).  Saving model ...
Validation loss decreased (0.415145 --> 0.415119).  Saving model ...
Validation loss decreased (0.415119 --> 0.415093).  Saving model ...
Validation loss decreased (0.415093 --> 0.415067).  Saving model ...
Validation loss decreased (0.415067 --> 0.415042).  Saving model ...
Validation loss decreased (0.415042 --> 0.415016).  Saving model ...
Validation loss decreased (0.415016 --> 0.414990).  Saving model ...
Validation loss decreased (0.414990 --> 0.414964).  Saving model ...
Validation loss decreased (0.414964 --> 0.414939).  Saving model ...
Validation loss decreased (0.414939 --> 0.414913).  Saving model ...
Validation loss decreased (0.414913 --> 0.414887).  Saving model ...
Validation loss decreased (0.414887 --> 0.414861).  Saving model ...
Validation loss decreased (0.414861 --> 0.414836).  Saving model ...
Validation loss decreased (0.414836 --> 0.414810).  Saving model ...
Validation loss decreased (0.414810 --> 0.414784).  Saving model ...
Validation loss decreased (0.414784 --> 0.414758).  Saving model ...
Validation loss decreased (0.414758 --> 0.414733).  Saving model ...
Validation loss decreased (0.414733 --> 0.414707).  Saving model ...
epoch 2901, loss 0.4147, train acc 80.31%, f1 0.7044, precision 0.7405, recall 0.6716, auc 0.7726
Validation loss decreased (0.414707 --> 0.414681).  Saving model ...
Validation loss decreased (0.414681 --> 0.414655).  Saving model ...
Validation loss decreased (0.414655 --> 0.414630).  Saving model ...
Validation loss decreased (0.414630 --> 0.414604).  Saving model ...
Validation loss decreased (0.414604 --> 0.414578).  Saving model ...
Validation loss decreased (0.414578 --> 0.414552).  Saving model ...
Validation loss decreased (0.414552 --> 0.414527).  Saving model ...
Validation loss decreased (0.414527 --> 0.414501).  Saving model ...
Validation loss decreased (0.414501 --> 0.414475).  Saving model ...
Validation loss decreased (0.414475 --> 0.414450).  Saving model ...
Validation loss decreased (0.414450 --> 0.414424).  Saving model ...
Validation loss decreased (0.414424 --> 0.414398).  Saving model ...
Validation loss decreased (0.414398 --> 0.414372).  Saving model ...
Validation loss decreased (0.414372 --> 0.414347).  Saving model ...
Validation loss decreased (0.414347 --> 0.414321).  Saving model ...
Validation loss decreased (0.414321 --> 0.414295).  Saving model ...
Validation loss decreased (0.414295 --> 0.414269).  Saving model ...
Validation loss decreased (0.414269 --> 0.414244).  Saving model ...
Validation loss decreased (0.414244 --> 0.414218).  Saving model ...
Validation loss decreased (0.414218 --> 0.414192).  Saving model ...
Validation loss decreased (0.414192 --> 0.414166).  Saving model ...
Validation loss decreased (0.414166 --> 0.414141).  Saving model ...
Validation loss decreased (0.414141 --> 0.414115).  Saving model ...
Validation loss decreased (0.414115 --> 0.414089).  Saving model ...
Validation loss decreased (0.414089 --> 0.414064).  Saving model ...
Validation loss decreased (0.414064 --> 0.414038).  Saving model ...
Validation loss decreased (0.414038 --> 0.414012).  Saving model ...
Validation loss decreased (0.414012 --> 0.413986).  Saving model ...
Validation loss decreased (0.413986 --> 0.413961).  Saving model ...
Validation loss decreased (0.413961 --> 0.413935).  Saving model ...
Validation loss decreased (0.413935 --> 0.413909).  Saving model ...
Validation loss decreased (0.413909 --> 0.413884).  Saving model ...
Validation loss decreased (0.413884 --> 0.413858).  Saving model ...
Validation loss decreased (0.413858 --> 0.413832).  Saving model ...
Validation loss decreased (0.413832 --> 0.413806).  Saving model ...
Validation loss decreased (0.413806 --> 0.413781).  Saving model ...
Validation loss decreased (0.413781 --> 0.413755).  Saving model ...
Validation loss decreased (0.413755 --> 0.413729).  Saving model ...
Validation loss decreased (0.413729 --> 0.413704).  Saving model ...
Validation loss decreased (0.413704 --> 0.413678).  Saving model ...
Validation loss decreased (0.413678 --> 0.413652).  Saving model ...
Validation loss decreased (0.413652 --> 0.413627).  Saving model ...
Validation loss decreased (0.413627 --> 0.413601).  Saving model ...
Validation loss decreased (0.413601 --> 0.413575).  Saving model ...
Validation loss decreased (0.413575 --> 0.413550).  Saving model ...
Validation loss decreased (0.413550 --> 0.413524).  Saving model ...
Validation loss decreased (0.413524 --> 0.413498).  Saving model ...
Validation loss decreased (0.413498 --> 0.413473).  Saving model ...
Validation loss decreased (0.413473 --> 0.413447).  Saving model ...
Validation loss decreased (0.413447 --> 0.413421).  Saving model ...
Validation loss decreased (0.413421 --> 0.413396).  Saving model ...
Validation loss decreased (0.413396 --> 0.413370).  Saving model ...
Validation loss decreased (0.413370 --> 0.413345).  Saving model ...
Validation loss decreased (0.413345 --> 0.413319).  Saving model ...
Validation loss decreased (0.413319 --> 0.413293).  Saving model ...
Validation loss decreased (0.413293 --> 0.413268).  Saving model ...
Validation loss decreased (0.413268 --> 0.413242).  Saving model ...
Validation loss decreased (0.413242 --> 0.413216).  Saving model ...
Validation loss decreased (0.413216 --> 0.413191).  Saving model ...
Validation loss decreased (0.413191 --> 0.413165).  Saving model ...
Validation loss decreased (0.413165 --> 0.413140).  Saving model ...
Validation loss decreased (0.413140 --> 0.413114).  Saving model ...
Validation loss decreased (0.413114 --> 0.413088).  Saving model ...
Validation loss decreased (0.413088 --> 0.413063).  Saving model ...
Validation loss decreased (0.413063 --> 0.413037).  Saving model ...
Validation loss decreased (0.413037 --> 0.413011).  Saving model ...
Validation loss decreased (0.413011 --> 0.412986).  Saving model ...
Validation loss decreased (0.412986 --> 0.412960).  Saving model ...
Validation loss decreased (0.412960 --> 0.412935).  Saving model ...
Validation loss decreased (0.412935 --> 0.412909).  Saving model ...
Validation loss decreased (0.412909 --> 0.412883).  Saving model ...
Validation loss decreased (0.412883 --> 0.412858).  Saving model ...
Validation loss decreased (0.412858 --> 0.412832).  Saving model ...
Validation loss decreased (0.412832 --> 0.412807).  Saving model ...
Validation loss decreased (0.412807 --> 0.412781).  Saving model ...
Validation loss decreased (0.412781 --> 0.412756).  Saving model ...
Validation loss decreased (0.412756 --> 0.412730).  Saving model ...
Validation loss decreased (0.412730 --> 0.412704).  Saving model ...
Validation loss decreased (0.412704 --> 0.412679).  Saving model ...
Validation loss decreased (0.412679 --> 0.412653).  Saving model ...
Validation loss decreased (0.412653 --> 0.412628).  Saving model ...
Validation loss decreased (0.412628 --> 0.412602).  Saving model ...
Validation loss decreased (0.412602 --> 0.412577).  Saving model ...
Validation loss decreased (0.412577 --> 0.412551).  Saving model ...
Validation loss decreased (0.412551 --> 0.412526).  Saving model ...
Validation loss decreased (0.412526 --> 0.412500).  Saving model ...
Validation loss decreased (0.412500 --> 0.412474).  Saving model ...
Validation loss decreased (0.412474 --> 0.412449).  Saving model ...
Validation loss decreased (0.412449 --> 0.412423).  Saving model ...
Validation loss decreased (0.412423 --> 0.412398).  Saving model ...
Validation loss decreased (0.412398 --> 0.412372).  Saving model ...
Validation loss decreased (0.412372 --> 0.412347).  Saving model ...
Validation loss decreased (0.412347 --> 0.412321).  Saving model ...
Validation loss decreased (0.412321 --> 0.412296).  Saving model ...
Validation loss decreased (0.412296 --> 0.412270).  Saving model ...
Validation loss decreased (0.412270 --> 0.412244).  Saving model ...
Validation loss decreased (0.412244 --> 0.412219).  Saving model ...
Validation loss decreased (0.412219 --> 0.412193).  Saving model ...
Validation loss decreased (0.412193 --> 0.412168).  Saving model ...
Validation loss decreased (0.412168 --> 0.412142).  Saving model ...
epoch 3001, loss 0.4121, train acc 80.99%, f1 0.7147, precision 0.7514, recall 0.6814, auc 0.7802
Validation loss decreased (0.412142 --> 0.412117).  Saving model ...
Validation loss decreased (0.412117 --> 0.412091).  Saving model ...
Validation loss decreased (0.412091 --> 0.412066).  Saving model ...
Validation loss decreased (0.412066 --> 0.412040).  Saving model ...
Validation loss decreased (0.412040 --> 0.412015).  Saving model ...
Validation loss decreased (0.412015 --> 0.411989).  Saving model ...
Validation loss decreased (0.411989 --> 0.411964).  Saving model ...
Validation loss decreased (0.411964 --> 0.411938).  Saving model ...
Validation loss decreased (0.411938 --> 0.411913).  Saving model ...
Validation loss decreased (0.411913 --> 0.411887).  Saving model ...
Validation loss decreased (0.411887 --> 0.411862).  Saving model ...
Validation loss decreased (0.411862 --> 0.411836).  Saving model ...
Validation loss decreased (0.411836 --> 0.411811).  Saving model ...
Validation loss decreased (0.411811 --> 0.411785).  Saving model ...
Validation loss decreased (0.411785 --> 0.411759).  Saving model ...
Validation loss decreased (0.411759 --> 0.411734).  Saving model ...
Validation loss decreased (0.411734 --> 0.411708).  Saving model ...
Validation loss decreased (0.411708 --> 0.411683).  Saving model ...
Validation loss decreased (0.411683 --> 0.411657).  Saving model ...
Validation loss decreased (0.411657 --> 0.411632).  Saving model ...
Validation loss decreased (0.411632 --> 0.411606).  Saving model ...
Validation loss decreased (0.411606 --> 0.411581).  Saving model ...
Validation loss decreased (0.411581 --> 0.411555).  Saving model ...
Validation loss decreased (0.411555 --> 0.411530).  Saving model ...
Validation loss decreased (0.411530 --> 0.411504).  Saving model ...
Validation loss decreased (0.411504 --> 0.411479).  Saving model ...
Validation loss decreased (0.411479 --> 0.411453).  Saving model ...
Validation loss decreased (0.411453 --> 0.411428).  Saving model ...
Validation loss decreased (0.411428 --> 0.411402).  Saving model ...
Validation loss decreased (0.411402 --> 0.411377).  Saving model ...
Validation loss decreased (0.411377 --> 0.411351).  Saving model ...
Validation loss decreased (0.411351 --> 0.411326).  Saving model ...
Validation loss decreased (0.411326 --> 0.411300).  Saving model ...
Validation loss decreased (0.411300 --> 0.411275).  Saving model ...
Validation loss decreased (0.411275 --> 0.411249).  Saving model ...
Validation loss decreased (0.411249 --> 0.411224).  Saving model ...
Validation loss decreased (0.411224 --> 0.411198).  Saving model ...
Validation loss decreased (0.411198 --> 0.411172).  Saving model ...
Validation loss decreased (0.411172 --> 0.411147).  Saving model ...
Validation loss decreased (0.411147 --> 0.411121).  Saving model ...
Validation loss decreased (0.411121 --> 0.411096).  Saving model ...
Validation loss decreased (0.411096 --> 0.411070).  Saving model ...
Validation loss decreased (0.411070 --> 0.411045).  Saving model ...
Validation loss decreased (0.411045 --> 0.411019).  Saving model ...
Validation loss decreased (0.411019 --> 0.410994).  Saving model ...
Validation loss decreased (0.410994 --> 0.410968).  Saving model ...
Validation loss decreased (0.410968 --> 0.410943).  Saving model ...
Validation loss decreased (0.410943 --> 0.410917).  Saving model ...
Validation loss decreased (0.410917 --> 0.410892).  Saving model ...
Validation loss decreased (0.410892 --> 0.410866).  Saving model ...
Validation loss decreased (0.410866 --> 0.410840).  Saving model ...
Validation loss decreased (0.410840 --> 0.410815).  Saving model ...
Validation loss decreased (0.410815 --> 0.410789).  Saving model ...
Validation loss decreased (0.410789 --> 0.410764).  Saving model ...
Validation loss decreased (0.410764 --> 0.410738).  Saving model ...
Validation loss decreased (0.410738 --> 0.410713).  Saving model ...
Validation loss decreased (0.410713 --> 0.410687).  Saving model ...
Validation loss decreased (0.410687 --> 0.410662).  Saving model ...
Validation loss decreased (0.410662 --> 0.410636).  Saving model ...
Validation loss decreased (0.410636 --> 0.410610).  Saving model ...
Validation loss decreased (0.410610 --> 0.410585).  Saving model ...
Validation loss decreased (0.410585 --> 0.410559).  Saving model ...
Validation loss decreased (0.410559 --> 0.410534).  Saving model ...
Validation loss decreased (0.410534 --> 0.410508).  Saving model ...
Validation loss decreased (0.410508 --> 0.410482).  Saving model ...
Validation loss decreased (0.410482 --> 0.410457).  Saving model ...
Validation loss decreased (0.410457 --> 0.410431).  Saving model ...
Validation loss decreased (0.410431 --> 0.410406).  Saving model ...
Validation loss decreased (0.410406 --> 0.410380).  Saving model ...
Validation loss decreased (0.410380 --> 0.410354).  Saving model ...
Validation loss decreased (0.410354 --> 0.410329).  Saving model ...
Validation loss decreased (0.410329 --> 0.410303).  Saving model ...
Validation loss decreased (0.410303 --> 0.410278).  Saving model ...
Validation loss decreased (0.410278 --> 0.410252).  Saving model ...
Validation loss decreased (0.410252 --> 0.410226).  Saving model ...
Validation loss decreased (0.410226 --> 0.410201).  Saving model ...
Validation loss decreased (0.410201 --> 0.410175).  Saving model ...
Validation loss decreased (0.410175 --> 0.410150).  Saving model ...
Validation loss decreased (0.410150 --> 0.410124).  Saving model ...
Validation loss decreased (0.410124 --> 0.410098).  Saving model ...
Validation loss decreased (0.410098 --> 0.410073).  Saving model ...
Validation loss decreased (0.410073 --> 0.410047).  Saving model ...
Validation loss decreased (0.410047 --> 0.410021).  Saving model ...
Validation loss decreased (0.410021 --> 0.409996).  Saving model ...
Validation loss decreased (0.409996 --> 0.409970).  Saving model ...
Validation loss decreased (0.409970 --> 0.409945).  Saving model ...
Validation loss decreased (0.409945 --> 0.409919).  Saving model ...
Validation loss decreased (0.409919 --> 0.409893).  Saving model ...
Validation loss decreased (0.409893 --> 0.409868).  Saving model ...
Validation loss decreased (0.409868 --> 0.409842).  Saving model ...
Validation loss decreased (0.409842 --> 0.409816).  Saving model ...
Validation loss decreased (0.409816 --> 0.409791).  Saving model ...
Validation loss decreased (0.409791 --> 0.409765).  Saving model ...
Validation loss decreased (0.409765 --> 0.409739).  Saving model ...
Validation loss decreased (0.409739 --> 0.409714).  Saving model ...
Validation loss decreased (0.409714 --> 0.409688).  Saving model ...
Validation loss decreased (0.409688 --> 0.409662).  Saving model ...
Validation loss decreased (0.409662 --> 0.409636).  Saving model ...
Validation loss decreased (0.409636 --> 0.409611).  Saving model ...
Validation loss decreased (0.409611 --> 0.409585).  Saving model ...
epoch 3101, loss 0.4096, train acc 81.51%, f1 0.7231, precision 0.7581, recall 0.6912, auc 0.7864
Validation loss decreased (0.409585 --> 0.409559).  Saving model ...
Validation loss decreased (0.409559 --> 0.409534).  Saving model ...
Validation loss decreased (0.409534 --> 0.409508).  Saving model ...
Validation loss decreased (0.409508 --> 0.409482).  Saving model ...
Validation loss decreased (0.409482 --> 0.409457).  Saving model ...
Validation loss decreased (0.409457 --> 0.409431).  Saving model ...
Validation loss decreased (0.409431 --> 0.409405).  Saving model ...
Validation loss decreased (0.409405 --> 0.409379).  Saving model ...
Validation loss decreased (0.409379 --> 0.409354).  Saving model ...
Validation loss decreased (0.409354 --> 0.409328).  Saving model ...
Validation loss decreased (0.409328 --> 0.409302).  Saving model ...
Validation loss decreased (0.409302 --> 0.409276).  Saving model ...
Validation loss decreased (0.409276 --> 0.409251).  Saving model ...
Validation loss decreased (0.409251 --> 0.409225).  Saving model ...
Validation loss decreased (0.409225 --> 0.409199).  Saving model ...
Validation loss decreased (0.409199 --> 0.409174).  Saving model ...
Validation loss decreased (0.409174 --> 0.409148).  Saving model ...
Validation loss decreased (0.409148 --> 0.409122).  Saving model ...
Validation loss decreased (0.409122 --> 0.409096).  Saving model ...
Validation loss decreased (0.409096 --> 0.409070).  Saving model ...
Validation loss decreased (0.409070 --> 0.409045).  Saving model ...
Validation loss decreased (0.409045 --> 0.409019).  Saving model ...
Validation loss decreased (0.409019 --> 0.408993).  Saving model ...
Validation loss decreased (0.408993 --> 0.408967).  Saving model ...
Validation loss decreased (0.408967 --> 0.408942).  Saving model ...
Validation loss decreased (0.408942 --> 0.408916).  Saving model ...
Validation loss decreased (0.408916 --> 0.408890).  Saving model ...
Validation loss decreased (0.408890 --> 0.408864).  Saving model ...
Validation loss decreased (0.408864 --> 0.408838).  Saving model ...
Validation loss decreased (0.408838 --> 0.408812).  Saving model ...
Validation loss decreased (0.408812 --> 0.408787).  Saving model ...
Validation loss decreased (0.408787 --> 0.408761).  Saving model ...
Validation loss decreased (0.408761 --> 0.408735).  Saving model ...
Validation loss decreased (0.408735 --> 0.408709).  Saving model ...
Validation loss decreased (0.408709 --> 0.408683).  Saving model ...
Validation loss decreased (0.408683 --> 0.408658).  Saving model ...
Validation loss decreased (0.408658 --> 0.408632).  Saving model ...
Validation loss decreased (0.408632 --> 0.408606).  Saving model ...
Validation loss decreased (0.408606 --> 0.408580).  Saving model ...
Validation loss decreased (0.408580 --> 0.408554).  Saving model ...
Validation loss decreased (0.408554 --> 0.408528).  Saving model ...
Validation loss decreased (0.408528 --> 0.408503).  Saving model ...
Validation loss decreased (0.408503 --> 0.408477).  Saving model ...
Validation loss decreased (0.408477 --> 0.408451).  Saving model ...
Validation loss decreased (0.408451 --> 0.408425).  Saving model ...
Validation loss decreased (0.408425 --> 0.408399).  Saving model ...
Validation loss decreased (0.408399 --> 0.408373).  Saving model ...
Validation loss decreased (0.408373 --> 0.408347).  Saving model ...
Validation loss decreased (0.408347 --> 0.408322).  Saving model ...
Validation loss decreased (0.408322 --> 0.408296).  Saving model ...
Validation loss decreased (0.408296 --> 0.408270).  Saving model ...
Validation loss decreased (0.408270 --> 0.408244).  Saving model ...
Validation loss decreased (0.408244 --> 0.408218).  Saving model ...
Validation loss decreased (0.408218 --> 0.408192).  Saving model ...
Validation loss decreased (0.408192 --> 0.408166).  Saving model ...
Validation loss decreased (0.408166 --> 0.408140).  Saving model ...
Validation loss decreased (0.408140 --> 0.408114).  Saving model ...
Validation loss decreased (0.408114 --> 0.408089).  Saving model ...
Validation loss decreased (0.408089 --> 0.408063).  Saving model ...
Validation loss decreased (0.408063 --> 0.408037).  Saving model ...
Validation loss decreased (0.408037 --> 0.408011).  Saving model ...
Validation loss decreased (0.408011 --> 0.407985).  Saving model ...
Validation loss decreased (0.407985 --> 0.407959).  Saving model ...
Validation loss decreased (0.407959 --> 0.407933).  Saving model ...
Validation loss decreased (0.407933 --> 0.407907).  Saving model ...
Validation loss decreased (0.407907 --> 0.407881).  Saving model ...
Validation loss decreased (0.407881 --> 0.407855).  Saving model ...
Validation loss decreased (0.407855 --> 0.407830).  Saving model ...
Validation loss decreased (0.407830 --> 0.407804).  Saving model ...
Validation loss decreased (0.407804 --> 0.407778).  Saving model ...
Validation loss decreased (0.407778 --> 0.407752).  Saving model ...
Validation loss decreased (0.407752 --> 0.407726).  Saving model ...
Validation loss decreased (0.407726 --> 0.407700).  Saving model ...
Validation loss decreased (0.407700 --> 0.407674).  Saving model ...
Validation loss decreased (0.407674 --> 0.407648).  Saving model ...
Validation loss decreased (0.407648 --> 0.407622).  Saving model ...
Validation loss decreased (0.407622 --> 0.407596).  Saving model ...
Validation loss decreased (0.407596 --> 0.407570).  Saving model ...
Validation loss decreased (0.407570 --> 0.407544).  Saving model ...
Validation loss decreased (0.407544 --> 0.407518).  Saving model ...
Validation loss decreased (0.407518 --> 0.407492).  Saving model ...
Validation loss decreased (0.407492 --> 0.407467).  Saving model ...
Validation loss decreased (0.407467 --> 0.407441).  Saving model ...
Validation loss decreased (0.407441 --> 0.407415).  Saving model ...
Validation loss decreased (0.407415 --> 0.407389).  Saving model ...
Validation loss decreased (0.407389 --> 0.407363).  Saving model ...
Validation loss decreased (0.407363 --> 0.407337).  Saving model ...
Validation loss decreased (0.407337 --> 0.407311).  Saving model ...
Validation loss decreased (0.407311 --> 0.407285).  Saving model ...
Validation loss decreased (0.407285 --> 0.407259).  Saving model ...
Validation loss decreased (0.407259 --> 0.407233).  Saving model ...
Validation loss decreased (0.407233 --> 0.407207).  Saving model ...
Validation loss decreased (0.407207 --> 0.407181).  Saving model ...
Validation loss decreased (0.407181 --> 0.407155).  Saving model ...
Validation loss decreased (0.407155 --> 0.407129).  Saving model ...
Validation loss decreased (0.407129 --> 0.407103).  Saving model ...
Validation loss decreased (0.407103 --> 0.407077).  Saving model ...
Validation loss decreased (0.407077 --> 0.407051).  Saving model ...
Validation loss decreased (0.407051 --> 0.407025).  Saving model ...
Validation loss decreased (0.407025 --> 0.407000).  Saving model ...
epoch 3201, loss 0.4070, train acc 81.51%, f1 0.7245, precision 0.7553, recall 0.6961, auc 0.7875
Validation loss decreased (0.407000 --> 0.406974).  Saving model ...
Validation loss decreased (0.406974 --> 0.406948).  Saving model ...
Validation loss decreased (0.406948 --> 0.406922).  Saving model ...
Validation loss decreased (0.406922 --> 0.406896).  Saving model ...
Validation loss decreased (0.406896 --> 0.406870).  Saving model ...
Validation loss decreased (0.406870 --> 0.406844).  Saving model ...
Validation loss decreased (0.406844 --> 0.406818).  Saving model ...
Validation loss decreased (0.406818 --> 0.406792).  Saving model ...
Validation loss decreased (0.406792 --> 0.406766).  Saving model ...
Validation loss decreased (0.406766 --> 0.406740).  Saving model ...
Validation loss decreased (0.406740 --> 0.406714).  Saving model ...
Validation loss decreased (0.406714 --> 0.406688).  Saving model ...
Validation loss decreased (0.406688 --> 0.406662).  Saving model ...
Validation loss decreased (0.406662 --> 0.406636).  Saving model ...
Validation loss decreased (0.406636 --> 0.406610).  Saving model ...
Validation loss decreased (0.406610 --> 0.406585).  Saving model ...
Validation loss decreased (0.406585 --> 0.406559).  Saving model ...
Validation loss decreased (0.406559 --> 0.406533).  Saving model ...
Validation loss decreased (0.406533 --> 0.406507).  Saving model ...
Validation loss decreased (0.406507 --> 0.406481).  Saving model ...
Validation loss decreased (0.406481 --> 0.406455).  Saving model ...
Validation loss decreased (0.406455 --> 0.406429).  Saving model ...
Validation loss decreased (0.406429 --> 0.406403).  Saving model ...
Validation loss decreased (0.406403 --> 0.406377).  Saving model ...
Validation loss decreased (0.406377 --> 0.406351).  Saving model ...
Validation loss decreased (0.406351 --> 0.406325).  Saving model ...
Validation loss decreased (0.406325 --> 0.406299).  Saving model ...
Validation loss decreased (0.406299 --> 0.406274).  Saving model ...
Validation loss decreased (0.406274 --> 0.406248).  Saving model ...
Validation loss decreased (0.406248 --> 0.406222).  Saving model ...
Validation loss decreased (0.406222 --> 0.406196).  Saving model ...
Validation loss decreased (0.406196 --> 0.406170).  Saving model ...
Validation loss decreased (0.406170 --> 0.406144).  Saving model ...
Validation loss decreased (0.406144 --> 0.406118).  Saving model ...
Validation loss decreased (0.406118 --> 0.406092).  Saving model ...
Validation loss decreased (0.406092 --> 0.406066).  Saving model ...
Validation loss decreased (0.406066 --> 0.406041).  Saving model ...
Validation loss decreased (0.406041 --> 0.406015).  Saving model ...
Validation loss decreased (0.406015 --> 0.405989).  Saving model ...
Validation loss decreased (0.405989 --> 0.405963).  Saving model ...
Validation loss decreased (0.405963 --> 0.405937).  Saving model ...
Validation loss decreased (0.405937 --> 0.405911).  Saving model ...
Validation loss decreased (0.405911 --> 0.405885).  Saving model ...
Validation loss decreased (0.405885 --> 0.405860).  Saving model ...
Validation loss decreased (0.405860 --> 0.405834).  Saving model ...
Validation loss decreased (0.405834 --> 0.405808).  Saving model ...
Validation loss decreased (0.405808 --> 0.405782).  Saving model ...
Validation loss decreased (0.405782 --> 0.405756).  Saving model ...
Validation loss decreased (0.405756 --> 0.405730).  Saving model ...
Validation loss decreased (0.405730 --> 0.405704).  Saving model ...
Validation loss decreased (0.405704 --> 0.405679).  Saving model ...
Validation loss decreased (0.405679 --> 0.405653).  Saving model ...
Validation loss decreased (0.405653 --> 0.405627).  Saving model ...
Validation loss decreased (0.405627 --> 0.405601).  Saving model ...
Validation loss decreased (0.405601 --> 0.405575).  Saving model ...
Validation loss decreased (0.405575 --> 0.405549).  Saving model ...
Validation loss decreased (0.405549 --> 0.405524).  Saving model ...
Validation loss decreased (0.405524 --> 0.405498).  Saving model ...
Validation loss decreased (0.405498 --> 0.405472).  Saving model ...
Validation loss decreased (0.405472 --> 0.405446).  Saving model ...
Validation loss decreased (0.405446 --> 0.405421).  Saving model ...
Validation loss decreased (0.405421 --> 0.405395).  Saving model ...
Validation loss decreased (0.405395 --> 0.405369).  Saving model ...
Validation loss decreased (0.405369 --> 0.405343).  Saving model ...
Validation loss decreased (0.405343 --> 0.405317).  Saving model ...
Validation loss decreased (0.405317 --> 0.405292).  Saving model ...
Validation loss decreased (0.405292 --> 0.405266).  Saving model ...
Validation loss decreased (0.405266 --> 0.405240).  Saving model ...
Validation loss decreased (0.405240 --> 0.405214).  Saving model ...
Validation loss decreased (0.405214 --> 0.405189).  Saving model ...
Validation loss decreased (0.405189 --> 0.405163).  Saving model ...
Validation loss decreased (0.405163 --> 0.405137).  Saving model ...
Validation loss decreased (0.405137 --> 0.405112).  Saving model ...
Validation loss decreased (0.405112 --> 0.405086).  Saving model ...
Validation loss decreased (0.405086 --> 0.405060).  Saving model ...
Validation loss decreased (0.405060 --> 0.405034).  Saving model ...
Validation loss decreased (0.405034 --> 0.405009).  Saving model ...
Validation loss decreased (0.405009 --> 0.404983).  Saving model ...
Validation loss decreased (0.404983 --> 0.404957).  Saving model ...
Validation loss decreased (0.404957 --> 0.404932).  Saving model ...
Validation loss decreased (0.404932 --> 0.404906).  Saving model ...
Validation loss decreased (0.404906 --> 0.404880).  Saving model ...
Validation loss decreased (0.404880 --> 0.404855).  Saving model ...
Validation loss decreased (0.404855 --> 0.404829).  Saving model ...
Validation loss decreased (0.404829 --> 0.404803).  Saving model ...
Validation loss decreased (0.404803 --> 0.404778).  Saving model ...
Validation loss decreased (0.404778 --> 0.404752).  Saving model ...
Validation loss decreased (0.404752 --> 0.404726).  Saving model ...
Validation loss decreased (0.404726 --> 0.404701).  Saving model ...
Validation loss decreased (0.404701 --> 0.404675).  Saving model ...
Validation loss decreased (0.404675 --> 0.404650).  Saving model ...
Validation loss decreased (0.404650 --> 0.404624).  Saving model ...
Validation loss decreased (0.404624 --> 0.404598).  Saving model ...
Validation loss decreased (0.404598 --> 0.404573).  Saving model ...
Validation loss decreased (0.404573 --> 0.404547).  Saving model ...
Validation loss decreased (0.404547 --> 0.404522).  Saving model ...
Validation loss decreased (0.404522 --> 0.404496).  Saving model ...
Validation loss decreased (0.404496 --> 0.404471).  Saving model ...
Validation loss decreased (0.404471 --> 0.404445).  Saving model ...
Validation loss decreased (0.404445 --> 0.404419).  Saving model ...
epoch 3301, loss 0.4044, train acc 81.34%, f1 0.7241, precision 0.7487, recall 0.7010, auc 0.7873
Validation loss decreased (0.404419 --> 0.404394).  Saving model ...
Validation loss decreased (0.404394 --> 0.404368).  Saving model ...
Validation loss decreased (0.404368 --> 0.404343).  Saving model ...
Validation loss decreased (0.404343 --> 0.404317).  Saving model ...
Validation loss decreased (0.404317 --> 0.404292).  Saving model ...
Validation loss decreased (0.404292 --> 0.404266).  Saving model ...
Validation loss decreased (0.404266 --> 0.404241).  Saving model ...
Validation loss decreased (0.404241 --> 0.404215).  Saving model ...
Validation loss decreased (0.404215 --> 0.404190).  Saving model ...
Validation loss decreased (0.404190 --> 0.404164).  Saving model ...
Validation loss decreased (0.404164 --> 0.404139).  Saving model ...
Validation loss decreased (0.404139 --> 0.404113).  Saving model ...
Validation loss decreased (0.404113 --> 0.404088).  Saving model ...
Validation loss decreased (0.404088 --> 0.404063).  Saving model ...
Validation loss decreased (0.404063 --> 0.404037).  Saving model ...
Validation loss decreased (0.404037 --> 0.404012).  Saving model ...
Validation loss decreased (0.404012 --> 0.403986).  Saving model ...
Validation loss decreased (0.403986 --> 0.403961).  Saving model ...
Validation loss decreased (0.403961 --> 0.403935).  Saving model ...
Validation loss decreased (0.403935 --> 0.403910).  Saving model ...
Validation loss decreased (0.403910 --> 0.403885).  Saving model ...
Validation loss decreased (0.403885 --> 0.403859).  Saving model ...
Validation loss decreased (0.403859 --> 0.403834).  Saving model ...
Validation loss decreased (0.403834 --> 0.403808).  Saving model ...
Validation loss decreased (0.403808 --> 0.403783).  Saving model ...
Validation loss decreased (0.403783 --> 0.403758).  Saving model ...
Validation loss decreased (0.403758 --> 0.403732).  Saving model ...
Validation loss decreased (0.403732 --> 0.403707).  Saving model ...
Validation loss decreased (0.403707 --> 0.403682).  Saving model ...
Validation loss decreased (0.403682 --> 0.403657).  Saving model ...
Validation loss decreased (0.403657 --> 0.403631).  Saving model ...
Validation loss decreased (0.403631 --> 0.403606).  Saving model ...
Validation loss decreased (0.403606 --> 0.403581).  Saving model ...
Validation loss decreased (0.403581 --> 0.403555).  Saving model ...
Validation loss decreased (0.403555 --> 0.403530).  Saving model ...
Validation loss decreased (0.403530 --> 0.403505).  Saving model ...
Validation loss decreased (0.403505 --> 0.403480).  Saving model ...
Validation loss decreased (0.403480 --> 0.403454).  Saving model ...
Validation loss decreased (0.403454 --> 0.403429).  Saving model ...
Validation loss decreased (0.403429 --> 0.403404).  Saving model ...
Validation loss decreased (0.403404 --> 0.403379).  Saving model ...
Validation loss decreased (0.403379 --> 0.403353).  Saving model ...
Validation loss decreased (0.403353 --> 0.403328).  Saving model ...
Validation loss decreased (0.403328 --> 0.403303).  Saving model ...
Validation loss decreased (0.403303 --> 0.403278).  Saving model ...
Validation loss decreased (0.403278 --> 0.403253).  Saving model ...
Validation loss decreased (0.403253 --> 0.403228).  Saving model ...
Validation loss decreased (0.403228 --> 0.403202).  Saving model ...
Validation loss decreased (0.403202 --> 0.403177).  Saving model ...
Validation loss decreased (0.403177 --> 0.403152).  Saving model ...
Validation loss decreased (0.403152 --> 0.403127).  Saving model ...
Validation loss decreased (0.403127 --> 0.403102).  Saving model ...
Validation loss decreased (0.403102 --> 0.403077).  Saving model ...
Validation loss decreased (0.403077 --> 0.403052).  Saving model ...
Validation loss decreased (0.403052 --> 0.403027).  Saving model ...
Validation loss decreased (0.403027 --> 0.403002).  Saving model ...
Validation loss decreased (0.403002 --> 0.402977).  Saving model ...
Validation loss decreased (0.402977 --> 0.402952).  Saving model ...
Validation loss decreased (0.402952 --> 0.402927).  Saving model ...
Validation loss decreased (0.402927 --> 0.402902).  Saving model ...
Validation loss decreased (0.402902 --> 0.402877).  Saving model ...
Validation loss decreased (0.402877 --> 0.402852).  Saving model ...
Validation loss decreased (0.402852 --> 0.402827).  Saving model ...
Validation loss decreased (0.402827 --> 0.402802).  Saving model ...
Validation loss decreased (0.402802 --> 0.402777).  Saving model ...
Validation loss decreased (0.402777 --> 0.402752).  Saving model ...
Validation loss decreased (0.402752 --> 0.402727).  Saving model ...
Validation loss decreased (0.402727 --> 0.402702).  Saving model ...
Validation loss decreased (0.402702 --> 0.402677).  Saving model ...
Validation loss decreased (0.402677 --> 0.402652).  Saving model ...
Validation loss decreased (0.402652 --> 0.402627).  Saving model ...
Validation loss decreased (0.402627 --> 0.402602).  Saving model ...
Validation loss decreased (0.402602 --> 0.402577).  Saving model ...
Validation loss decreased (0.402577 --> 0.402552).  Saving model ...
Validation loss decreased (0.402552 --> 0.402527).  Saving model ...
Validation loss decreased (0.402527 --> 0.402503).  Saving model ...
Validation loss decreased (0.402503 --> 0.402478).  Saving model ...
Validation loss decreased (0.402478 --> 0.402453).  Saving model ...
Validation loss decreased (0.402453 --> 0.402428).  Saving model ...
Validation loss decreased (0.402428 --> 0.402403).  Saving model ...
Validation loss decreased (0.402403 --> 0.402378).  Saving model ...
Validation loss decreased (0.402378 --> 0.402354).  Saving model ...
Validation loss decreased (0.402354 --> 0.402329).  Saving model ...
Validation loss decreased (0.402329 --> 0.402304).  Saving model ...
Validation loss decreased (0.402304 --> 0.402279).  Saving model ...
Validation loss decreased (0.402279 --> 0.402255).  Saving model ...
Validation loss decreased (0.402255 --> 0.402230).  Saving model ...
Validation loss decreased (0.402230 --> 0.402205).  Saving model ...
Validation loss decreased (0.402205 --> 0.402180).  Saving model ...
Validation loss decreased (0.402180 --> 0.402156).  Saving model ...
Validation loss decreased (0.402156 --> 0.402131).  Saving model ...
Validation loss decreased (0.402131 --> 0.402106).  Saving model ...
Validation loss decreased (0.402106 --> 0.402082).  Saving model ...
Validation loss decreased (0.402082 --> 0.402057).  Saving model ...
Validation loss decreased (0.402057 --> 0.402032).  Saving model ...
Validation loss decreased (0.402032 --> 0.402008).  Saving model ...
Validation loss decreased (0.402008 --> 0.401983).  Saving model ...
Validation loss decreased (0.401983 --> 0.401959).  Saving model ...
Validation loss decreased (0.401959 --> 0.401934).  Saving model ...
Validation loss decreased (0.401934 --> 0.401909).  Saving model ...
epoch 3401, loss 0.4019, train acc 81.51%, f1 0.7245, precision 0.7553, recall 0.6961, auc 0.7875
Validation loss decreased (0.401909 --> 0.401885).  Saving model ...
Validation loss decreased (0.401885 --> 0.401860).  Saving model ...
Validation loss decreased (0.401860 --> 0.401836).  Saving model ...
Validation loss decreased (0.401836 --> 0.401811).  Saving model ...
Validation loss decreased (0.401811 --> 0.401787).  Saving model ...
Validation loss decreased (0.401787 --> 0.401762).  Saving model ...
Validation loss decreased (0.401762 --> 0.401738).  Saving model ...
Validation loss decreased (0.401738 --> 0.401713).  Saving model ...
Validation loss decreased (0.401713 --> 0.401689).  Saving model ...
Validation loss decreased (0.401689 --> 0.401664).  Saving model ...
Validation loss decreased (0.401664 --> 0.401640).  Saving model ...
Validation loss decreased (0.401640 --> 0.401615).  Saving model ...
Validation loss decreased (0.401615 --> 0.401591).  Saving model ...
Validation loss decreased (0.401591 --> 0.401567).  Saving model ...
Validation loss decreased (0.401567 --> 0.401542).  Saving model ...
Validation loss decreased (0.401542 --> 0.401518).  Saving model ...
Validation loss decreased (0.401518 --> 0.401493).  Saving model ...
Validation loss decreased (0.401493 --> 0.401469).  Saving model ...
Validation loss decreased (0.401469 --> 0.401445).  Saving model ...
Validation loss decreased (0.401445 --> 0.401420).  Saving model ...
Validation loss decreased (0.401420 --> 0.401396).  Saving model ...
Validation loss decreased (0.401396 --> 0.401372).  Saving model ...
Validation loss decreased (0.401372 --> 0.401347).  Saving model ...
Validation loss decreased (0.401347 --> 0.401323).  Saving model ...
Validation loss decreased (0.401323 --> 0.401299).  Saving model ...
Validation loss decreased (0.401299 --> 0.401274).  Saving model ...
Validation loss decreased (0.401274 --> 0.401250).  Saving model ...
Validation loss decreased (0.401250 --> 0.401226).  Saving model ...
Validation loss decreased (0.401226 --> 0.401202).  Saving model ...
Validation loss decreased (0.401202 --> 0.401177).  Saving model ...
Validation loss decreased (0.401177 --> 0.401153).  Saving model ...
Validation loss decreased (0.401153 --> 0.401129).  Saving model ...
Validation loss decreased (0.401129 --> 0.401105).  Saving model ...
Validation loss decreased (0.401105 --> 0.401081).  Saving model ...
Validation loss decreased (0.401081 --> 0.401057).  Saving model ...
Validation loss decreased (0.401057 --> 0.401032).  Saving model ...
Validation loss decreased (0.401032 --> 0.401008).  Saving model ...
Validation loss decreased (0.401008 --> 0.400984).  Saving model ...
Validation loss decreased (0.400984 --> 0.400960).  Saving model ...
Validation loss decreased (0.400960 --> 0.400936).  Saving model ...
Validation loss decreased (0.400936 --> 0.400912).  Saving model ...
Validation loss decreased (0.400912 --> 0.400888).  Saving model ...
Validation loss decreased (0.400888 --> 0.400864).  Saving model ...
Validation loss decreased (0.400864 --> 0.400840).  Saving model ...
Validation loss decreased (0.400840 --> 0.400816).  Saving model ...
Validation loss decreased (0.400816 --> 0.400791).  Saving model ...
Validation loss decreased (0.400791 --> 0.400767).  Saving model ...
Validation loss decreased (0.400767 --> 0.400743).  Saving model ...
Validation loss decreased (0.400743 --> 0.400719).  Saving model ...
Validation loss decreased (0.400719 --> 0.400695).  Saving model ...
Validation loss decreased (0.400695 --> 0.400671).  Saving model ...
Validation loss decreased (0.400671 --> 0.400647).  Saving model ...
Validation loss decreased (0.400647 --> 0.400624).  Saving model ...
Validation loss decreased (0.400624 --> 0.400600).  Saving model ...
Validation loss decreased (0.400600 --> 0.400576).  Saving model ...
Validation loss decreased (0.400576 --> 0.400552).  Saving model ...
Validation loss decreased (0.400552 --> 0.400528).  Saving model ...
Validation loss decreased (0.400528 --> 0.400504).  Saving model ...
Validation loss decreased (0.400504 --> 0.400480).  Saving model ...
Validation loss decreased (0.400480 --> 0.400456).  Saving model ...
Validation loss decreased (0.400456 --> 0.400432).  Saving model ...
Validation loss decreased (0.400432 --> 0.400409).  Saving model ...
Validation loss decreased (0.400409 --> 0.400385).  Saving model ...
Validation loss decreased (0.400385 --> 0.400361).  Saving model ...
Validation loss decreased (0.400361 --> 0.400337).  Saving model ...
Validation loss decreased (0.400337 --> 0.400313).  Saving model ...
Validation loss decreased (0.400313 --> 0.400289).  Saving model ...
Validation loss decreased (0.400289 --> 0.400266).  Saving model ...
Validation loss decreased (0.400266 --> 0.400242).  Saving model ...
Validation loss decreased (0.400242 --> 0.400218).  Saving model ...
Validation loss decreased (0.400218 --> 0.400194).  Saving model ...
Validation loss decreased (0.400194 --> 0.400171).  Saving model ...
Validation loss decreased (0.400171 --> 0.400147).  Saving model ...
Validation loss decreased (0.400147 --> 0.400123).  Saving model ...
Validation loss decreased (0.400123 --> 0.400100).  Saving model ...
Validation loss decreased (0.400100 --> 0.400076).  Saving model ...
Validation loss decreased (0.400076 --> 0.400052).  Saving model ...
Validation loss decreased (0.400052 --> 0.400029).  Saving model ...
Validation loss decreased (0.400029 --> 0.400005).  Saving model ...
Validation loss decreased (0.400005 --> 0.399981).  Saving model ...
Validation loss decreased (0.399981 --> 0.399958).  Saving model ...
Validation loss decreased (0.399958 --> 0.399934).  Saving model ...
Validation loss decreased (0.399934 --> 0.399910).  Saving model ...
Validation loss decreased (0.399910 --> 0.399887).  Saving model ...
Validation loss decreased (0.399887 --> 0.399863).  Saving model ...
Validation loss decreased (0.399863 --> 0.399840).  Saving model ...
Validation loss decreased (0.399840 --> 0.399816).  Saving model ...
Validation loss decreased (0.399816 --> 0.399793).  Saving model ...
Validation loss decreased (0.399793 --> 0.399769).  Saving model ...
Validation loss decreased (0.399769 --> 0.399745).  Saving model ...
Validation loss decreased (0.399745 --> 0.399722).  Saving model ...
Validation loss decreased (0.399722 --> 0.399698).  Saving model ...
Validation loss decreased (0.399698 --> 0.399675).  Saving model ...
Validation loss decreased (0.399675 --> 0.399651).  Saving model ...
Validation loss decreased (0.399651 --> 0.399628).  Saving model ...
Validation loss decreased (0.399628 --> 0.399604).  Saving model ...
Validation loss decreased (0.399604 --> 0.399581).  Saving model ...
Validation loss decreased (0.399581 --> 0.399558).  Saving model ...
Validation loss decreased (0.399558 --> 0.399534).  Saving model ...
Validation loss decreased (0.399534 --> 0.399511).  Saving model ...
epoch 3501, loss 0.3995, train acc 82.02%, f1 0.7328, precision 0.7619, recall 0.7059, auc 0.7937
Validation loss decreased (0.399511 --> 0.399487).  Saving model ...
Validation loss decreased (0.399487 --> 0.399464).  Saving model ...
Validation loss decreased (0.399464 --> 0.399441).  Saving model ...
Validation loss decreased (0.399441 --> 0.399417).  Saving model ...
Validation loss decreased (0.399417 --> 0.399394).  Saving model ...
Validation loss decreased (0.399394 --> 0.399370).  Saving model ...
Validation loss decreased (0.399370 --> 0.399347).  Saving model ...
Validation loss decreased (0.399347 --> 0.399324).  Saving model ...
Validation loss decreased (0.399324 --> 0.399300).  Saving model ...
Validation loss decreased (0.399300 --> 0.399277).  Saving model ...
Validation loss decreased (0.399277 --> 0.399254).  Saving model ...
Validation loss decreased (0.399254 --> 0.399230).  Saving model ...
Validation loss decreased (0.399230 --> 0.399207).  Saving model ...
Validation loss decreased (0.399207 --> 0.399184).  Saving model ...
Validation loss decreased (0.399184 --> 0.399161).  Saving model ...
Validation loss decreased (0.399161 --> 0.399137).  Saving model ...
Validation loss decreased (0.399137 --> 0.399114).  Saving model ...
Validation loss decreased (0.399114 --> 0.399091).  Saving model ...
Validation loss decreased (0.399091 --> 0.399068).  Saving model ...
Validation loss decreased (0.399068 --> 0.399044).  Saving model ...
Validation loss decreased (0.399044 --> 0.399021).  Saving model ...
Validation loss decreased (0.399021 --> 0.398998).  Saving model ...
Validation loss decreased (0.398998 --> 0.398975).  Saving model ...
Validation loss decreased (0.398975 --> 0.398952).  Saving model ...
Validation loss decreased (0.398952 --> 0.398928).  Saving model ...
Validation loss decreased (0.398928 --> 0.398905).  Saving model ...
Validation loss decreased (0.398905 --> 0.398882).  Saving model ...
Validation loss decreased (0.398882 --> 0.398859).  Saving model ...
Validation loss decreased (0.398859 --> 0.398836).  Saving model ...
Validation loss decreased (0.398836 --> 0.398813).  Saving model ...
Validation loss decreased (0.398813 --> 0.398790).  Saving model ...
Validation loss decreased (0.398790 --> 0.398767).  Saving model ...
Validation loss decreased (0.398767 --> 0.398743).  Saving model ...
Validation loss decreased (0.398743 --> 0.398720).  Saving model ...
Validation loss decreased (0.398720 --> 0.398697).  Saving model ...
Validation loss decreased (0.398697 --> 0.398674).  Saving model ...
Validation loss decreased (0.398674 --> 0.398651).  Saving model ...
Validation loss decreased (0.398651 --> 0.398628).  Saving model ...
Validation loss decreased (0.398628 --> 0.398605).  Saving model ...
Validation loss decreased (0.398605 --> 0.398582).  Saving model ...
Validation loss decreased (0.398582 --> 0.398559).  Saving model ...
Validation loss decreased (0.398559 --> 0.398536).  Saving model ...
Validation loss decreased (0.398536 --> 0.398513).  Saving model ...
Validation loss decreased (0.398513 --> 0.398490).  Saving model ...
Validation loss decreased (0.398490 --> 0.398467).  Saving model ...
Validation loss decreased (0.398467 --> 0.398444).  Saving model ...
Validation loss decreased (0.398444 --> 0.398421).  Saving model ...
Validation loss decreased (0.398421 --> 0.398398).  Saving model ...
Validation loss decreased (0.398398 --> 0.398375).  Saving model ...
Validation loss decreased (0.398375 --> 0.398352).  Saving model ...
Validation loss decreased (0.398352 --> 0.398329).  Saving model ...
Validation loss decreased (0.398329 --> 0.398306).  Saving model ...
Validation loss decreased (0.398306 --> 0.398283).  Saving model ...
Validation loss decreased (0.398283 --> 0.398260).  Saving model ...
Validation loss decreased (0.398260 --> 0.398237).  Saving model ...
Validation loss decreased (0.398237 --> 0.398215).  Saving model ...
Validation loss decreased (0.398215 --> 0.398192).  Saving model ...
Validation loss decreased (0.398192 --> 0.398169).  Saving model ...
Validation loss decreased (0.398169 --> 0.398146).  Saving model ...
Validation loss decreased (0.398146 --> 0.398123).  Saving model ...
Validation loss decreased (0.398123 --> 0.398100).  Saving model ...
Validation loss decreased (0.398100 --> 0.398077).  Saving model ...
Validation loss decreased (0.398077 --> 0.398055).  Saving model ...
Validation loss decreased (0.398055 --> 0.398032).  Saving model ...
Validation loss decreased (0.398032 --> 0.398009).  Saving model ...
Validation loss decreased (0.398009 --> 0.397986).  Saving model ...
Validation loss decreased (0.397986 --> 0.397963).  Saving model ...
Validation loss decreased (0.397963 --> 0.397940).  Saving model ...
Validation loss decreased (0.397940 --> 0.397918).  Saving model ...
Validation loss decreased (0.397918 --> 0.397895).  Saving model ...
Validation loss decreased (0.397895 --> 0.397872).  Saving model ...
Validation loss decreased (0.397872 --> 0.397849).  Saving model ...
Validation loss decreased (0.397849 --> 0.397826).  Saving model ...
Validation loss decreased (0.397826 --> 0.397804).  Saving model ...
Validation loss decreased (0.397804 --> 0.397781).  Saving model ...
Validation loss decreased (0.397781 --> 0.397758).  Saving model ...
Validation loss decreased (0.397758 --> 0.397735).  Saving model ...
Validation loss decreased (0.397735 --> 0.397713).  Saving model ...
Validation loss decreased (0.397713 --> 0.397690).  Saving model ...
Validation loss decreased (0.397690 --> 0.397667).  Saving model ...
Validation loss decreased (0.397667 --> 0.397645).  Saving model ...
Validation loss decreased (0.397645 --> 0.397622).  Saving model ...
Validation loss decreased (0.397622 --> 0.397599).  Saving model ...
Validation loss decreased (0.397599 --> 0.397577).  Saving model ...
Validation loss decreased (0.397577 --> 0.397554).  Saving model ...
Validation loss decreased (0.397554 --> 0.397531).  Saving model ...
Validation loss decreased (0.397531 --> 0.397509).  Saving model ...
Validation loss decreased (0.397509 --> 0.397486).  Saving model ...
Validation loss decreased (0.397486 --> 0.397463).  Saving model ...
Validation loss decreased (0.397463 --> 0.397441).  Saving model ...
Validation loss decreased (0.397441 --> 0.397418).  Saving model ...
Validation loss decreased (0.397418 --> 0.397395).  Saving model ...
Validation loss decreased (0.397395 --> 0.397373).  Saving model ...
Validation loss decreased (0.397373 --> 0.397350).  Saving model ...
Validation loss decreased (0.397350 --> 0.397327).  Saving model ...
Validation loss decreased (0.397327 --> 0.397305).  Saving model ...
Validation loss decreased (0.397305 --> 0.397282).  Saving model ...
Validation loss decreased (0.397282 --> 0.397260).  Saving model ...
Validation loss decreased (0.397260 --> 0.397237).  Saving model ...
Validation loss decreased (0.397237 --> 0.397214).  Saving model ...
epoch 3601, loss 0.3972, train acc 82.53%, f1 0.7424, precision 0.7656, recall 0.7206, auc 0.8011
Validation loss decreased (0.397214 --> 0.397192).  Saving model ...
Validation loss decreased (0.397192 --> 0.397169).  Saving model ...
Validation loss decreased (0.397169 --> 0.397147).  Saving model ...
Validation loss decreased (0.397147 --> 0.397124).  Saving model ...
Validation loss decreased (0.397124 --> 0.397102).  Saving model ...
Validation loss decreased (0.397102 --> 0.397079).  Saving model ...
Validation loss decreased (0.397079 --> 0.397056).  Saving model ...
Validation loss decreased (0.397056 --> 0.397034).  Saving model ...
Validation loss decreased (0.397034 --> 0.397011).  Saving model ...
Validation loss decreased (0.397011 --> 0.396989).  Saving model ...
Validation loss decreased (0.396989 --> 0.396966).  Saving model ...
Validation loss decreased (0.396966 --> 0.396944).  Saving model ...
Validation loss decreased (0.396944 --> 0.396921).  Saving model ...
Validation loss decreased (0.396921 --> 0.396899).  Saving model ...
Validation loss decreased (0.396899 --> 0.396876).  Saving model ...
Validation loss decreased (0.396876 --> 0.396854).  Saving model ...
Validation loss decreased (0.396854 --> 0.396831).  Saving model ...
Validation loss decreased (0.396831 --> 0.396809).  Saving model ...
Validation loss decreased (0.396809 --> 0.396786).  Saving model ...
Validation loss decreased (0.396786 --> 0.396764).  Saving model ...
Validation loss decreased (0.396764 --> 0.396741).  Saving model ...
Validation loss decreased (0.396741 --> 0.396719).  Saving model ...
Validation loss decreased (0.396719 --> 0.396696).  Saving model ...
Validation loss decreased (0.396696 --> 0.396674).  Saving model ...
Validation loss decreased (0.396674 --> 0.396652).  Saving model ...
Validation loss decreased (0.396652 --> 0.396629).  Saving model ...
Validation loss decreased (0.396629 --> 0.396607).  Saving model ...
Validation loss decreased (0.396607 --> 0.396584).  Saving model ...
Validation loss decreased (0.396584 --> 0.396562).  Saving model ...
Validation loss decreased (0.396562 --> 0.396539).  Saving model ...
Validation loss decreased (0.396539 --> 0.396517).  Saving model ...
Validation loss decreased (0.396517 --> 0.396494).  Saving model ...
Validation loss decreased (0.396494 --> 0.396472).  Saving model ...
Validation loss decreased (0.396472 --> 0.396450).  Saving model ...
Validation loss decreased (0.396450 --> 0.396427).  Saving model ...
Validation loss decreased (0.396427 --> 0.396405).  Saving model ...
Validation loss decreased (0.396405 --> 0.396382).  Saving model ...
Validation loss decreased (0.396382 --> 0.396360).  Saving model ...
Validation loss decreased (0.396360 --> 0.396338).  Saving model ...
Validation loss decreased (0.396338 --> 0.396315).  Saving model ...
Validation loss decreased (0.396315 --> 0.396293).  Saving model ...
Validation loss decreased (0.396293 --> 0.396270).  Saving model ...
Validation loss decreased (0.396270 --> 0.396248).  Saving model ...
Validation loss decreased (0.396248 --> 0.396226).  Saving model ...
Validation loss decreased (0.396226 --> 0.396203).  Saving model ...
Validation loss decreased (0.396203 --> 0.396181).  Saving model ...
Validation loss decreased (0.396181 --> 0.396158).  Saving model ...
Validation loss decreased (0.396158 --> 0.396136).  Saving model ...
Validation loss decreased (0.396136 --> 0.396114).  Saving model ...
Validation loss decreased (0.396114 --> 0.396091).  Saving model ...
Validation loss decreased (0.396091 --> 0.396069).  Saving model ...
Validation loss decreased (0.396069 --> 0.396047).  Saving model ...
Validation loss decreased (0.396047 --> 0.396024).  Saving model ...
Validation loss decreased (0.396024 --> 0.396002).  Saving model ...
Validation loss decreased (0.396002 --> 0.395979).  Saving model ...
Validation loss decreased (0.395979 --> 0.395957).  Saving model ...
Validation loss decreased (0.395957 --> 0.395935).  Saving model ...
Validation loss decreased (0.395935 --> 0.395912).  Saving model ...
Validation loss decreased (0.395912 --> 0.395890).  Saving model ...
Validation loss decreased (0.395890 --> 0.395868).  Saving model ...
Validation loss decreased (0.395868 --> 0.395845).  Saving model ...
Validation loss decreased (0.395845 --> 0.395823).  Saving model ...
Validation loss decreased (0.395823 --> 0.395801).  Saving model ...
Validation loss decreased (0.395801 --> 0.395778).  Saving model ...
Validation loss decreased (0.395778 --> 0.395756).  Saving model ...
Validation loss decreased (0.395756 --> 0.395734).  Saving model ...
Validation loss decreased (0.395734 --> 0.395711).  Saving model ...
Validation loss decreased (0.395711 --> 0.395689).  Saving model ...
Validation loss decreased (0.395689 --> 0.395667).  Saving model ...
Validation loss decreased (0.395667 --> 0.395644).  Saving model ...
Validation loss decreased (0.395644 --> 0.395622).  Saving model ...
Validation loss decreased (0.395622 --> 0.395600).  Saving model ...
Validation loss decreased (0.395600 --> 0.395577).  Saving model ...
Validation loss decreased (0.395577 --> 0.395555).  Saving model ...
Validation loss decreased (0.395555 --> 0.395532).  Saving model ...
Validation loss decreased (0.395532 --> 0.395510).  Saving model ...
Validation loss decreased (0.395510 --> 0.395488).  Saving model ...
Validation loss decreased (0.395488 --> 0.395465).  Saving model ...
Validation loss decreased (0.395465 --> 0.395443).  Saving model ...
Validation loss decreased (0.395443 --> 0.395421).  Saving model ...
Validation loss decreased (0.395421 --> 0.395398).  Saving model ...
Validation loss decreased (0.395398 --> 0.395376).  Saving model ...
Validation loss decreased (0.395376 --> 0.395353).  Saving model ...
Validation loss decreased (0.395353 --> 0.395331).  Saving model ...
Validation loss decreased (0.395331 --> 0.395309).  Saving model ...
Validation loss decreased (0.395309 --> 0.395286).  Saving model ...
Validation loss decreased (0.395286 --> 0.395264).  Saving model ...
Validation loss decreased (0.395264 --> 0.395242).  Saving model ...
Validation loss decreased (0.395242 --> 0.395219).  Saving model ...
Validation loss decreased (0.395219 --> 0.395197).  Saving model ...
Validation loss decreased (0.395197 --> 0.395174).  Saving model ...
Validation loss decreased (0.395174 --> 0.395152).  Saving model ...
Validation loss decreased (0.395152 --> 0.395129).  Saving model ...
Validation loss decreased (0.395129 --> 0.395107).  Saving model ...
Validation loss decreased (0.395107 --> 0.395085).  Saving model ...
Validation loss decreased (0.395085 --> 0.395062).  Saving model ...
Validation loss decreased (0.395062 --> 0.395040).  Saving model ...
Validation loss decreased (0.395040 --> 0.395017).  Saving model ...
Validation loss decreased (0.395017 --> 0.394995).  Saving model ...
Validation loss decreased (0.394995 --> 0.394972).  Saving model ...
epoch 3701, loss 0.3950, train acc 82.53%, f1 0.7424, precision 0.7656, recall 0.7206, auc 0.8011
Validation loss decreased (0.394972 --> 0.394950).  Saving model ...
Validation loss decreased (0.394950 --> 0.394927).  Saving model ...
Validation loss decreased (0.394927 --> 0.394905).  Saving model ...
Validation loss decreased (0.394905 --> 0.394882).  Saving model ...
Validation loss decreased (0.394882 --> 0.394860).  Saving model ...
Validation loss decreased (0.394860 --> 0.394837).  Saving model ...
Validation loss decreased (0.394837 --> 0.394815).  Saving model ...
Validation loss decreased (0.394815 --> 0.394792).  Saving model ...
Validation loss decreased (0.394792 --> 0.394770).  Saving model ...
Validation loss decreased (0.394770 --> 0.394747).  Saving model ...
Validation loss decreased (0.394747 --> 0.394724).  Saving model ...
Validation loss decreased (0.394724 --> 0.394702).  Saving model ...
Validation loss decreased (0.394702 --> 0.394679).  Saving model ...
Validation loss decreased (0.394679 --> 0.394657).  Saving model ...
Validation loss decreased (0.394657 --> 0.394634).  Saving model ...
Validation loss decreased (0.394634 --> 0.394611).  Saving model ...
Validation loss decreased (0.394611 --> 0.394589).  Saving model ...
Validation loss decreased (0.394589 --> 0.394566).  Saving model ...
Validation loss decreased (0.394566 --> 0.394543).  Saving model ...
Validation loss decreased (0.394543 --> 0.394521).  Saving model ...
Validation loss decreased (0.394521 --> 0.394498).  Saving model ...
Validation loss decreased (0.394498 --> 0.394475).  Saving model ...
Validation loss decreased (0.394475 --> 0.394452).  Saving model ...
Validation loss decreased (0.394452 --> 0.394430).  Saving model ...
Validation loss decreased (0.394430 --> 0.394407).  Saving model ...
Validation loss decreased (0.394407 --> 0.394384).  Saving model ...
Validation loss decreased (0.394384 --> 0.394361).  Saving model ...
Validation loss decreased (0.394361 --> 0.394338).  Saving model ...
Validation loss decreased (0.394338 --> 0.394315).  Saving model ...
Validation loss decreased (0.394315 --> 0.394293).  Saving model ...
Validation loss decreased (0.394293 --> 0.394270).  Saving model ...
Validation loss decreased (0.394270 --> 0.394247).  Saving model ...
Validation loss decreased (0.394247 --> 0.394224).  Saving model ...
Validation loss decreased (0.394224 --> 0.394201).  Saving model ...
Validation loss decreased (0.394201 --> 0.394178).  Saving model ...
Validation loss decreased (0.394178 --> 0.394155).  Saving model ...
Validation loss decreased (0.394155 --> 0.394132).  Saving model ...
Validation loss decreased (0.394132 --> 0.394109).  Saving model ...
Validation loss decreased (0.394109 --> 0.394085).  Saving model ...
Validation loss decreased (0.394085 --> 0.394062).  Saving model ...
Validation loss decreased (0.394062 --> 0.394039).  Saving model ...
Validation loss decreased (0.394039 --> 0.394016).  Saving model ...
Validation loss decreased (0.394016 --> 0.393993).  Saving model ...
Validation loss decreased (0.393993 --> 0.393970).  Saving model ...
Validation loss decreased (0.393970 --> 0.393946).  Saving model ...
Validation loss decreased (0.393946 --> 0.393923).  Saving model ...
Validation loss decreased (0.393923 --> 0.393900).  Saving model ...
Validation loss decreased (0.393900 --> 0.393877).  Saving model ...
Validation loss decreased (0.393877 --> 0.393853).  Saving model ...
Validation loss decreased (0.393853 --> 0.393830).  Saving model ...
Validation loss decreased (0.393830 --> 0.393806).  Saving model ...
Validation loss decreased (0.393806 --> 0.393783).  Saving model ...
Validation loss decreased (0.393783 --> 0.393760).  Saving model ...
Validation loss decreased (0.393760 --> 0.393736).  Saving model ...
Validation loss decreased (0.393736 --> 0.393713).  Saving model ...
Validation loss decreased (0.393713 --> 0.393689).  Saving model ...
Validation loss decreased (0.393689 --> 0.393665).  Saving model ...
Validation loss decreased (0.393665 --> 0.393642).  Saving model ...
Validation loss decreased (0.393642 --> 0.393618).  Saving model ...
Validation loss decreased (0.393618 --> 0.393594).  Saving model ...
Validation loss decreased (0.393594 --> 0.393571).  Saving model ...
Validation loss decreased (0.393571 --> 0.393547).  Saving model ...
Validation loss decreased (0.393547 --> 0.393523).  Saving model ...
Validation loss decreased (0.393523 --> 0.393499).  Saving model ...
Validation loss decreased (0.393499 --> 0.393476).  Saving model ...
Validation loss decreased (0.393476 --> 0.393452).  Saving model ...
Validation loss decreased (0.393452 --> 0.393428).  Saving model ...
Validation loss decreased (0.393428 --> 0.393404).  Saving model ...
Validation loss decreased (0.393404 --> 0.393380).  Saving model ...
Validation loss decreased (0.393380 --> 0.393356).  Saving model ...
Validation loss decreased (0.393356 --> 0.393332).  Saving model ...
Validation loss decreased (0.393332 --> 0.393308).  Saving model ...
Validation loss decreased (0.393308 --> 0.393284).  Saving model ...
Validation loss decreased (0.393284 --> 0.393259).  Saving model ...
Validation loss decreased (0.393259 --> 0.393235).  Saving model ...
Validation loss decreased (0.393235 --> 0.393211).  Saving model ...
Validation loss decreased (0.393211 --> 0.393187).  Saving model ...
Validation loss decreased (0.393187 --> 0.393162).  Saving model ...
Validation loss decreased (0.393162 --> 0.393138).  Saving model ...
Validation loss decreased (0.393138 --> 0.393114).  Saving model ...
Validation loss decreased (0.393114 --> 0.393089).  Saving model ...
Validation loss decreased (0.393089 --> 0.393065).  Saving model ...
Validation loss decreased (0.393065 --> 0.393040).  Saving model ...
Validation loss decreased (0.393040 --> 0.393016).  Saving model ...
Validation loss decreased (0.393016 --> 0.392991).  Saving model ...
Validation loss decreased (0.392991 --> 0.392967).  Saving model ...
Validation loss decreased (0.392967 --> 0.392942).  Saving model ...
Validation loss decreased (0.392942 --> 0.392917).  Saving model ...
Validation loss decreased (0.392917 --> 0.392892).  Saving model ...
Validation loss decreased (0.392892 --> 0.392868).  Saving model ...
Validation loss decreased (0.392868 --> 0.392843).  Saving model ...
Validation loss decreased (0.392843 --> 0.392818).  Saving model ...
Validation loss decreased (0.392818 --> 0.392793).  Saving model ...
Validation loss decreased (0.392793 --> 0.392768).  Saving model ...
Validation loss decreased (0.392768 --> 0.392743).  Saving model ...
Validation loss decreased (0.392743 --> 0.392718).  Saving model ...
Validation loss decreased (0.392718 --> 0.392693).  Saving model ...
Validation loss decreased (0.392693 --> 0.392668).  Saving model ...
Validation loss decreased (0.392668 --> 0.392643).  Saving model ...
Validation loss decreased (0.392643 --> 0.392617).  Saving model ...
epoch 3801, loss 0.3926, train acc 82.71%, f1 0.7443, precision 0.7696, recall 0.7206, auc 0.8024
Validation loss decreased (0.392617 --> 0.392592).  Saving model ...
Validation loss decreased (0.392592 --> 0.392567).  Saving model ...
Validation loss decreased (0.392567 --> 0.392541).  Saving model ...
Validation loss decreased (0.392541 --> 0.392516).  Saving model ...
Validation loss decreased (0.392516 --> 0.392491).  Saving model ...
Validation loss decreased (0.392491 --> 0.392465).  Saving model ...
Validation loss decreased (0.392465 --> 0.392440).  Saving model ...
Validation loss decreased (0.392440 --> 0.392414).  Saving model ...
Validation loss decreased (0.392414 --> 0.392388).  Saving model ...
Validation loss decreased (0.392388 --> 0.392363).  Saving model ...
Validation loss decreased (0.392363 --> 0.392337).  Saving model ...
Validation loss decreased (0.392337 --> 0.392311).  Saving model ...
Validation loss decreased (0.392311 --> 0.392285).  Saving model ...
Validation loss decreased (0.392285 --> 0.392259).  Saving model ...
Validation loss decreased (0.392259 --> 0.392233).  Saving model ...
Validation loss decreased (0.392233 --> 0.392208).  Saving model ...
Validation loss decreased (0.392208 --> 0.392181).  Saving model ...
Validation loss decreased (0.392181 --> 0.392155).  Saving model ...
Validation loss decreased (0.392155 --> 0.392129).  Saving model ...
Validation loss decreased (0.392129 --> 0.392103).  Saving model ...
Validation loss decreased (0.392103 --> 0.392077).  Saving model ...
Validation loss decreased (0.392077 --> 0.392051).  Saving model ...
Validation loss decreased (0.392051 --> 0.392024).  Saving model ...
Validation loss decreased (0.392024 --> 0.391998).  Saving model ...
Validation loss decreased (0.391998 --> 0.391971).  Saving model ...
Validation loss decreased (0.391971 --> 0.391945).  Saving model ...
Validation loss decreased (0.391945 --> 0.391918).  Saving model ...
Validation loss decreased (0.391918 --> 0.391892).  Saving model ...
Validation loss decreased (0.391892 --> 0.391865).  Saving model ...
Validation loss decreased (0.391865 --> 0.391838).  Saving model ...
Validation loss decreased (0.391838 --> 0.391811).  Saving model ...
Validation loss decreased (0.391811 --> 0.391785).  Saving model ...
Validation loss decreased (0.391785 --> 0.391758).  Saving model ...
Validation loss decreased (0.391758 --> 0.391731).  Saving model ...
Validation loss decreased (0.391731 --> 0.391704).  Saving model ...
Validation loss decreased (0.391704 --> 0.391677).  Saving model ...
Validation loss decreased (0.391677 --> 0.391650).  Saving model ...
Validation loss decreased (0.391650 --> 0.391622).  Saving model ...
Validation loss decreased (0.391622 --> 0.391595).  Saving model ...
Validation loss decreased (0.391595 --> 0.391568).  Saving model ...
Validation loss decreased (0.391568 --> 0.391540).  Saving model ...
Validation loss decreased (0.391540 --> 0.391513).  Saving model ...
Validation loss decreased (0.391513 --> 0.391486).  Saving model ...
Validation loss decreased (0.391486 --> 0.391458).  Saving model ...
Validation loss decreased (0.391458 --> 0.391430).  Saving model ...
Validation loss decreased (0.391430 --> 0.391403).  Saving model ...
Validation loss decreased (0.391403 --> 0.391375).  Saving model ...
Validation loss decreased (0.391375 --> 0.391347).  Saving model ...
Validation loss decreased (0.391347 --> 0.391319).  Saving model ...
Validation loss decreased (0.391319 --> 0.391291).  Saving model ...
Validation loss decreased (0.391291 --> 0.391264).  Saving model ...
Validation loss decreased (0.391264 --> 0.391236).  Saving model ...
Validation loss decreased (0.391236 --> 0.391207).  Saving model ...
Validation loss decreased (0.391207 --> 0.391179).  Saving model ...
Validation loss decreased (0.391179 --> 0.391151).  Saving model ...
Validation loss decreased (0.391151 --> 0.391123).  Saving model ...
Validation loss decreased (0.391123 --> 0.391094).  Saving model ...
Validation loss decreased (0.391094 --> 0.391066).  Saving model ...
Validation loss decreased (0.391066 --> 0.391037).  Saving model ...
Validation loss decreased (0.391037 --> 0.391009).  Saving model ...
Validation loss decreased (0.391009 --> 0.390980).  Saving model ...
Validation loss decreased (0.390980 --> 0.390952).  Saving model ...
Validation loss decreased (0.390952 --> 0.390923).  Saving model ...
Validation loss decreased (0.390923 --> 0.390894).  Saving model ...
Validation loss decreased (0.390894 --> 0.390865).  Saving model ...
Validation loss decreased (0.390865 --> 0.390836).  Saving model ...
Validation loss decreased (0.390836 --> 0.390807).  Saving model ...
Validation loss decreased (0.390807 --> 0.390778).  Saving model ...
Validation loss decreased (0.390778 --> 0.390749).  Saving model ...
Validation loss decreased (0.390749 --> 0.390720).  Saving model ...
Validation loss decreased (0.390720 --> 0.390690).  Saving model ...
Validation loss decreased (0.390690 --> 0.390661).  Saving model ...
Validation loss decreased (0.390661 --> 0.390632).  Saving model ...
Validation loss decreased (0.390632 --> 0.390602).  Saving model ...
Validation loss decreased (0.390602 --> 0.390573).  Saving model ...
Validation loss decreased (0.390573 --> 0.390543).  Saving model ...
Validation loss decreased (0.390543 --> 0.390513).  Saving model ...
Validation loss decreased (0.390513 --> 0.390483).  Saving model ...
Validation loss decreased (0.390483 --> 0.390454).  Saving model ...
Validation loss decreased (0.390454 --> 0.390424).  Saving model ...
Validation loss decreased (0.390424 --> 0.390394).  Saving model ...
Validation loss decreased (0.390394 --> 0.390364).  Saving model ...
Validation loss decreased (0.390364 --> 0.390334).  Saving model ...
Validation loss decreased (0.390334 --> 0.390304).  Saving model ...
Validation loss decreased (0.390304 --> 0.390273).  Saving model ...
Validation loss decreased (0.390273 --> 0.390243).  Saving model ...
Validation loss decreased (0.390243 --> 0.390213).  Saving model ...
Validation loss decreased (0.390213 --> 0.390182).  Saving model ...
Validation loss decreased (0.390182 --> 0.390152).  Saving model ...
Validation loss decreased (0.390152 --> 0.390121).  Saving model ...
Validation loss decreased (0.390121 --> 0.390090).  Saving model ...
Validation loss decreased (0.390090 --> 0.390060).  Saving model ...
Validation loss decreased (0.390060 --> 0.390029).  Saving model ...
Validation loss decreased (0.390029 --> 0.389998).  Saving model ...
Validation loss decreased (0.389998 --> 0.389967).  Saving model ...
Validation loss decreased (0.389967 --> 0.389936).  Saving model ...
Validation loss decreased (0.389936 --> 0.389905).  Saving model ...
Validation loss decreased (0.389905 --> 0.389874).  Saving model ...
Validation loss decreased (0.389874 --> 0.389843).  Saving model ...
Validation loss decreased (0.389843 --> 0.389812).  Saving model ...
epoch 3901, loss 0.3898, train acc 82.88%, f1 0.7475, precision 0.7708, recall 0.7255, auc 0.8049
Validation loss decreased (0.389812 --> 0.389781).  Saving model ...
Validation loss decreased (0.389781 --> 0.389749).  Saving model ...
Validation loss decreased (0.389749 --> 0.389718).  Saving model ...
Validation loss decreased (0.389718 --> 0.389686).  Saving model ...
Validation loss decreased (0.389686 --> 0.389655).  Saving model ...
Validation loss decreased (0.389655 --> 0.389623).  Saving model ...
Validation loss decreased (0.389623 --> 0.389592).  Saving model ...
Validation loss decreased (0.389592 --> 0.389560).  Saving model ...
Validation loss decreased (0.389560 --> 0.389528).  Saving model ...
Validation loss decreased (0.389528 --> 0.389497).  Saving model ...
Validation loss decreased (0.389497 --> 0.389465).  Saving model ...
Validation loss decreased (0.389465 --> 0.389433).  Saving model ...
Validation loss decreased (0.389433 --> 0.389401).  Saving model ...
Validation loss decreased (0.389401 --> 0.389369).  Saving model ...
Validation loss decreased (0.389369 --> 0.389337).  Saving model ...
Validation loss decreased (0.389337 --> 0.389305).  Saving model ...
Validation loss decreased (0.389305 --> 0.389272).  Saving model ...
Validation loss decreased (0.389272 --> 0.389240).  Saving model ...
Validation loss decreased (0.389240 --> 0.389208).  Saving model ...
Validation loss decreased (0.389208 --> 0.389176).  Saving model ...
Validation loss decreased (0.389176 --> 0.389143).  Saving model ...
Validation loss decreased (0.389143 --> 0.389111).  Saving model ...
Validation loss decreased (0.389111 --> 0.389078).  Saving model ...
Validation loss decreased (0.389078 --> 0.389046).  Saving model ...
Validation loss decreased (0.389046 --> 0.389013).  Saving model ...
Validation loss decreased (0.389013 --> 0.388981).  Saving model ...
Validation loss decreased (0.388981 --> 0.388948).  Saving model ...
Validation loss decreased (0.388948 --> 0.388915).  Saving model ...
Validation loss decreased (0.388915 --> 0.388883).  Saving model ...
Validation loss decreased (0.388883 --> 0.388850).  Saving model ...
Validation loss decreased (0.388850 --> 0.388817).  Saving model ...
Validation loss decreased (0.388817 --> 0.388784).  Saving model ...
Validation loss decreased (0.388784 --> 0.388751).  Saving model ...
Validation loss decreased (0.388751 --> 0.388718).  Saving model ...
Validation loss decreased (0.388718 --> 0.388685).  Saving model ...
Validation loss decreased (0.388685 --> 0.388652).  Saving model ...
Validation loss decreased (0.388652 --> 0.388619).  Saving model ...
Validation loss decreased (0.388619 --> 0.388586).  Saving model ...
Validation loss decreased (0.388586 --> 0.388553).  Saving model ...
Validation loss decreased (0.388553 --> 0.388520).  Saving model ...
Validation loss decreased (0.388520 --> 0.388486).  Saving model ...
Validation loss decreased (0.388486 --> 0.388453).  Saving model ...
Validation loss decreased (0.388453 --> 0.388420).  Saving model ...
Validation loss decreased (0.388420 --> 0.388386).  Saving model ...
Validation loss decreased (0.388386 --> 0.388353).  Saving model ...
Validation loss decreased (0.388353 --> 0.388320).  Saving model ...
Validation loss decreased (0.388320 --> 0.388286).  Saving model ...
Validation loss decreased (0.388286 --> 0.388253).  Saving model ...
Validation loss decreased (0.388253 --> 0.388219).  Saving model ...
Validation loss decreased (0.388219 --> 0.388185).  Saving model ...
Validation loss decreased (0.388185 --> 0.388152).  Saving model ...
Validation loss decreased (0.388152 --> 0.388118).  Saving model ...
Validation loss decreased (0.388118 --> 0.388084).  Saving model ...
Validation loss decreased (0.388084 --> 0.388051).  Saving model ...
Validation loss decreased (0.388051 --> 0.388017).  Saving model ...
Validation loss decreased (0.388017 --> 0.387983).  Saving model ...
Validation loss decreased (0.387983 --> 0.387949).  Saving model ...
Validation loss decreased (0.387949 --> 0.387915).  Saving model ...
Validation loss decreased (0.387915 --> 0.387881).  Saving model ...
Validation loss decreased (0.387881 --> 0.387848).  Saving model ...
Validation loss decreased (0.387848 --> 0.387814).  Saving model ...
Validation loss decreased (0.387814 --> 0.387780).  Saving model ...
Validation loss decreased (0.387780 --> 0.387745).  Saving model ...
Validation loss decreased (0.387745 --> 0.387711).  Saving model ...
Validation loss decreased (0.387711 --> 0.387677).  Saving model ...
Validation loss decreased (0.387677 --> 0.387643).  Saving model ...
Validation loss decreased (0.387643 --> 0.387609).  Saving model ...
Validation loss decreased (0.387609 --> 0.387575).  Saving model ...
Validation loss decreased (0.387575 --> 0.387540).  Saving model ...
Validation loss decreased (0.387540 --> 0.387506).  Saving model ...
Validation loss decreased (0.387506 --> 0.387472).  Saving model ...
Validation loss decreased (0.387472 --> 0.387437).  Saving model ...
Validation loss decreased (0.387437 --> 0.387403).  Saving model ...
Validation loss decreased (0.387403 --> 0.387369).  Saving model ...
Validation loss decreased (0.387369 --> 0.387334).  Saving model ...
Validation loss decreased (0.387334 --> 0.387300).  Saving model ...
Validation loss decreased (0.387300 --> 0.387265).  Saving model ...
Validation loss decreased (0.387265 --> 0.387230).  Saving model ...
Validation loss decreased (0.387230 --> 0.387196).  Saving model ...
Validation loss decreased (0.387196 --> 0.387161).  Saving model ...
Validation loss decreased (0.387161 --> 0.387127).  Saving model ...
Validation loss decreased (0.387127 --> 0.387092).  Saving model ...
Validation loss decreased (0.387092 --> 0.387057).  Saving model ...
Validation loss decreased (0.387057 --> 0.387022).  Saving model ...
Validation loss decreased (0.387022 --> 0.386988).  Saving model ...
Validation loss decreased (0.386988 --> 0.386953).  Saving model ...
Validation loss decreased (0.386953 --> 0.386918).  Saving model ...
Validation loss decreased (0.386918 --> 0.386883).  Saving model ...
Validation loss decreased (0.386883 --> 0.386848).  Saving model ...
Validation loss decreased (0.386848 --> 0.386813).  Saving model ...
Validation loss decreased (0.386813 --> 0.386778).  Saving model ...
Validation loss decreased (0.386778 --> 0.386743).  Saving model ...
Validation loss decreased (0.386743 --> 0.386708).  Saving model ...
Validation loss decreased (0.386708 --> 0.386673).  Saving model ...
Validation loss decreased (0.386673 --> 0.386638).  Saving model ...
Validation loss decreased (0.386638 --> 0.386603).  Saving model ...
Validation loss decreased (0.386603 --> 0.386568).  Saving model ...
Validation loss decreased (0.386568 --> 0.386533).  Saving model ...
Validation loss decreased (0.386533 --> 0.386497).  Saving model ...
Validation loss decreased (0.386497 --> 0.386462).  Saving model ...
epoch 4001, loss 0.3865, train acc 82.88%, f1 0.7462, precision 0.7737, recall 0.7206, auc 0.8037
Validation loss decreased (0.386462 --> 0.386427).  Saving model ...
Validation loss decreased (0.386427 --> 0.386392).  Saving model ...
Validation loss decreased (0.386392 --> 0.386356).  Saving model ...
Validation loss decreased (0.386356 --> 0.386321).  Saving model ...
Validation loss decreased (0.386321 --> 0.386286).  Saving model ...
Validation loss decreased (0.386286 --> 0.386251).  Saving model ...
Validation loss decreased (0.386251 --> 0.386215).  Saving model ...
Validation loss decreased (0.386215 --> 0.386180).  Saving model ...
Validation loss decreased (0.386180 --> 0.386144).  Saving model ...
Validation loss decreased (0.386144 --> 0.386109).  Saving model ...
Validation loss decreased (0.386109 --> 0.386074).  Saving model ...
Validation loss decreased (0.386074 --> 0.386038).  Saving model ...
Validation loss decreased (0.386038 --> 0.386003).  Saving model ...
Validation loss decreased (0.386003 --> 0.385967).  Saving model ...
Validation loss decreased (0.385967 --> 0.385932).  Saving model ...
Validation loss decreased (0.385932 --> 0.385896).  Saving model ...
Validation loss decreased (0.385896 --> 0.385861).  Saving model ...
Validation loss decreased (0.385861 --> 0.385826).  Saving model ...
Validation loss decreased (0.385826 --> 0.385790).  Saving model ...
Validation loss decreased (0.385790 --> 0.385755).  Saving model ...
Validation loss decreased (0.385755 --> 0.385719).  Saving model ...
Validation loss decreased (0.385719 --> 0.385684).  Saving model ...
Validation loss decreased (0.385684 --> 0.385648).  Saving model ...
Validation loss decreased (0.385648 --> 0.385613).  Saving model ...
Validation loss decreased (0.385613 --> 0.385577).  Saving model ...
Validation loss decreased (0.385577 --> 0.385542).  Saving model ...
Validation loss decreased (0.385542 --> 0.385506).  Saving model ...
Validation loss decreased (0.385506 --> 0.385471).  Saving model ...
Validation loss decreased (0.385471 --> 0.385435).  Saving model ...
Validation loss decreased (0.385435 --> 0.385399).  Saving model ...
Validation loss decreased (0.385399 --> 0.385364).  Saving model ...
Validation loss decreased (0.385364 --> 0.385328).  Saving model ...
Validation loss decreased (0.385328 --> 0.385293).  Saving model ...
Validation loss decreased (0.385293 --> 0.385257).  Saving model ...
Validation loss decreased (0.385257 --> 0.385222).  Saving model ...
Validation loss decreased (0.385222 --> 0.385186).  Saving model ...
Validation loss decreased (0.385186 --> 0.385151).  Saving model ...
Validation loss decreased (0.385151 --> 0.385115).  Saving model ...
Validation loss decreased (0.385115 --> 0.385080).  Saving model ...
Validation loss decreased (0.385080 --> 0.385044).  Saving model ...
Validation loss decreased (0.385044 --> 0.385009).  Saving model ...
Validation loss decreased (0.385009 --> 0.384973).  Saving model ...
Validation loss decreased (0.384973 --> 0.384938).  Saving model ...
Validation loss decreased (0.384938 --> 0.384903).  Saving model ...
Validation loss decreased (0.384903 --> 0.384867).  Saving model ...
Validation loss decreased (0.384867 --> 0.384832).  Saving model ...
Validation loss decreased (0.384832 --> 0.384796).  Saving model ...
Validation loss decreased (0.384796 --> 0.384761).  Saving model ...
Validation loss decreased (0.384761 --> 0.384725).  Saving model ...
Validation loss decreased (0.384725 --> 0.384690).  Saving model ...
Validation loss decreased (0.384690 --> 0.384655).  Saving model ...
Validation loss decreased (0.384655 --> 0.384619).  Saving model ...
Validation loss decreased (0.384619 --> 0.384584).  Saving model ...
Validation loss decreased (0.384584 --> 0.384548).  Saving model ...
Validation loss decreased (0.384548 --> 0.384513).  Saving model ...
Validation loss decreased (0.384513 --> 0.384478).  Saving model ...
Validation loss decreased (0.384478 --> 0.384443).  Saving model ...
Validation loss decreased (0.384443 --> 0.384407).  Saving model ...
Validation loss decreased (0.384407 --> 0.384372).  Saving model ...
Validation loss decreased (0.384372 --> 0.384337).  Saving model ...
Validation loss decreased (0.384337 --> 0.384301).  Saving model ...
Validation loss decreased (0.384301 --> 0.384266).  Saving model ...
Validation loss decreased (0.384266 --> 0.384231).  Saving model ...
Validation loss decreased (0.384231 --> 0.384196).  Saving model ...
Validation loss decreased (0.384196 --> 0.384160).  Saving model ...
Validation loss decreased (0.384160 --> 0.384125).  Saving model ...
Validation loss decreased (0.384125 --> 0.384090).  Saving model ...
Validation loss decreased (0.384090 --> 0.384055).  Saving model ...
Validation loss decreased (0.384055 --> 0.384020).  Saving model ...
Validation loss decreased (0.384020 --> 0.383985).  Saving model ...
Validation loss decreased (0.383985 --> 0.383950).  Saving model ...
Validation loss decreased (0.383950 --> 0.383915).  Saving model ...
Validation loss decreased (0.383915 --> 0.383880).  Saving model ...
Validation loss decreased (0.383880 --> 0.383844).  Saving model ...
Validation loss decreased (0.383844 --> 0.383809).  Saving model ...
Validation loss decreased (0.383809 --> 0.383774).  Saving model ...
Validation loss decreased (0.383774 --> 0.383739).  Saving model ...
Validation loss decreased (0.383739 --> 0.383704).  Saving model ...
Validation loss decreased (0.383704 --> 0.383669).  Saving model ...
Validation loss decreased (0.383669 --> 0.383634).  Saving model ...
Validation loss decreased (0.383634 --> 0.383600).  Saving model ...
Validation loss decreased (0.383600 --> 0.383565).  Saving model ...
Validation loss decreased (0.383565 --> 0.383530).  Saving model ...
Validation loss decreased (0.383530 --> 0.383495).  Saving model ...
Validation loss decreased (0.383495 --> 0.383460).  Saving model ...
Validation loss decreased (0.383460 --> 0.383425).  Saving model ...
Validation loss decreased (0.383425 --> 0.383390).  Saving model ...
Validation loss decreased (0.383390 --> 0.383356).  Saving model ...
Validation loss decreased (0.383356 --> 0.383321).  Saving model ...
Validation loss decreased (0.383321 --> 0.383286).  Saving model ...
Validation loss decreased (0.383286 --> 0.383251).  Saving model ...
Validation loss decreased (0.383251 --> 0.383217).  Saving model ...
Validation loss decreased (0.383217 --> 0.383182).  Saving model ...
Validation loss decreased (0.383182 --> 0.383147).  Saving model ...
Validation loss decreased (0.383147 --> 0.383112).  Saving model ...
Validation loss decreased (0.383112 --> 0.383078).  Saving model ...
Validation loss decreased (0.383078 --> 0.383043).  Saving model ...
Validation loss decreased (0.383043 --> 0.383009).  Saving model ...
Validation loss decreased (0.383009 --> 0.382974).  Saving model ...
Validation loss decreased (0.382974 --> 0.382939).  Saving model ...
epoch 4101, loss 0.3829, train acc 83.05%, f1 0.7494, precision 0.7749, recall 0.7255, auc 0.8062
Validation loss decreased (0.382939 --> 0.382905).  Saving model ...
Validation loss decreased (0.382905 --> 0.382870).  Saving model ...
Validation loss decreased (0.382870 --> 0.382836).  Saving model ...
Validation loss decreased (0.382836 --> 0.382801).  Saving model ...
Validation loss decreased (0.382801 --> 0.382767).  Saving model ...
Validation loss decreased (0.382767 --> 0.382732).  Saving model ...
Validation loss decreased (0.382732 --> 0.382698).  Saving model ...
Validation loss decreased (0.382698 --> 0.382663).  Saving model ...
Validation loss decreased (0.382663 --> 0.382629).  Saving model ...
Validation loss decreased (0.382629 --> 0.382594).  Saving model ...
Validation loss decreased (0.382594 --> 0.382560).  Saving model ...
Validation loss decreased (0.382560 --> 0.382526).  Saving model ...
Validation loss decreased (0.382526 --> 0.382491).  Saving model ...
Validation loss decreased (0.382491 --> 0.382457).  Saving model ...
Validation loss decreased (0.382457 --> 0.382423).  Saving model ...
Validation loss decreased (0.382423 --> 0.382388).  Saving model ...
Validation loss decreased (0.382388 --> 0.382354).  Saving model ...
Validation loss decreased (0.382354 --> 0.382320).  Saving model ...
Validation loss decreased (0.382320 --> 0.382286).  Saving model ...
Validation loss decreased (0.382286 --> 0.382251).  Saving model ...
Validation loss decreased (0.382251 --> 0.382217).  Saving model ...
Validation loss decreased (0.382217 --> 0.382183).  Saving model ...
Validation loss decreased (0.382183 --> 0.382149).  Saving model ...
Validation loss decreased (0.382149 --> 0.382114).  Saving model ...
Validation loss decreased (0.382114 --> 0.382080).  Saving model ...
Validation loss decreased (0.382080 --> 0.382046).  Saving model ...
Validation loss decreased (0.382046 --> 0.382012).  Saving model ...
Validation loss decreased (0.382012 --> 0.381978).  Saving model ...
Validation loss decreased (0.381978 --> 0.381944).  Saving model ...
Validation loss decreased (0.381944 --> 0.381910).  Saving model ...
Validation loss decreased (0.381910 --> 0.381876).  Saving model ...
Validation loss decreased (0.381876 --> 0.381842).  Saving model ...
Validation loss decreased (0.381842 --> 0.381808).  Saving model ...
Validation loss decreased (0.381808 --> 0.381774).  Saving model ...
Validation loss decreased (0.381774 --> 0.381740).  Saving model ...
Validation loss decreased (0.381740 --> 0.381706).  Saving model ...
Validation loss decreased (0.381706 --> 0.381672).  Saving model ...
Validation loss decreased (0.381672 --> 0.381638).  Saving model ...
Validation loss decreased (0.381638 --> 0.381604).  Saving model ...
Validation loss decreased (0.381604 --> 0.381570).  Saving model ...
Validation loss decreased (0.381570 --> 0.381536).  Saving model ...
Validation loss decreased (0.381536 --> 0.381502).  Saving model ...
Validation loss decreased (0.381502 --> 0.381468).  Saving model ...
Validation loss decreased (0.381468 --> 0.381434).  Saving model ...
Validation loss decreased (0.381434 --> 0.381400).  Saving model ...
Validation loss decreased (0.381400 --> 0.381366).  Saving model ...
Validation loss decreased (0.381366 --> 0.381332).  Saving model ...
Validation loss decreased (0.381332 --> 0.381298).  Saving model ...
Validation loss decreased (0.381298 --> 0.381265).  Saving model ...
Validation loss decreased (0.381265 --> 0.381231).  Saving model ...
Validation loss decreased (0.381231 --> 0.381197).  Saving model ...
Validation loss decreased (0.381197 --> 0.381163).  Saving model ...
Validation loss decreased (0.381163 --> 0.381129).  Saving model ...
Validation loss decreased (0.381129 --> 0.381096).  Saving model ...
Validation loss decreased (0.381096 --> 0.381062).  Saving model ...
Validation loss decreased (0.381062 --> 0.381028).  Saving model ...
Validation loss decreased (0.381028 --> 0.380994).  Saving model ...
Validation loss decreased (0.380994 --> 0.380961).  Saving model ...
Validation loss decreased (0.380961 --> 0.380927).  Saving model ...
Validation loss decreased (0.380927 --> 0.380893).  Saving model ...
Validation loss decreased (0.380893 --> 0.380859).  Saving model ...
Validation loss decreased (0.380859 --> 0.380826).  Saving model ...
Validation loss decreased (0.380826 --> 0.380792).  Saving model ...
Validation loss decreased (0.380792 --> 0.380758).  Saving model ...
Validation loss decreased (0.380758 --> 0.380724).  Saving model ...
Validation loss decreased (0.380724 --> 0.380691).  Saving model ...
Validation loss decreased (0.380691 --> 0.380657).  Saving model ...
Validation loss decreased (0.380657 --> 0.380623).  Saving model ...
Validation loss decreased (0.380623 --> 0.380590).  Saving model ...
Validation loss decreased (0.380590 --> 0.380556).  Saving model ...
Validation loss decreased (0.380556 --> 0.380522).  Saving model ...
Validation loss decreased (0.380522 --> 0.380489).  Saving model ...
Validation loss decreased (0.380489 --> 0.380455).  Saving model ...
Validation loss decreased (0.380455 --> 0.380421).  Saving model ...
Validation loss decreased (0.380421 --> 0.380388).  Saving model ...
Validation loss decreased (0.380388 --> 0.380354).  Saving model ...
Validation loss decreased (0.380354 --> 0.380321).  Saving model ...
Validation loss decreased (0.380321 --> 0.380287).  Saving model ...
Validation loss decreased (0.380287 --> 0.380253).  Saving model ...
Validation loss decreased (0.380253 --> 0.380220).  Saving model ...
Validation loss decreased (0.380220 --> 0.380186).  Saving model ...
Validation loss decreased (0.380186 --> 0.380152).  Saving model ...
Validation loss decreased (0.380152 --> 0.380119).  Saving model ...
Validation loss decreased (0.380119 --> 0.380085).  Saving model ...
Validation loss decreased (0.380085 --> 0.380052).  Saving model ...
Validation loss decreased (0.380052 --> 0.380018).  Saving model ...
Validation loss decreased (0.380018 --> 0.379984).  Saving model ...
Validation loss decreased (0.379984 --> 0.379951).  Saving model ...
Validation loss decreased (0.379951 --> 0.379917).  Saving model ...
Validation loss decreased (0.379917 --> 0.379883).  Saving model ...
Validation loss decreased (0.379883 --> 0.379850).  Saving model ...
Validation loss decreased (0.379850 --> 0.379816).  Saving model ...
Validation loss decreased (0.379816 --> 0.379783).  Saving model ...
Validation loss decreased (0.379783 --> 0.379749).  Saving model ...
Validation loss decreased (0.379749 --> 0.379715).  Saving model ...
Validation loss decreased (0.379715 --> 0.379682).  Saving model ...
Validation loss decreased (0.379682 --> 0.379648).  Saving model ...
Validation loss decreased (0.379648 --> 0.379615).  Saving model ...
Validation loss decreased (0.379615 --> 0.379581).  Saving model ...
Validation loss decreased (0.379581 --> 0.379547).  Saving model ...
epoch 4201, loss 0.3795, train acc 83.39%, f1 0.7557, precision 0.7772, recall 0.7353, auc 0.8111
Validation loss decreased (0.379547 --> 0.379514).  Saving model ...
Validation loss decreased (0.379514 --> 0.379480).  Saving model ...
Validation loss decreased (0.379480 --> 0.379446).  Saving model ...
Validation loss decreased (0.379446 --> 0.379413).  Saving model ...
Validation loss decreased (0.379413 --> 0.379379).  Saving model ...
Validation loss decreased (0.379379 --> 0.379345).  Saving model ...
Validation loss decreased (0.379345 --> 0.379312).  Saving model ...
Validation loss decreased (0.379312 --> 0.379278).  Saving model ...
Validation loss decreased (0.379278 --> 0.379244).  Saving model ...
Validation loss decreased (0.379244 --> 0.379210).  Saving model ...
Validation loss decreased (0.379210 --> 0.379177).  Saving model ...
Validation loss decreased (0.379177 --> 0.379143).  Saving model ...
Validation loss decreased (0.379143 --> 0.379109).  Saving model ...
Validation loss decreased (0.379109 --> 0.379076).  Saving model ...
Validation loss decreased (0.379076 --> 0.379042).  Saving model ...
Validation loss decreased (0.379042 --> 0.379008).  Saving model ...
Validation loss decreased (0.379008 --> 0.378974).  Saving model ...
Validation loss decreased (0.378974 --> 0.378940).  Saving model ...
Validation loss decreased (0.378940 --> 0.378907).  Saving model ...
Validation loss decreased (0.378907 --> 0.378873).  Saving model ...
Validation loss decreased (0.378873 --> 0.378839).  Saving model ...
Validation loss decreased (0.378839 --> 0.378805).  Saving model ...
Validation loss decreased (0.378805 --> 0.378771).  Saving model ...
Validation loss decreased (0.378771 --> 0.378737).  Saving model ...
Validation loss decreased (0.378737 --> 0.378703).  Saving model ...
Validation loss decreased (0.378703 --> 0.378670).  Saving model ...
Validation loss decreased (0.378670 --> 0.378636).  Saving model ...
Validation loss decreased (0.378636 --> 0.378602).  Saving model ...
Validation loss decreased (0.378602 --> 0.378568).  Saving model ...
Validation loss decreased (0.378568 --> 0.378534).  Saving model ...
Validation loss decreased (0.378534 --> 0.378500).  Saving model ...
Validation loss decreased (0.378500 --> 0.378466).  Saving model ...
Validation loss decreased (0.378466 --> 0.378432).  Saving model ...
Validation loss decreased (0.378432 --> 0.378398).  Saving model ...
Validation loss decreased (0.378398 --> 0.378364).  Saving model ...
Validation loss decreased (0.378364 --> 0.378330).  Saving model ...
Validation loss decreased (0.378330 --> 0.378295).  Saving model ...
Validation loss decreased (0.378295 --> 0.378261).  Saving model ...
Validation loss decreased (0.378261 --> 0.378227).  Saving model ...
Validation loss decreased (0.378227 --> 0.378193).  Saving model ...
Validation loss decreased (0.378193 --> 0.378159).  Saving model ...
Validation loss decreased (0.378159 --> 0.378125).  Saving model ...
Validation loss decreased (0.378125 --> 0.378090).  Saving model ...
Validation loss decreased (0.378090 --> 0.378056).  Saving model ...
Validation loss decreased (0.378056 --> 0.378022).  Saving model ...
Validation loss decreased (0.378022 --> 0.377988).  Saving model ...
Validation loss decreased (0.377988 --> 0.377953).  Saving model ...
Validation loss decreased (0.377953 --> 0.377919).  Saving model ...
Validation loss decreased (0.377919 --> 0.377885).  Saving model ...
Validation loss decreased (0.377885 --> 0.377850).  Saving model ...
Validation loss decreased (0.377850 --> 0.377816).  Saving model ...
Validation loss decreased (0.377816 --> 0.377781).  Saving model ...
Validation loss decreased (0.377781 --> 0.377747).  Saving model ...
Validation loss decreased (0.377747 --> 0.377713).  Saving model ...
Validation loss decreased (0.377713 --> 0.377678).  Saving model ...
Validation loss decreased (0.377678 --> 0.377644).  Saving model ...
Validation loss decreased (0.377644 --> 0.377609).  Saving model ...
Validation loss decreased (0.377609 --> 0.377575).  Saving model ...
Validation loss decreased (0.377575 --> 0.377540).  Saving model ...
Validation loss decreased (0.377540 --> 0.377505).  Saving model ...
Validation loss decreased (0.377505 --> 0.377471).  Saving model ...
Validation loss decreased (0.377471 --> 0.377436).  Saving model ...
Validation loss decreased (0.377436 --> 0.377402).  Saving model ...
Validation loss decreased (0.377402 --> 0.377367).  Saving model ...
Validation loss decreased (0.377367 --> 0.377332).  Saving model ...
Validation loss decreased (0.377332 --> 0.377298).  Saving model ...
Validation loss decreased (0.377298 --> 0.377263).  Saving model ...
Validation loss decreased (0.377263 --> 0.377228).  Saving model ...
Validation loss decreased (0.377228 --> 0.377194).  Saving model ...
Validation loss decreased (0.377194 --> 0.377159).  Saving model ...
Validation loss decreased (0.377159 --> 0.377124).  Saving model ...
Validation loss decreased (0.377124 --> 0.377089).  Saving model ...
Validation loss decreased (0.377089 --> 0.377055).  Saving model ...
Validation loss decreased (0.377055 --> 0.377020).  Saving model ...
Validation loss decreased (0.377020 --> 0.376985).  Saving model ...
Validation loss decreased (0.376985 --> 0.376950).  Saving model ...
Validation loss decreased (0.376950 --> 0.376915).  Saving model ...
Validation loss decreased (0.376915 --> 0.376880).  Saving model ...
Validation loss decreased (0.376880 --> 0.376846).  Saving model ...
Validation loss decreased (0.376846 --> 0.376811).  Saving model ...
Validation loss decreased (0.376811 --> 0.376776).  Saving model ...
Validation loss decreased (0.376776 --> 0.376741).  Saving model ...
Validation loss decreased (0.376741 --> 0.376706).  Saving model ...
Validation loss decreased (0.376706 --> 0.376672).  Saving model ...
Validation loss decreased (0.376672 --> 0.376637).  Saving model ...
Validation loss decreased (0.376637 --> 0.376602).  Saving model ...
Validation loss decreased (0.376602 --> 0.376567).  Saving model ...
Validation loss decreased (0.376567 --> 0.376532).  Saving model ...
Validation loss decreased (0.376532 --> 0.376497).  Saving model ...
Validation loss decreased (0.376497 --> 0.376462).  Saving model ...
Validation loss decreased (0.376462 --> 0.376428).  Saving model ...
Validation loss decreased (0.376428 --> 0.376393).  Saving model ...
Validation loss decreased (0.376393 --> 0.376358).  Saving model ...
Validation loss decreased (0.376358 --> 0.376323).  Saving model ...
Validation loss decreased (0.376323 --> 0.376288).  Saving model ...
Validation loss decreased (0.376288 --> 0.376254).  Saving model ...
Validation loss decreased (0.376254 --> 0.376219).  Saving model ...
Validation loss decreased (0.376219 --> 0.376184).  Saving model ...
Validation loss decreased (0.376184 --> 0.376149).  Saving model ...
Validation loss decreased (0.376149 --> 0.376114).  Saving model ...
epoch 4301, loss 0.3761, train acc 83.56%, f1 0.7576, precision 0.7812, recall 0.7353, auc 0.8124
Validation loss decreased (0.376114 --> 0.376080).  Saving model ...
Validation loss decreased (0.376080 --> 0.376045).  Saving model ...
Validation loss decreased (0.376045 --> 0.376010).  Saving model ...
Validation loss decreased (0.376010 --> 0.375975).  Saving model ...
Validation loss decreased (0.375975 --> 0.375941).  Saving model ...
Validation loss decreased (0.375941 --> 0.375906).  Saving model ...
Validation loss decreased (0.375906 --> 0.375871).  Saving model ...
Validation loss decreased (0.375871 --> 0.375837).  Saving model ...
Validation loss decreased (0.375837 --> 0.375802).  Saving model ...
Validation loss decreased (0.375802 --> 0.375768).  Saving model ...
Validation loss decreased (0.375768 --> 0.375733).  Saving model ...
Validation loss decreased (0.375733 --> 0.375698).  Saving model ...
Validation loss decreased (0.375698 --> 0.375664).  Saving model ...
Validation loss decreased (0.375664 --> 0.375629).  Saving model ...
Validation loss decreased (0.375629 --> 0.375595).  Saving model ...
Validation loss decreased (0.375595 --> 0.375560).  Saving model ...
Validation loss decreased (0.375560 --> 0.375526).  Saving model ...
Validation loss decreased (0.375526 --> 0.375491).  Saving model ...
Validation loss decreased (0.375491 --> 0.375457).  Saving model ...
Validation loss decreased (0.375457 --> 0.375422).  Saving model ...
Validation loss decreased (0.375422 --> 0.375388).  Saving model ...
Validation loss decreased (0.375388 --> 0.375353).  Saving model ...
Validation loss decreased (0.375353 --> 0.375319).  Saving model ...
Validation loss decreased (0.375319 --> 0.375285).  Saving model ...
Validation loss decreased (0.375285 --> 0.375250).  Saving model ...
Validation loss decreased (0.375250 --> 0.375216).  Saving model ...
Validation loss decreased (0.375216 --> 0.375182).  Saving model ...
Validation loss decreased (0.375182 --> 0.375147).  Saving model ...
Validation loss decreased (0.375147 --> 0.375113).  Saving model ...
Validation loss decreased (0.375113 --> 0.375079).  Saving model ...
Validation loss decreased (0.375079 --> 0.375045).  Saving model ...
Validation loss decreased (0.375045 --> 0.375010).  Saving model ...
Validation loss decreased (0.375010 --> 0.374976).  Saving model ...
Validation loss decreased (0.374976 --> 0.374942).  Saving model ...
Validation loss decreased (0.374942 --> 0.374908).  Saving model ...
Validation loss decreased (0.374908 --> 0.374874).  Saving model ...
Validation loss decreased (0.374874 --> 0.374840).  Saving model ...
Validation loss decreased (0.374840 --> 0.374805).  Saving model ...
Validation loss decreased (0.374805 --> 0.374771).  Saving model ...
Validation loss decreased (0.374771 --> 0.374737).  Saving model ...
Validation loss decreased (0.374737 --> 0.374703).  Saving model ...
Validation loss decreased (0.374703 --> 0.374669).  Saving model ...
Validation loss decreased (0.374669 --> 0.374635).  Saving model ...
Validation loss decreased (0.374635 --> 0.374601).  Saving model ...
Validation loss decreased (0.374601 --> 0.374567).  Saving model ...
Validation loss decreased (0.374567 --> 0.374533).  Saving model ...
Validation loss decreased (0.374533 --> 0.374499).  Saving model ...
Validation loss decreased (0.374499 --> 0.374465).  Saving model ...
Validation loss decreased (0.374465 --> 0.374431).  Saving model ...
Validation loss decreased (0.374431 --> 0.374397).  Saving model ...
Validation loss decreased (0.374397 --> 0.374364).  Saving model ...
Validation loss decreased (0.374364 --> 0.374330).  Saving model ...
Validation loss decreased (0.374330 --> 0.374296).  Saving model ...
Validation loss decreased (0.374296 --> 0.374262).  Saving model ...
Validation loss decreased (0.374262 --> 0.374228).  Saving model ...
Validation loss decreased (0.374228 --> 0.374194).  Saving model ...
Validation loss decreased (0.374194 --> 0.374161).  Saving model ...
Validation loss decreased (0.374161 --> 0.374127).  Saving model ...
Validation loss decreased (0.374127 --> 0.374093).  Saving model ...
Validation loss decreased (0.374093 --> 0.374059).  Saving model ...
Validation loss decreased (0.374059 --> 0.374026).  Saving model ...
Validation loss decreased (0.374026 --> 0.373992).  Saving model ...
Validation loss decreased (0.373992 --> 0.373958).  Saving model ...
Validation loss decreased (0.373958 --> 0.373925).  Saving model ...
Validation loss decreased (0.373925 --> 0.373891).  Saving model ...
Validation loss decreased (0.373891 --> 0.373857).  Saving model ...
Validation loss decreased (0.373857 --> 0.373823).  Saving model ...
Validation loss decreased (0.373823 --> 0.373790).  Saving model ...
Validation loss decreased (0.373790 --> 0.373756).  Saving model ...
Validation loss decreased (0.373756 --> 0.373723).  Saving model ...
Validation loss decreased (0.373723 --> 0.373689).  Saving model ...
Validation loss decreased (0.373689 --> 0.373655).  Saving model ...
Validation loss decreased (0.373655 --> 0.373622).  Saving model ...
Validation loss decreased (0.373622 --> 0.373588).  Saving model ...
Validation loss decreased (0.373588 --> 0.373555).  Saving model ...
Validation loss decreased (0.373555 --> 0.373521).  Saving model ...
Validation loss decreased (0.373521 --> 0.373488).  Saving model ...
Validation loss decreased (0.373488 --> 0.373454).  Saving model ...
Validation loss decreased (0.373454 --> 0.373421).  Saving model ...
Validation loss decreased (0.373421 --> 0.373387).  Saving model ...
Validation loss decreased (0.373387 --> 0.373354).  Saving model ...
Validation loss decreased (0.373354 --> 0.373320).  Saving model ...
Validation loss decreased (0.373320 --> 0.373287).  Saving model ...
Validation loss decreased (0.373287 --> 0.373253).  Saving model ...
Validation loss decreased (0.373253 --> 0.373220).  Saving model ...
Validation loss decreased (0.373220 --> 0.373187).  Saving model ...
Validation loss decreased (0.373187 --> 0.373153).  Saving model ...
Validation loss decreased (0.373153 --> 0.373120).  Saving model ...
Validation loss decreased (0.373120 --> 0.373087).  Saving model ...
Validation loss decreased (0.373087 --> 0.373053).  Saving model ...
Validation loss decreased (0.373053 --> 0.373020).  Saving model ...
Validation loss decreased (0.373020 --> 0.372986).  Saving model ...
Validation loss decreased (0.372986 --> 0.372953).  Saving model ...
Validation loss decreased (0.372953 --> 0.372920).  Saving model ...
Validation loss decreased (0.372920 --> 0.372887).  Saving model ...
Validation loss decreased (0.372887 --> 0.372853).  Saving model ...
Validation loss decreased (0.372853 --> 0.372820).  Saving model ...
Validation loss decreased (0.372820 --> 0.372787).  Saving model ...
Validation loss decreased (0.372787 --> 0.372753).  Saving model ...
Validation loss decreased (0.372753 --> 0.372720).  Saving model ...
epoch 4401, loss 0.3727, train acc 83.73%, f1 0.7595, precision 0.7853, recall 0.7353, auc 0.8137
Validation loss decreased (0.372720 --> 0.372687).  Saving model ...
Validation loss decreased (0.372687 --> 0.372654).  Saving model ...
Validation loss decreased (0.372654 --> 0.372620).  Saving model ...
Validation loss decreased (0.372620 --> 0.372587).  Saving model ...
Validation loss decreased (0.372587 --> 0.372554).  Saving model ...
Validation loss decreased (0.372554 --> 0.372521).  Saving model ...
Validation loss decreased (0.372521 --> 0.372488).  Saving model ...
Validation loss decreased (0.372488 --> 0.372455).  Saving model ...
Validation loss decreased (0.372455 --> 0.372421).  Saving model ...
Validation loss decreased (0.372421 --> 0.372388).  Saving model ...
Validation loss decreased (0.372388 --> 0.372355).  Saving model ...
Validation loss decreased (0.372355 --> 0.372322).  Saving model ...
Validation loss decreased (0.372322 --> 0.372289).  Saving model ...
Validation loss decreased (0.372289 --> 0.372256).  Saving model ...
Validation loss decreased (0.372256 --> 0.372223).  Saving model ...
Validation loss decreased (0.372223 --> 0.372190).  Saving model ...
Validation loss decreased (0.372190 --> 0.372156).  Saving model ...
Validation loss decreased (0.372156 --> 0.372123).  Saving model ...
Validation loss decreased (0.372123 --> 0.372090).  Saving model ...
Validation loss decreased (0.372090 --> 0.372057).  Saving model ...
Validation loss decreased (0.372057 --> 0.372024).  Saving model ...
Validation loss decreased (0.372024 --> 0.371991).  Saving model ...
Validation loss decreased (0.371991 --> 0.371958).  Saving model ...
Validation loss decreased (0.371958 --> 0.371925).  Saving model ...
Validation loss decreased (0.371925 --> 0.371892).  Saving model ...
Validation loss decreased (0.371892 --> 0.371859).  Saving model ...
Validation loss decreased (0.371859 --> 0.371826).  Saving model ...
Validation loss decreased (0.371826 --> 0.371793).  Saving model ...
Validation loss decreased (0.371793 --> 0.371760).  Saving model ...
Validation loss decreased (0.371760 --> 0.371727).  Saving model ...
Validation loss decreased (0.371727 --> 0.371694).  Saving model ...
Validation loss decreased (0.371694 --> 0.371661).  Saving model ...
Validation loss decreased (0.371661 --> 0.371628).  Saving model ...
Validation loss decreased (0.371628 --> 0.371596).  Saving model ...
Validation loss decreased (0.371596 --> 0.371563).  Saving model ...
Validation loss decreased (0.371563 --> 0.371530).  Saving model ...
Validation loss decreased (0.371530 --> 0.371497).  Saving model ...
Validation loss decreased (0.371497 --> 0.371464).  Saving model ...
Validation loss decreased (0.371464 --> 0.371431).  Saving model ...
Validation loss decreased (0.371431 --> 0.371398).  Saving model ...
Validation loss decreased (0.371398 --> 0.371365).  Saving model ...
Validation loss decreased (0.371365 --> 0.371332).  Saving model ...
Validation loss decreased (0.371332 --> 0.371300).  Saving model ...
Validation loss decreased (0.371300 --> 0.371267).  Saving model ...
Validation loss decreased (0.371267 --> 0.371234).  Saving model ...
Validation loss decreased (0.371234 --> 0.371201).  Saving model ...
Validation loss decreased (0.371201 --> 0.371168).  Saving model ...
Validation loss decreased (0.371168 --> 0.371135).  Saving model ...
Validation loss decreased (0.371135 --> 0.371103).  Saving model ...
Validation loss decreased (0.371103 --> 0.371070).  Saving model ...
Validation loss decreased (0.371070 --> 0.371037).  Saving model ...
Validation loss decreased (0.371037 --> 0.371004).  Saving model ...
Validation loss decreased (0.371004 --> 0.370971).  Saving model ...
Validation loss decreased (0.370971 --> 0.370939).  Saving model ...
Validation loss decreased (0.370939 --> 0.370906).  Saving model ...
Validation loss decreased (0.370906 --> 0.370873).  Saving model ...
Validation loss decreased (0.370873 --> 0.370840).  Saving model ...
Validation loss decreased (0.370840 --> 0.370808).  Saving model ...
Validation loss decreased (0.370808 --> 0.370775).  Saving model ...
Validation loss decreased (0.370775 --> 0.370742).  Saving model ...
Validation loss decreased (0.370742 --> 0.370709).  Saving model ...
Validation loss decreased (0.370709 --> 0.370677).  Saving model ...
Validation loss decreased (0.370677 --> 0.370644).  Saving model ...
Validation loss decreased (0.370644 --> 0.370611).  Saving model ...
Validation loss decreased (0.370611 --> 0.370579).  Saving model ...
Validation loss decreased (0.370579 --> 0.370546).  Saving model ...
Validation loss decreased (0.370546 --> 0.370513).  Saving model ...
Validation loss decreased (0.370513 --> 0.370481).  Saving model ...
Validation loss decreased (0.370481 --> 0.370448).  Saving model ...
Validation loss decreased (0.370448 --> 0.370415).  Saving model ...
Validation loss decreased (0.370415 --> 0.370383).  Saving model ...
Validation loss decreased (0.370383 --> 0.370350).  Saving model ...
Validation loss decreased (0.370350 --> 0.370317).  Saving model ...
Validation loss decreased (0.370317 --> 0.370285).  Saving model ...
Validation loss decreased (0.370285 --> 0.370252).  Saving model ...
Validation loss decreased (0.370252 --> 0.370219).  Saving model ...
Validation loss decreased (0.370219 --> 0.370187).  Saving model ...
Validation loss decreased (0.370187 --> 0.370154).  Saving model ...
Validation loss decreased (0.370154 --> 0.370122).  Saving model ...
Validation loss decreased (0.370122 --> 0.370089).  Saving model ...
Validation loss decreased (0.370089 --> 0.370056).  Saving model ...
Validation loss decreased (0.370056 --> 0.370024).  Saving model ...
Validation loss decreased (0.370024 --> 0.369991).  Saving model ...
Validation loss decreased (0.369991 --> 0.369959).  Saving model ...
Validation loss decreased (0.369959 --> 0.369926).  Saving model ...
Validation loss decreased (0.369926 --> 0.369894).  Saving model ...
Validation loss decreased (0.369894 --> 0.369861).  Saving model ...
Validation loss decreased (0.369861 --> 0.369829).  Saving model ...
Validation loss decreased (0.369829 --> 0.369796).  Saving model ...
Validation loss decreased (0.369796 --> 0.369764).  Saving model ...
Validation loss decreased (0.369764 --> 0.369731).  Saving model ...
Validation loss decreased (0.369731 --> 0.369698).  Saving model ...
Validation loss decreased (0.369698 --> 0.369666).  Saving model ...
Validation loss decreased (0.369666 --> 0.369633).  Saving model ...
Validation loss decreased (0.369633 --> 0.369601).  Saving model ...
Validation loss decreased (0.369601 --> 0.369568).  Saving model ...
Validation loss decreased (0.369568 --> 0.369536).  Saving model ...
Validation loss decreased (0.369536 --> 0.369503).  Saving model ...
Validation loss decreased (0.369503 --> 0.369471).  Saving model ...
Validation loss decreased (0.369471 --> 0.369439).  Saving model ...
epoch 4501, loss 0.3694, train acc 83.90%, f1 0.7602, precision 0.7926, recall 0.7304, auc 0.8139
Validation loss decreased (0.369439 --> 0.369406).  Saving model ...
Validation loss decreased (0.369406 --> 0.369374).  Saving model ...
Validation loss decreased (0.369374 --> 0.369341).  Saving model ...
Validation loss decreased (0.369341 --> 0.369309).  Saving model ...
Validation loss decreased (0.369309 --> 0.369276).  Saving model ...
Validation loss decreased (0.369276 --> 0.369244).  Saving model ...
Validation loss decreased (0.369244 --> 0.369211).  Saving model ...
Validation loss decreased (0.369211 --> 0.369179).  Saving model ...
Validation loss decreased (0.369179 --> 0.369147).  Saving model ...
Validation loss decreased (0.369147 --> 0.369114).  Saving model ...
Validation loss decreased (0.369114 --> 0.369082).  Saving model ...
Validation loss decreased (0.369082 --> 0.369049).  Saving model ...
Validation loss decreased (0.369049 --> 0.369017).  Saving model ...
Validation loss decreased (0.369017 --> 0.368985).  Saving model ...
Validation loss decreased (0.368985 --> 0.368952).  Saving model ...
Validation loss decreased (0.368952 --> 0.368920).  Saving model ...
Validation loss decreased (0.368920 --> 0.368887).  Saving model ...
Validation loss decreased (0.368887 --> 0.368855).  Saving model ...
Validation loss decreased (0.368855 --> 0.368823).  Saving model ...
Validation loss decreased (0.368823 --> 0.368790).  Saving model ...
Validation loss decreased (0.368790 --> 0.368758).  Saving model ...
Validation loss decreased (0.368758 --> 0.368726).  Saving model ...
Validation loss decreased (0.368726 --> 0.368693).  Saving model ...
Validation loss decreased (0.368693 --> 0.368661).  Saving model ...
Validation loss decreased (0.368661 --> 0.368629).  Saving model ...
Validation loss decreased (0.368629 --> 0.368596).  Saving model ...
Validation loss decreased (0.368596 --> 0.368564).  Saving model ...
Validation loss decreased (0.368564 --> 0.368532).  Saving model ...
Validation loss decreased (0.368532 --> 0.368499).  Saving model ...
Validation loss decreased (0.368499 --> 0.368467).  Saving model ...
Validation loss decreased (0.368467 --> 0.368435).  Saving model ...
Validation loss decreased (0.368435 --> 0.368403).  Saving model ...
Validation loss decreased (0.368403 --> 0.368370).  Saving model ...
Validation loss decreased (0.368370 --> 0.368338).  Saving model ...
Validation loss decreased (0.368338 --> 0.368306).  Saving model ...
Validation loss decreased (0.368306 --> 0.368273).  Saving model ...
Validation loss decreased (0.368273 --> 0.368241).  Saving model ...
Validation loss decreased (0.368241 --> 0.368209).  Saving model ...
Validation loss decreased (0.368209 --> 0.368177).  Saving model ...
Validation loss decreased (0.368177 --> 0.368144).  Saving model ...
Validation loss decreased (0.368144 --> 0.368112).  Saving model ...
Validation loss decreased (0.368112 --> 0.368080).  Saving model ...
Validation loss decreased (0.368080 --> 0.368048).  Saving model ...
Validation loss decreased (0.368048 --> 0.368015).  Saving model ...
Validation loss decreased (0.368015 --> 0.367983).  Saving model ...
Validation loss decreased (0.367983 --> 0.367951).  Saving model ...
Validation loss decreased (0.367951 --> 0.367919).  Saving model ...
Validation loss decreased (0.367919 --> 0.367887).  Saving model ...
Validation loss decreased (0.367887 --> 0.367854).  Saving model ...
Validation loss decreased (0.367854 --> 0.367822).  Saving model ...
Validation loss decreased (0.367822 --> 0.367790).  Saving model ...
Validation loss decreased (0.367790 --> 0.367758).  Saving model ...
Validation loss decreased (0.367758 --> 0.367726).  Saving model ...
Validation loss decreased (0.367726 --> 0.367693).  Saving model ...
Validation loss decreased (0.367693 --> 0.367661).  Saving model ...
Validation loss decreased (0.367661 --> 0.367629).  Saving model ...
Validation loss decreased (0.367629 --> 0.367597).  Saving model ...
Validation loss decreased (0.367597 --> 0.367565).  Saving model ...
Validation loss decreased (0.367565 --> 0.367533).  Saving model ...
Validation loss decreased (0.367533 --> 0.367501).  Saving model ...
Validation loss decreased (0.367501 --> 0.367468).  Saving model ...
Validation loss decreased (0.367468 --> 0.367436).  Saving model ...
Validation loss decreased (0.367436 --> 0.367404).  Saving model ...
Validation loss decreased (0.367404 --> 0.367372).  Saving model ...
Validation loss decreased (0.367372 --> 0.367340).  Saving model ...
Validation loss decreased (0.367340 --> 0.367308).  Saving model ...
Validation loss decreased (0.367308 --> 0.367276).  Saving model ...
Validation loss decreased (0.367276 --> 0.367243).  Saving model ...
Validation loss decreased (0.367243 --> 0.367211).  Saving model ...
Validation loss decreased (0.367211 --> 0.367179).  Saving model ...
Validation loss decreased (0.367179 --> 0.367147).  Saving model ...
Validation loss decreased (0.367147 --> 0.367115).  Saving model ...
Validation loss decreased (0.367115 --> 0.367083).  Saving model ...
Validation loss decreased (0.367083 --> 0.367051).  Saving model ...
Validation loss decreased (0.367051 --> 0.367019).  Saving model ...
Validation loss decreased (0.367019 --> 0.366987).  Saving model ...
Validation loss decreased (0.366987 --> 0.366955).  Saving model ...
Validation loss decreased (0.366955 --> 0.366923).  Saving model ...
Validation loss decreased (0.366923 --> 0.366890).  Saving model ...
Validation loss decreased (0.366890 --> 0.366858).  Saving model ...
Validation loss decreased (0.366858 --> 0.366826).  Saving model ...
Validation loss decreased (0.366826 --> 0.366794).  Saving model ...
Validation loss decreased (0.366794 --> 0.366762).  Saving model ...
Validation loss decreased (0.366762 --> 0.366730).  Saving model ...
Validation loss decreased (0.366730 --> 0.366698).  Saving model ...
Validation loss decreased (0.366698 --> 0.366666).  Saving model ...
Validation loss decreased (0.366666 --> 0.366634).  Saving model ...
Validation loss decreased (0.366634 --> 0.366602).  Saving model ...
Validation loss decreased (0.366602 --> 0.366570).  Saving model ...
Validation loss decreased (0.366570 --> 0.366538).  Saving model ...
Validation loss decreased (0.366538 --> 0.366506).  Saving model ...
Validation loss decreased (0.366506 --> 0.366474).  Saving model ...
Validation loss decreased (0.366474 --> 0.366442).  Saving model ...
Validation loss decreased (0.366442 --> 0.366410).  Saving model ...
Validation loss decreased (0.366410 --> 0.366378).  Saving model ...
Validation loss decreased (0.366378 --> 0.366346).  Saving model ...
Validation loss decreased (0.366346 --> 0.366314).  Saving model ...
Validation loss decreased (0.366314 --> 0.366282).  Saving model ...
Validation loss decreased (0.366282 --> 0.366250).  Saving model ...
Validation loss decreased (0.366250 --> 0.366218).  Saving model ...
epoch 4601, loss 0.3662, train acc 84.59%, f1 0.7716, precision 0.8000, recall 0.7451, auc 0.8225
Validation loss decreased (0.366218 --> 0.366185).  Saving model ...
Validation loss decreased (0.366185 --> 0.366153).  Saving model ...
Validation loss decreased (0.366153 --> 0.366121).  Saving model ...
Validation loss decreased (0.366121 --> 0.366089).  Saving model ...
Validation loss decreased (0.366089 --> 0.366057).  Saving model ...
Validation loss decreased (0.366057 --> 0.366025).  Saving model ...
Validation loss decreased (0.366025 --> 0.365993).  Saving model ...
Validation loss decreased (0.365993 --> 0.365961).  Saving model ...
Validation loss decreased (0.365961 --> 0.365929).  Saving model ...
Validation loss decreased (0.365929 --> 0.365897).  Saving model ...
Validation loss decreased (0.365897 --> 0.365865).  Saving model ...
Validation loss decreased (0.365865 --> 0.365833).  Saving model ...
Validation loss decreased (0.365833 --> 0.365801).  Saving model ...
Validation loss decreased (0.365801 --> 0.365769).  Saving model ...
Validation loss decreased (0.365769 --> 0.365737).  Saving model ...
Validation loss decreased (0.365737 --> 0.365705).  Saving model ...
Validation loss decreased (0.365705 --> 0.365673).  Saving model ...
Validation loss decreased (0.365673 --> 0.365641).  Saving model ...
Validation loss decreased (0.365641 --> 0.365609).  Saving model ...
Validation loss decreased (0.365609 --> 0.365577).  Saving model ...
Validation loss decreased (0.365577 --> 0.365545).  Saving model ...
Validation loss decreased (0.365545 --> 0.365513).  Saving model ...
Validation loss decreased (0.365513 --> 0.365481).  Saving model ...
Validation loss decreased (0.365481 --> 0.365449).  Saving model ...
Validation loss decreased (0.365449 --> 0.365417).  Saving model ...
Validation loss decreased (0.365417 --> 0.365385).  Saving model ...
Validation loss decreased (0.365385 --> 0.365353).  Saving model ...
Validation loss decreased (0.365353 --> 0.365321).  Saving model ...
Validation loss decreased (0.365321 --> 0.365289).  Saving model ...
Validation loss decreased (0.365289 --> 0.365257).  Saving model ...
Validation loss decreased (0.365257 --> 0.365224).  Saving model ...
Validation loss decreased (0.365224 --> 0.365192).  Saving model ...
Validation loss decreased (0.365192 --> 0.365160).  Saving model ...
Validation loss decreased (0.365160 --> 0.365128).  Saving model ...
Validation loss decreased (0.365128 --> 0.365096).  Saving model ...
Validation loss decreased (0.365096 --> 0.365064).  Saving model ...
Validation loss decreased (0.365064 --> 0.365032).  Saving model ...
Validation loss decreased (0.365032 --> 0.365000).  Saving model ...
Validation loss decreased (0.365000 --> 0.364968).  Saving model ...
Validation loss decreased (0.364968 --> 0.364936).  Saving model ...
Validation loss decreased (0.364936 --> 0.364904).  Saving model ...
Validation loss decreased (0.364904 --> 0.364871).  Saving model ...
Validation loss decreased (0.364871 --> 0.364839).  Saving model ...
Validation loss decreased (0.364839 --> 0.364807).  Saving model ...
Validation loss decreased (0.364807 --> 0.364775).  Saving model ...
Validation loss decreased (0.364775 --> 0.364743).  Saving model ...
Validation loss decreased (0.364743 --> 0.364711).  Saving model ...
Validation loss decreased (0.364711 --> 0.364679).  Saving model ...
Validation loss decreased (0.364679 --> 0.364646).  Saving model ...
Validation loss decreased (0.364646 --> 0.364614).  Saving model ...
Validation loss decreased (0.364614 --> 0.364582).  Saving model ...
Validation loss decreased (0.364582 --> 0.364550).  Saving model ...
Validation loss decreased (0.364550 --> 0.364518).  Saving model ...
Validation loss decreased (0.364518 --> 0.364485).  Saving model ...
Validation loss decreased (0.364485 --> 0.364453).  Saving model ...
Validation loss decreased (0.364453 --> 0.364421).  Saving model ...
Validation loss decreased (0.364421 --> 0.364389).  Saving model ...
Validation loss decreased (0.364389 --> 0.364356).  Saving model ...
Validation loss decreased (0.364356 --> 0.364324).  Saving model ...
Validation loss decreased (0.364324 --> 0.364292).  Saving model ...
Validation loss decreased (0.364292 --> 0.364260).  Saving model ...
Validation loss decreased (0.364260 --> 0.364227).  Saving model ...
Validation loss decreased (0.364227 --> 0.364195).  Saving model ...
Validation loss decreased (0.364195 --> 0.364163).  Saving model ...
Validation loss decreased (0.364163 --> 0.364130).  Saving model ...
Validation loss decreased (0.364130 --> 0.364098).  Saving model ...
Validation loss decreased (0.364098 --> 0.364065).  Saving model ...
Validation loss decreased (0.364065 --> 0.364033).  Saving model ...
Validation loss decreased (0.364033 --> 0.364001).  Saving model ...
Validation loss decreased (0.364001 --> 0.363968).  Saving model ...
Validation loss decreased (0.363968 --> 0.363936).  Saving model ...
Validation loss decreased (0.363936 --> 0.363903).  Saving model ...
Validation loss decreased (0.363903 --> 0.363871).  Saving model ...
Validation loss decreased (0.363871 --> 0.363838).  Saving model ...
Validation loss decreased (0.363838 --> 0.363806).  Saving model ...
Validation loss decreased (0.363806 --> 0.363773).  Saving model ...
Validation loss decreased (0.363773 --> 0.363741).  Saving model ...
Validation loss decreased (0.363741 --> 0.363708).  Saving model ...
Validation loss decreased (0.363708 --> 0.363676).  Saving model ...
Validation loss decreased (0.363676 --> 0.363643).  Saving model ...
Validation loss decreased (0.363643 --> 0.363610).  Saving model ...
Validation loss decreased (0.363610 --> 0.363578).  Saving model ...
Validation loss decreased (0.363578 --> 0.363545).  Saving model ...
Validation loss decreased (0.363545 --> 0.363512).  Saving model ...
Validation loss decreased (0.363512 --> 0.363480).  Saving model ...
Validation loss decreased (0.363480 --> 0.363447).  Saving model ...
Validation loss decreased (0.363447 --> 0.363414).  Saving model ...
Validation loss decreased (0.363414 --> 0.363382).  Saving model ...
Validation loss decreased (0.363382 --> 0.363349).  Saving model ...
Validation loss decreased (0.363349 --> 0.363316).  Saving model ...
Validation loss decreased (0.363316 --> 0.363283).  Saving model ...
Validation loss decreased (0.363283 --> 0.363250).  Saving model ...
Validation loss decreased (0.363250 --> 0.363217).  Saving model ...
Validation loss decreased (0.363217 --> 0.363184).  Saving model ...
Validation loss decreased (0.363184 --> 0.363151).  Saving model ...
Validation loss decreased (0.363151 --> 0.363118).  Saving model ...
Validation loss decreased (0.363118 --> 0.363086).  Saving model ...
Validation loss decreased (0.363086 --> 0.363052).  Saving model ...
Validation loss decreased (0.363052 --> 0.363019).  Saving model ...
Validation loss decreased (0.363019 --> 0.362986).  Saving model ...
epoch 4701, loss 0.3630, train acc 84.42%, f1 0.7696, precision 0.7958, recall 0.7451, auc 0.8212
Validation loss decreased (0.362986 --> 0.362953).  Saving model ...
Validation loss decreased (0.362953 --> 0.362920).  Saving model ...
Validation loss decreased (0.362920 --> 0.362887).  Saving model ...
Validation loss decreased (0.362887 --> 0.362854).  Saving model ...
Validation loss decreased (0.362854 --> 0.362821).  Saving model ...
Validation loss decreased (0.362821 --> 0.362787).  Saving model ...
Validation loss decreased (0.362787 --> 0.362754).  Saving model ...
Validation loss decreased (0.362754 --> 0.362721).  Saving model ...
Validation loss decreased (0.362721 --> 0.362687).  Saving model ...
Validation loss decreased (0.362687 --> 0.362654).  Saving model ...
Validation loss decreased (0.362654 --> 0.362621).  Saving model ...
Validation loss decreased (0.362621 --> 0.362587).  Saving model ...
Validation loss decreased (0.362587 --> 0.362554).  Saving model ...
Validation loss decreased (0.362554 --> 0.362520).  Saving model ...
Validation loss decreased (0.362520 --> 0.362487).  Saving model ...
Validation loss decreased (0.362487 --> 0.362453).  Saving model ...
Validation loss decreased (0.362453 --> 0.362419).  Saving model ...
Validation loss decreased (0.362419 --> 0.362386).  Saving model ...
Validation loss decreased (0.362386 --> 0.362352).  Saving model ...
Validation loss decreased (0.362352 --> 0.362318).  Saving model ...
Validation loss decreased (0.362318 --> 0.362284).  Saving model ...
Validation loss decreased (0.362284 --> 0.362251).  Saving model ...
Validation loss decreased (0.362251 --> 0.362217).  Saving model ...
Validation loss decreased (0.362217 --> 0.362183).  Saving model ...
Validation loss decreased (0.362183 --> 0.362149).  Saving model ...
Validation loss decreased (0.362149 --> 0.362115).  Saving model ...
Validation loss decreased (0.362115 --> 0.362081).  Saving model ...
Validation loss decreased (0.362081 --> 0.362047).  Saving model ...
Validation loss decreased (0.362047 --> 0.362013).  Saving model ...
Validation loss decreased (0.362013 --> 0.361979).  Saving model ...
Validation loss decreased (0.361979 --> 0.361945).  Saving model ...
Validation loss decreased (0.361945 --> 0.361911).  Saving model ...
Validation loss decreased (0.361911 --> 0.361876).  Saving model ...
Validation loss decreased (0.361876 --> 0.361842).  Saving model ...
Validation loss decreased (0.361842 --> 0.361808).  Saving model ...
Validation loss decreased (0.361808 --> 0.361773).  Saving model ...
Validation loss decreased (0.361773 --> 0.361739).  Saving model ...
Validation loss decreased (0.361739 --> 0.361705).  Saving model ...
Validation loss decreased (0.361705 --> 0.361670).  Saving model ...
Validation loss decreased (0.361670 --> 0.361636).  Saving model ...
Validation loss decreased (0.361636 --> 0.361601).  Saving model ...
Validation loss decreased (0.361601 --> 0.361566).  Saving model ...
Validation loss decreased (0.361566 --> 0.361532).  Saving model ...
Validation loss decreased (0.361532 --> 0.361497).  Saving model ...
Validation loss decreased (0.361497 --> 0.361462).  Saving model ...
Validation loss decreased (0.361462 --> 0.361428).  Saving model ...
Validation loss decreased (0.361428 --> 0.361393).  Saving model ...
Validation loss decreased (0.361393 --> 0.361358).  Saving model ...
Validation loss decreased (0.361358 --> 0.361323).  Saving model ...
Validation loss decreased (0.361323 --> 0.361288).  Saving model ...
Validation loss decreased (0.361288 --> 0.361253).  Saving model ...
Validation loss decreased (0.361253 --> 0.361218).  Saving model ...
Validation loss decreased (0.361218 --> 0.361183).  Saving model ...
Validation loss decreased (0.361183 --> 0.361148).  Saving model ...
Validation loss decreased (0.361148 --> 0.361113).  Saving model ...
Validation loss decreased (0.361113 --> 0.361078).  Saving model ...
Validation loss decreased (0.361078 --> 0.361043).  Saving model ...
Validation loss decreased (0.361043 --> 0.361007).  Saving model ...
Validation loss decreased (0.361007 --> 0.360972).  Saving model ...
Validation loss decreased (0.360972 --> 0.360937).  Saving model ...
Validation loss decreased (0.360937 --> 0.360902).  Saving model ...
Validation loss decreased (0.360902 --> 0.360866).  Saving model ...
Validation loss decreased (0.360866 --> 0.360831).  Saving model ...
Validation loss decreased (0.360831 --> 0.360795).  Saving model ...
Validation loss decreased (0.360795 --> 0.360760).  Saving model ...
Validation loss decreased (0.360760 --> 0.360725).  Saving model ...
Validation loss decreased (0.360725 --> 0.360689).  Saving model ...
Validation loss decreased (0.360689 --> 0.360653).  Saving model ...
Validation loss decreased (0.360653 --> 0.360618).  Saving model ...
Validation loss decreased (0.360618 --> 0.360582).  Saving model ...
Validation loss decreased (0.360582 --> 0.360547).  Saving model ...
Validation loss decreased (0.360547 --> 0.360511).  Saving model ...
Validation loss decreased (0.360511 --> 0.360475).  Saving model ...
Validation loss decreased (0.360475 --> 0.360440).  Saving model ...
Validation loss decreased (0.360440 --> 0.360404).  Saving model ...
Validation loss decreased (0.360404 --> 0.360368).  Saving model ...
Validation loss decreased (0.360368 --> 0.360332).  Saving model ...
Validation loss decreased (0.360332 --> 0.360297).  Saving model ...
Validation loss decreased (0.360297 --> 0.360261).  Saving model ...
Validation loss decreased (0.360261 --> 0.360225).  Saving model ...
Validation loss decreased (0.360225 --> 0.360189).  Saving model ...
Validation loss decreased (0.360189 --> 0.360153).  Saving model ...
Validation loss decreased (0.360153 --> 0.360117).  Saving model ...
Validation loss decreased (0.360117 --> 0.360082).  Saving model ...
Validation loss decreased (0.360082 --> 0.360046).  Saving model ...
Validation loss decreased (0.360046 --> 0.360010).  Saving model ...
Validation loss decreased (0.360010 --> 0.359974).  Saving model ...
Validation loss decreased (0.359974 --> 0.359938).  Saving model ...
Validation loss decreased (0.359938 --> 0.359902).  Saving model ...
Validation loss decreased (0.359902 --> 0.359866).  Saving model ...
Validation loss decreased (0.359866 --> 0.359830).  Saving model ...
Validation loss decreased (0.359830 --> 0.359794).  Saving model ...
Validation loss decreased (0.359794 --> 0.359758).  Saving model ...
Validation loss decreased (0.359758 --> 0.359722).  Saving model ...
Validation loss decreased (0.359722 --> 0.359687).  Saving model ...
Validation loss decreased (0.359687 --> 0.359651).  Saving model ...
Validation loss decreased (0.359651 --> 0.359615).  Saving model ...
Validation loss decreased (0.359615 --> 0.359579).  Saving model ...
Validation loss decreased (0.359579 --> 0.359543).  Saving model ...
Validation loss decreased (0.359543 --> 0.359507).  Saving model ...
epoch 4801, loss 0.3595, train acc 84.42%, f1 0.7696, precision 0.7958, recall 0.7451, auc 0.8212
Validation loss decreased (0.359507 --> 0.359471).  Saving model ...
Validation loss decreased (0.359471 --> 0.359435).  Saving model ...
Validation loss decreased (0.359435 --> 0.359399).  Saving model ...
Validation loss decreased (0.359399 --> 0.359363).  Saving model ...
Validation loss decreased (0.359363 --> 0.359327).  Saving model ...
Validation loss decreased (0.359327 --> 0.359291).  Saving model ...
Validation loss decreased (0.359291 --> 0.359256).  Saving model ...
Validation loss decreased (0.359256 --> 0.359220).  Saving model ...
Validation loss decreased (0.359220 --> 0.359184).  Saving model ...
Validation loss decreased (0.359184 --> 0.359148).  Saving model ...
Validation loss decreased (0.359148 --> 0.359112).  Saving model ...
Validation loss decreased (0.359112 --> 0.359076).  Saving model ...
Validation loss decreased (0.359076 --> 0.359041).  Saving model ...
Validation loss decreased (0.359041 --> 0.359005).  Saving model ...
Validation loss decreased (0.359005 --> 0.358969).  Saving model ...
Validation loss decreased (0.358969 --> 0.358934).  Saving model ...
Validation loss decreased (0.358934 --> 0.358898).  Saving model ...
Validation loss decreased (0.358898 --> 0.358862).  Saving model ...
Validation loss decreased (0.358862 --> 0.358826).  Saving model ...
Validation loss decreased (0.358826 --> 0.358791).  Saving model ...
Validation loss decreased (0.358791 --> 0.358755).  Saving model ...
Validation loss decreased (0.358755 --> 0.358720).  Saving model ...
Validation loss decreased (0.358720 --> 0.358684).  Saving model ...
Validation loss decreased (0.358684 --> 0.358649).  Saving model ...
Validation loss decreased (0.358649 --> 0.358613).  Saving model ...
Validation loss decreased (0.358613 --> 0.358578).  Saving model ...
Validation loss decreased (0.358578 --> 0.358542).  Saving model ...
Validation loss decreased (0.358542 --> 0.358507).  Saving model ...
Validation loss decreased (0.358507 --> 0.358471).  Saving model ...
Validation loss decreased (0.358471 --> 0.358436).  Saving model ...
Validation loss decreased (0.358436 --> 0.358400).  Saving model ...
Validation loss decreased (0.358400 --> 0.358365).  Saving model ...
Validation loss decreased (0.358365 --> 0.358330).  Saving model ...
Validation loss decreased (0.358330 --> 0.358294).  Saving model ...
Validation loss decreased (0.358294 --> 0.358259).  Saving model ...
Validation loss decreased (0.358259 --> 0.358224).  Saving model ...
Validation loss decreased (0.358224 --> 0.358189).  Saving model ...
Validation loss decreased (0.358189 --> 0.358154).  Saving model ...
Validation loss decreased (0.358154 --> 0.358119).  Saving model ...
Validation loss decreased (0.358119 --> 0.358083).  Saving model ...
Validation loss decreased (0.358083 --> 0.358048).  Saving model ...
Validation loss decreased (0.358048 --> 0.358013).  Saving model ...
Validation loss decreased (0.358013 --> 0.357978).  Saving model ...
Validation loss decreased (0.357978 --> 0.357943).  Saving model ...
Validation loss decreased (0.357943 --> 0.357908).  Saving model ...
Validation loss decreased (0.357908 --> 0.357873).  Saving model ...
Validation loss decreased (0.357873 --> 0.357838).  Saving model ...
Validation loss decreased (0.357838 --> 0.357804).  Saving model ...
Validation loss decreased (0.357804 --> 0.357769).  Saving model ...
Validation loss decreased (0.357769 --> 0.357734).  Saving model ...
Validation loss decreased (0.357734 --> 0.357699).  Saving model ...
Validation loss decreased (0.357699 --> 0.357664).  Saving model ...
Validation loss decreased (0.357664 --> 0.357630).  Saving model ...
Validation loss decreased (0.357630 --> 0.357595).  Saving model ...
Validation loss decreased (0.357595 --> 0.357560).  Saving model ...
Validation loss decreased (0.357560 --> 0.357526).  Saving model ...
Validation loss decreased (0.357526 --> 0.357491).  Saving model ...
Validation loss decreased (0.357491 --> 0.357456).  Saving model ...
Validation loss decreased (0.357456 --> 0.357422).  Saving model ...
Validation loss decreased (0.357422 --> 0.357387).  Saving model ...
Validation loss decreased (0.357387 --> 0.357353).  Saving model ...
Validation loss decreased (0.357353 --> 0.357318).  Saving model ...
Validation loss decreased (0.357318 --> 0.357284).  Saving model ...
Validation loss decreased (0.357284 --> 0.357250).  Saving model ...
Validation loss decreased (0.357250 --> 0.357215).  Saving model ...
Validation loss decreased (0.357215 --> 0.357181).  Saving model ...
Validation loss decreased (0.357181 --> 0.357147).  Saving model ...
Validation loss decreased (0.357147 --> 0.357112).  Saving model ...
Validation loss decreased (0.357112 --> 0.357078).  Saving model ...
Validation loss decreased (0.357078 --> 0.357044).  Saving model ...
Validation loss decreased (0.357044 --> 0.357010).  Saving model ...
Validation loss decreased (0.357010 --> 0.356975).  Saving model ...
Validation loss decreased (0.356975 --> 0.356941).  Saving model ...
Validation loss decreased (0.356941 --> 0.356907).  Saving model ...
Validation loss decreased (0.356907 --> 0.356873).  Saving model ...
Validation loss decreased (0.356873 --> 0.356839).  Saving model ...
Validation loss decreased (0.356839 --> 0.356805).  Saving model ...
Validation loss decreased (0.356805 --> 0.356771).  Saving model ...
Validation loss decreased (0.356771 --> 0.356737).  Saving model ...
Validation loss decreased (0.356737 --> 0.356703).  Saving model ...
Validation loss decreased (0.356703 --> 0.356669).  Saving model ...
Validation loss decreased (0.356669 --> 0.356635).  Saving model ...
Validation loss decreased (0.356635 --> 0.356601).  Saving model ...
Validation loss decreased (0.356601 --> 0.356567).  Saving model ...
Validation loss decreased (0.356567 --> 0.356534).  Saving model ...
Validation loss decreased (0.356534 --> 0.356500).  Saving model ...
Validation loss decreased (0.356500 --> 0.356466).  Saving model ...
Validation loss decreased (0.356466 --> 0.356432).  Saving model ...
Validation loss decreased (0.356432 --> 0.356398).  Saving model ...
Validation loss decreased (0.356398 --> 0.356365).  Saving model ...
Validation loss decreased (0.356365 --> 0.356331).  Saving model ...
Validation loss decreased (0.356331 --> 0.356297).  Saving model ...
Validation loss decreased (0.356297 --> 0.356264).  Saving model ...
Validation loss decreased (0.356264 --> 0.356230).  Saving model ...
Validation loss decreased (0.356230 --> 0.356196).  Saving model ...
Validation loss decreased (0.356196 --> 0.356163).  Saving model ...
Validation loss decreased (0.356163 --> 0.356129).  Saving model ...
Validation loss decreased (0.356129 --> 0.356096).  Saving model ...
Validation loss decreased (0.356096 --> 0.356062).  Saving model ...
Validation loss decreased (0.356062 --> 0.356029).  Saving model ...
epoch 4901, loss 0.3560, train acc 84.76%, f1 0.7747, precision 0.8010, recall 0.7500, auc 0.8250
Validation loss decreased (0.356029 --> 0.355995).  Saving model ...
Validation loss decreased (0.355995 --> 0.355962).  Saving model ...
Validation loss decreased (0.355962 --> 0.355929).  Saving model ...
Validation loss decreased (0.355929 --> 0.355895).  Saving model ...
Validation loss decreased (0.355895 --> 0.355862).  Saving model ...
Validation loss decreased (0.355862 --> 0.355828).  Saving model ...
Validation loss decreased (0.355828 --> 0.355795).  Saving model ...
Validation loss decreased (0.355795 --> 0.355762).  Saving model ...
Validation loss decreased (0.355762 --> 0.355728).  Saving model ...
Validation loss decreased (0.355728 --> 0.355695).  Saving model ...
Validation loss decreased (0.355695 --> 0.355662).  Saving model ...
Validation loss decreased (0.355662 --> 0.355629).  Saving model ...
Validation loss decreased (0.355629 --> 0.355595).  Saving model ...
Validation loss decreased (0.355595 --> 0.355562).  Saving model ...
Validation loss decreased (0.355562 --> 0.355529).  Saving model ...
Validation loss decreased (0.355529 --> 0.355496).  Saving model ...
Validation loss decreased (0.355496 --> 0.355463).  Saving model ...
Validation loss decreased (0.355463 --> 0.355430).  Saving model ...
Validation loss decreased (0.355430 --> 0.355397).  Saving model ...
Validation loss decreased (0.355397 --> 0.355364).  Saving model ...
Validation loss decreased (0.355364 --> 0.355330).  Saving model ...
Validation loss decreased (0.355330 --> 0.355297).  Saving model ...
Validation loss decreased (0.355297 --> 0.355264).  Saving model ...
Validation loss decreased (0.355264 --> 0.355231).  Saving model ...
Validation loss decreased (0.355231 --> 0.355198).  Saving model ...
Validation loss decreased (0.355198 --> 0.355166).  Saving model ...
Validation loss decreased (0.355166 --> 0.355133).  Saving model ...
Validation loss decreased (0.355133 --> 0.355100).  Saving model ...
Validation loss decreased (0.355100 --> 0.355067).  Saving model ...
Validation loss decreased (0.355067 --> 0.355034).  Saving model ...
Validation loss decreased (0.355034 --> 0.355001).  Saving model ...
Validation loss decreased (0.355001 --> 0.354968).  Saving model ...
Validation loss decreased (0.354968 --> 0.354935).  Saving model ...
Validation loss decreased (0.354935 --> 0.354902).  Saving model ...
Validation loss decreased (0.354902 --> 0.354870).  Saving model ...
Validation loss decreased (0.354870 --> 0.354837).  Saving model ...
Validation loss decreased (0.354837 --> 0.354804).  Saving model ...
Validation loss decreased (0.354804 --> 0.354771).  Saving model ...
Validation loss decreased (0.354771 --> 0.354739).  Saving model .../home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

Validation loss decreased (0.354739 --> 0.354706).  Saving model ...
Validation loss decreased (0.354706 --> 0.354673).  Saving model ...
Validation loss decreased (0.354673 --> 0.354640).  Saving model ...
Validation loss decreased (0.354640 --> 0.354608).  Saving model ...
Validation loss decreased (0.354608 --> 0.354575).  Saving model ...
Validation loss decreased (0.354575 --> 0.354542).  Saving model ...
Validation loss decreased (0.354542 --> 0.354510).  Saving model ...
Validation loss decreased (0.354510 --> 0.354477).  Saving model ...
Validation loss decreased (0.354477 --> 0.354445).  Saving model ...
Validation loss decreased (0.354445 --> 0.354412).  Saving model ...
Validation loss decreased (0.354412 --> 0.354380).  Saving model ...
Validation loss decreased (0.354380 --> 0.354347).  Saving model ...
Validation loss decreased (0.354347 --> 0.354314).  Saving model ...
Validation loss decreased (0.354314 --> 0.354282).  Saving model ...
Validation loss decreased (0.354282 --> 0.354249).  Saving model ...
Validation loss decreased (0.354249 --> 0.354217).  Saving model ...
Validation loss decreased (0.354217 --> 0.354184).  Saving model ...
Validation loss decreased (0.354184 --> 0.354152).  Saving model ...
Validation loss decreased (0.354152 --> 0.354120).  Saving model ...
Validation loss decreased (0.354120 --> 0.354087).  Saving model ...
Validation loss decreased (0.354087 --> 0.354055).  Saving model ...
Validation loss decreased (0.354055 --> 0.354022).  Saving model ...
Validation loss decreased (0.354022 --> 0.353990).  Saving model ...
Validation loss decreased (0.353990 --> 0.353958).  Saving model ...
Validation loss decreased (0.353958 --> 0.353925).  Saving model ...
Validation loss decreased (0.353925 --> 0.353893).  Saving model ...
Validation loss decreased (0.353893 --> 0.353861).  Saving model ...
Validation loss decreased (0.353861 --> 0.353828).  Saving model ...
Validation loss decreased (0.353828 --> 0.353796).  Saving model ...
Validation loss decreased (0.353796 --> 0.353764).  Saving model ...
Validation loss decreased (0.353764 --> 0.353732).  Saving model ...
Validation loss decreased (0.353732 --> 0.353699).  Saving model ...
Validation loss decreased (0.353699 --> 0.353667).  Saving model ...
Validation loss decreased (0.353667 --> 0.353635).  Saving model ...
Validation loss decreased (0.353635 --> 0.353603).  Saving model ...
Validation loss decreased (0.353603 --> 0.353571).  Saving model ...
Validation loss decreased (0.353571 --> 0.353538).  Saving model ...
Validation loss decreased (0.353538 --> 0.353506).  Saving model ...
Validation loss decreased (0.353506 --> 0.353474).  Saving model ...
Validation loss decreased (0.353474 --> 0.353442).  Saving model ...
Validation loss decreased (0.353442 --> 0.353410).  Saving model ...
Validation loss decreased (0.353410 --> 0.353378).  Saving model ...
Validation loss decreased (0.353378 --> 0.353346).  Saving model ...
Validation loss decreased (0.353346 --> 0.353314).  Saving model ...
Validation loss decreased (0.353314 --> 0.353282).  Saving model ...
Validation loss decreased (0.353282 --> 0.353250).  Saving model ...
Validation loss decreased (0.353250 --> 0.353218).  Saving model ...
Validation loss decreased (0.353218 --> 0.353186).  Saving model ...
Validation loss decreased (0.353186 --> 0.353154).  Saving model ...
Validation loss decreased (0.353154 --> 0.353122).  Saving model ...
Validation loss decreased (0.353122 --> 0.353090).  Saving model ...
Validation loss decreased (0.353090 --> 0.353058).  Saving model ...
Validation loss decreased (0.353058 --> 0.353026).  Saving model ...
Validation loss decreased (0.353026 --> 0.352994).  Saving model ...
Validation loss decreased (0.352994 --> 0.352962).  Saving model ...
Validation loss decreased (0.352962 --> 0.352930).  Saving model ...
Validation loss decreased (0.352930 --> 0.352899).  Saving model ...
Validation loss decreased (0.352899 --> 0.352867).  Saving model ...
Validation loss decreased (0.352867 --> 0.352835).  Saving model ...
Validation loss decreased (0.352835 --> 0.352803).  Saving model ...
Validation loss decreased (0.352803 --> 0.352771).  Saving model ...
/home/junda/.conda/envs/thenv/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=FutureWarning)
./test_pima/standlization_data/pima_std_train_3.csv
./test_pima/standlization_data/pima_std_test_3.csv
MLP_normal_True
normal_normal
./test_pima/model_MLP_normal_True/record_1/MLP_normal_True_3
./test_pima/result_MLP_normal_True_normal_normal/record_1/
----------------------



Traceback (most recent call last):
  File "./classifier_MLP/test.py", line 193, in <module>
    transform_method, ref_data_type, ref_num_type, ref_times, boundary_type = get_test_info(test_method)
  File "./classifier_MLP/test.py", line 137, in get_test_info
    return transform_method, ref_data_type, ref_num_type, ref_times, boundary_type
UnboundLocalError: local variable 'transform_method' referenced before assignment
